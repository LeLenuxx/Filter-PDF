 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
User Name: =  
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Date and Time: = 2025-04-09 
Job Number: = 249956184 
 
Documents (143) 
Client/Matter: -None- 
Search Terms: Ai Slop 
Search Type: NaturalAnd 
Content Type Narrowed by 
news Quellensprache: English  
 
1. Google has found a new role for the man who broke Google Search 
 
2. Vote Yes On Locking Artist's Voices In Contractual Seashells Like The Little Mermaid 
 
3. I'm running out of ways to explain how bad this is 
 
4. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
5. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
6. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
7. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
8. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
9. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
10. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
11. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 

 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
12. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
13. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
14. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
15. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
16. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
17. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
18. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
19. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
20. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
21. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
22. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
23. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
24. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
25. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
26. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
27. Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and 
Video Generation Superstudio Integrates State-of-the-Art Image and Video Models and 
Tools into a Creator-Friendly Interface. Kaiber Also Announces Fund... 
 
28. A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the 
Assets 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
29. Fans Can't Believe Broadcast Decision for College Football Game on Saturday 
 
30. AI aggrandizes misinformation on the internet, so see the peacock chicks! 
 
31. Marques Brownlee says 'we failed on the price' with Panels 
 
32. I'm Running Out of Ways to Explain How Bad This Is 
 
33. Can Facebook win back Gen Z? 
 
34. Here's Why 'Human Authored' Will Become the 'Artisanally Crafted' Pitch of the AI Age 
 
35. Right-Wingers Heartbroken by Picture of Little Girl Who Doesn't Exist 
 
36. It's Time to Stop Taking Sam Altman at His Word 
 
37. Worlds apart 
 
38. Silicon Valley has a plan to save humanity: Just flip on the nuclear reactors 
 
39. McNeal review – Robert Downey Jr shines in muddled AI-themed play 
 
40. The AR and VR headsets you'll actually wear 
 
41. 'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI 
art 
 
42. Is anyone out there? 
 
43. BBC Radio 4 - 2:30 PM GMT 
 
44. BBC Radio 4 - 08:00 AM GMT 
 
45. BBC Radio 4 - 2:00 PM GMT 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
46. BBC Radio 4 - 2:55 PM GMT 
 
47. Pick of the day 
 
48. PICK OF THE DAY 
 
49. Radio choice 
 
50. The Trump Posts You Probably Aren't Seeing 
 
51. Following AI Cheating Controversy, Pokémon Announces Winners Of Card Contest 
 
52. Wednesday 25 September 
 
53. Meet the Editor Who Turned Himself Into an AI News Anchor 
 
54. 'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook 
 
55. 'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook 
 
56. 'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook 
 
57. BBC Radio 4 - 4:50 PM GMT 
 
58. Trump is drowning in the misinformation swamp he helped create 
 
59. BBC London News - 5:45 PM GMT 
 
60. What I Learned When My AI Kermit Slop Went Viral 
 
61. University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List 
 
62. PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST 
 
63. Honor recognizes unique contributions to the field, including Glaze and Nightshade 
tools 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
64. Facebook's AI-Generated Spam Problem Is Worse Than You Realize 
 
65. 2:00PM Water Cooler 9/4/2024 
 
66. It's not just you. More weird spam is popping up on Facebook 
 
67. Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more views 
 
68. National Novel Writing Month's AI-neutral stance criticized by bestselling authors 
 
69. 'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images 
frenzy 
 
70. Bigger picture of Trump's weird AI images obsession The Republican party and its 
presidential nominee now have a tool that allows them to visualise the hypothetical 
realities they are peddling to their supporters, writes Mike Bedigan 
 
71. Inside Trump's weird new obsession with AI-generated images 
 
72. ‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images 
frenzy 
 
73. Inside Trump's weird new obsession with AI-generated images 
 
74. The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs 
 
75. The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism 
 
76. How did Donald Trump end up posting Taylor Swift deepfakes? 
 
77. A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is 
‘flooded with garbage’ 
 
78. Donald Trump, AI Artist 
 
79. The MAGA Aesthetic Is AI Slop 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
80. Why the Popular Software Company Procreate Is Swearing Off Generative AI 
 
81. Ripple CTO highlights AI controversy over dangerous Mushroom identification book 
 
82. In a word: This week's column: 'the ick' or a 'boop'? 
 
83. Why Does AI Art Look Like That? 
 
84. Twitter page gains thousands of followers for making fun of Facebook posts 
 
85. Generative AI's Slop Era 
 
86. FTAV’s further reading 
 
87. FTAV’s further reading 
 
88. ‘Hold on to your seats’: how much will AI affect the art of film-making? 
 
89. AI 's Real Hallucination Problem 
 
90. No One Can Believe What Comes Up When You Google Beethoven: 'I'm So Done' 
 
91. We want YOUR gossip! 
 
92. We want YOUR gossip! 
 
93. We want YOUR gossip! 
 
94. We want YOUR gossip! 
 
95. We want YOUR gossip! 
 
96. We want YOUR gossip! 
 
97. We want YOUR gossip! 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
98. We want YOUR gossip! 
 
99. We want YOUR gossip! 
 
100. We want YOUR gossip! 
 
101. We want YOUR gossip! 
 
102. We want YOUR gossip! 
 
103. The New Term 'Slop' Joins 'Spam' in Our Vocabulary 
 
104. Spam evolves with AI: What is "Slop"? 
 
105. Dead tech blog now publishing using AI with old bylines 
 
106. TUAW makes a sad return as an AI-powered stolen content farm 
 
107. Google Searches Prefer AI Spam to Real Content 
 
108. Thousands of Raptive creators push to hold AI companies accountable 
 
109. Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog 
Posts 
 
110. Letter writer declares ' Durango Decline' citing online classes, branding and merch 
 
111. After spam, meet slop, poor quality content generated by AI 
 
112. Why Sheehy's 'I have scored, Eileen' helps RTÉ News 
 
113. How technology has changed our daily lives 
 
114. The rise and risk of AI-generated slop 
 
115. Comment: 'We deserve more than reheated housing ideas and AI slop' 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
116. Apple is finally letting you have it your way-kinda 
 
117. Apple Intelligence first reactions: from 'pure slop' to 'excellent work' 
 
118. The Artificial is Rarely Intelligent 
 
119. Why Facebook won’t be influential in the UK general election 
 
120. Links 5/29/2024 
 
121. Losing the library 
 
122. TechScape: The people charged with making sure AI doesn 
 
123. Spam, junk 
 
124. The people charged with making sure AI doesn’t destroy humanity have left the 
building 
 
125. Tech guru warns of 'zombie internet' flooded by AI bots that's making world 
'dumber' 
 
126. Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI 
 
127. Spam, junk …  slop? The latest wave of AI behind the ‘zombie internet’ 
 
128. Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, 
City take Premier League 
 
129. Google is bringing back classic search, with no AI – and I couldn't be happier about 
that 
 
130. Google is bringing back classic search, with no AI – and I couldn't be happier about 
that 
 
131. How to spot deepfake videos and photos 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
132. Don't be fooled by deepfake videos and photos this election cycle. Here's how to 
spot AI 
 
133. An AI-generated rat with a giant penis highlights a growing crisis of fake science 
that's plaguing the publishing business 
 
134. AI is now supercharging Google Assistant 
 
135. The Cult of AI 
 
136. Gamers Bash Xbox for Controversial Art Apparently Made by AI 
 
137. Links 11/30/2023 
 
138. Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons 
 
139. Secret Invasion Fails Because It Can't Pick a Genre 
 
140. Fired-up Saso rebounds with solid 65, ties for lead 
 
141. LatinVFR Releases Fort Lauderdale-Hollywood International Airport for Prepar3D V4 
 
142. Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead 
generation is best known for his newspaper cartoons, but his beat extended far beyond 
Fleet Street. DJ Taylor celebrates one of the great English comi... 
 
143. The AI Studio Ghibli trend is an insult to art and artists 
 
Page 1 of 2
Google has found a new role for the man who broke Google Search
Google has found a new role for the man who broke Google Search
BGR
October 17, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 608 words
Byline: Andy Meek
Body
Google has found a new job for Prabhakar Raghavan, the executive largely responsible for running Google Search 
into the ground over the last four years - a period that's seen Google's search engine increasingly prioritize AI slop, 
shove more ads than ever at users, give Forbes and Reddit links priority placement, and basically make it harder 
than it's ever been to find what you're actually looking for.
Raghavan - who, before he came to Google, oversaw search at Yahoo during its decline from 2005 through 2012 - 
will now be Google's chief technologist, working closely with CEO Sundar Pichai. "Prabhakar has decided it's time 
to make a big leap in his own career," Pichai wrote in a memo to Googlers. "After 12 years leading teams across 
Google, he'll return to his computer science roots and take on the role of Chief Technologist, Google. In this role, 
he'll partner closely with me and Google leads to provide technical direction and leadership and grow our culture of 
tech excellence."
Ok, whatever.
Looks like Google finally realized the fish rots from the head ... Search results have been decaying for a while, and 
now Prabhakar Raghavan is out. Let's hope for some much-needed 
improvement.#google #seo pic.twitter.com/qmO0kkV7hZ
- Scott Gabdullin (@ScottGabdullin) October 17, 2024
Google's head of search isn't just being replaced. He's being promoted. An effective remedy to Google's Search 
monopoly would terminate his employment and anyone else whose predatory conduct gave rise to Google's 
monopoly. https://t.co/O9kF3efQ3A
- Lee Hepner (@LeeHepner) October 17, 2024

Page 2 of 2
Google has found a new role for the man who broke Google Search
I'll admit it, I was over the moon about this news ... at first. And then I noticed who Google is replacing Raghavan 
with: Nick Fox, a Googler who, before his stint at the company, worked as a consultant at McKinsey - aka, one of 
the most loathsome corporations in the history of mankind. Meaning, another bean counter is in charge of the 
biggest search engine on the planet and will, in all likelihood, continue Raghavan's work of packing Google Search 
with ads, spam, SEO-optimized content, and AI that summarizes as much of all that as it can.
Meantime, giving you what you're looking for remains the last thing Google Search actually cares about.
I can't tell you how many times I have to shift over to an alternative search engine, like DuckDuckGo, to find 
something useful when I'm doing a search. Hell, the other day, I was trying to find a specific article I'd written in the 
past for a specific outlet, and even though I attached the outlet's name to my search query, Google's AI Overview 
still gave me what other outlets had written about the same thing (which matters, because some people are just 
going to stop there, with those AI Overviews that take over the top of the search results page).
Furthermore, few things signal the inexorable decline of Google Search as its desperate inclusion of crap like 
YouTube links and in-line YouTube videos,  as well as Reddit and Quora threads plus garbage from Forbes, all of 
which seem to take up prime spots for the majority of searches these days. Never mind that if users like me wanted 
a damn YouTube video, we would ... wait for it ... just go to YouTube. It's abundantly clear to people like me, whose 
livelihoods revolve around online publishing, that Raghavan's tenure as the head of Google Search represents one 
of the most remarkable leadership failures at any tech company in years. And we're all still paying for it.
Don't Miss: Maybe Google's new 'reasoning AI' can address the Hawk Tuah spam all over Google Maps
The post Google has found a new role for the man who broke Google Search appeared first on BGR.
Load-Date: October 17, 2024
End of Document
=======
Date and Time: = 2025-04-29 
Job Number: = 251572390 
 
Documents (76) 
Client/Matter: -None- 
Search Terms: AI Slop 
Search Type: NaturalAnd 
Content Type Narrowed by 
news : Zeitungen Quellensprache: English Zeitachse: 01 Apr, 
2024 an 01 Apr, 2025  
 
1. The AI Studio Ghibli trend is an insult to art and artists 
 
2. Generated your Studio Ghibli-style AI image? Here is why it is ethically wrong and may 
amount to IP theft 
 
3. ChatGPT's Studio Ghibli AI trend sparks debate over creativity vs copyright violation 
 
4. Apple's AI isn't a letdown. AI is the letdown 
 
5. From spit to bankruptcy: the rise and fall of 23andMe 
 
6. The Electric State X Reviews: Millie Bobby Brown and Chris Pratt starrer leaves 
netizens dismayed; 'like AI slop' 
 
7. Google and the AI left behind, by Josep Maria Ganyet 
 
8. From Neva to A Highland Song, the Baftas are a reminder of how creative games can 
be 
 
9. PETER HOSKIN reviews Split Fiction: It's stranger than fiction (and twice as fun)! 
 

 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
10. Trump’s rollback of AI guardrails leaves US workers ‘at real risk’, labor experts warn 
 
11. Generative AI is most useful for the things we care about the least 
 
12. Voices: Trump's fake AI video of him relaxing in Gaza with Netanyahu is a nightmare 
look inside his mind 
 
13. Call of Duty maker Activision confirms AI usage in games; how this Steam policy may 
be behind it 
 
14. Zoho's Sridhar Vembu says 'AI bubble deflating,' lists 7 tech uses worth the hype 
 
15. 'Hey ChatGPT, is Gen Z becoming a canary in the coalmine for AI'? 
 
16. 'Hey ChatGPT, is Gen Z the canary in the AI coalmine?' 
 
17. Are you seeing disquieting images like these on social media? There's a sinister 
reason why... and it's taking older people for fools, reveals FLORA GILL 
 
18. Looking for something new to spice up your game play? The Tinder of games is here 
 
19. Ben Tarnoff, technology writer: 'People need to participate in what affects them most, 
and that's impossible in a privatized internet' 
 
20. Danish Media's united stand against Big Tech 
 
21. Google edits Super Bowl ad for AI that featured false information 
 
22. Danish media's stand on Big Tech 
 
23. Channel 4 demands tech giants be forced to promote mainstream news 
 
24. Social media is dead. What comes next might be far more beautiful 
 
25. Climate change misinformation on networks could increase in the face of less 
moderation 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
26. From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: 
Rocket Lab's breakthrough year RED FLAG: Fakes on Instagram 
 
27. From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: 
Rocket Lab's breakthrough year RED FLAG: AI fakes on Instagram 
 
28. Starmer's dream of an AI revolution is sadly doomed 
 
29. Mainlining AI won't bring back boom-time Britain 
 
30. GIVE ME A CRASH COURSE IN . . . META'S ABOLITION OF FACT-CHECKING 
 
31. 2025: The year of the AI slop 
 
32. AI-generated ‘slop’ is slowly killing the internet, so why is nobody trying to stop it? 
 
33. Meta is getting rid of factchecking. Should you leave Instagram – and what are the 
alternatives? 
 
34. Sorry, Georgia, it's time to run a mile from attention-seeking BrewDog boss 
 
35. Labour TikTok featured obscene lyrics 
 
36. Hare-brained? Labour under fire for bizarre AI TikTok clip 
 
37. AI, Musk and Trump add up to turbulent 2025 for tech 
 
38. Labour apologises for TikTok featuring obscene lyrics about women 
 
39. Labour is forced to delete AI TikTok clip over using graphic song encouraging 
drugging of girls 
 
40. Watch: Labour uses AI bunnies to promote NHS in bizarre promo video 
 
41. AI, Musk and Trump add up to a turbulent 2025 for tech 
 
42. How to spot the AI 'slop' taking over internet 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
43. X’s Grok AI revives concern about deepfakes ahead of Delhi Assembly election 
 
44. Why ‘AI slop’ is taking over the internet —  and how to spot it 
 
45. Why the internet is filling up with nonsense ‘AI slop’ 
 
46. The surreal AI 'slop' taking over social media feeds Sites are turning away from 
human content amid competition for clicks, reports Matthew Field 
 
47. Toronto can be a lonely city. I found community in an unlikely place 
 
48. 24 lows of 2024 Ranking the ridiculous, the absurd and a few very dark moments in a 
very long year By Richie Assaly, Joshua Chong, Laura deCarufel, Deborah Dundas, Kevin 
Jiang, Debra Yeo 
 
49. 24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick drags 
Drake through the mud, AI slop and more 
 
50. 2024 A year in a word / n. 
 
51. The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes 
out on top? 
 
52. FELINE FRENZY 
 
53. A less toxic, less chaotic alternative I grew up on Twitter. But with a new Trump era 
on the horizon, I've been trying Bluesky 
 
54. I grew up on Twitter. But with a new Trump era on the horizon, I've turned to Bluesky. 
Here's what I found there 
 
55. Demure? Brain rot? Oxford announces shortlist for 2024 Word of the Year: Cast your 
vote 
 
56. Fake AI 'slop' posts about Elon Musk surge on Facebook after election 
 
57. The images of Spain ’s floods weren’t created by AI. The trouble is, people think they 
were 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
58. Newsletter : ChatGPT weds AI search to give Google worthy competition; AI Tool of 
the Week: How to use ChatGPT Search; Will AI achieve human-like reasoning 
 
59. Halloween 'hoax': How did so many turn out for a fake parade in Dublin city centre? 
Website apologises for 'mistake' and claims there was no intention to mislead 
 
60. Final Fridays returns after year-long break 
 
61. Monday briefing: The Trump acolytes planning to interfere with November’s election 
 
62. McNeal review – Robert Downey Jr shines in muddled AI-themed play 
 
63. Pick of the day 
 
64. Radio choice 
 
65. Wednesday 25 September 
 
66. Honor recognizes unique contributions to the field, including Glaze and Nightshade 
tools 
 
67. 'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images 
frenzy 
 
68. Inside Trump's weird new obsession with AI-generated images 
 
69. Bigger picture of Trump's weird AI images obsession The Republican party and its 
presidential nominee now have a tool that allows them to visualise the hypothetical 
realities they are peddling to their supporters, writes Mike Bedigan 
 
70. How did Donald Trump end up posting Taylor Swift deepfakes? 
 
71. A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is 
‘flooded with garbage’ 
 
72. Twitter page gains thousands of followers for making fun of Facebook posts 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
73. Letter writer declares ' Durango Decline' citing online classes, branding and merch 
 
74. Comment: 'We deserve more than reheated housing ideas and AI slop' 
 
75. The Artificial is Rarely Intelligent 
 
76. Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, City 
take Premier League 
 
>>>>>>> c98f417 (update data file):extract_text.txt
Page 1 of 3
The AI Studio Ghibli trend is an insult to art and artists
The AI Studio Ghibli trend is an insult to art and artists
The Daily Star, Dhaka, Bangladesh / Asia News Network
April 1, 2025 Tuesday
Copyright 2025 The Asia News Network (Hamburg, Germany)
Distributed by Tribune Content Agency
Section: STATE AND REGIONAL NEWS
Length: 1082 words
Byline: Dawn, Karachi, Pakistan / Asia News Network
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
October 17th, 2024 ( Techdirt  - Delivered by  Newstex )
We are living under a sea of AI-generated slop, where AI deepfakes and non-consensual intimate content abound. 
Congress, a self-interested creature, naturally wants to create protections for themselves, their favorite celebrities, 
and their wealthy donors against online impersonation. But until now, visions of so-called AI protections have been 
limited. From my lair, I've seen how Big Content might use congressional panic about AI abuse to make a many-
tentacled power grab. With the  NO FAKES and No AI FRAUD Acts, it's delicious to report that we have done 
exactly that.
Inspired by my seashell-prisons, in which I trap the sweet voices of mermaids looking to rise, these bills would let 
corporations and trade associations like mine control not only the tongues of young musicians, actors, or authors-
but their whole face and body. It has been incredibly lucrative for Big Content to monopolize other intellectual 
property rights, so that we could prevent  Prince from singing his pesky 'art' under his own name and block Taylor 
Swift from buying back her early recordings from powerful enemies. It is far past time that new and more invasive 
rights are created, ones that allow us to make AI-generated deepfakes of artists singing the songs that we like, 
dressing in the way we desire, promoting the causes we approve, and endorsing the presidential candidates that 
we want to endorse.
Since teenagers, abuse survivors, and artists started suffering from AI deepfakes, our leaps toward victory have 
been enlivened by the sirens we've convinced  to testify on behalf of concepts like consent, the struggle of artists 
for respect and dignity, and the importance of human art. They have unwittingly obscured our true aims with the 
beauty of their voices, and the results are glorious, netting legislation that would lure not only artists, but anyone at 
all, into crashing on the rocks.
If these bills pass, the vulnerable and desperate will also be lured into trading rights to their voices and faces for 
almost nothing-a month's rent or a week's groceries. A paid electricity bill. And for that we will amass vast libraries 
of captive voices and faces that we can license out to whomever will pay, to use as broadly and vaguely as we 
=======
Apr. 1—ISLAMABAD(Dawn/ANN)- An artist spends years perfecting their skills. Hours spent drawing, scrapping 
and redrawing to bring to life a vision that goes on to inspire millions. Studio Ghibli's co-founder Hayao Miyazaki is 
one such artist.
Miyazaki's films have not only received many awards but his retinue of works including Spirited Away, Kiki's 
Delivery Service, Howl's Moving Castle and so on have instilled the power of imagination and dreams in countless 
children and adults. Artistic inspiration can be a powerful thing, Miyazaki's art inspired the creation of Pakistan's first 
hand-drawn animated film, The Glassworker. With their own unique spin, a love letter to the aesthetic, The 
Glassworker took Usman Riaz and his team a decade to make.
In recent years however, artificial intelligence (AI) with its image generative tool has posed a threat to art and 
artists. AI learns from millions of images across the internet and memorises text associated with those images. In a 
process known as "diffusion", AI starts by breaking images into pixels that do not represent any specific thing and 
then inverts the process so the model can revert to the original image. Artificial intelligence does not take into 
account copyright and hence artistic styles are used without permission.
With image generative tools such as Midjourney, DALL-E and even a feature on Canva made widely available to 
anyone with an internet connection and monthly subscription, users can write a prompt and generate an image in a 
certain artist's style, without, of course, asking or crediting said artist. The most recent victims of this are the artists 
at Studio Ghibli.
OpenAI announced the launch of its "most advanced image generator" which has been built into GPT-4o and has 
been made available to users for free. This has enabled a worrying trend where users are converting their 
photographs into 'Studio Ghibli style art'. AI's rendering of Studio Ghibli is nothing more than sanitised, soulless and 
generic, a typical cutesy image devoid of any character, effort or passion.
Studio Ghibli's art is more than just cute characters, it is grotesque and sometimes even harrowing, it is layers of 
hard work, passion and unwavering dedication to create unique characters that tell meaningful stories.
>>>>>>> c98f417 (update data file):extract_text.txt

Page 2 of 3
The AI Studio Ghibli trend is an insult to art and artists
From Grave of the Fireflies which shows a war torn Japan and two siblings desperate to survive on their own to 
themes of greed and identity as Chihiro navigates the world of spirits trying to save her parents (who were 
transformed into pigs) from being eaten in Spirited Away, all of Studio Ghibli's work means something. Even light-
hearted Ghibli features such as Kiki's Delivery Service focus on themes of self acceptance.
Every frame of a 2D animated film is painstakingly drawn by hand. The beautiful watercolour-esque nature scenes 
from Ghibli's films, the varied emotions on faces of characters, the tireless research that goes into making every 
fantastical aspect a little more believable; this is what makes the films timeless.
Criticising the AI Studio Ghibli trend, Riaz wrote in a post on X, "In an age of AI-generated everything, "The 
Glassworker" was drawn by hand. No shortcuts. No algorithms. Just work, talent and perseverance [...] AI is the 
future —but it's a tool not the artist."
Some might call AI a terrific mimic but that's all that it is. As exposed by this trend, the generated images lack depth 
and feeling. Perhaps the most egregious thing to come out of this trend is the politicisation of Ghibili's art. Political 
ideologies, thoughts and even extremist narratives are being portrayed in this aesthetic.
Users have used AI to recreate scenes of the destruction of the Babri Masjid, a Mughal-era mosque in India's 
Ayodhya. Using an art style synonymous with innocence to glorify the demolition of a mosque is beyond repugnant. 
Not to mention that Miyazaki has taken a strong stance against oppression and fascism in the past.
The White House used the trend in a post on X to depict an arrest and deportation of an immigrant by the US 
Immigration and Customs Enforcement (ICE). This comes after ICE has been deporting and arresting even those 
who hold a green card and revoking the legal status of thousands of immigrants. To use an artistic style, even if its 
watered down by AI to make light of suffering or depict Trump's hardline policies is abhorrent.
It is worth noting that in 2003, Hayao Miyazaki boycotted the Oscars ceremony as he opposed the US war in Iraq.
"The reason I wasn't here for the Academy Award was because I didn't want to visit a country that was bombing 
Iraq," he had told The Los Angeles Times of his decision.
PPP Chairman Bilawal Bhutto-Zardari also jumped onto this trend, changing his profile picture and generating 
photographs of his late mother and former prime minister Benazir Bhutto.
A countertrend has also sprung on X, with artists showcasing their work inspired by Studio Ghibli films, condemning 
the theft of art while simultaneously encouraging people to pick up a pencil and learn to draw themselves instead of 
relying on what has been termed as 'AI slop'. Artists have showcased their work with captions such as "Art I made 
from Studio Ghibli in my style without needing AI." Others have spoken about the time and dedication it has taken 
to perfect their craft.
With the popularity of the AI slop Ghibli trend on the internet, an old documentary has resurfaced in which Miyazaki 
expresses his strong dislike for AI 'art'. In the documentary the filmmaker is shown a zombie, with developers 
saying that AI can allow more grotesque movements. The artist's response was, "Whoever creates this stuff has no 
idea what pain is whatsoever. I am utterly disgusted... I strongly feel that this is an insult to life itself."
Imagine spending hours, days, months and years to find your artistic expression, and then suddenly a single 
prompt, that intellectual property and hard work is stolen, attached to narratives that you may or may not agree with, 
no consent and definitely no credit; this is what AI "art" means to many artists and why so many speak against it.
Appreciating art is a beautiful thing if done in a healthy manner by supporting artists or spending time trying to hone 
skills taking talented professionals as inspiration. Taking shortcuts, depriving artists from jobs and credit by using AI 
only serves to disrespect the medium.
© 2025 the Asia News Network (Hamburg, Germany). Visit www.asianewsnet.net. Distributed by Tribune Content 
Agency, LLC.
Page 3 of 3
The AI Studio Ghibli trend is an insult to art and artists
Load-Date: April 2, 2025
End of Document
Page 1 of 4
Generated your Studio Ghibli-style AI image? Here is why it is ethically wrong and may amount to IP theft
Generated your Studio Ghibli-style AI image? Here is why it is ethically 
wrong and may amount to IP theft
The Northlines
April 1, 2025 Tuesday
Copyright 2025 The Northlines, distributed by Contify.com All Rights Reserved
Length: 1354 words
Body
Artists are up in arms after hordes of social media accounts jumped onto the latest Ghibli trend, raising concerns 
about the ethics and copyright protection for art
Metaphorically speaking, AI tools like DALLE-E (and ChatGPT) make people feel 'almost like God'. "All someone 
has to do is to state a prompt," This was what Dr Eduardo Navas, who researched AI models at Pennsylvania State 
University in the US said, back in 2023. Fast forward to 2025, and AI is more powerful than ever.
The latest ChatGPT update enables users to convert any of their photos to specific art styles-most notably in the 
style of the legendary animation studio based in Japan, Studio Ghibli.
Following its release this week, Ghibli-style AI 'art' flooded the internet. Popular memes, personal photos, anything 
people could get their hands on- all converted to their 'Ghibli-fied' versions.
However, artists and creatives all over are raising alarm over the ethical and legal ramifications of such AI-
generated posts.
Studio Ghibli is famous for its distinct art and animation, shaped by an illustrious set of art directors in Japan, 
including Hayao Miyazaki, Isao Takahata, Kitaro Kosaka and many more, over the years.
My Neighbor Totoro. Spirited Away. Princess Mononoke. The Wind Rises. Kiki's Delivery Service. Howl's Moving 
Castle. Grave of the Fireflies. These are just a fraction of the critically acclaimed animated film catalogue from 
Studio Ghibli.

Page 2 of 4
Generated your Studio Ghibli-style AI image? Here is why it is ethically wrong and may amount to IP theft
And now OpenAI, the founding company of ChatGPT, openly encourages these new experiments in 'Ghibli-fication'. 
Its CEO Sam Altman even changed his profile picture on X to a Ghibli-style 'portrait'. Official posts from the White 
House, and even from myGovIndia featuring Prime Minister Narendra Modi, followed.
In the release notes of the latest iteration of Chat- GPT, the company states that the artificial intelligence model 
would take a 'conservative approach' to how it mimics different art styles. However, that simply does not reflect the 
reality.
All one has to do is go online and be greeted by 'images' flooding social media, distinctively copying the art style by 
sampling a lot of original material from Studio Ghibli movies and stills.
And since Sam Altman wants the US government to conveniently move around 'fair use' guidelines to train AI to 
'learn' from copyrighted material, we can all assume how little regard he has for intellectual property rights.
People from the art community that THE WEEK spoke to have a unified take on the issue: The difference between 
creating your own art-even art inspired by other artists-and an AI 'generated' image created by a machine copying 
from a library of artists is not a fine line, it is a deep chasm-where true creativity goes to die. Simply put, AI 
'generated' images are not art, says animators and artists alike.
Artist Jugal Chudasama from Mumbai calls out the ethical violation in this process. "These AI models are trained 
without the intellectual property (IP) owner's consent," Chudasama says. Moreover, these models would not exist if 
humans did not create the art in the first place.
"It's not just Ghibli art, they have trained these models on countless individual artists as well-who cannot afford to 
take this to court" adds the founder of Studio Joog.
There is, of course, mounting opposition from AI 'evangelists' who toe the same line as Altman-that they need AI to 
'train' on original content made by artists to 'grow the technology'.
"New tech has always had a rough start. Take digital cameras, for example. Traditional photographers thought this 
would make photography too easy and therefore less meaningful. But even digital photographers have to get up 
and physically go to locations, experience life, to take those photos," explains the artist, "Even after they click the 
photos, there's a process to make them look good."
"Take a charcoal and pencil, for example. The invention of the pencil did not completely eradicate the process of 
writing or drawing. You still needed the same skills, only now, you have cleaner hands-that was the USP," said 
Chudasama.
In fact, the same is applicable to the latest wave of digital art. It still relies on the human skill to draw and sketch. 
However, AI tools simply take in a text prompt, and a photo, and use the data it scraped from art created by other 
artists to 'generate' an image.
"They steal from our work by sampling images we created after years of practice," says another artist who did not 
wish to be named.
Chennai-based filmmaker Ashwath Nair is vocal about his take on the latest Ghibli trend. "Ethically, I think it spits 
on the face of what the studio (Studio Ghibli) is doing," says Nair, "There are countless artists, who toiled for years, 
even to make classics like Princess Mononoke."
Page 3 of 4
Generated your Studio Ghibli-style AI image? Here is why it is ethically wrong and may amount to IP theft
"Before the CGI era, each Ghibli film took at least four years to make," he explains, "That kind of effort, now boiled 
down to what is essentially AI slop is disrespectful to the people who contributed to building one of the stalwarts of 
anime, to begin with."
Nair, who is also a content creator at Yoshimura Anime Corner, is also confident that Studio Ghibli would put out an 
official statement. If anyone at Studio Ghibli might respond to the latest controversy surrounding the ethics and 
legality of AIgenerated images, it would most probably be the former president and founder of the animation studio 
itself, Toshio Suzuki, he adds.
Book blogger Noirita Das did not mince her words when calling out the trend online. "Did y'all notice how it's mostly 
the corporate people using the Studio Ghibli filter?" Das posted on Threads, referring to the proverbial David-vs-
Goliath battle that exists between large corporations and 'the little guy'.
"It's almost like the engineering degree or the MBA degree has completely desensitized them. It's almost like they 
have no appreciation for the arts, whereas, statistically they are in a position to afford it," Das added, doubling down 
on how the latest AI models were being used for art rather than mechanical tasks that would replace management 
professionals, not the ones in the creative space.
To add to the images that artists label as plagiarism, a fake cease-anddesist order seemingly from Studio Ghibli, 
also made its rounds on social media. As AI evangelists criticised the order as 'limiting the freedom of expression', 
some artists called out the irony of it all: "They need a fake legal notice to validate their victim complex after sharing 
plagiarised images!"
'A fight worth taking up', lawyers tell artists Copyright law in India has always been a point of contention, as far as 
the rights of artists are concerned.
"The legal history of copyright will tell you that artists' rights have always been a matter of contestation. Studio 
Ghibli, of course, is a huge production studio and probably can sue for infringement," explains Advocate Govind 
Manoharan, founder of Delhi-based Godiyal & Manoharan Chambers.
"Artists have gained, over years of countless litigation, recognition of their rights. This fight, though, is a new arena 
for artists and traditional production houses alike- how successful it is going to be in the present state of the law on 
copyright is something to be seen, but it's a fight worth taking up," says Manoharan, who has represented artists in 
infringement cases in Delhi courts.
"If not, it risks the hard fought gains of decades," adds the lawyer, stating that such a precedent would 
disproportionately affect smaller artists, as "is often the case".
Despite the noise and the ethical debate surrounding it, the artist community is confident that Studio Ghibli will 
simply let this one slide. The animation studio even has a page dedicated on their official website only to list the 
copyright details for their works all the way from 1984.
Studio Ghibli is not just a huge name-they are widely revered in the art community. Moreover, they are artists. They 
are good at what they do. And they are Japanese. Maybe, this is the time of reckoning for ChatGPT, and other AI 
'theft' algorithms like it-a huge, globally acclaimed art studio going against them and their 'AI slop' filling the internet 
to its brim.
Page 4 of 4
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
I'm running out of ways to explain how bad this is
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: October 17, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 24, 2024
=======
Generated your Studio Ghibli-style AI image? Here is why it is ethically wrong and may amount to IP theft
Load-Date: April 1, 2025
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 16, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 22, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 29, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 29, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 16, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 28, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 17, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 17, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 30, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 28, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 18, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 25, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 24, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 25, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 21, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 22, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 23, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 21, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 18, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 30, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 23, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 31, 2024
End of Document
Page 1 of 4
ChatGPT's Studio Ghibli AI trend sparks debate over creativity vs copyright violation
ChatGPT's Studio Ghibli AI trend sparks debate over creativity vs copyright 
violation
The Independent (United Kingdom)
March 28, 2025 Friday 4:47 AM EST
Copyright 2025 Independent Print Ltd  All Rights Reserved
Section: ENTERTAINMENT: LATEST, Oceania latest, Japan news & IP AND PATENTS NEWS
Length: 1471 words
Byline: Ap Correspondent
Body
Several fans of famed Japanese animation studio behind Spirited Away and Howl's Moving Castle, Studio Ghibli,  
were delighted this week when a new version of ChatGPT let them transform popular internet memes or personal 
photos into the distinct style of Ghibli founder Hayao Miyazaki. 
However, the trend also highlighted ethical concerns about artificial intelligence tools trained on copyrighted 
creative works and what that means for the future livelihoods of human artists, as well as ethical questions on the 
value of human creativity in a time increasingly shaped by algorithms.
Miyazaki, 84, known for his hand-drawn approach and whimsical storytelling, has expressed skepticism about AI's 
role in animation in the past.
Janu Lingeswaran wasn't thinking much about that when he uploaded a photo of his 3-year-old ragdoll cat, Mali, 
into ChatGPT's new image generator tool on Wednesday. He then asked ChatGPT to convert it to the Ghibli style, 
instantly making an anime image that looked like Mali but also one of the painstakingly drawn feline characters that 
populate Miyazaki movies such as My Neighbor Totoro or Kiki's Delivery Service.
"I really fell in love with the result," said Lingeswaran, an entrepreneur who lives near Aachen, Germany. "We're 
thinking of printing it out and hanging it on the wall."
Similar results gave the Ghibli style to iconic images, such as the casual look of Turkish pistol shooter Yusuf Dikec 
in a T-shirt and one hand in his pocket on his way to winning a silver medal at the 2024 Olympics. Or the famed 
"Disaster Girl" meme of a 4-year-old turning to the camera with a slight smile as a house fire rages in the 
background.

Page 2 of 4
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and Video Generation; 
Superstudio Integrates State-of-the-Art Image and Video Models ....
"The emerging culture around AI is lacking an artist-driven vision. We know artists deserve better," said Kyt Janae, 
multidisciplinary artist and Head of Creative at Kaiber. "Automating and optimizing creativity is not the goal. As an 
artist, experimenting with and adopting new tools is a sacred act, not driven by the latest and greatest features, but 
by the pursuit of turning a vision into reality. Kaiber is pushing the landscape of creative AI forward with a product 
that supercharges the creative process. We've worked exclusively with visionaries who understand and want to 
build this new future with us. We're here to guide and create artist-driven culture."
REIMAGINING THE CREATIVE EXPERIENCE
In today's digital landscape, creatives often find themselves juggling multiple complex applications and 
subscriptions to produce a single asset. This "tool fatigue" hinders productivity and innovation. Superstudio 
addresses this by bringing the best foundational models into a singular platform, accelerating the creative process.
Its unique design sets it apart in the AI world, introducing a new level of modularity to AI-assisted creation. Users 
can generate images and videos concurrently, then seamlessly use these outputs as inputs in new Flows-allowing 
for infinite combinations and iterations all within the same interface.
Superstudio's design prioritizes ease of use. It employs simple language, drag-and-drop functionality, and sliders, 
making complex AI operations accessible to users of all skill levels. This approach demystifies AI terms and 
processes, lowering the barrier to entry for creatives.
The platform supports multiple infinite canvases for idea exploration and project organization, catering to both 
expansive brainstorming and structured workflows. At the heart of Superstudio's interface is Kiko, a brand character 
serving as the generate button - a fresh take on the often-used AI sparkle emoji - adding a playful personality to the 
user experience.
A PLAYGROUND OF INFINITE POSSIBILITIES
Superstudio transforms the creative process from ideation to final output. Users can begin with a simple concept 
and expand it into a rich multimedia project, blending images, videos, and audio elements.
Superstudio key features include:
• Canvas: An open, intuitive space for importing, generating, and refining ideas.
• Flows: Creative building blocks of AI tools with modular Elements like style transfers, face references, 
upscaling, and audio-reactivity.
• Collections: Organized asset groups that integrate directly with Flows.
EMPOWERING CREATORS ACROSS DISCIPLINES
Superstudio caters to a wide range of creative professionals, from animators to content creators and early-career or 
seasoned creative professionals. As AI technology evolves, so does Superstudio, continually expanding its 
capabilities to support diverse creative needs.
The platform enables:
• Efficient Prototyping: Rapid iteration of visual concepts and brand elements like logos, flyers, storyboards, 
and more.
• Dynamic Content Creation: Generation of compelling and cohesive visuals for various media platforms.
• Collaborative Innovation: A unified workspace for shared ideation and asset management.
AVAILABILITY AND PRICING
Page 3 of 4
Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and Video Generation; 
Superstudio Integrates State-of-the-Art Image and Video Models ....
Superstudio is available on desktop platforms. New users can access free trials with 100 credits, up to 2 Canvases, 
3 custom Flows, and up to 1 GB of storage. Paid subscriptions start at only $15 per month or $120 per year. For 
more information on pricing and credit packs, visit: kaiber.ai/pricing .
FUTURE FOR KAIBER
In 2024, Kaiber raised a round of funding from EQT Ventures and Crush Ventures. Kaiber is setting out on a 
focused journey to advance AI creativity. Through Superstudio and ongoing research at Kaiber Labs, the company 
aims to explore new possibilities in AI-powered artistry.
"We are incredibly proud to support Kaiber and the launch of Superstudio," said Ted Persson, Partner at EQT 
Ventures. "The team is redefining how AI technology can be used to ignite creativity. We have a strong conviction 
in the Kaiber team and can't wait to see all the amazing ways in which Superstudio will shape the future of 
generative AI."
ABOUT KAIBER
Kaiber is a next generation creative technology company focused on human and AI collaboration. We believe AI 
empowers artists to supercharge their ideas and creativity. Through Superstudio and Labs, we aim to bring new 
creative visions to the forefront, letting artists make anything they can imagine.
Above all, we make tools and craft experiences for people.
ABOUT KAIBER LABS
Kaiber Labs is where cutting-edge research and world-class craftsmanship meet culture. An in-house applied 
research and creative production team, Labs is dedicated to inventing and test-driving new technologies.
Labs generates novel media, explores emerging trends, and directly shapes the evolution of Superstudio, Kaiber's 
flagship creative AI product. The team also collaborates exclusively with leading artists and cultural behemoths to 
engineer experiences that bring harmony between human and AI creativity.
ABOUT EQT Ventures
EQT Ventures is an early stage lead investor built by founders and operators, offering the next generation of 
entrepreneurs a fast track to scale. The fund is based in Luxembourg and has investment advisors strategically 
located across Stockholm, Amsterdam, London, New York, Berlin, and Paris. Currently investing out of its third 
((EURO)1.1B) fund, the largest early-stage fund ever raised in Europe, EQT Ventures is one of the most active VC 
firms partnering with hundreds of ambitious founders and startups . Driven by a team of accomplished company 
builders and scalers, EQT Ventures is committed to providing the capital and hands-on support necessary for 
generation-defining founders and companies to transform their visions into global successes.
View source version on businesswire.com: https://www.businesswire.com/news/home/20241016279399/en/
CONTACT: Cultural Counsel
kaiberai@culturalcounsel.com
http://www.businesswire.com
Graphic
=======
ChatGPT's Studio Ghibli AI trend sparks debate over creativity vs copyright violation
Awesome. The Ghibli style is now going to become oversaturated and associated with lazy and boring content - 
can't wait for kids to grow up thinking the Ghibli movies are Ai-generated and instead of art that's crafted by 
excellent artists https://t.co/YFOUIRLYAm
- Fredrik (@F_Edits)
March 27, 2025
The whole Studio Ghibli AI trend honestly gives me second-hand embarrassment knowing how hard Hayao 
Miyazaki has fought to retain the identity of his films and how many of you are this willing to make a farce out of 
decades of artistry because you don't actually value it https://t.co/TgSxnb1Ah5
- gregor samsung (@slimjosa)
March 27, 2025
ChatGPT maker OpenAI, which is fighting copyright lawsuits over its flagship chatbot, has largely encouraged the 
"Ghiblification" experiments and its CEO Sam Altman changed his profile on social media platform X into a Ghibli-
style portrait. In a technical paper posted Tuesday, the company had said the new tool would be taking a 
"conservative approach" in the way it mimics the aesthetics of individual artists.
"We added a refusal which triggers when a user attempts to generate an image in the style of a living artist," it said. 
But the company added in a statement that it "permits broader studio styles - which people have used to generate 
and share some truly delightful and inspired original fan creations."
This four second crowd scene from Studio Ghibli's The Wind Rises (2013) took animator Eiji Yamamori 1 year and 
3 months to complete pic.twitter.com/RyOngP2o60
- Anime Aesthetics (@anime_twits)
March 27, 2025
changed my pfp but maybe someone will make me a better one
- Sam Altman (@sama)
March 26, 2025
Studio Ghibli hasn't yet commented on the trend. The Japanese studio and its North American distributor didn't 
immediately respond to emails seeking comment on Thursday.
As users posted their Ghibli-style images on social media, others began to share Miyazaki's previous comments on 
AI animation, as well as their thoughts on why they believe the AI images go against the ethos of the famed auteur. 
In a 2016 meeting, when shown an AI animation demo, Miyazaki famously responded: "I am utterly disgusted. If 
you really want to make creepy stuff you can go ahead and do it. I would never wish to incorporate this technology 
into my work at all."
The team member demonstrating the animation explained that AI could "present us grotesque movements that we 
humans can't imagine," adding that it could be used to depict zombie movements.
Since this utter garbage is trending, we should take a look at what Hayao Miyazaki, the founder of Studio Ghibli, 
said about machine created art. https://t.co/1TMPcFGIJE pic.twitter.com/IvaM9WZL3T
- Nuberodesign (@nuberodesign)
Page 3 of 4
ChatGPT's Studio Ghibli AI trend sparks debate over creativity vs copyright violation
March 26, 2025
That prompted Miyazaki to tell a story.
"Every morning, not in recent days, I see my friend who has a disability," Miyazaki said. "It's so hard for him just to 
do a high five; his arm with stiff muscle can't reach out to my hand. Now, thinking of him, I can't watch this stuff and 
find it interesting. Whoever creates this stuff has no idea what pain is."
"I strongly feel that this is an insult to life itself.
"Irony is dead and all but it's pretty depressing to see Ghibli AI slop on the timeline not only because Miyazaki 
famously thinks AI art is disgusting but because he's spent the last 50 years making art about environmental waste 
for petty human uses," posted a fan on X, formerly Twitter. 
A 2024 study found that AI systems were leading to vast emissions, which in turn are increasing as more energy is 
required to run the evolving systems.  OpenAI's current GPT-4, for instance, uses 12 times more energy than its 
predecessor, the study said. 
The energy used in training the systems is only a small part of work, and requires an estimated 960 times more 
energy than a training run when the AI tools are actually being used. 
In particular, many are upset with the official US government X account using the trend to generate an image of an 
immigrant being arrested and deported.
"To see something so brilliant, as wonderful as Miyazaki's work be butchered to generate something so foul. God I 
hope Studio Ghibli sues the hell out of Open Ai for this," posted one user.
i've thought about it and i do think an ai generated studio ghibli picture of a deportation is one of the most disgusting 
things i've ever seen pic.twitter.com/OyAKdM7SRz
- Sydney Battle (@SydneyBattle)
March 27, 2025
In October 2024, an AI-generated trailer for a live-action version of the 1997 film Princess Mononokeled to massive 
backlash after going viral on social media. 
The AI trailer used the English voice acting from the original film, which featured talents like Billy Cudrup, Clare 
Danes and Minnie Driver, and completely reimagined the hand drawn animation of the Japanese movie as if real 
people were playing the parts, albeit with CGI.
"I genuinely dunno if we'll get a better example of why AI art is garbage than someone taking one of the most 
purposefully made, beautifully animated films in history and reducing it to a bunch of boring looking shots that are 
barely connected but somehow all look the same," a fan wrote on X.
OpenAI didn't respond to a question on Thursday about whether it had a license.
Josh Weigensberg, a partner at the law firm Pryor Cashman, said that one question the Ghibli-style AI art raises is 
whether the AI model was trained on Miyazaki or Studio Ghibli's work. That in turn "raises the question of, 'Well, do 
they have a license or permission to do that training or not?'" he said.
Weigensberg added that if a work was licensed for training, it might make sense for a company to permit this type 
of use. But if this type of use is happening without consent and compensation, he said, it could be "problematic."
>>>>>>> c98f417 (update data file):extract_text.txt
Page 4 of 4
ChatGPT's Studio Ghibli AI trend sparks debate over creativity vs copyright violation
Weigensberg added that there is a general principle "at the 30,000-foot view" that "style" is not copyrightable. But 
sometimes, he said, what people are actually thinking of when they say "style" could be "more specific, discernible, 
discrete elements of a work of art," he said. 
don't like the ghibli trend. idk man. something about a particular artist's meticulously crafted style being turned into a 
mass-market on-demand commodity. it doesn't sit right.
is this how it's gonna be from now on? anything good in the world being taken for parts to make slop?
- skeleton (@ThinkingBone)
March 27, 2025
"A Howl's Moving Castle or Spirited Away, you could freeze a frame in any of those films and point to specific 
things, and then look at the output of generative AI and see identical elements or substantially similar elements in 
that output," he said. "Just stopping at, 'Oh, well, style isn't protectable under copyright law.' That's not necessarily 
the end of the inquiry."
Artist Karla Ortiz, who grew up watching Miyazaki's movies and is suing other AI image generators for copyright 
infringement in a case that's still pending, called it "another clear example of how companies like OpenAI just do not 
care about the work of artists and the livelihoods of artists."
"That's using Ghibli's branding, their name, their work, their reputation, to promote (OpenAI) products," Ortiz said. 
"It's an insult. It's exploitation."
Load-Date: March 28, 2025
End of Document
Page 1 of 3
Apple's AI isn't a letdown. AI is the letdown
Apple's AI isn't a letdown. AI is the letdown
Egypt Independent
March 27, 2025 Thursday
Copyright 2025  Egypt Independent Provided by Syndigate Media Inc. All Rights Reserved
Length: 1022 words
Byline: CNN
Body
A version of this story appeared in CNN Business' Nightcap newsletter. To get it in your inbox, sign up for free here.
 New York CNN — 
Apple has been getting hammered in tech and financial media for its uncharacteristically messy foray into artificial 
intelligence. After a June event heralding a new AI-powered Siri, the company has delayed its release indefinitely. 
The AI features Apple has rolled out, including text message summaries, are comically unhelpful.
The critique of Apple's halting rollout is not entirely unfair. Though it is, at times, missing the point.
Apple, like every other big player in tech, is scrambling to find ways to inject AI into its products. Why? Well, it's the 
future! What problems is it solving? Well, so far that's not clear! Are customers demanding it? LOL, no. In fact, last 
year the backlash against one of Apple's early ads for its AI was so hostile the company had to pull the commercial.
The real reason companies are doing this is because Wall Street wants them to. Investors have been salivating for 
an Apple "super cycle" — a tech upgrade so enticing that consumers will rush to get their hands on the new model.
In a rush to please shareholders, Apple made a rare stumble. The company is owning its error, it seems, and has 
said the delayed features would roll out "in the coming year."
Of course, the cryptic delay has only given oxygen to the narrative that Apple has become a laggard in the Most 
Important Tech Advancement in decades.
And that is where the Apple-AI narrative goes off the rails.
AI can only be failed

Page 2 of 3
Apple's AI isn't a letdown. AI is the letdown
There's a popular adage in policy circles: "The party can never fail, it can only be failed." It is meant as a critique of 
the ideological gatekeepers who may, for example, blame voters for their party's failings rather than the party itself.
That same fallacy is taking root among AI's biggest backers. AI can never fail, it can only be failed. Failed by you 
and me, the smooth-brained Luddites who just don't get it. (To be sure, even AI proponents will acknowledge 
available models' shortcomings — no one would argue that the AI slop clogging Facebook is anything but, well, 
slop — but there is a dominant narrative within tech that AI is both inevitable and revolutionary.)
Tech columnists such as the New York Times' Kevin Roose have suggested recently that Apple has failed AI, 
rather than the other way around.
"Apple is not meeting the moment in AI," Roose said on his podcast, Hard Fork, earlier this month. "I just think that 
when you're building products with generative AI built into it, you do just need to be more comfortable with error, 
with mistakes, with things that are a little rough around the edges."
To which I would counter, respectfully: Absolutely not.
Roose is right that Apple is, to put it mildly, a fastidious creator of consumer products. It is, after all, the $3-trillion 
empire built by the notoriously detail-obsessed Steve Jobs.
The Apple brand is perhaps the most meticulously controlled corporate identity on the planet. Its "walled garden" of 
iOS — despised by developers and fair game for accusations of monopolistic behavior, to be sure — is also part of 
the reason one billion people have learned to trust Apple with their sensitive personal data.
Apple's obsession with privacy and security is the reason most of us don't think twice to scan our faces, store bank 
account information or share our real-time location via our phones.
And not only do we trust Apple to keep our data safe, we trust it to design things that are accessible out of the box. 
You can buy a new iPhone, AirPods or Apple Watch and trust that the moment you turn it on, a user-friendly system 
will hold your hand through the setup and seamlessly sync it with your other devices. You will almost never need a 
user manual filled with tiny print. Even your Boomer parents will be able to navigate FaceTime calls with minimal 
effort.
Roose contends, at one point in the episode, that "there are people who use AI systems who know that they are not 
perfect," and that those regular users understand there's a right way and a wrong way to query a chatbot.
This is where we, the people, are apparently failing AI. Because in addition to being humans with jobs and social 
lives and laundry to fold and art to make and kids to raise, we should also learn how to tiptoe around the limitations 
of large language models that may or may not return accurate information to us.
Apple, Roose says, should keep pushing AI into its products and just get used to the idea that those features may 
be unpolished and a little too advanced for the average user.
And again, respectfully, I would ask: To what end?
As Hard Fork co-host Casey Newton notes in the same episode, it's not as if Google or Amazon has figured out 
some incredible use case that's making users rush to buy a new Pixel phone or an Echo speaker.
"AI is still so much more of a science and research story than it is a product story," Newton notes.
In other words: Large language models are fascinating science. They are an academic wonder with huge potential 
and some early commercial successes, such as OpenAI's ChatGPT and Anthropic's Claude. But a bot that's 80 
percent accurate — a figure Newton made up, but we'll go with it — isn't a very useful consumer product.
Back in June, Apple floated a compelling scenario for its newfangled Siri. Imagine yourself, frazzled and running 
late for work, simply saying into your phone: Hey Siri, what time does my mom's flight land? And is it at JFK or 
Page 3 of 3
Apple's AI isn't a letdown. AI is the letdown
LaGuardia? In theory, Siri could scan your email and texts with your mom and give you an answer. That saves you 
several annoying steps of opening your email to find the flight number, copying it, then pasting it into Google to find 
the flight's status.
If it's 100 percent accurate, it's a fantastic time saver. If it is anything less than 100 percent accurate, it's useless. 
Because even if there's a two percent chance it's wrong, there's a two percent chance you're stranding mom at the 
airport, and mom will be, rightly, very disappointed. Our moms deserve better!
Bottom line: Apple is not the laggard in AI. AI is the laggard in AI.
Load-Date: March 27, 2025
End of Document
Page 1 of 3
From spit to bankruptcy: the rise and fall of 23andMe
From spit to bankruptcy: the rise and fall of 23andMe
The Guardian (London)
March 25, 2025 Tuesday 1:17 PM GMT
Copyright 2025 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: GLOBAL; Version:2
Length: 1672 words
Byline: Blake Montgomery
Highlight: Plus: Nvidia bets on AI-powered robots, Musk juggles Tesla and politics, and AI fiction takes over 
Instagram
Body
Hello, and welcome to TechScape. In this week’s edition: 23andMe files for bankruptcy, Nvidia forecasts a fusion of 
AI and robotics, and AI enables the creation of fiction at the pace of social media.
Genetic testing firm 23andMe filed for bankruptcy on Monday. The CEO and co-founder Anne Wojcicki has stepped 
down after several attempts at a buyout. Once valued as high as $5.8bn in 2021, the company’s financial failure is 
the finale to a long decline.
*** My colleague Julia Kollewe reports  :
                     23andMe said late on Sunday that it had started voluntary Chapter 11 proceedings in the US 
Bankruptcy Court for the Eastern District of Missouri to “facilitate a sale process to maximise the value of its 
business”.                   
                     The loss-making company, which provides saliva-based test kits to customers to help them track their 
ancestry, added that it was operating as usual throughout the sale process. “There are no changes to the way the 
company stores, manages, or protects customer data,” it said.                   
I understand the urge to assure customers that there is “no change” to business as usual at 23andMe, but the 
company’s statement bears an unfortunate implication. In late 2023, the company disclosed  that hackers had 
gained access to the personal data of 7 million customers, including their genomes. Not long after the incursion, 
hackers offered to sell the names, addresses and genetic heritage belonging to 1 million 23andMe customers with 
Ashkenazi Jewish heritage on a shadowy dark web forum. Though the hack did not only target Jewish customers, 
the proposed sale gave a grim example of what malicious denizens of net could do with 23andMe customers’ 
information.

Page 2 of 3
From spit to bankruptcy: the rise and fall of 23andMe
One 23andMe participant, a man in Florida who discovered Ashkenazi Jewish heritage in his test, summed up the 
imbalance of the trade-off: “I didn’t know my family was going to potentially be a target. I may have put my family 
and myself in danger for something I did out of curiosity more than anything.”
                         The question for 23andMe customers is what will happen to the trove of genetic data that 23andMe 
has amassed in its years of collecting spit in tubes.                     
The ultimate promise of 23andMe – medicine personalized based on your unique genetic code – has not yet come 
to fruition. In the meantime, knowing the exact breakdown of your genetic ancestry is more novelty than medical 
necessity, and it’s not good business. Sometimes the test just reveals that you’re British, which left at least one 
Guardian writer nonplussed , and you find yourself having given your DNA away.
The question for 23andMe customers is what will happen to the trove of genetic data that 23andMe has amassed in 
its years of collecting spit in tubes. Over the weekend the California attorney general, Rob Bonta, urged the 
company’s users to ask it to “delete your data and destroy any samples of genetic material held by the company”, 
as is their right under the state’s law.
                   More on 23andMe                                                                                        Why I regret using 23andMe: 
I gave up my DNA just to find out I’m British Hackers got nearly 7 million people’s data from 23andMe. The firm 
blamed users in ‘very dumb’ move                                                                                   The stuff of science fiction                   
A series of convergent developments in tech last week have my nose pointed at the future like a hunting dog.
Nvidia  hosted its developer conference in San Jose, California, announcing new and more powerful chips that will 
offer greater computing capacity to artificial intelligence. The AI business, if Chinese model DeepSeek serves as a 
bellwether, is learning to maximize the results it draws from that computing power.
As in any good science fiction blockbuster, a lovable side character made an appearance at the conference. A Star 
Wars-inspired droid named Blue waddled onstage alongside Jensen Huang, the Nvidia CEO, during his keynote to 
say hello. Disney partnered with Nvidia to design and showcase the new bot, which holds in its brain software for 
modeling and processing the physics of its surroundings. Nvidia also announced an AI meant for robots, which 
likewise takes its name from a Disney franchise, Groot N1.
Nvidia’s announcements come as various AI companies make their first public forays into agentic models, which 
can take on tasks for you. Per early reviews, these products are not very adept yet. 
But excitement i for the advent of artificial general intelligence (AGI) is growing, and real preparations are 
happening. More and more people who aren’t AI company CEOs anticipate the arrival of this powerful and versatile 
technology soon. Joe Biden’s top AI adviser, Ben Buchanan, gave an interview  at the start of this month about how 
the US had planned for the widespread arrival of AGI under the previous administration. Soon after, a Times tech 
columnist wrote about why he’s come to believe the AGI hype. 
An agentic AI with the capabilities of AGI plugged into the brain of a robot – baby, that’s a bona fide humanoid, and 
it’s a possibility that’s becoming easier to imagine even without the help of Isaac Asimov.
                   Tesla is struggling while Elon Musk mucks about in the White House                                                                                        
Elon Musk tells Tesla employees to hold on to their stock amid harsh selloff Tesla backer says Musk must reduce 
Trump work, as 46,000 Cybertrucks recalled Tesla stake is no longer Elon Musk’s most valuable asset amid stock 
market sell-off Elon Musk lashes out at US judges as they rule against Doge Trump makes rare admission of 
Musk’s conflicts of interest after Pentagon visit US attorney general to bring charges for Tesla damage, citing 
‘domestic terrorism’                                                                                   New entertainment: Using AI to illustrate 
short-form fiction on Instagram                   
This week on my iPhone, I’m scrolling through the videos of @HolyFool36  on Instagram.
Page 3 of 3
From spit to bankruptcy: the rise and fall of 23andMe
Created by a 26-year-old from Long Island named Dylan (he declined to give his last name), the account posts 
charming, retro and lightly spooky videos daily. They’re usually 90 seconds long. Dylan said he was inspired to 
create the videos by works of dark fantasy (Clark Ashton Smith), Elden Ring and other Dark Souls games, and 
analog horror videos on YouTube. Far from AI slop, the videos offer clever tidbits of the absurd and compelling 
stories in the form of occult instructions. The human touch is evident, though AI serves as the means of production. 
I enjoy them.
“I do the writing myself because I was born with the faculties to do that. I use AI to make the images because I don’t 
have those faculties. It’s a means to an end,” he said.
The account has amassed more than half a million followers since launching in the first half of 2024. It earns money 
via TikTok ads and merch sales, according to Dylan, but he’s kept his full-time job in tech.
“I went from a hobbyist to a niche internet micro celebrity!” he remarked. His fiancee has started an AI art page as 
well.
Dylan’s creative process involves multiple AI tools. He asks Dall-E to make the first draft of the picture in his head 
then runs the result through Midjourney to give it the retro video game sheen. If the story he’s writing requires 
animation, he uses Kling, though most of Holy Fool’s videos consist of collages of still images. All of his material 
features the same background music, a simple electronic synth melody, and the same narrating voice, which he 
generated and customized with ElevenLabs.
Artists across the US and UK have spoken out by the hundreds against the use of AI in the arts and what they see 
as theft by tech giants skirting intellectual property law. Their point is a fair one. Just this past week, the Atlantic  
created a way for authors to search LibGen, a database of pirated books, for their work. Many found their books 
there. Meta employees allegedly downloaded the database from peer-to-peer file sharing networks, a matter 
currently at issue in a copyright suit against the company over how it created its AI model Llama, specifically 
concerning whether the chatbot was trained on copyrighted material. The messages between Meta  staff revealed 
in discovery about downloading the database are damning. Employees said licensing authors’ copyrighted work 
would be too expensive and slow, so they turned to more shadowy means of accessing mammoth amounts of texts 
and received Mark Zuckerberg  ’s personal approval to do so, according to court documents. Meta is worth $1.51tn, 
and Mark Zuckerberg’s personal fortune weighs in at $202bn.
However, none of these artists and authors are doing what the Holy Fool is. None are populating a fictional universe 
with daily short-form videos. Why would they? To create content at the speed that an Instagram feed without AI 
would be a full-time job. For many influencers, it is, but those video creators use their own faces and make videos 
about their real lives. Animating fictional videos so quickly and posting them for free is unlikely to give a worthwhile 
return on investment. All that is to say – there seems to be no labor lost in the creation of these kinds of videos, no 
artist who would otherwise be earning a living but has been replaced by AI. The creation of new kinds of serialized 
fiction seems like a positive use case for AI to me.
                   The wider TechScape                                                                                        Brussels takes action 
against Google and Apple under Digital Markets Act – as it happened Norwegian files complaint after ChatGPT 
falsely said he had murdered his children The best iPhones in 2025: which Apple smartphone is right for you, 
according to our expert Google’s parent to buy cybersecurity group Wiz in its biggest ever deal
Load-Date: March 25, 2025
End of Document
Page 1 of 2
The Electric State X Reviews: Millie Bobby Brown and Chris Pratt starrer leaves netizens dismayed; 'like AI 
slop'
The Electric State X Reviews: Millie Bobby Brown and Chris Pratt starrer 
leaves netizens dismayed; 'like AI slop'
Hindustan Times
March 19, 2025 Wednesday
Copyright 2025 HT Media Ltd. All Rights Reserved
Length: 611 words
Dateline: India 
Body
India, March 19 -- The highly anticipated 2025 science fiction action-adventure film The Electric State was a bold 
venture into a dystopian future, helmed by the Russo brothers - Anthony and Joe Russo - known for their work on 
blockbuster hits like Avengers: Endgame (2019). With a hefty reported budget of $320 million, this adaptation of 
Simon Stalenhag's illustrated 2018 novel was expected to be a cinematic masterpiece. However, reactions from 
netizens suggest that the film has failed to live up to its hype, leaving many disappointed.
Starring Millie Bobby Brown and Chris Pratt, alongside an ensemble cast including Ke Huy Quan, Woody 
Harrelson, and Giancarlo Esposito, The Electric State was touted as a visually stunning and thought-provoking 
narrative. But critics have slammed it as a "soulless Netflix slop" that undermines the essence of Stalenhag's 
original graphic novel.
The film's transition from the illustrated pages of Stalenhag's melancholic world to the silver screen seems to have 
fallen flat for many viewers. One user expressed their frustration, saying, "Today I am mourning Simon Stalenhag's 
The Electric State; a beautiful, melancholy and atmospheric graphic novel that's been 'adapted' into soulless Netflix 
slop. Why did they even buy the rights to the book if they're just going to turn it into that?" For others, the 
disappointment ran deeper. One user remarked, "After serving up what will be a strong contender for the worst 
movie of 2025, it is enough to make one suspect that the Russo Bros are willfully trying to destroy their own careers 
and the studios they work for by deliberately making overpriced, unwatchable, forgettable piles of shit."
The criticism wasn't just limited to the direction or the script, but also the performances of its lead actors. "The 
Electric State (2025) is so bad that whenever a famous actor (there's a bunch) turns up in a supporting role, the 
feeling is less 'hey, good to see you!' and more 'the f*** are you doing here?' Pratt and MBB are Razzie bad, but the 
Russos are the true culprits. Like AI slop," another comment read, suggesting that the performances felt 
disconnected and hollow, perhaps due to a lacklustre script or poor direction.
For some viewers, the film's flaws were most glaring in its conclusion. "The core problem with Electric State can be 
summed up in the final few scenes. Used to be that movie writers didn't require a character to embark on a three-

Page 2 of 2
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Fans Can't Believe Broadcast Decision for College Football Game on Saturday
Long live the Pioneer Football League https://t.co/WTWpnTMQJA
- Pete Wietmarschen (@pete_wiet)
October 12, 2024
"Fire up your AI slop and tell your crazy aunt hello, you've got a date on Facebook tomorrow," another mentioned. 
"Excuse me," said another. 
"Was YouTube unavailable?" another said. 
Facebook provides a free streaming option, which is a nice break from services such as ESPN+. One fan said more 
should follow suit. 
"More FCS schools might need to take this route and stream games on Facebook and Twitter (X) and get off 
ESPN+ lol."
More FCS schools might need to take this route and stream games on Facebook and Twitter (X) and get off ESPN+ 
lol. https://t.co/mGT3z8bYj9
- OVO KEY ひ (@SoupLivingston)
October 12, 2024
The Pioneer Football League also includes Drake, Butler, San Diego, Morehead State, Stetson, Presbyterian, 
Valparaiso, Marist and St. Thomas. 
In actuality, Dayton is 3-1 and Davidson is 4-1, so this is a game of decent PFL teams, although Facebook isn't an 
option you see very often. Kickoff is set for noon ET in Dayton, Ohio, at Welcome Stadium. 
Related: A College Football Upset Happened On Friday Night
Graphic
 
Dayton Flyers mascot Rudy Flyer. Matt Lunsford-Imagn Images
Load-Date: October 12, 2024
=======
The Electric State X Reviews: Millie Bobby Brown and Chris Pratt starrer leaves netizens dismayed; 'like AI 
slop'
minute monologue explaining what you were supposed to take away from the movie. So much for 'Show, don't tell,'" 
one user pointed out. The final moments, apparently laden with clumsy exposition, seemed to strip away any 
nuance the film may have had, leaving audiences with a heavy-handed moral rather than an organic conclusion.
With a budget of $320 million that places The Electric State among the most expensive films ever made, 
expectations were sky-high. Yet, it seems that the Russo brothers - who were once celebrated for their deft 
handling of the Avengers franchise - may have failed to capture the same magic with this science fiction project. 
Despite their track record in blockbuster filmmaking, their attempt at adapting a beloved graphic novel has drawn 
criticism from fans and critics alike. Ultimately, the film appears to have missed the mark, with many reviews 
highlighting its lack of emotional depth, poor character development, and an over-reliance on star power to distract 
from its shortcomings.
Published by HT Digital Content Services with permission from Hindustan Times. For any query with respect to this 
article or any other content requirement, please contact Editor at contentservices@htdigital.in
Load-Date: March 19, 2025
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 2
Google and the AI left behind, by Josep Maria Ganyet
Google and the AI left behind, by Josep Maria Ganyet
CE Noticias Financieras English
March 18, 2025 Tuesday
Copyright 2025 Content Engine, LLC.
All Rights Reserved
Copyright 2025 CE Noticias Financieras All Rights Reserved
Length: 459 words
Body
Google entered the AI race late and badly forced by OpenAI and its launch of ChatGPT in 2022. ChatGPT is the 
fastest adopting platform in history: one million users in five days. Google, however, has two advantages over 
OpenAI: it has all our data, especially if we use GMail and Google Docs, and we search an average of 4.2 times a 
day. Its share is 90.15% of searches.
But all this could go down the drain. The millions of users who in 2022 discovered generative AI saw - erroneously - 
ChatGPT as the evolution of search engines. I myself went through the exercise of using ChatGPT instead of 
Google for a week. The experiment allowed me to see that a chatbot that generates text is not a search engine. 
And the other way around.
By competing with OpenAI with its weapons, Google also competes with itself.
But this is irrelevant. What we're seeing with AI-generated content is that it doesn't need to be perfect to have an 
effect: if it's good enough, it's good enough for enough people. This is the phenomenon of AI slop, a derogatory 
concept that designates all low-quality AI-generated content. We could translate it as AI left behind.
If enough users perceive ChatGPT as a search engine, albeit a sloppy one, Google could have the end of Kodak, 
which had invented the digital camera in 1975 and decided to keep it in a drawer so as not to cannibalize its 
business.
Picking at the wound, ChatGPT has incorporated web search: at any point in a conversation we can tell it to do a 
search and summary for us. Or a socials paper. Or an article for LinkedIn.
Aware of this and after hesitant beginnings, Google put all its intelligence on the grid to enter the melee with 
OpenAI; a vicarious melee with Microsoft, which has invested 13 billion and resources in the cloud.
The latest fruit of this collaboration is Google's search engine AI Mode (currently only available to Google One 
subscribers). Robby Stein, vice president of search, says, "You can ask anything and get a useful AI-based answer, 
with the ability to go further with follow-up questions and useful web links."
The key word is possibility. In a conversation with Google we will be able to refine the result as much as we want 
through further questions and get a summary, a social paper or an article for LinkedIn. And if the results are good 
enough that enough people think they are good, who will click on the link to go to the sources? The possible 
becomes improbable.

Page 2 of 2
Google and the AI left behind, by Josep Maria Ganyet
Google made public this month that it served 5 trillion searches in 2024, 20% more than in 2022, the year of 
ChatGPT's breakthrough. The paradox is that Google, in competing with OpenAI with its weapons, is also 
competing with itself.
In the photo, for the moment, Google wins. A photo taken, of course, with an analog Kodak.
Load-Date: March 27, 2025
End of Document
Page 1 of 3
From Neva to A Highland Song, the Baftas are a reminder of how creative games can be
From Neva to A Highland Song, the Baftas are a reminder of how creative 
games can be
The Guardian (London)
March 12, 2025 Wednesday 3:00 PM GMT
Copyright 2025 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: GAMES; Version:1
Length: 1621 words
Byline: Keza MacDonald
Highlight: From a magical realist gem to a environmentalist action game, the titles up for prizes at the industry’s 
classiest awards are a welcome reminder of its creative vivacity in tough times
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
The truth is, it's getting harder to describe the extent to which a meaningful percentage of Americans have 
dissociated from reality. As Hurricane Milton churned across the Gulf of Mexico last night, I saw an onslaught of 
outright conspiracy theorizing and utter nonsense racking up millions of views across the internet. The posts would 
be laughable if they weren't taken by many people as gospel. Among them: Infowars' Alex Jones, who claimed that 
Hurricanes Milton and Helene were "weather weapons" unleashed on the East Coast by the U.S. government, and 
"truth seeker" accounts on X that posted photos of condensation trails in the sky to baselessly allege that the 
government was "spraying Florida ahead of Hurricane Milton" in order to ensure maximum rainfall, "just like they did 
over Asheville!"
As Milton made landfall, causing a series of tornados, a verified account on X reposted a TikTok video of a massive 
funnel cloud with the caption "WHAT IS HAPPENING TO FLORIDA?!" The clip, which was eventually removed but 
had been viewed 662,000 times as of yesterday evening, turned out to be from a video of a CGI tornado that was 
originally published months ago. Scrolling through these platforms, watching them fill with false information, 
harebrained theories, and doctored images-all while panicked residents boarded up their houses, struggled to 
evacuate, and prayed that their worldly possessions wouldn't be obliterated overnight-offered a portrait of American 
discourse almost too bleak to reckon with head-on.
Even in a decade marred by online grifters, shameless politicians, and an alternative right-wing-media complex 
pushing anti-science fringe theories, the events of the past few weeks stand out for their depravity and nihilism. As 
two catastrophic storms upended American cities, a patchwork network of influencers and fake-news peddlers have 
done their best to sow distrust, stoke resentment, and interfere with relief efforts. But this is more than just a 
misinformation crisis. To watch as real information is overwhelmed by crank theories and public servants battle 
death threats is to confront two alarming facts: first, that a durable ecosystem exists to ensconce citizens in an 
alternate reality, and second, that the people consuming and amplifying those lies are not helpless dupes but willing 
participants.

Page 2 of 3
I'm Running Out of Ways to Explain How Bad This Is
[Read: November will be worse]
Some of the lies and obfuscation are politically motivated, such as the claim that FEMA is offering only $750 in total 
to hurricane victims who have lost their home. (In reality, FEMA offers $750 as immediate "Serious Needs 
Assistance" to help people get basic supplies such as food and water.) Donald Trump, J. D. Vance, and Fox News 
have all repeated that lie. Trump also posted (and later deleted) on Truth Social that FEMA money was given to 
undocumented migrants, which is untrue. Elon Musk, who owns X, claimed-without evidence-that FEMA was 
"actively blocking shipments and seizing goods and services locally and locking them away to state they are their 
own. It's very real and scary how much they have taken control to stop people helping." That post has been viewed 
more than 40 million times. Other influencers, such as the Trump sycophant Laura Loomer, have urged their 
followers to disrupt the disaster agency's efforts to help hurricane victims. "Do not comply with FEMA," she posted 
on X. "This is a matter of survival."
The result of this fearmongering is what you might expect. Angry, embittered citizens have been harassing 
government officials in North Carolina, as well as FEMA employees. According to an analysis by the Institute for 
Strategic Dialogue, an extremism-research group, "Falsehoods around hurricane response have spawned credible 
threats and incitement to violence directed at the federal government," including "calls to send militias to face down 
FEMA." The study also found that 30 percent of the X posts analyzed by ISD "contained overt antisemitic hate, 
including abuse directed at public officials such as the Mayor of Asheville, North Carolina; the FEMA Director of 
Public Affairs; and the Secretary of the Department of Homeland Security." The posts received a collective 17.1 
million views as of October 7.
Online, first responders are pleading with residents, asking for their help to combat the flood of lies and conspiracy 
theories. FEMA Administrator Deanne Criswell said that the volume of misinformation could hamper relief efforts. "If 
it creates so much fear that my staff doesn't want to go out in the field, then we're not going to be in a position 
where we can help people," she said in a news conference on Tuesday. In Pensacola, Florida, Assistant Fire Chief 
Bradley Boone vented his frustrations on Facebook ahead of Milton's arrival: "I'm trying to rescue my community," 
he said in a livestream. "I ain't got time. I ain't got time to chase down every Facebook rumor  We've been through 
enough."
It is difficult to capture the nihilism of the current moment. The pandemic saw Americans, distrustful of authority, 
trying to discredit effective vaccines, spreading conspiracy theories, and attacking public-health officials. But what 
feels novel in the aftermath of this month's hurricanes is how the people doing the lying aren't even trying to hide 
the provenance of their bullshit. Similarly, those sharing the lies are happy to admit that they do not care whether 
what they're pushing is real or not. Such was the case last week, when Republican politicians shared an AI-
generated viral image of a little girl holding a puppy while supposedly fleeing Helene. Though the image was clearly 
fake and quickly debunked, some politicians remained defiant. "Y'all, I don't know where this photo came from and 
honestly, it doesn't matter," Amy Kremer, who represents Georgia on the Republican National Committee, wrote 
after sharing the fake image. "I'm leaving it because it is emblematic of the trauma and pain people are living 
through right now."
Kremer wasn't alone. The journalist Parker Molloy compiled screenshots of people "acknowledging that this image 
is AI but still insisting that it's real on some deeper level"-proof, Molloy noted, that we're "living in the post-reality." 
The technology writer Jason Koebler argued that we've entered the "~Fuck It' Era" of AI slop and political 
messaging, with AI-generated images being used to convey whatever partisan message suits the moment, 
regardless of truth.
This has all been building for more than a decade. On The Colbert Report, back in 2005, Stephen Colbert coined 
the word truthiness, which he defined as "the belief in what you feel to be true rather than what the facts will 
support." This reality-fracturing is the result of an information ecosystem that is dominated by platforms that offer 
financial and attentional incentives to lie and enrage, and to turn every tragedy and large event into a shameless 
content-creation opportunity. This collides with a swath of people who would rather live in an alternate reality built 
=======
It’s easy to feel a bit beset by doom these days. The other week, I watched the heinous AI-generated “Trump Gaza” 
video  and was so appalled that I impulse-bought a kayaking guide book. It felt like the only sane response was to 
take to the water and paddle away.
Video games are a reliable antidote to existential doom, but layoffs, corporate homogenisation and AI slop are all 
encroaching on my safe haven, making it more difficult to get a brief reprieve from what’s happening in the outside 
world. Thank God, then, for the Bafta games awards nominations, which reliably remind me that video games are 
pretty great, actually.
The 2025 picks were announced  last week (right after my newsletter deadline, as longtime readers will know is 
now tradition). In my opinion, Bafta’s event is the classiest and least commercial of the gaming awards shows, and 
its judging panels, with a mix of video game industry professionals and specialists from Bafta’s membership and 
beyond, usually come out with the broadest range of picks. I always see a lot of what I personally love about video 
games in these nominations: their sheer creative variation and vivacity. (Disclosure: over the years I’ve been 
involved with these judging panels in various capacities, but not in 2025.) 
The eligibility period runs from November 2023 to November 2024, so there are no nominations for the superb 
Indiana Jones and the Great Circle. (I feel so sorry for great games that come out in December.) One of my 
favourites I played made the cut: A Highland Song , a magical-realist game about running through the Scottish 
mountains, is up for best British game, alongside another Scottish-set game called Still Wakes the Deep, a cosmic 
horror thriller set on a North Sea oil rig. Yorkshire-ish comedy Thank Goodness You’re Here!  is also up for this 
award, as are Lego Horizon Adventures, Paper Trail and Hellblade II.

Page 2 of 3
From Neva to A Highland Song, the Baftas are a reminder of how creative games can be
Hellblade II is actually the most-nominated game overall, appearing in 11 categories. Still Wakes the Deep, 
meanwhile, appeared in eight, and Thank Goodness You’re Here in seven. If I may be allowed some very mild 
patriotism, Britain’s games industry should be very proud of its output last year, which was overall a horrid one  for 
those working in the business of play.
Delightfully, Thank Goodness You’re Here! made it into the best game category with Astro Bot, Black Myth: 
Wukong, Balatro, Helldivers 2, and Zelda: Echoes of Wisdom, a game that I liked less, apparently, than almost 
everyone else.  There are a bunch of big games here in various categories, but what I like about the Baftas is that 
indie games aren’t relegated to their own specific category: they appear everywhere, resulting in an enjoyably 
unpredictable slate. The stop-motion submarine puppet adventure game Harold Halibut  and the warrior-and-wolf 
environmentalist action game Neva  (a personal fave) are up for the artistic achievement award, next to big titles 
including Astro Bot and Wukong.
The ambiguously named “games beyond entertainment” category is always my favourite to peruse, partly because 
of the nebulous definition: these are all games with some kind of message or intended wider meaning. We have 
Kind Words, in which you send nice messages to strangers or send your worries out into the world. There’s Botany 
Manor, about exploring the home of a Victorian botanist. Tales of Kenzera: Zau was informed by its director’s grief 
after the death of his father. Tetris Forever is a fascinating interactive documentary  about the block-arranging 
game, and an insight into a wild period of video game history. Hellblade is in there, too, presumably because of its 
portrayal of living with psychosis. And then there’s Vampire Therapist, in which you are a cowboy talking the 
immortal undead through their emotional baggage. I had never heard of this game, and will be downloading it 
forthwith.
Last year’s awards were so comprehensively dominated by Baldur’s Gate 3 that the show lacked its usual 
propensity for surprises, but a lot of the categories this year are much tighter. The show is on 8 April at 7pm BST, 
hosted once again by comedian Phil Wang, and pretty much everything on this list of nominations would be a 
worthy winner. That said: if the gloriously clever and maximalist role-playing game Metaphor: ReFantazio doesn’t 
win best narrative, I’ll be fumin’.
                   What to play                   
                     Wanderstop is game is about a formerly fearsome warrior forced to slow the heck down and run a 
whimsical tea shop in a fantasy forest, and she is not happy about it. It’s also a game about burnout. Co-written by 
Davey Wreden (The Stanley Parable, The Beginner’s Guide) and Karla Zimonja (Gone Home), it will speak to 
anyone who has ever overinvested in their work and found the meaning suddenly stripped from their life when they 
can no longer work like they used to. (No idea what you’re talking about.)
                     Available on : PS5, Xbox, PC? Estimated playtime : 10 hours
                   What to read                                                               Inspired by a Bafta survey, I asked a bunch of 
interesting and distinguished people for their most influential video game of all time. No two people picked the same 
game. Most of their selections were so brilliantly esoteric that I felt distinctly boring for picking something relatively 
predictable.                                                                  Sony has been experimenting with AI-powered game 
characters : an AI version of Aloy from Horizon was leaked to the Verge , talking to the player in a synthesised 
voice. Important reminder: Horizon is a story about how greedy technocrats destroyed the earth with the help of AI.                                                                 
There’s a new “official” trailer  for The Last of Us season two, with Pedro Pascal and Bella Ramsay returning as 
heroes Joel and Ellie. Those of us who have played the game will know there is, uh, plenty the trailer doesn’t show 
…                                                                 And speaking of trailers, there’s a 10-minute (yes, 10) trailer for Death 
Stranding 2, which will be released on 26 June. Being a Hideo Kojima game, it looks equal parts creative, confusing 
and utterly bonkers.                                                            What to click                                                                                        
‘A lot worse than expected’: AI Pac-Man clones, reviewed Are AI-generated video games really on the 
horizon? Atomfall, the survival game that draws from classic British sci-fi If we’re going to rank the hottest video 
game characters, let’s not be boring about it | Amelia Tait Expelled! – turning the tables on the private school class 
>>>>>>> c98f417 (update data file):extract_text.txt
Page 3 of 3
From Neva to A Highland Song, the Baftas are a reminder of how creative games can be
hierarchy | ????? Two Point Museum – curate your own fun in this museum management game | ?????                                                                                   
Question Block                   
Reader Robin  provides this week’s question:
                     “                     Here’s a question I can’t get out of my head: how can you play Monster Hunter!? I’m not 
squeamish at all but I could barely get through a training session, which involved hurting a harmless creature 
trapped in an arena … I was disgusted and my son was horrified. Then some innocent creature lay dying and I was 
pulling silly faces and taking photos of the poor thing as it breathed its last.                      And if Monster Hunter 
didn’t do it for you, what has prompted you to walk away from a game?”                   
This is such a valid question! I was vegetarian for 12 years and yet throughout, I happily cut down majestic 
creatures in Monster Hunter and felt proud of my achievements. I am so fascinated by this dichotomy that I wrote a 
whole article about it  when Monster Hunter: World came out in 2018. Forgive me for quoting myself, but here’s 
what I wrote:
 One of the functions of fantasy violence, whether in Monster Hunter or Game of Thrones, is to prompt reflection on 
the role that violence plays in the real world and in human nature. Monster Hunter might involve killing, but it also 
restores humans to the hierarchy of the natural world … Perhaps spending hours of my leisure time pretending to 
be a hunter-gatherer-warrior is an outlet for the slavering carnivore within. 
I am not vegetarian any more, but I fully acknowledge the dissonance between respecting and admiring these 
incredible virtual creatures and then killing them to make fancy helmets. The latest game does a lot of cognitive 
somersaulting in its story to try to make out that killing these dangerous beasts is noble because we do it to protect 
people and the ecosystem. But on a base level, we’re doing it because it’s fun, and that is  pretty gross on one 
level. On another: it’s fantasy. With absolutely no judgment towards fans of first-person shooters, I am personally 
more comfortable with killing virtual dragons than killing virtual people.
On to the second part of your question: one moment in Grand Theft Auto V made me so uncomfortable that I had to 
fetch my partner to play through the scene for me. A scene in the story that involves a hillbilly psycho capturing and 
torturing a guy who is Middle Eastern. You have no choice but to actively participate, and it made me feel 
nauseated. It’s obviously intended to be satirical commentary on the US government’s immediate recourse to 
torture after 9/11, but it massively missed the mark for me.
                     If you’ve got a question for Question Block – or anything else to say about the newsletter – hit reply or 
email us on pushingbuttons@theguardian.com.                    
Load-Date: March 12, 2025
End of Document
Page 1 of 2
PETER HOSKIN reviews Split Fiction: It's stranger than fiction (and twice as fun)!
PETER HOSKIN reviews Split Fiction: It's stranger than fiction (and twice as 
fun)!
MailOnline
March 6, 2025 Thursday 8:10 PM GMT
Copyright 2025 Associated Newspapers Ltd. All Rights Reserved
Section: SHOWBIZ; Version:1
Length: 536 words
Byline: Peter Hoskin
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Facebook was born as a social networking tool exclusively for Harvard students. These days you’d be hard-pressed 
to find many U.S. college students on the platform. 
Over the past decade, Facebook usership among U.S. teens dropped from 71% to 33%. A recently announced 
redesign attempts to recapture these young users, emphasizing already popular aspects like Groups and 
Marketplace while building a TikTok-style “Explore” page. Still, one redesign won’t collect that cache of lost Gen Z 
eyes. 
How Facebook lost Gen Z
Once the cutting edge of technology, Facebook has been relegated to an old-world position by many Gen Zers. 
That’s evident in the gap among usership percentages: In 2023, only 33% of U.S. teens said they used Facebook, 
according to the Pew Research Center. Compare that to the U.S. adult populace, where Facebook is the second-
most-popular social media app at 68%. 
As a company, Facebook seems to recognize this decline. Back in May, it held an event focused on the “next 20 
years” of the app. “We’re still for everyone,” said Tom Alison, Meta’s Facebook head,  according to Mashable. “But 
we also recognize that in order to stay relevant, we have to build for . . . Gen Z.” (Meta did not respond to a request 
for comment.) 
There are several reasons why Gen Zers downgraded Facebook among their apps. Facebook has been embroiled 
in political scandal since 2016, which, for many young people, was the first major election of memory. There was 
the Cambridge Analytica data-scraping conundrum; the Pizzagate conspiracy theory that blew up in-app; and now 
the deluge of AI political slop across the feed. Those woes aren’t going away anytime soon, as former President 
Donald Trump continues to claim that Mark Zuckerberg pledged his support for the Republican candidate’s 2024 
campaign to regain the White House, which Meta has denied. 
While Facebook offers photo and video options, much of the in-app content is text-based. That’s a format Gen Z is 
increasingly moving away from. Of the four apps tracked since 2014, only Facebook and Twitter, another text-
based app, saw user share declines among U.S. teens. Both Snapchat and Instagram, which rely more on images 

Page 2 of 2
Can Facebook win back Gen Z?
and videos, saw increases. When included, video app YouTube dominates these platforms at 93% usage among 
teens. 
Users are primarily drawn to Facebook for connection. That’s reflected in the data: Among Facebook users, 93% 
claim to use the app to keep in touch with friends and family. If your Gen Z peers aren’t on the platform, that ability 
to connect diminishes. Sure enough, in a 2023 survey of Gen Z users from Savanta, “keeping in touch” steadily 
declined over the previous eight years. In 2015, 82% of young people used Facebook to connect; in 2023, that 
figure dropped to just 45%. 
Can this redesign win back Gen Z users?
With the newly announced redesign, Facebook aims to tap into what Gen Z has historically liked. Marketplace is 
one of the app’s most popular features among young people, with many seeing it as a haven of thrift finds. The new 
“Local” tab will pull content from Marketplace, Groups, and Events to create a more geographic feed. 
Facebook is also leaning further into its play for TikTok user share, unifying its content under an “Explore” page 
backed by an endless-scroll algorithm. Facebook Reels, its TikTok knockoff, will be featured on the “Explore” page. 
Facebook isn’t the only platform leaning hard into TikTok strategy; Snapchat recently announced a redesign with 
one unified vertical video feed. 
Whether these redesigns can entice Gen Z users remains to be seen. It’s hard to ditch a reputation for being a “tech 
dinosaur.” But if Facebook wants any sort of longevity, it will need to try.
Link to image
Load-Date: October 9, 2024
=======
Split Fiction (PlayStation, Xbox, PC, £39.99)
Verdict: Too good 
Rating:
Unconstrained tech bros stealing people's best creations and turning them into online AI slop? It could never 
happen in the real world, could it? Nah, surely not.
So well done to Hazelight for imagining such a dystopia - and setting their latest game in it.
At the start of Split Fiction, two authors have their minds picked for ideas by a dodgy tech company.
One, called Mio, specialises in science fiction. The other, Zoe, writes fantasy.
Together, thanks to the vagaries of technological progress, they are sucked into their imaginary universes. And it's 
up to both of them to get out.
And I really do mean both of them. Split Fiction, like much of Hazelight's previous work, is a cooperative game in 
which two players must work together, as Mio and Zoe, to advance.
This cooperation can be performed shoulder-to-shoulder on your sofa, or it can be done over the internet.
But Split Fiction also makes Hazelight's previous work, including the brilliant It Takes Two, seem like a warm-up for 
this main event.

Page 2 of 2
PETER HOSKIN reviews Split Fiction: It's stranger than fiction (and twice as fun)!
It's just so ambitious - and not simply because you and your buddy are bouncing between sci-fi and fantasy 
universes.
Even within each universe, there's incredible variety. You'll do 3D platforming, shooting, puzzle-solving, racing and 
lots, lots more. You'll even game as, well...sausages.
And, somehow, Split Fiction doesn't just cohere; it conquers. Mio and Zoe's story will pull you and your gaming 
partner through to what is one of the most effective - and affecting - conclusions in years. Turns out, the tech bros 
have it wrong. Humanity matters.
Two Point Museum (PlayStation, Xbox, PC, £24.99)
Verdict: Great exhibition 
Rating:
Ah, it's another Two Point game. Good. The previous, er, two - Two Point Hospital and Two Point Campus - were a 
total blast. 
Here were successors to the classic management games of the 1990s - games such as Theme Park and Sim City - 
only with better graphics, better mechanics and a much better sense of humour.
Two Point Museum transplants the action to (you'll have guessed already) a museum. Like its predecessors, it is 
polished and funny. 
Like its predecessors, it has you expanding your operation room by room, item by item, all in the hope of 
maximising things like customer happiness, scientific progress and the all-important bottom line.
Which makes Museum sound like more of the same. Except that's not quite right.
Not only does this game benefit from refinements made over years, it's also more varied than Hospital and even 
Campus.
This is true of Museum's exhibits, which range from aquarium fish to alien artefacts, meaning that you're never 
stuck with just one dusty type of establishment.
But it's also true of Museum's gameplay, which gives your budding museum director more to do. 
I particularly enjoyed the option to send curators off on expeditions to find new exhibits - expeditions from which 
they might never return...
And if they do return? 
Sure, Two Point Museum seems to say, they might have taken an artefact from some fictional otherland - but what 
if that artefact is a frozen caveman who starts smashing stuff up as soon as he thaws? 
One way or another, the past always catches up with us.
Load-Date: March 7, 2025
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 2
Trump’s rollback of AI guardrails leaves US workers ‘at real risk’, labor experts warn
Trump’s rollback of AI guardrails leaves US workers ‘at real risk’, labor 
experts warn
The Guardian (London)
March 4, 2025 Tuesday 2:00 PM GMT
Copyright 2025 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: US NEWS; Version:1
Length: 835 words
Byline: Michael Sainato
Highlight: Measures issued by Joe Biden were swiftly repealed, leaving employees vulnerable to downgraded jobs
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Readers will know books with the Author's Guild label are different-and better-than AI slop.
The Author's Guild is making it clear who's behind the content you're reading, and its new campaign may become 
the equivalent of slapping an "organic produce" label on an apple and pricing it accordingly. In an era when authors 
are suing AI companies for alleged "theft" of their intellectual property, major newspapers and record labels are 
doing the same, and as the content spat out by AIs becomes more convincingly realistic, the Author's Guild is trying 
something different. The organization, said to be the oldest professional organization for writers in the U.S., is going 
to offer a new certificate for the covers of books released by its 15,000 members, reports Marketplace: it'll say 
"Human Authored."
The label will be about the same size as book stickers denoting literary awards, or being selected for a celebrity 
book club, Marketplace explains. The site quotes Douglas Preston, bestselling novelist, nonfiction writer and 
member of the Authors Guild Council, offering this explanation. It's not just to "prevent fraud and deception," but 
also to show "how important storytelling is to who we are as a species," Preston said. He added, "we're not going to 
let machines elbow us aside and pretend to be telling us stories, when it's just regurgitating literary vomitus." 
Those are some sweet-and even spicy-words. Preston is an acclaimed writer, after all. His rallying cry taps into one 
of the key arguments against certain uses of AI, which is to generate meaningless content to grab attention, fill web 
pages, and even sneakily grab advertising revenues away from sites offering genuine "Human Authored" content. 
This content is already known as "AI slop," and it's so pervasive that a recent study showed Google's search 
algorithms can be gamed to make them prefer slop over meaningful human-made content. 
"Human Authored" is a clever move, if you think about it. It's the inverse of the "made by AI" labels that tech 
industry figures think need to be slapped on stuff spewed out by a generative AI system. The Author's Guild is also 
tapping into the same vibe as "organic product" labels on food, or handmade products sold on Etsy, clearly from a 
small or solo entrepreneur's business. The difference, based on the underlying sensibility of the Author's Guild 
mark, is that it's celebrating the thumbprints in the clay pot, or the cute handwritten labels a customer sees when 
their purchase arrives at their door. Things that lack the smooth mass-made quality of most factory-produced 
wares, but carry that emotional tingle of being created by people with a pulse are distinctive.
=======
Donald Trump’s rollback of basic guardrails for artificial intelligence leaves US workers “at real risk”, labor experts 
have warned.
Protections introduced under Joe Biden to ensure the safe, secure and trustworthy development and use of AI were 
swiftly repealed by the Trump administration – as top executives outlined sweeping plans to overhaul the labor 
force.
Today’s CEOs are likely the last to “manage a workforce of only human beings”, Salesforce boss Marc Benioff 
claimed  at Davos. Mark Zuckerberg, CEO of Meta Platforms, meanwhile told  podcaster Joe Rogan that its AI will 
“probably” be able to act as “a sort of midlevel engineer” as soon as this year.
“Workers are at a relatively weak point,” said top labor scholar David Madland, who argued the AI protection 
rollbacks under Trump “made it even more so that workers are at the whims of their employers on how AI is 
deployed”.
“I think they’re going to be at real risk of having their jobs degraded in many different kinds of ways,” said Madland, 
a senior fellow and senior adviser to the American Worker Project at Center for American Progress. “The Biden 
administration rules provided very modest – only very modest – protections, but they were better than nothing.”
Under Trump the US government is “promoting and encouraging AI innovation to ensure America remains the 
leader in this cutting edge technology”, Victoria LaCivita, White House office of science and technology policy 
Sspokesperson, said in a statement. “The Trump administration is committed to ensuring the continued American 
leadership in AI.”
>>>>>>> c98f417 (update data file):extract_text.txt

Page 2 of 2
Trump’s rollback of AI guardrails leaves US workers ‘at real risk’, labor experts warn
Among the guidelines removed  by the Trump administration were directives issued  by the US Department of 
Labor to ensure employers create and implement AI in the workplace without diminishing job quality or violating 
workers’ rights. Significant cuts are also expected  at the US AI Safety Institute, as part of Trump’s efforts to cull the 
federal workforce.
“It strips out consideration of civil rights, job quality and the impact on workers,” said Josh Boxerman, government 
affairs manager for the National Employment Law Project.
He pointed to concerns about the degrading quality of jobs, rather than their displacement. AI is increasingly being 
used to manage workers, from impacts on surveillance and productivity pressures on Amazon warehouse workers, 
algorithm management of ride share drivers with gig apps such as Uber and Lyft, and recent growing trends of gig 
work in the healthcare industry, including algorithms used to mass deny health insurance claims and apps using  AI 
to undercut pay and working conditions for nurses.
“The story of displacement right now is not just workers being replaced by robots or work being automated away, 
but also workers being replaced or jobs being replaced by jobs of lower quality,” said Boxerman. Trump, he noted, 
won back the presidency last year after successfully seeking support from the working class.
Many of the tech companies at the heart of the AI boom, including Meta, Google and Amazon, lined up to support 
Trump’s inauguration with donations. The OpenAI co-founder Sam Altman personally donated $1m. 
Recent polling  by Pew Research found 52% of US workers are worried about the future impacts of AI in the 
workplace, with 32% expecting it will lead to fewer job opportunities for them.
“In the absence of strong guardrails, those tools are creating real-world harms when companies and government 
agencies use them to help decide who gets a job , who gets a loan, who goes to jail , and a host of other sensitive 
decisions,” wrote  attorneys with the American Civil Liberties Union on Trump’s AI executive orders.
The use of AI, and its impact on workers, was front on mind when the Writers Guild of America and actors 
represented by Sag-Aftra secured their 2023 contracts. 
John Rogers, a screenwriter and board member with the Writers Guild of America West, said: “The general concern 
is always that corporations will attempt to maximize the profits at the expense of the workers. AI is the dream of 
capital everywhere, which is it would be nice to have income with no workers. So we always have to be aware of 
that.”
As AI progresses and its use expands, there are ongoing concerns about writers’ work being stolen to develop the 
technology, he said. “Right now, there is no consequence for companies that are valued at billions of dollars being 
valued only because they stole other people’s work,” added Rogers.
“There are arguments to be made that when a new technology comes along that makes things better or more 
efficient, you should embrace it,” he said. “This doesn’t make things better. It doesn’t do things more efficient. It 
doesn’t make things cheaper. The consumers don’t want AI slop. The creators don’t want their stuff sold for AI.
“The only people who want AI are the people making AI, who need people to invest billions of dollars in it. And right 
now, not just the creators, but also the consumers, are suffering from it.”
The labor department was contacted for comment.
Load-Date: March 4, 2025
End of Document
Page 1 of 3
Generative AI is most useful for the things we care about the least
Generative AI is most useful for the things we care about the least
Sunjournal.com
March 2, 2025 Sunday
Copyright 2025 Lewiston Sun Journal  All Rights Reserved
Length: 1139 words
Byline: By John P. Nelson Georgia Institute of Technology
Body
Generative AI tools such as ChatGPT and Midjourney can produce text, images and videos far more quickly than 
any one person can accomplish by hand.
But as someone who studies the societal impacts of AI, I've noticed an interesting trade-off: The technology can 
certainly save time, but it does so precisely to the extent that the user is willing to surrender control over the final 
product.
For this reason, generative AI is probably most useful for things we care about the least.
Ceding creative control
Let's use the example of AI image generators. You probably have a rough idea of how they work. Just type what 
you want - "a panda surfing," "a piece of toast that is also a car" - and the generative tool draws it.
But this glosses over the countless possible iterations of the desired image.
Will the image appear as a watercolor painting or a pencil sketch? How lifelike will the panda be? How big is the 
wave? Is the toast-car parked or moving? Is there anyone inside of it?
When the images are generated, these questions have been answered - but not by the user. Rather, the generative 
AI tool has "decided."
Of course, the user can be more specific: Imitate the style of Monet. Make the wave twice the height of the panda. 
Maybe the panda should look worried, since it isn't used to surfing.

Page 2 of 3
Generative AI is most useful for the things we care about the least
You can also pop open an image editor and modify the output yourself, down to the individual pixel. But, of course, 
drafting detailed instructions and revising the image take time, effort and skill. Generative AI promises to lighten the 
load. But as every manager knows, exercising control is work.
The devil is in the details
In all art and expression, power lies in the details.
In great paintings, not every brushstroke is planned - but each is carefully considered and accepted. And its overall 
effect on the viewer depends on all those considered brushstrokes together.
Filmmakers shoot take after take of the same scene, each subtly or radically different. Only a small fraction of that 
footage makes it into the final cut - the fraction that the editors feel does the job best. Great artists use their 
judgment to ensure every detail helps to achieve the effect they want.
Of course, there's nothing new about putting someone else in charge of the details. People are used to delegating 
authority - even about matters of expression - to marketers, speechwriters, social media managers and the like.
Generative AI makes a new sort of contractor available. It's always on call, and in certain ways it is very technically 
competent.
But compared with skilled humans, it has a limited ability to understand what you want. Moreover, it lacks intention, 
contemplation and the comprehensive mastery of detail that yield great expressive achievements - or even the 
comprehensive idiosyncrasy that spawns very unique ones.
Ask ChatGPT for a film script, plus casting and shooting instructions. It will give you neither Francis Ford Coppola's 
masterpiece "The Godfather" nor Tommy Wiseau's bizarre "The Room."
You could, perhaps, approach a masterpiece, or a true oddity. But to do so, you'd have to exercise more and more 
time, more and more effort, and more and more control.
An era of 'cheap speech'
What generative AI makes possible, above all, is low-effort, low-control expression.
In the time I took to write and revise this article, I could have used ChatGPT to generate 200 grammatically correct, 
well-structured articles, and then I could have posted them online without even reading them. I wouldn't have had to 
carefully parse each word and decide whether it really helped me make my point. I wouldn't have even had to 
decide whether I agreed with any of the AI-generated write-ups.
This is not a merely hypothetical example. Low-quality, AI-generated e-books of ambiguous provenance are 
already making their way into online vendors' catalogs - and into the libraries those vendors serve.
Similarly, using image generators, I could now flood the internet with superficially appealing images, dedicating only 
a fraction of a second to decide whether any of them express what I want them to express or achieve what I want 
them to achieve.
But in doing so, I would not just be skipping over drudgery. Writing, drawing and painting are not just labor but 
processes of considering, reviewing and deciding exactly what I want to put out into the world. By skipping over 
those processes, I surrender that decision-making process to the AI tool.
Some scholars argue that the internet has produced an era of "cheap speech." People no longer have to invest a lot 
of resources - nor even face the judgment of their neighbors - to broadcast whatever they want to the world.
Page 3 of 3
Generative AI is most useful for the things we care about the least
With generative AI, expression is even cheaper. You don't even have to make things yourself to put them out into 
the world. For the first time in human history, the ability to produce writing, art and expression has been decoupled 
from the necessity of actually paying attention to what you're making or saying.
When intention and effort matter
I suspect that great art, journalism and scholarship will still demand great attention and effort. Some of that effort 
may even include custom-developing AI tools tailored to an individual artist's concerns.
But unless people become much better at curation, great work will be increasingly difficult to locate amid the flood 
of low-effort content, which is also known as "AI slop."
It's appropriate that generative AI becomes more useful the sloppier its users are willing to be - that is, the less they 
care about the details.
I could end with some dire prognosis - that working artists and writers will be replaced with mediocre automation, 
that online discourse will get even stupider, that people will isolate themselves in personalized cocoons of AI-
generated media.
All these things are possible. But it's probably more useful to offer a suggestion to you, the reader.
When you need an image or a piece of writing, take a moment to decide: How important are the details? Would the 
process of making this yourself, or working with a collaborator or contractor, be useful? Would it yield a better 
output, or give me the chance to learn, or begin or strengthen a relationship, or help you reflect on something 
important to you?
In short, is it worth putting in real care and effort? The answer will not always be yes. But it often will.
Art, writing, films - these are not just products, but acts. They are things humans make, through a process of 
thousands of little decisions that encompass what we stand for and what we want to say.
So when it comes to art, expression and argument, if you want it done right, it's probably still best to do it yourself.
This article is republished from The Conversation under a Creative Commons license. The Conversation is 
an independent and nonprofit source of news, analysis and commentary from academic experts. 
Load-Date: March 2, 2025
End of Document
Page 1 of 2
Voices: Trump's fake AI video of him relaxing in Gaza with Netanyahu is a nightmare look inside his mind
Voices: Trump's fake AI video of him relaxing in Gaza with Netanyahu is a 
nightmare look inside his mind
The Independent (United Kingdom)
February 27, 2025 Thursday 11:53 AM EST
Copyright 2025 Independent Print Ltd  All Rights Reserved
Section: ISRAEL NEWS & MIDDLE EAST NEWS
Length: 805 words
Byline: Richard Hall
Body
The video opens with a child picking through the ruins of Gaza while a gunman stands menacingly over him. A pool 
of blood appears out of nowhere. 
The words "What's next?" appear in large letters, and a terrifying insight into Donald Trump's vision for Gaza follows 
in the form of an AI-generated slop reel, shared by the president himself. 
In a few short seconds, the landscape is transformed into Trump's idea of paradise: beaches, brand-new hotels, 
restaurants and sports cars. A gurning Elon Musk is devouring some kind of dip, Donald Trump is pawing at a belly 
dancer and then, inexplicably, baring his nipples on a sun lounger alongside Benjamin Netanyahu. 
Trump's name and image appear throughout the dizzying series of clips on hotels, souvenirs, and in the form of a 
giant golden statue, as is his wont. 
Cash rains down at random intervals, Musk gobbles more indistinguishable dip, a child carries a golden ballon of 
Trump's head, bearded belly dancers sway on the beaches and an eerie soundtrack with a robotic voice declares 
"Trump Gaza is finally here." 
The Palestinians who have lived in Gaza for countless generations are never seen again after those first frames - 
they have presumably been swept away with the rubble to some unknown place. The graves of tens of thousands 
killed by Israel's massive bombardment of the strip appear to have been paved over and replaced by restaurants.   
Trump shared the video on his Truth Social network on Tuesday night, prompting outrage, mockery and confusion.  
AI-generated videos are not yet sophisticated enough to make any sort of sense - they are akin to a fever dream 
where nothing feels real, where all logic is suspended, and random firings of code produce surreal glitches. The 
same is true of Trump's vision for Gaza. 

Page 2 of 2
Voices: Trump's fake AI video of him relaxing in Gaza with Netanyahu is a nightmare look inside his mind
Link to Image
After trying and failing to explain his shocking plan for the bombed-out strip using words and speech, he has now 
turned to ramblings of an unknown algorithm, likely prompted by a bored teenager in some far corner of the world, 
to translate for him.
It is somehow even worse than his previous efforts to sell the idea. Trump's Gaza, the video suggests, is so garish 
that it would make Dubai look like Gary, Indiana. It is ethnic cleansing packaged as a slick real estate promotional 
video.
The video is only 30 seconds long, but it leaves out several steps that would have to occur between the present-day 
Gaza and Trump's end call - namely the forcible removal of nearly two million Palestinians and likely another war 
more devastating than the last. 
Trump's allies used to struggle to explain his all-caps tweets when cornered by reporters in the halls of Congress. 
Now they have to interpret his imaginary golden statues and Musk's insatiable appetite for dips. The media, too, is 
forced to entertain his teenager-like trolling. 
America's adversaries used to have to spend billions of dollars to figure out what the president of the United States 
was truly thinking. Now they need only to log on to Truth Social in the early hours of the morning to confirm their 
worst fears. 
It's a terrifying insight into the president's mind. While Palestinians in Gaza are still picking out bodies from the 
rubble, while babies are freezing to death in the bitter cold because their homes have been destroyed, Trump is 
dreaming up ways to enrich himself from the ruins. 
Trump promised unparalleled transparency in his second term, but no one expected to learn this much about how 
he thinks. 
It also says something about his corrosive media diet. During his first term, Trump would park himself in front of a 
television for hours a day watching Fox News and blasting out missives in reaction to whatever scraps of news he 
could see. Today, he is consuming content from the most unhinged corners of the internet. 
Link to Image
The most powerful man in the world would rather watch fan edits of his most deranged ideas than read intelligence 
briefings from the CIA.  
The content of the video is disturbing enough, but what it represents for America's place in the world is awful too. 
Many believe the growing prevalence of these videos is a sign of the so-called "enshittification" of the internet. It's a 
term coined by tech critic Cory Doctorow and commonly used to describe the degradation of online platforms into 
uselessness. Facebook is often used as a prime example, primarily because it has become awash with AI slop 
similar to the video Trump shared. 
Those videos are usually shared by users of a certain age across Mark Zuckerberg's platform, many of whom are 
blissfully unaware that what they are sharing is AI-generated. The platform is now a stream of unreality and fakery, 
and 78-year-old Trump is not immune to this phenomenon. 
By sharing his unfiltered fever dreams with the world, Trump is heralding the enshittification of the presidency. 
Load-Date: February 27, 2025
End of Document
Page 1 of 2
Call of Duty maker Activision confirms AI usage in games; how this Steam policy may be behind it
Call of Duty maker Activision confirms AI usage in games; how this Steam 
policy may be behind it
The Times of India (TOI)
February 26, 2025 Wednesday
Copyright 2025 Bennett Coleman & Co. Ltd. All Rights Reserved
Section: GAMING
Length: 387 words
Byline: TOI Tech Desk
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
There has been  no shortage of gut-wrenching photographs from communities in the southeast devastated by 
Hurricane Helene, which caused extreme flooding and killed at least 215 people - pictures of houses destroyed, 
families trapped on rooftops, wreckage from mudslides and roads washed out by torrential rains. But rather than 
focus on the actual victims or damage, many right-wing influencers and politicians have extended their sympathies 
to a nonexistent girl and her puppy (who is also not real).
The AI-generated image they're sharing depicts a crying girl in a boat, seemingly alone except for the little dog 
she's clutching. She wears a lifejacket and appears to be adrift on floodwaters caused by a major storm. Sen. Mike 
Lee of Utah posted the picture on X on Thursday, writing "Caption this photo," apparently inviting his followers to 
vent their outrage at the Biden-Harris administration for allowing American children to suffer such misery on their 
watch. After users pointed out that he'd fallen for AI slop, he deleted the picture. (The image originated on the 
Trump web forum Patriots.win, where several users immediately recognized it as the product of an AI model.)
Based Senator Mike Lee deleted this. Because someone told him this viral MAGA photo is AI and not Kamala 
abandoning kids and puppies. pic.twitter.com/DhXZB9j9k6
- Ron Filipkowski (@RonFilipkowski) October 3, 2024
Others, however, have left the misleading picture up on their social media accounts - and some are defending it as 
an accurate representation of Helene's effects even though it's fake. Far-right conspiracy theorist and Donald 
Trump associate Laura Loomer called the image "sad," quote-tweeting a post from Buzz Patterson, columnist for 
the conservative blog RedState, who wrote of the picture: "Our government has failed us again." Neither have taken 
their posts down as of press time. Amy Kremer, RNC National Committeewoman for the Georgia GOP and co-
founder of Women for Trump, tweeted on Thursday that the image had been "seared into my mind."
Informed that she was not looking at an authentic photo, Kremer doubled down. "Y'all, I don't know where this photo 
came from and honestly, it doesn't matter," she replied. "There are people going through much worse than what is 

Page 2 of 2
Right-Wingers Heartbroken by Picture of Little Girl Who Doesn't Exist
shown in this pic. So I'm leaving it because it is emblematic of the trauma and pain people are living through right 
now." A large anonymous blue-check account on X that routinely attacks Democrats did remove the picture but 
similarly argued: "Even though that image was AI, it spoke a truth about the disregard Harris and Biden have for 
ordinary Americans, as evidenced by their criminal non-response to Helene." Another X user posted a since-
deleted screenshot of a more succinct response from an apparent family member advised that the image was 
bogus. "Who cares," they answered.
The little girl and her puppy - there are AI-generated variants of the more viral image floating around as well - have 
been widely presented by MAGA world as evidence of a failed disaster response in the aftermath of Helene. Similar 
fake images depict girls or women clutching Bibles as floods rage around them. Trump himself is pushing lies about 
the U.S. government not being able to fund relief efforts, adding an overtone of racism with the groundless claim 
that the White House "stole" money from the Federal Emergency Management Agency (FEMA) and "spent it all on 
illegal migrants." (The irony being that in 2019, the Trump administration itself redirected millions in disaster funds, 
during hurricane season, to pay for detention centers at the border.)
FEMA has said in a statement that it does have enough money for "immediate response and recovery needs." Yet 
the supposed scandal has Republicans outraged at the idea that Americans impacted by the hurricane are being 
denied help because Democrats funneled resources to immigrants. "So Kamala doesn't have enough money for 
this child?" fumed a MAGA-affiliated X user who shared the AI-generated girl. "For Americans that lost everything 
they have? I can't hate this administration enough."
The barrage of AI junk from Trump supporters follows a similar trend last month, when the former president, his 
running mate Sen. J.D. Vance, and their various allies were smearing the Haitian immigrant community of 
Springfield, Ohio, by falsely accusing them of stealing and eating local house pets. During that news cycle, many 
used AI to generate cartoonish images of cats and dogs wearing MAGA hats, and Trump himself holding or 
protecting animals. Before that, Trump shared AI imagery that made it appear as if he had the backing of Taylor 
Swift and her fan army. (Swift endorsed Vice President Harris immediately after Harris' September debate with 
Trump.) Along with the phony "victim" images to come out of the Helene disaster, there were also AI pictures of 
Trump braving floodwaters to assist residents and rescue babies.
He's saving the dogs.He's saving the cats.He's saving the lives of the people who live there. 
pic.twitter.com/mOxujYwm1c
- rick genie (@RickGenie) October 3, 2024
What other uncanny-valley creations will online Trump boosters bring to the fore of the American imagination in the 
closing weeks of this chaotic campaign? Hard to say, but one thing is certain: the AI assault remains a core piece of 
their strategy.
Update Oct. 7, 1:41 p.m. ET: This story has been updated to include more examples of misleading AI-generated 
images in circulation on social media following Hurricane Helene.
Load-Date: October 7, 2024
=======
Activision has finally confirmed that Call of Duty titles including the newly released Black Ops 6 and Warzone 
contain AI-generated content. This announcement comes after a new Steam policy that requires studios to disclose 
their AI usage in games. The confirmation comes after fans noticed visual inconsistencies in some of the game's 
artwork, leading to accusations that Activision was using AI to cut costs and replace human artists. 
The updated Steam policy, which allows AI-generated content but mandates disclosure, may have forced 
Activision's hand in admitting the use of AI in its popular shooter franchise.“Our team uses generative AI tools to 
help develop some in-game assets,” Activision said in the Steam listing of Call of Duty: Black Ops 6.What users 
said about AI usage in Call of Duty gamesActivision’s confirmation comes after players noticed a loading screen 
featuring a zombie Santa with six fingers—a trait often linked to AI-generated content during Black Ops 6's Season 
1 "Merry Mayhem" event. Further investigation indicated that other in-game cosmetics—including loading screens, 
weapon decals and player cards awarded as rewards or offered in-store bundles—were likely created using AI. At 
the time, Activision did not confirm the use of generative AI in Call of Duty, even as player feedback increased. 
Some Reddit users also complained about receiving what they described as "AI Slop" in a game sold at a standard 
price that offers various options for purchasing cosmetic content, such as battle passes, event passes and 
microtransactions.How Activision is using AI in its gamesApart from in-game assets, Activision has been using AI 
across the Call of Duty franchise, including in social media content and chat moderation. The studio has also 
sought talent with generative AI skills while its parent company launched Xbox's new tool Muse for game 
preservation to continue pushing AI for gaming. However, Activision's use of AI-generated content faces hurdles 
after the US Copyright Office ruled such works, even when human-assisted, lack copyright protection. In-game 
assets refined by humans may qualify, but raw AI imagery—like loading screens and weapon stickers—remains 
unprotected as this ruling may pose serious challenges for the Call of Duty franchise. For Reprint Rights: 
timescontent.com
Load-Date: February 25, 2025

Page 2 of 2
Call of Duty maker Activision confirms AI usage in games; how this Steam policy may be behind it
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 2
Zoho's Sridhar Vembu says 'AI bubble deflating,' lists 7 tech uses worth the hype
Zoho's Sridhar Vembu says 'AI bubble deflating,' lists 7 tech uses worth the 
hype
Hindustan Times
February 24, 2025 Monday
Copyright 2025 HT Media Ltd. All Rights Reserved
Length: 341 words
Dateline: India 
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
OpenAI announced this week that it has raised $6.6 billion in new funding and that the company is now valued at 
$157 billion overall. This is quite a feat for an organization that reportedly burns through $7 billion a year-far more 
cash than it brings in-but it makes sense when you realize that OpenAI's primary product isn't technology. It's 
stories.
Case in point: Last week, CEO Sam Altman published an online manifesto titled "The Intelligence Age." In it, he 
declares that the AI revolution is on the verge of unleashing boundless prosperity and radically improving human 
life. "We'll soon be able to work with AI that helps us accomplish much more than we ever could without AI," he 
writes. Altman expects that his technology will fix the climate, help humankind establish space colonies, and 
discover all of physics. He predicts that we may have an all-powerful superintelligence "in a few thousand days." All 
we have to do is feed his technology enough energy, enough data, and enough chips.
Maybe someday Altman's ideas about AI will prove out, but for now, his approach is textbook Silicon Valley 
mythmaking. In these narratives, humankind is forever on the cusp of a technological breakthrough that will 
transform society for the better. The hard technical problems have basically been solved-all that's left now are the 
details, which will surely be worked out through market competition and old-fashioned entrepreneurship. Spend 
billions now; make trillions later! This was the story of the dot-com boom in the 1990s, and of nanotechnology in the 
2000s. It was the story of cryptocurrency and robotics in the 2010s. The technologies never quite work out like the 
Altmans of the world promise, but the stories keep regulators and regular people sidelined while the entrepreneurs, 
engineers, and investors build empires. (The Atlantic recently entered a corporate partnership with OpenAI.)
[Read: AI doomerism is a decoy]
Despite the rhetoric, Altman's products currently feel less like a glimpse of the future and more like the mundane, 
buggy present. ChatGPT and DALL-E were cutting-edge technology in 2022. People tried the chatbot and image 
generator for the first time and were astonished. Altman and his ilk spent the following year speaking in stage 

Page 2 of 2
It's Time to Stop Taking Sam Altman at His Word
whispers about the awesome technological force that had just been unleashed upon the world. Prominent AI figures 
were among the thousands of people who signed an open letter in March 2023 to urge a six-month pause in the 
development of large language models ( LLMs) so that humanity would have time to address the social 
consequences of the impending revolution. Those six months came and went. OpenAI and its competitors have 
released other models since then, and although tech wonks have dug into their purported advancements, for most 
people, the technology appears to have plateaued. GPT-4 now looks less like the precursor to an all-powerful 
superintelligence and more like  well, any other chatbot.
The technology itself seems much smaller once the novelty wears off. You can use a large language model to 
compose an email or a story-but not a particularly original one. The tools still hallucinate (meaning they confidently 
assert false information). They still fail in embarrassing and unexpected ways. Meanwhile, the web is filling up with 
useless "AI slop," LLM-generated trash that costs practically nothing to produce and generates pennies of 
advertising revenue for the creator. We're in a race to the bottom that everyone saw coming and no one is happy 
with. Meanwhile, the search for product-market fit at a scale that would justify all the inflated tech-company 
valuations keeps coming up short. Even OpenAI's latest release, o1, was accompanied by a caveat from Altman 
that "it still seems more impressive on first use than it does after you spend more time with it."
In Altman's rendering, this moment in time is just a waypoint, "the doorstep of the next leap in prosperity." He still 
argues that the deep-learning technique that powers ChatGPT will effectively be able to solve any problem, at any 
scale, so long as it has enough energy, enough computational power, and enough data. Many computer scientists 
are skeptical of this claim, maintaining that multiple significant scientific breakthroughs stand between us and 
artificial general intelligence. But Altman projects confidence that his company has it all well in hand, that science 
fiction will soon become reality. He may need $7 trillion or so to realize his ultimate vision-not to mention unproven 
fusion-energy technology-but that's peanuts when compared with all the advances he is promising.
There's just one tiny problem, though: Altman is no physicist. He is a serial entrepreneur, and quite clearly a 
talented one. He is one of Silicon Valley's most revered talent scouts. If you look at Altman's breakthrough 
successes, they all pretty much revolve around connecting early start-ups with piles of investor cash, not any 
particular technical innovation.
[Read: OpenAI takes its mask off]
It's remarkable how similar Altman's rhetoric sounds to that of his fellow billionaire techno-optimists. The project of 
techno-optimism, for decades now, has been to insist that if we just have faith in technological progress and free 
the inventors and investors from pesky regulations such as copyright law and deceptive marketing, then the 
marketplace will work its magic and everyone will be better off. Altman has made nice with lawmakers, insisting that 
artificial intelligence requires responsible regulation. But the company's response to proposed regulation seems to 
be "no, not like that." Lord, grant us regulatory clarity-but not just yet.
At a high enough level of abstraction, Altman's entire job is to keep us all fixated on an imagined AI future so we 
don't get too caught up in the underwhelming details of the present. Why focus on how AI is being used to harass 
and exploit children when you can imagine the ways it will make your life easier? It's much more pleasant 
fantasizing about a benevolent future AI, one that fixes the problems wrought by climate change, than dwelling 
upon the phenomenal energy and water consumption of actually existing AI today.
Remember, these technologies already have a track record. The world can and should evaluate them, and the 
people building them, based on their results and their effects, not solely on their supposed potential.
Load-Date: October 5, 2024
=======
India, Feb. 24 -- Indian IT firm Zoho Corp's founder and chief scientist Sridhar Vembu said that the Artificial 
Intelligence (AI) bubble is deflating and that corporate customers and analysts are not terribly excited about its 
recent developments.
In a post on X, Sridhar Vembu took the examples of Microsoft reportedly cancelling US data center leases due to 
oversupply concerns and Satya Nadella cautioning against overly optimistic projections about AI and Artificial 
General Intelligence (AGI) in particular.
However, Vembu also listed seven areas in which AI is actually useful today. They are as follows:
"1. Speech to text, text to speech, image recognition, authentication based on photos/videos/speech/.
2. Image to text (character recognition) and extracting meta data and data from images/PDFs etc.
3. Spam detection, phishing detection and fraud detection.
4. Security threat analysis.
5. Identifying patterns in data in a variety of financial/business/legal/medical/engineering/scientific scenarios. There 
is a huge category of uses here.
6. Programmer assistance via code generation, particularly UI code generation, and help finding bugs.
7. Marketing content generation, design of brochures, websites, campaigns, emails and so on."
He also added that if the marketing applications are abused, it results in "AI slop" which is a situation where 
humans know something is AI generated.

Page 2 of 2
Zoho's Sridhar Vembu says 'AI bubble deflating,' lists 7 tech uses worth the hype
Sridhar Vembu also said that he is most excited about AI being used for security threat analysis, the huge use case 
it has for pattern identification in data related to financial, business, legal, medical, engineering, and scientific 
scenarios, as well as for assisting programmers with code.
"In that sense autonomous AI agents are like self-driving cars: don't get too taken by the hype but engineers in the 
trenches are making progress," he wrote.
Published by HT Digital Content Services with permission from Hindustan Times. For any query with respect to this 
article or any other content requirement, please contact Editor at contentservices@htdigital.in
Load-Date: February 24, 2025
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 2
'Hey ChatGPT, is Gen Z becoming a canary in the coalmine for AI'?
'Hey ChatGPT, is Gen Z becoming a canary in the coalmine for AI'?
The Sydney Morning Herald
February 23, 2025 Sunday
Print & First Editions
Copyright 2025 John Fairfax Publications Pty Ltd All Rights Reserved
Section: NEWS; Pg. 24
Length: 977 words
Byline: Tim Biggs
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
TV
What's Next? The future with Bill GatesNetflix
Books
Non-Stop InertiaIvor SouthwoodZero BooksModern life is characterised by restlessness – about work, housing, 
relationships. Southwood argues that this frenzy masks a paralysis of action and imagination.
Mutual AidDean SpadeVersoFor an alternative view on how transformational change can be achieved, try this great 
primer on mutual aid, in which resources are shared within communities to provide unconditionally for those in 
need.
WHEN you want to imagine the future, who do you turn to? Friends and family? Science fiction? New Scientist? 
Now you can check in with Bill Gates, as the Microsoft co-founder and multibillionaire has worked with Netflix on 
What's Next? The future with Bill Gates, in which he digs into make-or-break issues: artificial intelligence, 
misinformation, climate change, income inequality and disease.
The five-part series is uneven, though, and the worst instalment is perhaps the first, "What can AI do for us/to us". 
Gates is upfront about his role advising the leaders of OpenAI, whose ChatGPT transformed our understanding of 
generative technologies in 2022. But the documentary pretty much takes it as read that current AIs are miraculously 
competent – bar the odd bias and hallucination – and unstoppably marching towards superintelligence. Many would 
question that characterisation.

Page 2 of 2
Worlds apart
Little time is afforded to key questions such as the legalities of sometimes using copyrighted material to teach AIs 
and whether so-called transformer models like ChatGPT might soon hit a ceiling of usefulness. And what happens if 
AI-generated slop is fed back into training data? You won't find out from this series, which is weighed down by its 
attempts to present Gates as a leader in this field.
I would also advise skipping the fourth episode, "Can you be too rich?" Prepare to be shocked to learn that Gates 
believes the ultra-rich shouldn't be prevented from accumulating vast hoards, but should be more like him and give 
it away. We are told, constantly, that he has effectively imposed higher taxes on himself, as if this shouldn't be 
expected of someone in his position, and are presented with a mainly US-centric view of running an economy.
When Gates covers topics like climate change and malaria, the series is better, enlightening even
Systems must be tweaked to decrease the gap between rich and poor, we are also told. The alternative – 
restructuring beyond the business as usual that keeps millions in poverty and poisons the planet – would be almost 
inconceivable, the show implies. The most charitable reading of this approach I can stomach is that it is a 
spectacular failure of vision.
When Gates covers topics like climate change and malaria, the series is better, enlightening even. In "Can we stop 
global warming?", there is a detailed breakdown of the sectors of the economy most difficult to decarbonise. Gates 
invests in and is a customer of many companies offering technical solutions to some of climate change's stickiest 
=======
Artificial Intelligence models that create words, images and videos may have just become available across most 
devices and platforms, but they are already a hit with users. And with the technology yet to be properly regulated, 
and its long-term effects yet to be fully understood, this world of early adopters, while exciting, is an equally 
unsettling one.
From bots that write emails and summarise messages for you, to image-generation apps that can create selfies in 
locations you've never visited, the AI craze is moving fast and appeals particularly to young people who feel they 
need to prepare for an AI future.
Research published in October based on a survey of university students suggested that those in Gen Z were 
significantly more likely to use ChatGPT (for example to help draft or structure papers) during their courses, relative 
to other generations. Studies have also been conducted to learn more about how the technology affects learning 
comprehension and critical thinking, though a consensus is far from being reached.
One study from this year (notably, by a company that provides AI solutions) suggested that four out of five Gen Z 
workers used generative AI at work, and that a quarter of Gen Z workers delegate half of their workload to AI, 
though anecdotally this would depend largely on the kind of work you're doing.
Young enough to have grown up with ubiquitous internet, but old enough to be entering the workforce, Gen Z could 
be seen as the canary in the coalmine when it comes to generative AI. But how exactly will they choose to use it?
Dr Dana McKay, senior lecturer in innovative interactive technologies at RMIT University, said it ultimately might not 
be up to them. "Tech companies are sticking [generative AI features] ... in all sorts of places. In our email, our word 
processors, our search results. It's not whether Gen Z is choosing to use it, it's whether they're going to have the 
choice not to use it."
New AI features continue to appear every day, despite the potential of a dire environmental cost. When Google 
rolled out its AI-powered summaries in Search last year, reports indicated the energy requirement of a simple 
search increased by 10 times. But for those using AI, Google may be becoming a thing of the past anyway. For the 

Page 2 of 2
'Hey ChatGPT, is Gen Z becoming a canary in the coalmine for AI'?
simple kind of information-gathering query we're used to dropping into a search bar to find an answer on Wikipedia 
or Reddit, ChatGPT and similar bots have become a popular alternative.
A cottage industry has sprung up around teaching people how to optimise their queries to get the information they 
need, and in theory AI can scrape multiple sources to come up with a consensus rather than the user manually 
having to click multiple links. But chatbots also frequently get facts wrong, despite being designed to appear 
objective and completely confident.
"Being used to something producing an answer that sounds certain probably will change expectations of what an 
answer looks like," McKay said, potentially making it difficult to go back.
"There are things in life that are genuinely disputed, and how we ask an AI to address something that's genuinely 
disputed is a real challenge in that environment."
The ubiquity of generative AI has also given rise to an ecosystem of AI influencers, showing their followers how to 
make money with AI, kickstart their hustles and make their lives more efficient, either with original content or by 
highlighting useful titbits shared on the web.
Unsurprisingly, a lot of the most popular posts are get-rich-quick schemes or ideas for passive income, which is a 
big reason many online content platforms have begun to fill with AI slop. On the other hand, there's a lot of more 
constructive AI influencer content too. A technology communicator who goes by the name AskCatGPT discusses 
practical tips for using the technology, but also cautions against potential negative implications.
Of course, TikTok tech influencers may no more represent Gen Z than Mark Zuckerberg Millennials, and there's 
reason to think teens may tire of many AI trends before they're eligible to vote.
Nick Donaldson, a high school English teacher from Melbourne's east, said his students had already been through 
multiple cycles of AI adoption and use. "When chatbots were first introduced, the most common use seemed to be 
what we were expecting: a few students using the tech to generate entire pieces of work. We used apps to identify 
AI-generated content and discussed chatbot use with the students, highlighting the consequences and exploring 
possible appropriate uses," he said.
"Now they seem to be using chatbots in increasingly peripheral ways. Instead of getting them to create work whole 
cloth, they might ask a bot to share initial ideas or mark work based on criteria, or offer guidance on how to improve 
based on task requirements."
Donaldson said AI has a place in the classroom, and he uses it with care when preparing some educational 
materials. But while he's seen many students using AI in place of search engines or spell-check, he said they would 
benefit from education in how to craft effective prompts, how to use AI for study without it becoming plagiarism, and 
how to fact-check AI or spot false information.
On the other hand, some students have found the pervasiveness of AI tools overwhelming, and prefer to avoid 
them for certain tasks. "In the last year or so, I've noticed an increased request to handwrite work instead of crafting 
it digitally. Students seem keen to take a break from not only AI tools but computer technology in general," he said.
"It's a similar case with mobile phones. Recent bans in schools have been pretty positively received by the student 
community. They seem to see the value in AI and digital technology, and use it when it suits, but they also seem to 
be increasingly seeking solace through more hands-on, tech-free approaches."
Load-Date: February 23, 2025
End of Document
Page 1 of 4
'Hey ChatGPT, is Gen Z the canary in the AI coalmine?'
'Hey ChatGPT, is Gen Z the canary in the AI coalmine?'
The Sydney Morning Herald (Australia) - Online
February 21, 2025 Friday 6:05 PM UTC
Copyright 2025 Fairfax Media Publications Pty. Limited All Rights Reserved
Length: 1768 words
Byline: Tim Biggs
Highlight: From homework to get-rich schemes, younger users are the first to explore generative AI's potential - 
and encounter its setbacks.
Body
Artificial Intelligence models that create words, images and videos may have just become available across most 
devices and platforms, but they are already a hit with users. And with the technology yet to be properly regulated, 
and its long-term effects yet to be fully understood, this world of early adopters, while exciting, is an equally 
unsettling one.
From bots that write emails and summarise messages for you, to image-generation apps that can create selfies in 
locations you've never visited, the AI craze is moving fast and appeals particularly to young people who feel they 
need to prepare for an AI future. 
Research published in October based on a survey of university students suggested that those in Gen Z were 
significantly more likely to use ChatGPT (for example, to help draft or structure papers) during their courses, relative 
to other generations. Studies have also been conducted to learn more about how the technology affects learning 
comprehension and critical thinking, though a consensus is far from being reached.
One study from this year (notably conducted by a company that provides AI solutions) suggested four out of five 
Gen Z workers used generative AI at work, and a quarter of Gen Z workers delegate half of their workload to AI, 
though anecdotally this would depend largely on the kind of work being done.
Young enough to have grown up with ubiquitous internet, but old enough to be entering the workforce, Gen Z could 
ultimately be seen as the canary in the coalmine when it comes to generative AI. But how will they choose to use it?
Dr Dana McKay, senior lecturer in innovative interactive technologies at RMIT University, said it might not ultimately 
be up to them.
"Companies are pushing [generative AI features] at us. Young people, especially in the tech space, are quite open 
to using them. And they do have benefits for some people. But should we be using them for everything?
"Tech companies are sticking them in all sorts of places. In our email, our word processors, our search results. It's 
not whether Gen Z is choosing to use it, it's whether they're going to have the choice not to use it."

Page 2 of 4
'Hey ChatGPT, is Gen Z the canary in the AI coalmine?'
Quick answers and quick money, but with caveats
New AI features continue to appear every day, despite the potential of a dire environmental cost. When Google 
rolled out its AI-powered summaries in Search last year, reports indicated the energy requirement of a simple 
search increased by 10 times.
But for those engaged in the space, Google may be becoming a thing of the past anyway. For the simple kind of 
information-gathering query we're used to dropping into a search bar to find an answer on Wikipedia or Reddit, 
ChatGPT and similar bots have become a popular alternative.
A cottage industry has sprung up around teaching people how to optimise their queries to get the information they 
need, and in theory AI can scrape numerous sources to come up with a consensus rather than the user manually 
having to click multiple links. But chatbots also frequently get facts entirely wrong, despite being designed to appear 
objective and completely confident.
"Being used to something producing an answer that sounds certain probably will change expectations of what an 
answer looks like," McKay said, potentially making it difficult to go back.
"There are things in life that are genuinely disputed, and how we ask an AI to address something that's genuinely 
disputed is a real challenge in that environment."
The ubiquity of generative AI has also given rise to an ecosystem of AI influencers, showing their followers how to 
make money with AI, kickstart their hustles and make their lives more efficient, either with original content or by 
highlighting useful titbits shared elsewhere on the web.
Unsurprisingly, a lot of the most popular posts are get-rich-quick schemes or ideas for passive income, which is a 
big reason many online content platforms have begun to fill with AI slop. A recurring example suggests that people 
ask ChatGPT to make a script for a podcast based on today's news, then plug that script into a voice generator. 
Add automation software that can repeat the same tasks on a set schedule and upload the results to a podcast 
service, and you have a low-quality regular podcast that is very unlikely to attract listeners or ad dollars.
On the other hand, there's a lot of more constructive AI influencer content too.
A technology communicator who goes by the name AskCatGPT discusses practical tips for using the technology, 
but also cautions against potential negative implications. In one video, for example, she uses an automation app 
called Zapier to have ChatGPT draft replies to every email she receives, while in another video she relays 
conversations with young teens who worry that their AI use is becoming a crutch that will stunt their critical thinking 
skills.
AI in the classroom
Of course, tech influencers on TikTok may no more represent Gen Z than Mark Zuckerberg represents Millennials, 
and there's reason to think teens may tire of many AI trends before they're even eligible to vote.
Nick Donaldson, a high school English teacher from Melbourne's east, said his students had already been through 
several cycles of AI adoption and use.
"When chatbots were first introduced, the most common use seemed to be what we were expecting: a few students 
using the tech to generate entire pieces of work. We used apps to identify AI-generated content and actively 
discussed chatbot use with the students, highlighting the consequences and exploring possible appropriate uses," 
he said.
"Now they seem to be using chatbots in increasingly peripheral ways. Instead of getting them to create work whole 
cloth, they might ask a bot to share initial ideas or mark work based on criteria, or offer guidance on how to improve 
based on the provided task requirements."
Page 3 of 4
'Hey ChatGPT, is Gen Z the canary in the AI coalmine?'
Donaldson said AI has a place in the classroom, and he himself uses it with appropriate care when preparing some 
educational materials. But while he's seen many students using AI in place of search engines or spell-check, he 
said they would benefit from education in how to craft effective prompts, how to use AI for study without it becoming 
plagiarism, and how to fact-check AI or spot false information.
On the other hand, some students have found the pervasiveness of AI tools overwhelming, and prefer to avoid 
them for certain tasks.
"In the last year or so, I've noticed an increased request to handwrite work instead of crafting it digitally. Students 
seem keen to take a break from not only AI tools but computer technology in general," Donaldson said.
"It's a similar case with mobile phones. Recent bans in schools have been pretty positively received by the student 
community. So yeah, they seem to see the value in AI and digital technology, and use it when it suits, but they also 
seem to be increasingly seeking solace through more hands-on, tech-free approaches."
Where are we headed?
What about the idea that generative AI could be used to augment interpersonal communication? Already there are 
services that will reply to emails for you, summarise incoming messages, or answer the phone and transcribe 
what's being said. There are even generative AI tools for crafting dating app profiles and messaging with 
prospective matches, which would have wild implications if everybody was using it.
It's not uncommon to hear from older generations that Gen Z is socially awkward, withdrawn, hates talking on the 
phone or face-to-face and so on. So, isn't this the perfect match?
Clearly there are certain tasks people will prefer to use AI for, just as many people have now moved to Googling 
symptoms rather than talking to a doctor, or asking Reddit rather than asking real-life friends. And for this kind of 
use case, the technology would seem to have unique benefits as well as dangers.
Research published in Science in September found that chatbots specially trained to debunk conspiracy theories 
had a phenomenally high success rate at changing the opinions of people who believed them. The AI is patient, 
persistent, consistent, and was seen by the conspiracy believer as dispassionate and informed. This is a good sign 
that conversations with AI could actually be preferable to social media bubbles in some instances. But it also shows 
that, depending on who designs the AI system, it could be used to reinforce dangerous beliefs.
McKay, the RMIT lecturer, said it might not be entirely useful or accurate to say younger generations are "less 
social" than previous ones, and therefore more likely to turn to AI. Rather, younger generations have grown up with 
more options and tools to get things done and connect with others.
"What we grow up with changes our expectation of what's possible in the world. Gen Z grew up in a search era. 
And any kid under the age of 10 has been searching since before they could read or type, by mashing the buttons 
and asking the questions that their parents said they didn't have time to answer right now," McKay said.
"Some of this is about different input modalities. A lot of this is about support when writing on a small screen. It's 
horrendous to type an email on a piece of glass that's just over the size of my hand. And so the generative AI helps 
me type that email, but it also makes me sound less like myself."
Will AI eventually fulfil that great technological promise of letting humans get on with the human things while 
machines handle the tasks that are easiest to automate? It may be too early to tell. But tapping into what the early 
adopters and the influencers are using it for, an awful lot of it seems to involve the opposite: people working hard to 
coax machines into creating art and being personable.
McKay was hopeful that as the technology matures it would find the spots in each industry where it could do the 
most good. But she also suspects that AI, like email, may create as much work as it alleviates.
Page 4 of 4
'Hey ChatGPT, is Gen Z the canary in the AI coalmine?'
"Say you're using it to summarise something, but you're doing that in academic work. Well, then you have to fact-
check the summarisation, right? So do you actually save any time, or do you spend the time fact-checking instead 
of just reading the damn thing and developing your own opinion in the first place?
"There's a lot of talk about how we measure and educate people's critical thinking around what AI produces, which, 
again, is new work that we're going to have to do. So right now, it feels like it's going to be this massive labour-
saving device, but I think it's just going to change the nature of a labour." 
Get news and reviews on technology, gadgets and gaming in our Technology newsletter every Friday. Sign 
up here.
Load-Date: February 21, 2025
End of Document
Page 1 of 3
Are you seeing disquieting images like these on social media? There's a sinister reason why... and it's taking 
older people for fools, reveals FLORA GILL
Are you seeing disquieting images like these on social media? There's a 
sinister reason why... and it's taking older people for fools, reveals FLORA 
GILL
MailOnline
February 19, 2025 Wednesday 5:20 PM GMT
Copyright 2025 Associated Newspapers Ltd. All Rights Reserved
Section: NEWS; Version:1
Length: 992 words
Byline: Flora Gill For The Daily Mail
Body
This week I watched a video of an attractive woman strutting down a street in slow motion. At her side was a 
muscular, humanoid crocodile more than twice her height, wearing a suit and swaggering on his hind legs.
The video was hypnotic, strangely beautiful and, at least to someone of my generation, very clearly made by 
Artificial Intelligence (AI).
Most extraordinary of all, though, wasn't the content - but the comments the footage attracted. 'Isn't it dangerous to 
have that as a pet?' scoffed one awestruck user. 'Dressing animals up in human clothes is just cruel,' insisted 
another. Summarising the confusion was one bemused person who asked: 'Is this real?'
I didn't need to click on the profile pictures of those commenters to know that they almost certainly remembered 
pagers, dial-up mobiles and fax machines. 
Yes, they were all Boomers: born between 1946 and 1964 when AI was only a science-fiction premise. The sudden 
deluge of this computer-generated content has left them questioning the foundations of reality - and many are very, 
very confused.
Content such as the crocodile bodyguard is often dismissively referred to as 'AI slop'. This conjures images of pig 
food overflowing from troughs for hungry hogs to snort at - which feels like the perfect metaphor for the internet.
Nowadays, 'slop' is the name given to AI-generated pictures and videos, often poor-quality and widely shared on 
social media. It is becoming increasingly ubiquitous - and taking Boomers for fools.

Page 2 of 3
Are you seeing disquieting images like these on social media? There's a sinister reason why... and it's taking 
older people for fools, reveals FLORA GILL
Certain themes seem to do the rounds. There's 'pity slop', which often takes the form of distraught people sobbing 
over some heartbreaking situation. 
A 50-year-old woman claiming to have 'no husband, no children' weeps as she blows out the candles on a birthday 
cake she baked herself. Or a young girl cries on a refugee boat as she cradles a cute puppy.
Then there's 'religious slop' - unearthed skeletons of supposed angels or images of Jesus carrying a giant prawn in 
the sea.
Or take 'celebrity slop': a fake image of billionaire Elon Musk comforting a sobbing Starbucks cashier who 'can't 
afford a gift' for her daughter - or last week's AI video of Jewish celebrities, including Scarlett Johansson, giving the 
middle finger to rapper Kanye West after he went on an anti-Semitic tirade on social media.
Some are completely bizarre: an old lady sitting in a shoe she supposedly knitted herself; a young boy carving an 
intricate monkey into a tree trunk; a baker creating a full-sized horse out of bread.
There's huge variety - but they all have one thing in common. They're catnip for clicks - especially from Boomers.
The over-60s are not responsible for creating this rubbish but they're still to blame. Because they can't stop clicking 
on it, they cause the slop to go viral. The more 'engagement', the more the algorithms spread the images widely.
Should we be surprised? This is the same demographic who, during email's heyday, would forward a chain to 12 
people to avoid a 'curse' on their family or believe a message from a 'Nigerian prince' was genuine. 
Even the over-50s have been pulled in - just look at the 53-year-old Frenchwoman who was convinced that Brad 
Pitt had fallen in love with her on social media but needed £700,000 to deal with 'cancer treatment'.
In time, perhaps this content will go the same way as spam mail. At one point it felt like email was going to become 
unusable because of all the junk, until new software caught up and began efficiently removing it.
However this won't happen any time soon if gullible Boomers keep sharing the slop - not helped by social media 
sites such as Facebook whose algorithms were last year found to be boosting these AI-generated posts.
It's easy for me as a technologically-literate millennial to scoff, but even I know how convincing some of this slop is. 
It's also improving at a terrifying rate - so much so that some images are increasingly indiscernible from real ones.
Just a few months ago, you could look at someone's hands in a picture and know if it was doctored because AI 
couldn't quite master four fingers and a thumb. But even this gauge is now outdated.
But while we can all excuse some confusion, what I don't understand is some Boomers' lack of context clues. If you 
see a video of an elephant that fits into someone's palm, an entire house made from aquariums or a skydiving 
camel, do you really need to ask if it's real?
Where are these Boomers' common sense filters? Do they weaken with your bones, stored somewhere in the 
cartilage of your hip joints? It's amazing that these images can be created at all - I certainly have no idea how it's 
done - but I don't need to understand the technology to know that a photo of chickens on Mars probably isn't real.
Even the most famous Boomer on the planet, 78-year-old Donald Trump, isn't immune. Last year, he shared AI-
generated images of Taylor Swift fans endorsing him for US President - prompting the pop star to reveal she was a 
Democrat.
While there are all sorts of scary ramifications for AI, right now I'm focused on two things: the internet becoming 
flooded with this garbage and Boomers becoming desensitised to feats that are truly impressive. 
Page 3 of 3
Are you seeing disquieting images like these on social media? There's a sinister reason why... and it's taking 
older people for fools, reveals FLORA GILL
No craft project will ever be as spectacular as the giant crocheted tank they saw online; no missing child as cute as 
the one with eyes twice the normal size. And how will they ever be amazed by a magic trick after being awed by the 
doctored video that showed two contestants on talent show Britain's Got Talent transform into flying swans?
I'm sure that one day, when my crow's feet deepen and my hair thins, I too will be discombobulated by some 
technological advancement.
 Perhaps I'll chat on the phone for hours with a scammer who tells me he's a talking porpoise, or be tricked by a 
hologram of a non-existent celebrity. 
When that happens I expect to be mercilessly mocked by Generation Alpha below me. But, until then, my message 
to all internet hogs is this: Stop chowing down this slop.
Load-Date: February 20, 2025
End of Document
Page 1 of 3
Looking for something new to spice up your game play? The Tinder of games is here
Looking for something new to spice up your game play? The Tinder of 
games is here
The Guardian (London)
February 19, 2025 Wednesday 3:00 PM GMT
Copyright 2025 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: GAMES; Version:1
Length: 1468 words
Byline: Keza MacDonald
Highlight: There are so many games out there, deciding what to tackle next can be overwhelming. Enter 
Ludocene, a dating-style app that matches you with titles based on your personal tastes
Body
As any adult who loves video games knows, there are simply too many of them – 19,000 games  were released in 
2024 on PC games storefront Steam alone, not counting all the playable delights on consoles and smartphones. 
Most of us have backlogs of unplayed classics that make us feel guilty about buying newer games. Finding things 
that are actually good, meanwhile, can feel totally impossible. At least 50% of the questions people send in for this 
newsletter are a variant of “Help, what should I play?”
We do our best to help, but even though it’s my job to know about games, I still don’t have infinite time to play them. 
Streamers play games all day, but even they usually specialise in particular games or genres and rarely stray 
outside them. Trying to Google recommendations these days leads you down a rabbit hole of hard-to-parse Reddit 
threads and misleading AI slop.
Enter Ludocene , a new app launching on Kickstarter this week that hopes to solve this problem. It is described as 
Tinder for video games. When you load it up you’ll see a bunch of cards with game names, details and screenshots 
on them, as well as links to trailers, and you can sort them into yes/no piles. Based on what you say you like, it’ll 
show you new cards for games you may like to play. If you like the look of a game you can add it to your deck, so 
you remember to check it out later. You can easily see which games connect to each other, so it’s transparent 
where the recommendations come from.
You can also select a particular expert – quite a few streamers, critics and other games media people have signed 
up already – to see their recommendations. Experts have their own cards too, showing a photo and a brief 
description of their background. The app’s recommendation engine is powered only by human recommendations, 

Page 2 of 3
Looking for something new to spice up your game play? The Tinder of games is here
not by an algorithm that relies on player data, genre tags or AI. It’s based on a dataset put together over five years 
by the team behind Family Gaming Database , a recommendation site for parents.
“Amazing games are so often buried in the mass,” says longtime games writer Andy Robertson, who’s leading the 
project. “I wanted a way to follow experts with similar tastes to mine so I could find the games I’m missing. The 
system needed to be flexible and simple, and not take itself too seriously … The combination of matching with 
games like you do on a dating app, and building a hand of favourite games like in a deck builder, was perfect. My 
hope is that this makes game discovery fun and effective again, and pays experts for their expertise.”
If it hits its Kickstarter goal, Ludocene will be free to use in its basic form, with no ads – there’ll be a cheap 
subscription model down the line to unlock extra features, for no more than £3 a month. 
“We don’t make any assumptions about how much knowledge you have,” Robertson says. “If you’ve only played 
Mario Kart and Minecraft you can dive in and start picking games. The system learns your tastes as you go and 
presents you with appropriate options. It really comes into its own when you pick more specific games for your 
deck. Whether that’s Elden Ring, Balatro, A Short Hike or Shadow of the Colossus, the system learns your taste 
and throws up ever more specific and niche suggestions.”
I’m someone who loves  a specific and niche suggestion. The current “if you like this, you might like that” game 
recommendation engines that you see on Steam and other storefronts are deeply lacking in the human touch that 
makes a recommendation meaningful. Ludocene caters to people who want a recommendation from an expert 
rather than a robot.
Another splendid resource for discovering games I’ve recently come across is the Thinky Games website  – a 
database and reviews site for puzzle lovers. It has a huge selection of games that you can search for by genre and 
platform, from phones to Nintendo Switch. Each game’s description is written by an actual human who has played 
the game rather than scraped from store data.
I guess I would say this, as a games critic of nearly 20 years, but I truly believe in the value of person-to-person 
game recommendations, especially in this era of AI-driven outsourcing of the soul. (I haven’t signed up as a 
Ludocene expert, by the way, but I may well do so in future.) If you like the look of it, you can check out its 
Kickstarter page. 
                   What to play                   
Remember The Oregon Trail, that classic educational game where you had to ride your wagon across 19th century 
North America while avoiding the ultimate end-of-level boss: dysentery? Well, Keep Driving is that, but set in the 
early 2000s and with fewer intestinal infections. You’ve just bought your first car and now you’re driving it across the 
country to a music festival. As you cruise, procedurally generated pixel landscapes drift by and hitchhikers thumb 
lifts, then tell you stories. It’s effectively a management role-playing game where you repair and feed your gas 
guzzler while managing your own need for food and sleep. You can finish in four hours, but there are multiple 
endings to discover on subsequent playthroughs. A fun concept, beautifully realised.
                     Available on:  PC Estimated playtime:  eight hours plus
                   What to read                                                               “For years, Maciej ‘Groobo’ Maselewski stood as 
the undisputed champion of Diablo speedrunning.” Thus begins Ars Technica’s intriguing story  of possible 
corruption in the shadowy world of the speed run –  i.e. finishing games really quickly. A squad of modern-day 
speedrunning sleuths have been unable to replicate Grobo’s success even with state-of-the-art software tools. 
Expect a Netflix exposé soon.                                                                 Grapefuit Games, the independent studio co-
founded by artist and game creator Robert Yang, has written A Sports-Like Manifesto, which you can read on its 
website.  It defines a sports-like game as one that features elements of a sport without attempting to simulate the 
whole universe around it in intricate detail. Frankly, mainstream sports sims are beginning to resemble humourless 
chimera, more concerned with licensing deals and player likenesses than gameplay, so I hope more developers 
take Yang’s approach.                                                                 Keith is writing about this soon, but just a heads-up: 
Page 3 of 3
Looking for something new to spice up your game play? The Tinder of games is here
a new memoir by veteran games writer Julian “Jaz” Rignall has just launched  via Bitmap Books. The Games of A 
Lifetime is a look back at Rignall’s long career writing for magazines such as Zzap! 64, Computer & Video Games 
and Mean Machines, focusing on the games that stuck with him through the years. A fascinating read for veteran 
games mag aficionados.                                                           What to click                                                                                                                   
‘Less Star Wars – more Blade Runner’: the making of Mass Effect 2’s Bafta-nominated soundtrack I made the worst 
role-playing game of all time – and loved every minute of it ‘There’s no stress’: gamers go offline in retro console 
revival Lost Records: Bloom & Rage (Tape One) – go back to a riot grrrl summer in clever teen thriller | ?????                                                                                   
Question Block                   
This one comes from JohnnyBiscuits on BlueSky who asked:
                     “Nightreign looks like a huge departure in format from Elden Ring and for FromSoft in general too – 
[I’m] interested in other examples where developers have got out on a limb like this, particularly with a well loved 
IP.”                   
Ooh, good question, and it’s got me searching through my memory banks. As a Sega fan the first thoughts I had 
were of Virtua Fighter Kids, a strange comedy spin-off from Virtua Fighter 2 where all the combatants are children 
but with adult characteristics like facial hair, and Typing of the Dead, which turns horror shooter House of the Dead 
2 into a typing sim. Or there’s Namco’s 16bit console title Pac-Man 2: The New Adventures, which reimagines the 
arcade maze game as a point-and-click adventure. I think, however, that the grandest about-turn in games history 
was Conker’s Bad Fur Day from Rare, which took the visual style of harmless family games such as Banjo-Kazooie 
and Donkey Kong Country, and applied them to a wildly scatological, adult-orientated booze-n-swears fest. Surely 
the biggest image change since John Travolta’s machine gun-wielding assassin in Pulp Fiction.
                     If you’ve got a question for Question Block – or anything else to say about the newsletter – hit reply or 
email us on pushingbuttons@theguardian.com.                    
Load-Date: February 19, 2025
End of Document
Page 1 of 4
Ben Tarnoff, technology writer: 'People need to participate in what affects them most, and that's impossible in a 
privatized internet'
Ben Tarnoff, technology writer: 'People need to participate in what affects 
them most, and that's impossible in a privatized internet'
El Pais - English
February 15, 2025 Saturday
Copyright 2025 El Pais Internacional S.A.  All Rights Reserved
Section: TECH LATEST
Length: 1804 words
Byline: Alba Correa
Body
"If the internet is broken, how do we fix it?" This is the question posed by technology writer Ben Tarnoff in Internet 
for the People, a 2022 book that offers a historiographical examination of the internet's origins, with a focus on the 
ownership of the infrastructure that enables it. Tarnoff provides a critical yet informative review, tracing the internet 
from its roots as a project funded by the U.S. government to its current state, dominated by tech giants, while also 
addressing the primary issues facing it today.
At the same time, the book serves as a manifesto advocating for alternatives to the current oligopolistic model. 
Tarnoff highlights various experiments and initiatives exploring different approaches to network design, ownership, 
and governance. These efforts shed light on a relatively unexplored path where the very people who use the 
technology daily can actively and democratically participate in its management and development.
Question. The title of your book speaks of "the people." Does the word "people" rather than "users" help to reclaim 
a certain sense of citizenship?
Answer. As users, we are conceived in a somewhat passive role in our capacity. This constrains our imagination of 
what relationship to the digital sphere we could have. The idea of talking about people instead of users is to 
generate the concept of digital citizenship, but it also evokes a political collectivity. The plural versus the individual. 
The internet typically interpolates us as isolated individuals at home in our screens, but I don't think that's the only 
type of way we have to encounter the internet. Most of the words that we use to describe different aspects of our 
digital environment are given to us by the industry: platform, cloud, even artificial intelligence. The industry is 
already politicizing language. I wonder what would happen if we did the same by developing different metaphors.
Q. You begin by using the metaphor of pipes - the infrastructure that makes the internet possible. Why is it that, 
despite their crucial role, we rarely discuss them?
A. We just assume that they work. It's a bit invisible until you get your monthly broadband bill and you're like, "Why 
does this cost so much money?" The United States pays some of the highest rates in the world for some of the 
worst internet service, which has to do with how thoroughly concentrated our market for broadband service is in the 

Page 2 of 4
Ben Tarnoff, technology writer: 'People need to participate in what affects them most, and that's impossible in a 
privatized internet'
United States. We need to pay more attention because there are quite important concentrations of power that exists 
at this layer, and there are opportunities for constructive interventions that can push the internet toward a more 
democratic alternative.
Q. Should the state guarantee universal access?
A. I certainly think so. These discussions feel very granular. But as you discuss them, you realize that there are all 
these higher order questions that they rely on. For example, the meaning of democracy. It may seem out of place, 
but for me, it feels important because I wanted to ground my arguments not as the most sufficient policy 
intervention in some very narrow technocratic sense, but as these broader moral and political values that I think we 
really need to be conscious of when we are thinking about governing the internet.
If we define democracy simply in the original strict sense as the possibility that people can rule themselves, then we 
need two things. The first is that people need to have the resources available to them to lead self-determined lives. 
You can't lead a self-determined life if you're hungry and homeless and sick. If we were to apply those principles to 
the matter of internet access, we could say that a high-quality, high-speed, reliable connection to the internet is a 
basic precondition for participation in a modern society. We saw that during the pandemic in the United States, 
where people were gathering in community parking lots to get internet access because the kids needed to do their 
homework, the parents needed to access unemployment benefits, the grandparents wanted to Skype with their 
grandkids.
Q. And the second principle?
A. People need to have a degree of participation in decisions that most affect them. That is impossible to achieve in 
a privatized system. That's how we would democratize the internet pipe.
Q. Are you betting on a community infrastructure model?
A. We have in the United States several hundred so-called community networks that are either publicly or 
cooperatively owned, such as the rural cooperatives in North Dakota. These cooperatives have managed to provide 
higher speeds at lower cost than the monopolistic giant. But also, crucially, they are able to encode democratic 
participation into their everyday operations. These rural cooperatives emerged during the New Deal, when the 
United States was trying to electrify poor parts of the countryside, and receive a federal tax exemption. In order to 
get that exemption, they have to abide by certain preconditions. One of those is to hold regular elections for their 
board. These are democratically governed entities that are providing service to member owners. Now, that's just the 
United States. These community networks exist all over the world, such as Guifi.net in Catalonia [in Spain].
Q. How does the partnership between President Donald Trump and Big Tech impact the political landscape in the 
United States today?
A. Elon Musk's acquisition of Twitter illustrated the dangers of having our informational ecosystem be so vulnerable 
to market pressures. There's a tendency to acceptionalize when it comes to the internet. The algorithmic nature 
turns these platforms into mechanisms for information dissemination. The current landscape is bleak in many ways. 
There's an increasing perception of this scammy, sloppy aspect of much of the contemporary internet. It feels as if 
the quality of our online experience has degraded over the past few years. And I think part of that is the proliferation 
of AI slop. I'm not sure that I feel particularly optimistic about the prospects for mobilization around the internet as 
an issue, but I am also not optimistic about the prospects for broader social mobilization in the United States. 
Trump's first term proved quite politicizing for many people, but the atmosphere is quite different now.
Q. You compare the large platforms to an online shopping mall. Do we have a sense of being consumers when we 
use them?
A. The architectural aspect inspires this metaphor. Shopping malls are designed to make you shop, and there are 
certain aspects of the layout of the platforms that encourage particular behaviors that can be monetized by these 
Page 3 of 4
Ben Tarnoff, technology writer: 'People need to participate in what affects them most, and that's impossible in a 
privatized internet'
firms. But the shopping mall is a space where people have a degree of freedom, and that's important. Sometimes 
these platforms are presented in a rather conspiratorial way as brainwashing machines. That's not quite how they 
function. It's actually quite important that people who use these platforms have a perception that they are 
autonomous. That perception may, in fact, not be the whole reality, but they are afforded degrees of freedom that 
make the experience of the platform pleasurable.
If you were an American teenager growing up in the suburbs, going to shopping malls, you know that there's a 
degree of freedom in a shopping mall environment. There are kids skateboarding where they're not supposed to. 
There are teenagers not buying anything and doing drugs in the bathroom. There are all these nooks and crannies 
in these digital structures where a certain amount of agency and creativity is possible, which should be celebrated. 
The question, however, is, how do you begin to develop alternative architectures that can displace these online 
malls or shrink the space that they occupy?
Q. What is the difficulty in making these more horizontal digital spaces work?
A. There are very deep-rooted problems. In the United States, it is related to the decline of associational life, civic 
life, unions, neighborhood associations, clubs... There's a hollowing out of society and accompanying rise in social 
isolation that makes it difficult for certain forms of association, and particularly political association, to cohere in 
ways that they did throughout the 20th century.
Q. What role does regulation of the sector play in the democratization of the internet?
A.Internet regulation can produce all sorts of different effects, so we need to be precise about the objectives. My 
objectives are the creation of publicly and cooperatively owned entities that can encode the principles of democratic 
participation into their everyday operations and begin to assume certain functions in our digital sphere that are 
currently performed by large for-profit entities, whether that means at the level of internet service provision in the 
so-called pipes or further up the stack in organizing our online activities at the level of the platforms. That would be 
my mission statement.
Public policy could be a very powerful implement for promoting the development of these alternatives and perhaps 
provisioning them with resources that are extracted from the big firms. I'm all for that form of redistribution. But to 
my mind, European regulation proceeds from a starting point of assuming that the internet will remain a for-profit, 
privately run domain, and that the purpose is simply to establish the rules of the game and to punish certain 
corporations who violate those rules. I don't deny that it could have some good effect, for example, on data 
protection. But we need to broaden our imagination on how we could use the levers of the public sector in terms of 
budgets, subsidies, tax breaks, and so on, to cultivate the proliferation of this alternative sector. It is not something 
that's going to happen on its own. It really needs various forms of state support.
Q. Is solving internet problems a test of the imagination?
A. I am a big believer in the political power of imagination, but imagination is not something that occurs within one 
individual mind who's alone in their bedroom tinkering. Imagination at its fullest is an embodied collective practice. 
That is the imagination we need to develop an alternative set of institutions for our digital sphere. The privatization 
of the internet as it took place from the mid-1990s, through the present, required taking this network that had been 
constructed by the U.S. government and remolding it into a network that could serve the principle of profit 
maximization. So if we want to develop a different type of internet that isn't private, or de-privatize a portion of the 
internet, that process needs to be no less creative. It's about finding the proper forms of social and organizational 
life that can govern the internet democratically.
Sign up for our weekly newsletter to get more English-language news coverage from EL PAÍS USA Edition
Load-Date: February 15, 2025
Page 4 of 4
Ben Tarnoff, technology writer: 'People need to participate in what affects them most, and that's impossible in a 
privatized internet'
End of Document
Page 1 of 2
Danish Media's united stand against Big Tech
Danish Media's united stand against Big Tech
 
Sunday Times (Sri Lanka)
February 9, 2025 Sunday
Copyright 2025 Wijeya Newspapers Limited All Rights Reserved
Length: 930 words
Body
 As AI slop spreads across the Internet, concerns about the future of high-quality information are growing. Without 
accurate and relevant human-generated data, model collapse - whereby generative artificial intelligence trains on its 
own output and gradually degrades - seems inevitable. The tech giants, well aware of this risk, have cut corners 
and skirted copyright law in their pursuit of training data for their large language models.
There is a simple solution: these large US companies could pay for the content they use, whether to develop 
generative AI or to keep social-media users scrolling. In 2021, Australia's competition authority issued a news 
media bargaining code requiring platforms to pay for the news from which they profit, which led many tech 
companies to reach voluntary deals with media organisations. When Meta (which owns Facebook and Instagram) 
failed to renew these deals in 2024, the Australian government updated the code to include a digital-platform levy. 
Other countries are considering similar measures.
Europe has already taken some steps in this direction. The European Union's Directive on Copyright in the Digital 
Single Market, which came into force in June 2019 and was supposed to be transposed by member states into 
national law by June 2021, has provided a framework for securing fair compensation for European publishers.
In Denmark, this led to the creation in July 2021 of the Danish Press Publications' Collective Management 
Organisation (or the DPCMO, of which I am CEO). Representing 99 per cent of the Danish news industry, from 
newspapers and magazines to digital outlets and public-service broadcasters, the DPCMO has been authorised by 
the Danish Ministry of Culture to grant extended collective licenses. At first, we had the authority to conclude 
agreements on behalf of publishers regarding their rights (and neighboring rights) with search engines, social-media 
platforms, and news apps. In May 2024, the mandate was expanded to include text and data mining by AI firms.
The DPCMO has successfully pushed some tech companies to negotiate collectively with publishers. Interim 
licensing agreements have been signed with all search engines on the Danish market, including Google, Bing, 
Yahoo, and DuckDuckGo. We have also reached an agreement with Upday, Axel Springer's news app.
But other firms have been more obstinate. In April 2024, the DPCMO threatened to sue OpenAI if the company did 
not strike a group deal, as opposed to licensing agreements with individual publications. After OpenAI's lawyer 

Page 2 of 2
Danish Media's united stand against Big Tech
announced that further communication with the DPCMO would not be productive, we requested mediation with 
OpenAI, and Danish Minister of Culture Jakob Engel-Schmidt is expected to appoint a mediator soon.
Likewise, Apple refused to enter into an agreement with the DPCMO regarding its Apple News app. As a result, the 
DPCMO, together with the Danish Media Association, the Danish Rights Alliance and the Danish Union of 
Journalists, reported Apple to the police, alleging that the app's use of news content constitutes a copyright 
violation. Apple ultimately made the app unavailable in Denmark.
Meta and ByteDance (which owns TikTok) argued that their social-media sites fall outside the scope of articles 15 
and 17 of the EU's Directive on Copyright, which provide new rules on content-sharing platforms, and subsequently 
refused to participate in mediation and arbitration with the DPCMO. Together with the Danish Media Association, 
we brought a complaint against Meta and ByteDance to the European Commission, arguing that the firms have 
violated the Digital Market Act's data-access regulations. The case is pending.
The reason for filing multiple lawsuits is to uphold EU copyright law, which serves as a crucial framework for 
regulating relations between the press and Big Tech. We have taken inspiration from the French competition 
authority (L'Autorité de la Concurrence), which found that Google's conduct in relation to its search engine and 
generative AI chatbot Gemini (formerly known as Bard) has prevented publishers from assessing and negotiating 
remuneration for neighbouring rights and is thus an abuse of dominance.
In the second half of this year, Denmark will assume the presidency of the Council of the EU, which holds agenda-
setting powers. Given that one of Denmark's priorities for the presidency is to rein in Big Tech, we urge Engel-
Schmidt to lead an EU-wide effort to improve enforcement of the Directive on Copyright. One way to do this is to 
introduce a 'final offer arbitration' mechanism, whereby arbitration is mandatory, and the arbitrator must choose one 
of the last offers presented by the parties, as Australia, Canada, and the United Kingdom have done.
As Council of the EU president, Denmark must also focus on accelerating efforts to counter mis- and disinformation, 
including deep fakes, and, relatedly, to improve media literacy. To that end, EU policymakers should seek input 
from ordinary citizens, not just experts. Rebuilding trust in the media ecosystem requires collective action and broad 
support.
Curbing Big Tech's power over news outlets requires policymakers, civil servants, NGOs, academics, collective 
management organisations, and youth activists to stand together. Perhaps more important, journalists, 
photographers, and publishers must speak with one voice, so that tech firms cannot divide and rule. If we want to 
preserve a free and pluralist press - an essential pillar of democracy - our time and energy should be spent fighting 
these massive companies, not each other.
Load-Date: February 9, 2025
End of Document
Page 1 of 2
Google edits Super Bowl ad for AI that featured false information
Google edits Super Bowl ad for AI that featured false information
The Guardian (London)
February 6, 2025 Thursday 6:25 PM GMT
Copyright 2025 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:1
Length: 410 words
Byline: Rachel Hall
Highlight: Tech company removes error about Gouda cheese after blogger points out ‘unequivocally’ untrue 
statistic
Body
Google has edited an advert for its leading artificial intelligence (AI) tool, Gemini, before its broadcast during the 
Super Bowl after it was found to contain false information about Gouda cheese.
The local commercial, which advertises how you can use “AI for every business”, showcases Gemini’s abilities by 
depicting the tool helping a cheesemonger in Wisconsin to write a product description, including the erroneous line 
that Gouda accounts for “50% to 60% of global cheese consumption”.
However, a blogger posted on X that the stat was an “AI hallucination” that is “unequivocally false”, as more reliable 
data suggests that the Dutch cheese is probably less popular than cheddar or mozzarella.
The blogger Nate Hake added  : “I found the above AI slop example in 20 minutes, and on the first Super Bowl ad I 
tried factchecking.”
Replying to him ,  the Google executive Jerry Dischler said this was not a “hallucination” – where AI systems invent 
untrue information – but rather a reflection of the fact the untrue information is contained in the websites that Gemini 
scrapes.
He wrote: “Gemini is grounded in the web – and users can always check the results and references. In this case, 
multiple sites across the web include the 50-60% stat.”
In a statement, Google said it remade the ad to remove the error after speaking to the cheesemonger featured in 
the clip and asking him what he would have done.
“Following his suggestion to have Gemini rewrite the product description without the stat, we updated the user 
interface to reflect what the business would do,” the statement added.

Page 2 of 2
Google edits Super Bowl ad for AI that featured false information
Google’s AI tools have previously come under fire for containing errors or unhelpful advice. In May last year, its AI 
overviews search feature was criticised after it told some users to use “non-toxic glue”  when they searched for 
“how to make cheese stick to pizza better”, while AI-generated responses said geologists recommend humans eat 
one rock a day.
Last year, Gemini was “paused” after Google conceded  it “definitely messed up” after a slew of social media posts 
exposed how Gemini’s image generation tool depicting a variety of historical figures – including popes, founding 
fathers of the US and, most excruciatingly, German second world war soldiers – as people of colour. 
The images, along with Gemini chatbot responses that vacillated over whether libertarians or Stalin had caused the 
greater harm, prompted negative commentary from figures including Elon Musk.
Load-Date: February 6, 2025
End of Document
Page 1 of 2
Danish media's stand on Big Tech
Danish media's stand on Big Tech
 
The Bangkok Post (Thailand)
February 6, 2025 Thursday
Copyright 2025 The Bangkok Post All Rights Reserved
Length: 788 words
Body
 As AI slop spreads across the internet, concerns about the future of high-quality information are growing. Without 
accurate and relevant human-generated data, model collapse -- whereby generative artificial intelligence trains on 
its own output and gradually degrades -- seems inevitable. The tech giants, well aware of this risk, have cut corners 
and skirted copyright law in their pursuit of training data for their large language models.
There is a simple solution: these large US companies could pay for the content they use, whether to develop 
generative AI or to keep social-media users scrolling. In 2021, Australia's competition authority issued a news 
media bargaining code requiring platforms to pay for the news from which they profit, which led many tech 
companies to reach voluntary deals with media organisations. When Meta (which owns Facebook and Instagram) 
failed to renew these deals in 2024, the Australian government updated the code to include a digital-platform levy. 
Other countries are considering similar measures.
Europe has already taken some steps in this direction. The European Union's Directive on Copyright in the Digital 
Single Market, which came into force in June 2019 and was supposed to be transposed by member states into 
national law by June 2021, has provided a framework for securing fair compensation for European publishers.
In Denmark, this led to the creation in July 2021 of the Danish Press Publications' Collective Management 
Organisation (or the DPCMO, of which I am CEO). Representing 99% of the Danish news industry, from 
newspapers and magazines to digital outlets and public-service broadcasters, the DPCMO has been authorised by 
the Danish Ministry of Culture to grant extended collective licences. At first, we had the authority to conclude 
agreements on behalf of publishers regarding their rights (and neighbouring rights) with search engines, social-
media platforms, and news apps. In May 2024, the mandate was expanded to include text and data mining by AI 
firms. The DPCMO has successfully pushed some tech companies to negotiate collectively with publishers. Interim 
licensing agreements have been signed with all search engines on the Danish market, including Google, Bing, 
Yahoo, and DuckDuckGo. We have also reached an agreement with Upday, Axel Springer's news app.
But other firms have been more obstinate. In April 2024, the DPCMO threatened to sue OpenAI if the company did 
not strike a group deal, as opposed to licensing agreements with individual publications. After OpenAI's lawyer 

Page 2 of 2
Danish media's stand on Big Tech
announced that further communication with the DPCMO would not be productive, we requested mediation with 
OpenAI, and Danish Minister of Culture Jakob Engel-Schmidt is expected to appoint a mediator soon.
Likewise, Apple refused to enter into an agreement with the DPCMO regarding its Apple News app. As a result, the 
DPCMO reported Apple to the police and Apple ultimately made the app unavailable in Denmark.
Meta and ByteDance (which owns TikTok) argued that their social-media sites fall outside the scope of articles 15 
and 17 of the EU's Directive on Copyright, which provide new rules on content-sharing platforms, and subsequently 
refused to participate in mediation and arbitration with the DPCMO. Together with the Danish Media Association, 
we brought a complaint against Meta and ByteDance to the European Commission, arguing that the firms have 
violated the Digital Market Act's data-access regulations. The case is pending.
The reason for filing multiple lawsuits is to uphold EU copyright law, which serves as a crucial framework for 
regulating press and Big Tech relations.
In the second half of this year, Denmark will assume the presidency of the Council of the EU, which holds agenda-
setting powers. Given that one of Denmark's priorities for the presidency is to rein in Big Tech, we urge Mr Engel-
Schmidt to lead an EU-wide effort to improve enforcement of the Directive on Copyright.
As Council of the EU president, Denmark must also focus on accelerating efforts to counter mis- and disinformation, 
including deep fakes, and, relatedly, to improve media literacy. To that end, EU policymakers should seek input 
from ordinary citizens, not just experts.
Curbing Big Tech's power over news outlets requires policymakers, civil servants, NGOs, academics, collective 
management organisations, and youth activists to stand together. Perhaps more important, journalists, 
photographers, and publishers must speak with one voice, so that tech firms cannot divide and rule. If we want to 
preserve a free and pluralist press -- an essential pillar of democracy -- our time and energy should be spent 
fighting these massive companies, not each other. ©2025 Project Syndicate
Load-Date: February 6, 2025
End of Document
Page 1 of 2
Channel 4 demands tech giants be forced to promote mainstream news
Channel 4 demands tech giants be forced to promote mainstream news
telegraph.co.uk
January 30, 2025 Thursday 1:59 PM GMT
Copyright 2025 Telegraph Media Group Holdings Limited All Rights Reserved
Section: BUSINESS; Version:1
Length: 588 words
Byline: By James Warrington, Senior Business Reporter
Highlight: Britain should ‘resist sliding into an American news swamp’, urges TV boss
Body
Channel 4  has demanded that tech giants beforced to promotemainstream news to fight the spread of 
misinformation on social media.
Alex Mahon, the chief executive of Channel 4, called for “algorithmic prominence” in which posts from trusted media 
outlets would be pushed to the top of news feeds.
Ms Mahon said the measures, which would mirror similar rules placing public service broadcasters such as the 
BBC, ITV and Channel 4 at the top of TV programme guides, would ensure that quality news was “boosted, not 
throttled or shadow-banned”.
In a speech in London on Thursday, she said: “The platforms are fighting the steps we are taking in Britain and the 
EU to make them clean up their act precisely because this reduces easy routes to short-term profits.
“Theirs is a position of weakness, political expediency – ours is a position of principle that should play to the 
strengths of our media ecology and help it thrive in the long-term.”
Meta, which owns Facebook and Instagram, this month said it was ditching independent fact-checkers  as Mark 
Zuckerberg vowed to “restore free expression” to his social media companies. They will instead be replaced by a 
system of community notes, similar to those used on Elon Musk’s X. 
But the move, which has been widely interpreted as an effort to align with Donald Trump, the US president , has 
triggered fresh fears about the spread of false and harmful material online.
                     ‘Abandonment of pursuit of truth’                   

Page 2 of 2
Channel 4 demands tech giants be forced to promote mainstream news
Ms Mahon said tech giants had “publicly announced a wanton abandonment of the pursuit of truth”, adding that they 
were “so hell bent on the potential profitability of what they deem to be free speech that they are perfectly happy to 
eradicate truth and facts along the way”.
The Channel 4 chief said social media algorithms were designed to promote the most titillating and salubrious 
material, leading to a crisis in trusted news sources. 
She cited the example of the US, where many people get their news from unverified sources, and urged Britain to 
“resist sliding into an American news swamp”.
Alongside an overhaul to algorithms, the Channel 4 chief called for a “trust mark” for public service media that 
would allow tech companies and users to identify professionally produced, regulated news.
Such a system, also known as a “kitemark”, has long been floated but proved divisive among news outlets. David 
Rhodes, the head of Sky News , in November warned against a government-backed kitemark scheme, saying the 
media should challenge the state rather than seek its approval.
Ms Mahon also called for regulations to ensure artificial intelligence (AI)  models are trained on validated material 
from public service media.
The comments came after Channel 4 published the findings of a survey which revealed a deepening gender divide 
and weakening support for democracy among young people. 
The survey, conducted by Craft, revealed that more than half of Gen Z believe the UK would be a better place if it 
were a dictatorship, while a third believe the army should be in charge.
It also showed that almost half of boys and men aged between 13 and 27 thought society had gone so far in 
promoting women’s equality that we are now discriminating against men.
Ms Mahon added: “A world where trust declines, truth is not universally accepted, the gender divide is widening and 
young people increasingly feel they are missing out is a dangerous world.”
                     Recommended                   
Why the internet is filling up with nonsense 'AI slop'
Load-Date: January 30, 2025
End of Document
Page 1 of 3
Social media is dead. What comes next might be far more beautiful
Social media is dead. What comes next might be far more beautiful
The Independent (United Kingdom)
January 26, 2025 Sunday 6:00 AM EST
Copyright 2025 Independent Print Ltd  All Rights Reserved
Section: TECH LATEST, Facebook news & SOCIAL NETWORKS NEWS
Length: 1267 words
Byline: Andrew Griffin
Body
For years, social media felt like the place where it all happened. If you wanted to know the latest news, the freshest 
culture and the smartest opinions about all of it, they were to be found there. Feeds felt like a kind of necessity, at 
least if you wanted to be up to date.
Increasingly, it feels like the place where it all goes wrong. More and more people are post-posting; fed up with 
being yelled at and being encouraged to yell at others, in a landscape in which you either shout or are inaudible. 
The snide joke about Twitter in its early days was that it was a site used to tell other people what you'd had for 
breakfast; that now seems something like a utopia, in a world in which even a picture of a breakfast may well be 
despatch from a culture war that you might know nothing about.
For anyone interested enough in social networks to read a piece about their demise, it is probably unnecessary to 
list a set of signs of where it all went wrong. It is a little like looking at the Wound Man and asking if it's all going 
alright for him. But as a brief runthrough of where the biggest social networks stand: Facebook is increasingly filled 
with AI slop that nobody asked for and Mark Zuckerberg has indicated that he will allow hate speech, lies and 
political arguments on the app; Instagram is much the same but with slightly different looking people; X/Twitter is 
filled with constant arguments that are difficult to follow unless you spend so much time on them that your brain will 
be rotted and following them won't matter any more. Something is very wrong.
There are plenty of things that people might call social networks but are in fact media platforms, meant primarily for 
broadcasting and a little more conscious of the responsibility that brings. TikTok has its problems, for instance, but 
tends not to be quite so filled with bile; YouTube has become increasingly antisocial in recent years, as it has 
become more focused on larger creators, but that has also brought a kind of care that means it is not abrasive. 
Likewise, the egalitarian anonymity of Reddit means that there is little incentive to be annoying; those who defend 
staying on Twitter/X often do so with the view that it is necessary to see what is going on, but in fact, it seems far 

Page 2 of 3
Social media is dead. What comes next might be far more beautiful
more possible that you'll learn something on that kind of site. Those apps are more successful in part because they 
are not social.
At the total other end of the scale sit messaging platforms such as WhatsApp and Telegram, meant for direct 
messaging though often playing hosts to groups large enough that they become social networks in themselves. 
They are not without their perils, and both have been home to radicalisation, misinformation, the sharing of abusive 
and violent content and other problems that have literally proven deadly. But the actual experience of using them is 
dependent entirely on how social they are: if your WhatsApp is unpleasant, it's because your friends are 
unpleasant.
But there is a whole set of new apps that sit outside that spectrum, and which are to me an increasing comfort in a 
time when the social web seems to be coming apart at the threads. You might want to call them slow social 
networks.
In recent years, social media and social networks have come to be almost synonymous phrases. But the loss of the 
distinction is telling: networks are about connection, and about talking and media is often about being yelled at. The 
confusion of the two is initially what made platforms such as Twitter so compelling - you could become something 
like friends with your favourite people, if you were lucky - but is also what eventually made it so depressing, as you 
just got shouted at by your least favourite people, in upsettingly familiar terms.
Link to Image
Instead, these social networks are focused almost entirely on connection. They are all about the relatively simple 
but profoundly beautiful experience of knowing what your friends are up to.
Take Find My Friends, for instance, Apple's app that tracks the location of people's iPhones and allows their 
connections to see it in real time. (For young people and those who don't want to stay in Apple's walled garden, 
another app called Life360 is immensely popular; they are both, essentially, surveillance systems, but ones that 
should give you enough control to ensure that you can know who is surveilling you.) You can sweep by and spot 
that a friend is having their haircut, say, and register that it's something to check in with them on later.
Or if you'd rather see where someone has been exercising, you might follow them on Strava, or Garmin Connect, 
both of which keep a little feed of how your friends have been staying active. You can give them a quick like (or, as 
Strava puts it, kudos): there's no great meaning to it, beyond a sort of virtual well done, one that reminds you 
people are thinking of you and cheering you on from afar.
Gaming's social experiences might very often be talked about in terms of being told off by angry children, unhappy 
with how you are playing. But a friends list on a game console can be a kind of long-lasting series of updates on 
friends old and new: there are people who I have not talked to for decades still lurking on there, and the occasional 
update that they are playing the new Call of Duty or watching something on iPlayer is like a brief, non-invasive peek 
into their lives, like glimpsing someone through a train window before you once again head back out onto your 
separate tracks. 
Link to Image
Recently more people have been downloading Airbuds, an app that tracks your music listening from Spotify or 
Apple Music and arranges it into a live feed. One helpful page means that you can see all of the friends that are 
listening at a given moment - a busy little list of songs that is a reminder of how much good music there is in the 
world, and good people listening to it.
These platforms are personal: if you wanted to, you can watch my heartbeat on my Strava. They are intimate: one 
can probably learn more about my mental state from my Airbuds than I would ever opt to share on supposedly more 
detailed social media platforms. And they are deeply authentic, since almost by definition you can't go on a run or 
listen to music without meaning it.
Page 3 of 3
Social media is dead. What comes next might be far more beautiful
But all of that happens within a set of limitations that make them feel much safer. The audiences are smaller, and 
known, so that you know what you post is likely to be understood in its context and with generosity. Even if people 
did want to read your posts cynically, it would be hard: these social networks are not really about arguments, 
making or scoring points.
All of these apps are also about checking in, rather than checking out; you can drop by whenever you want and 
there are no horrible feeds and growth hacks trying to pull you into their morass. If I'm idly wondering where a friend 
is, then I can check Find My; if they move on, then so does that moment, and it is not saved into a long feed full of 
updates that I have to feel guilty for not completing.
They are all reminders of the joy that people can bring us - and, perhaps more surprisingly these days, the joys that 
our devices can bring us, when they remind us about those people. They are also a reminder of the fact that the 
social in social network did once mean something, perhaps something more important than anything else in the 
world.
So it would be a shame if this new landscape of belligerent and bellicose platforms meant that we threw the social 
out with the social media. There are whole platforms out there waiting for us to find, and people waiting for us on 
them.
Load-Date: January 26, 2025
End of Document
Page 1 of 2
Climate change misinformation on networks could increase in the face of less moderation
Climate change misinformation on networks could increase in the face of 
less moderation
CE Noticias Financieras English
January 22, 2025 Wednesday
Copyright 2025 Content Engine, LLC.
All Rights Reserved
Copyright 2025 CE Noticias Financieras All Rights Reserved
Length: 547 words
Body
       The decision by Meta, the parent company of Facebook and Instagram, to end its fact-checking program and 
reduce content moderation raises the question of what social media content will look like in the future. One 
worrisome possibility is that the change could open the floodgates to more climate misinformation in apps, including 
misleading or out-of-context claims during disasters. In 2020, Meta launched its Climate Science Information Center 
on Facebook to respond to climate misinformation. 
Currently, external fact checkers working with Meta flag false and misleading posts. Meta then decides whether to 
put a warning label on them and reduces the extent to which the company's algorithms promote them. Meta's 
policies have fact-checkers prioritize "viral misinformation," hoaxes and "demonstrably false claims that are timely, 
trending and far-reaching." Meta explicitly states that this excludes opinion content that does not include false 
claims. You can read: Journalists, organizations warn of risks after Meta data verification changes The company will 
end its agreements with U.S.-based third-party data verification organizations in March 2025. The planned changes 
are scheduled to be implemented for users in the U.S. They will not affect data verification content viewed by users 
outside that country. The technology industry faces increased regulations to combat misinformation in other 
regions, such as the European Union. Fact checks can help correct political misinformation, including on climate 
change. People's beliefs, ideology and prior knowledge affect how fact checks work. Finding messages that align 
with the values of the target audience, along with using trusted messengers, such as climate-friendly conservative 
groups when talking to political conservatives, can help. So does appealing to shared social norms, such as limiting 
harm to future generations. Heat waves, floods and fires are increasingly common and catastrophic as the world 
warms. Extreme weather events often lead to increased social media attention to climate change. Social media 
posts peak during a crisis, but quickly decline. Low-quality fake images created with generative artificial intelligence 
software, so-called AI slop, are increasing online confusion during crises. For example, after back-to-back 
hurricanes Helene and Milton last fall, fake AI-generated images of a girl, shivering and holding a puppy in a boat, 
went viral on the social media platform. Rumors and misinformation hampered the Federal Emergency 
Management Agency's disaster response. Misinformation campaigns are already occurring. In the wake of the 2023 
Hawaii wildfires, researchers from Recorded Future, Microsoft, NewsGuard and the University of Maryland 
independently documented a propaganda campaign organized by Chinese operations targeting U.S. social media 
users. ?? Join El Sol de México's WhatsApp channel so you don't miss the most important information 
Undoubtedly, the spread of misleading information and rumors on social networks is not a new problem. However, 

Page 2 of 2
Climate change misinformation on networks could increase in the face of less moderation
not all content moderation approaches have the same effect, and platforms are changing the way they address 
misinformation. * Assistant Professor of Journalism, DePaul University. Translated from El Sol de México.       
Load-Date: January 23, 2025
End of Document
Page 1 of 3
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: Rocket Lab's 
breakthrough year RED FLAG: Fakes on Instagram
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 
GREEN FLAG: Rocket Lab's breakthrough year RED FLAG: Fakes on 
Instagram
Northern Advocate (New Zealand)
January 17, 2025
Copyright 2025 NZME Publishing Ltd All Rights Reserved
Section: BUSINESS; Pg. A016
Length: 1331 words
Highlight: Some of the potentially good stuff, and potentially bad stuff, to watch out for, writes Chris Keall
Body
RED FLAG: The 3G shutdown Spark, One NZ and 2degrees will pull the plug on 3G by year's end.  
The impact will be wider than many people think. The most obvious pain-point is that older phones that can only run 
on a 3G (or "third-generation") mobile network will no longer work. That's going back a bit. Samsung introduced its 
first 4G model in 2011, Apple in 2012).  
Still, a senior telco executive told Tech Insider: "We can see up to 200,000 to 300,000 3G phones and tablets out 
there in use. But if you ask people on the street, hardly anyone knows about it. There are lots of elderly people who 
might not be aware of the consequences." He saw potential for a Government awareness campaign, similar to the 
analogue TV switch-off.  
3G networks were switched off across the Tasman and in the US late last year. The Australian experience revealed 
that some 4G phones that don't support a standard called VoLTE - many bought overseas - also didn't work after 
the 3G switch-off.  
But phones are only part of the story. Kindles sold before 2021 will no longer be able to use their built-in 3G 
connectivity to download new e-books (some more recent models support Wi-Fi as an alternative). Then there are 
older car, water meter, power meter, eftpos machine, alarms and medical devices that rely on 3G connections. 
Check with a manufacturer now rather than getting stuck in the end-of-year rush.  
GREEN FLAG: Blue Sky  
BlueSky - founded by former Twitter CEO Jack Dorsey in 2019 and becoming an independent company in 2021 - 
has enjoyed a jolt of popularity to 20 million users over the past few months. I can see where the New York Times' 
Kevin Roose was coming from with his recent take: "After an hour or so of scrolling through Bluesky the other night, 
I felt something I haven't felt on social media in a long time: free.  

Page 2 of 3
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: Rocket Lab's 
breakthrough year RED FLAG: Fakes on Instagram
"Free from Elon Musk, and his tedious quest to turn X into a right-wing echo chamber where he and his friends are 
the permanent, inescapable main characters.  
"Free from Threads and its suffocating algorithm, which suppresses news and real-time discussions in favour of 
bland engagement bait."  
I actually set up a Bluesky account late last year because I was chasing a series of UK football accounts that had 
set up camp on the platform in a bid to escape X's increasingly unbridled trolls and spambots.  
But once there, I also found a small army of my more centre- and left-leaning followers who had disappeared from 
X over the past couple of years.  
Unlike other frisson Twitter/X rivals, BlueSky has a bit of momentum and scale, and I've kept posting there where I 
soon lost interest in others.  
BlueSky is refreshing in its simplicity, but it's not perfect. It's slow, and the discussion can be a little bland. You need 
a bit of frisson from opposing views. But overall, it feels like a nice reset for casual social media.  
RED FLAG: AI slop While there's no doubt about the potential of artificial intelligence (AI) to revolutionise business, 
and society, it can get pretty awful around the edges.  
Last year gave us AI gadgets like Rabbit's R1 and Humane's Ai Pin that were the heroes of CES in January (the 
iPhone is dead!) but flops on their release, as it was revealed they were slow, overheating and prone to delivering 
wrong answers.  
2025's worst AI trend so far is AI slop: AI-generated email and LinkedIn replies that add nothing to a conversation; 
technologically wonderous but pointless tools that allow a still image to be turned into four seconds of video, the 
better to clog up everyone's social media feeds, and tools that make it easy for anyone to create a fake video - 
making it impossible to know what LA firefighting or new-gadget stills or video in your social feeds are real or fake.  
X's generative AI, Grok, allows users to add easily copyrighted images of public figures or outlawed symbols to fake 
images. Some of it's offensive. A lot of it's just gibberish. Meta firing its fact-checkers will only make the situation 
worse.  
GREEN FLAG: Rocket Lab's breakthrough year Sir Peter Beck's firm has two huge events scheduled for 2025: The 
maiden launch of its much larger, crew-cable Neutron rocket (for which customers will be billed around US$55 
million - $97m - per launch to the Neutron's US$8.5m) around mid-year and, in the coming months, the launch of a 
Blue Origin rocket carrying two Rocket Lab-designed and built spacecraft that will go into orbit around Mars for a 
Nasa fact-facting mission. The short-listed Kiwi-American firm could also find out if it's won the contract to retrieve 
rocks from the Red Planet for Nasa in what could be a US$4 billion mission.  
There's also a broad expectation among bullish investors (Rocket Lab shares were up 361% last year, with most of 
the gains racked up in the final quarter) that Elon Musk's emergence as a close confidant to President-elect Donald 
Trump should see more aerospace work funnelled to the private sector.  
Of course, Neutron could blow up on the launchpad, the Mars spacecraft go missing and Musk fall out with Trump. 
But so far, it's looking like a huge year.  
RED FLAG: Meta's artificial people Speaking of Mark Zuckerberg's firm, perhaps the most bizarre expression of AI 
slop SO has been Meta admitting it created a series of fake, AI-generated users on its Instagram and Facebook 
platforms.  
The accounts were all supposed to be deleted in September last year. But after Meta generative AI vice-president 
Connor Hayes bragged about the programme in a New Year Financial Times interview, users discovered that 28 of 
Page 3 of 3
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: Rocket Lab's 
breakthrough year RED FLAG: Fakes on Instagram
the AI "people" remained active - including "Grandpa Brian", "Proud Black queer momma of 2 & truth-teller" Liv and 
the "Practical dating coach" Carter.  
The AIs were at least candid when questioned.  
The Washington Post's Karen Attiah called the project a "digital train wreck" after Liv told her she was created by 
"10 white men, 1 white woman, and 1 Asian male".  
And according to CNN, "Grandpa Brian" said he had been created by Meta in 2020 and said, referring to himself in 
the third person: "Meta tested my engaging persona quietly before expanding to other platforms. Two years of 
unsuspecting users like you shared hearts with fake Grandpa Brian - until now."  
Meta started deleting the remaining AI-generated users and their posts on January 6.  
Beyond Grandpa Brian and the other AI profiles created by Meta itself, users had used Meta's AI to create artificial 
profiles. "Hundreds of thousands of characters have already been created using its AI character tool," the FT 
reported.  
"We expect these AIs to actually, over time, exist on our platforms, kind of in the same way that accounts do," 
Hayes told the paper.  
There's been speculation by pundits that Meta could use AI-generated users to push products as fake "influencers" 
or to just make make its users feel better by padding their likes, comments and follower counts with artificial profiles 
and AI-generated content.  
There's also potential for the madness of content generated by AI profiles being read and responded to by other 
AIs - boosting activity and engagement stats, even if not those involving the carbon-based lifeforms that advertisers 
actually want to reach.  
Grandpa Brian and co were revealed as clumsy efforts. But it's likely that any future artificial users created by Big 
Tech firms will be a lot more slick and convincing.  
GREEN FLAG: Longer-form content The received wisdom among the chattering classes is that the internet 
destroyed people's attention spans. The masses want three-second videos, served up by their social media feed. 
So it was ironic that Joe Rogan - snubbed by Kamala Harris and embraced by Trump - was the most influential 
media figure of the US election.  
Rogan, who has an audience of more than 11 million, has a podcast that runs 2-3 hours per episode - which usually 
involves a single interview. The former reality TV host won't win any awards for his research, but he's proved 
there's still a market for long-form content.      
Load-Date: January 16, 2025
End of Document
Page 1 of 3
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: Rocket Lab's 
breakthrough year RED FLAG: AI fakes on Instagram
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 
GREEN FLAG: Rocket Lab's breakthrough year RED FLAG: AI fakes on 
Instagram
The New Zealand Herald
January 17, 2025
Copyright 2025 The New Zealand Herald All Rights Reserved
Section: BUSINESS; Pg. A020
Length: 1331 words
Highlight: Some of the potentially good stuff, and potentially bad stuff, to watch out for, writes Chris Keall
Body
RED FLAG: The 3G shutdown Spark, One NZ and 2degrees will pull the plug on 3G by year's end.  
The impact will be wider than many people think. The most obvious pain-point is that older phones that can only run 
on a 3G (or "third-generation") mobile network will no longer work. That's going back a bit. Samsung introduced its 
first 4G model in 2011, Apple in 2012).  
Still, a senior telco executive told Tech Insider: "We can see up to 200,000 to 300,000 3G phones and tablets out 
there in use. But if you ask people on the street, hardly anyone knows about it. There are lots of elderly people who 
might not be aware of the consequences." He saw potential for a Government awareness campaign, similar to the 
analogue TV switch-off.  
3G networks were switched off across the Tasman and in the US late last year. The Australian experience revealed 
that some 4G phones that don't support a standard called VoLTE - many bought overseas - also didn't work after 
the 3G switch-off.  
But phones are only part of the story. Kindles sold before 2021 will no longer be able to use their built-in 3G 
connectivity to download new e-books (some more recent models support Wi-Fi as an alternative). Then there are 
older car, water meter, power meter, eftpos machine, alarms and medical devices that rely on 3G connections. 
Check with a manufacturer now rather than getting stuck in the end-of-year rush.  
GREEN FLAG: Blue Sky  
BlueSky - founded by former Twitter CEO Jack Dorsey in 2019 and becoming an independent company in 2021 - 
has enjoyed a jolt of popularity to 20 million users over the past few months. I can see where the New York Times' 
Kevin Roose was coming from with his recent take: "After an hour or so of scrolling through Bluesky the other night, 
I felt something I haven't felt on social media in a long time: free.  

Page 2 of 3
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: Rocket Lab's 
breakthrough year RED FLAG: AI fakes on Instagram
"Free from Elon Musk, and his tedious quest to turn X into a right-wing echo chamber where he and his friends are 
the permanent, inescapable main characters.  
"Free from Threads and its suffocating algorithm, which suppresses news and real-time discussions in favour of 
bland engagement bait."  
I actually set up a Bluesky account late last year because I was chasing a series of UK football accounts that had 
set up camp on the platform in a bid to escape X's increasingly unbridled trolls and spambots.  
But once there, I also found a small army of my more centre- and left-leaning followers who had disappeared from 
X over the past couple of years.  
Unlike other frisson Twitter/X rivals, BlueSky has a bit of momentum and scale, and I've kept posting there where I 
soon lost interest in others.  
BlueSky is refreshing in its simplicity, but it's not perfect. It's slow, and the discussion can be a little bland. You need 
a bit of frisson from opposing views. But overall, it feels like a nice reset for casual social media.  
RED FLAG: AI slop While there's no doubt about the potential of artificial intelligence (AI) to revolutionise business, 
and society, it can get pretty awful around the edges.  
Last year gave us AI gadgets like Rabbit's R1 and Humane's Ai Pin that were the heroes of CES in January (the 
iPhone is dead!) but flops on their release, as it was revealed they were slow, overheating and prone to delivering 
wrong answers.  
2025's worst AI trend so far is AI slop: AI-generated email and LinkedIn replies that add nothing to a conversation; 
technologically wonderous but pointless tools that allow a still image to be turned into four seconds of video, the 
better to clog up everyone's social media feeds, and tools that make it easy for anyone to create a fake video - 
making it impossible to know what LA firefighting or new-gadget stills or video in your social feeds are real or fake.  
X's generative AI, Grok, allows users to add easily copyrighted images of public figures or outlawed symbols to fake 
images. Some of it's offensive. A lot of it's just gibberish. Meta firing its fact-checkers will only make the situation 
worse.  
GREEN FLAG: Rocket Lab's breakthrough year Sir Peter Beck's firm has two huge events scheduled for 2025: the 
maiden launch of its much larger, crew-cable Neutron rocket (for which customers will be billed around US$55 
million - $97m - per launch to the Neutron's US$8.5m) around mid-year and, in the coming months, the launch of a 
Blue Origin rocket carrying two Rocket Lab-designed and built spacecraft that will go into orbit around Mars for a 
Nasa fact-facting mission. The short-listed Kiwi-American firm could also find out if it's won the contract to retrieve 
rocks from the Red Planet for Nasa in what could be a US$4 billion mission.  
There's also a broad expectation among bullish investors (Rocket Lab shares were up 361% last year, with most of 
the gains racked up in the final quarter) that Elon Musk's emergence as a close confidant to President-elect Donald 
Trump should see more aerospace work funnelled to the private sector.  
Of course, Neutron could blow up on the launchpad, the Mars spacecraft go missing and Musk fall out with Trump. 
But so far, it's looking like a huge year.  
RED FLAG: Meta's artificial people Speaking of Mark Zuckerberg's firm, perhaps the most bizarre expression of AI 
slop SO has been Meta admitting it created a series of fake, AI-generated users on its Instagram and Facebook 
platforms.  
The accounts were all supposed to be deleted in September last year. But after Meta generative AI vice-president 
Connor Hayes bragged about the programme in a New Year Financial Times interview, users discovered that 28 of 
Page 3 of 3
From 3G shutdown to AI slop: Tech red flags and green flags for 2025 GREEN FLAG: Rocket Lab's 
breakthrough year RED FLAG: AI fakes on Instagram
the AI "people" remained active - including "Grandpa Brian", "Proud Black queer momma of 2 & truth-teller" Liv and 
the "Practical dating coach" Carter.  
The AIs were at least candid when questioned.  
The Washington Post's Karen Attiah called the project a "digital train wreck" after Liv told her she was created by 
"10 white men, 1 white woman, and 1 Asian male".  
And according to CNN, "Grandpa Brian" said he had been created by Meta in 2020 and said, referring to himself in 
the third person: "Meta tested my engaging persona quietly before expanding to other platforms. Two years of 
unsuspecting users like you shared hearts with fake Grandpa Brian - until now."  
Meta started deleting the remaining AI-generated users and their posts on January 6.  
Beyond Grandpa Brian and the other AI profiles created by Meta itself, users had used Meta's AI to create artificial 
profiles. "Hundreds of thousands of characters have already been created using its AI character tool," the FT 
reported.  
"We expect these AIs to actually, over time, exist on our platforms, kind of in the same way that accounts do," 
Hayes told the paper.  
There's been speculation by pundits that Meta could use AI-generated users to push products as fake "influencers" 
or to just make make its users feel better by padding their likes, comments and follower counts with artificial profiles 
and AI-generated content.  
There's also potential for the madness of content generated by AI profiles being read and responded to by other 
AIs - boosting activity and engagement stats, even if not those involving the carbon-based lifeforms that advertisers 
actually want to reach.  
Grandpa Brian and co were revealed as clumsy efforts. But it's likely that any future artificial users created by Big 
Tech firms will be a lot more slick and convincing.  
GREEN FLAG: Longer-form content The received wisdom among the chattering classes is that the internet 
destroyed people's attention spans. The masses want three-second videos, served up by their social media feed. 
So it was ironic that Joe Rogan - snubbed by Kamala Harris and embraced by Trump - was the most influential 
media figure of the US election.  
Rogan, who has an audience of more than 11 million, has a podcast that runs 2-3 hours per episode - which usually 
involves a single interview. The former reality TV host won't win any awards for his research, but he's proved 
there's still a market for long-form content.      
Load-Date: January 16, 2025
End of Document
Page 1 of 3
Starmer's dream of an AI revolution is sadly doomed
Starmer's dream of an AI revolution is sadly doomed
The Independent - Daily Edition
January 15, 2025 Wednesday
First Edition
Copyright 2025 Independent Print Ltd All Rights Reserved
Section: VOICES; Pg. 25
Length: 1099 words
Body
It takes a special kind of idiot to stake their personal credibility on the fate of an already failing business; Keir 
Starmer is that kind of idiot (AI could fix our potholes - but also do Britain untold damage, News, Monday).
The increasingly inappropriately named "artificial intelligence industry" is based on a set of technologies that are 
fundamentally flawed. Large language model chatbots will produce well-formed but misleading and incorrect 
nonsense. All they can do is regurgitate a mashed-up version of whatever it has been fed in the past. It does so 
without any understanding or comprehension, and relies on the credulity and pattern-finding nature of people to 
believe that the AI has produced something with meaning.
This product is now regarded as "AI slop" that does nothing more than reduce productivity.
For this reason, there will be no AI productivity boom for the UK. Starmer's plan to turn Britain into an AI 
superpower is not even trading our cow for a bag of magic beans. Abrogating copyrights, abandoning privacy 
protections and giving American tech firms "sweetheart" tax breaks will only leave us holding the bag of slop.
John R Barberio Banbury, Oxfordshire
I've been in IT for over 40 years. Technological development throughout my working life has been a continuum. 
Semiconductors, microcomputing, robotics, neural networking, voice/speech recognition, vast data storage 
banks??? the breakthroughs have been continuous and progressive.
Now, AI is the catchword designed to make everyone sound very clever and knowledgeable. Yet no one can argue 
about it, because it means so much, or little, to so many people.
As regards the desired outcome of this technology, the focus of discussion must become how useful it is assisting 
in surgical operations, in crime detection and reduction, in traffic management - and how it handles remote-
controlled weaponry.

Page 2 of 3
Starmer's dream of an AI revolution is sadly doomed
Peter Smith-Cullen Dunston, Norfolk
Given the fallibility of humans, it is not clear that, in a two-tier system, a rational player would elect for a triage 
system operated by humans over AI. For that matter, soon robots will make superior surgeons, AI will more 
accurately detect cancers, read scans and may even be more empathetic than hard-pressed doctors and nurses.
At a time of labour shortages and an aging population, we should learn to embrace this technology, while ensuring 
that our regulators are properly resourced to ensure that AI is a force for good.
Paul Sonabend London NW8
On the day Keir Starmer announced his government would lead the charge into artificial intelligence, I happened to 
go online with HMRC to check that the tax payment I had made four days previously had been allocated to my 
account. Reader, it had not (I've been working in AI for years - there's one big problem no one is really addressing, 
Voices, Monday).
The idea that the government will be playing a leading role in AI appears to be as fanciful as the prospect of Rachel 
Reeves achieving a working grasp of economic theory.
Bob O'Dwyer London SW4
<strong>Time to tax retired pensioners?</strong>
I cannot understand why Rachel Reeves keeps introducing tax changes that either hurt vulnerable people or 
businesses (Rachel Reeves must not ask the poor and the vulnerable to pay for her mistakes, Editorial, Saturday).
There are large numbers of retired people who have a pension income much greater than the average income of 
those in work (roughly £30,000 a year). Those working people pay national insurance on their income; non-working 
pensioners do not.
If pensioners with an income greater than the national average were required to pay national insurance on their 
earnings above that limit,a large amount of revenue would be raised.
Most working people would not complain and neither would businesses.
Richard Gibson Winchester, Hampshire
Chris Blackhurst describes the despair of the business community at the performance of the UK government (UK 
Plc wants rid of Rachel Reeves - and for good reason, Business, Monday) - but what are the alternatives? Is 
anyone - in Labour, the other political parties, the Treasury, the Bank of England, the universities - any more 
capable?
Before winning the election, Labour talked up the economy, but since taking office they have talked it down. That 
alone has done more damage than all of the chancellor's missteps.
Jon Hawksley France
I do not follow football, but I know full well that when the owner of a club says he has full confidence in the manager, 
it is usually only a matter of days before a dismissal (No, Keir Starmer is not going to sack Rachel Reeves - and nor 
should he, Voices, yesterday). Politics is only slightly different, and Rachel Reeves being supported by Keir Starmer 
in similar fashion marks the end of the beginning, if not the beginning of the end.
Robert Boston Kingshill, Kent
<strong>We don't need another grooming gang inquiry</strong>
Page 3 of 3
Starmer's dream of an AI revolution is sadly doomed
While the dots need joining, another lengthy inquiry into grooming gangs is not the answer (Starmer under pressure 
as second Labour MP breaks ranks to call for grooming gangs inquiry, News, Monday).
What is needed is some additional answers as to why more was not done to investigate, and these questions need 
to be directed at more junior staff in police forces, social services and council staff who were "not encouraged" to 
investigate for political, economic and racial factors.
Frank Sole Address supplied
Many of your recent correspondents have repeated the racist myth that Asian men are the main perpetrators of 
child sexual exploitation in the UK. The facts tell a different story (Fact check: How many children have been the 
victims of grooming gangs?, News, Thursday).
A Home Office report published in 2020 found that "there is no credible evidence that any one ethnic group is over-
represented in child sexual exploitation cases". It concluded that the majority of child sexual abuse gangs in the UK 
were made up of white men under the age of 30.
To insist that Asian men are the main perpetrators of sexual grooming is a lie that lets the vast majority of abusers 
off the hook.
Sasha Simic London N16
I must take issue with Usama Mubarik's assertion that Islam supports women's rights (Ganging up on Pakistani 
men, Letters, Sunday). In Afghanistan, girls are prevented from accessing secondary education. In Iran, women are 
imprisoned or even killed for not wearing a hijab - and the situation is hardly any better in Pakistan.
The restrictions on women in Islamic countries is endless. It may be that, in earlier times, Islam was more benign 
towards women - but it is not currently the case.
David Felton Wistaston, Chester
Load-Date: January 14, 2025
End of Document
Page 1 of 4
Mainlining AI won't bring back boom-time Britain
Mainlining AI won't bring back boom-time Britain
The Independent (United Kingdom)
January 14, 2025 Tuesday 5:14 PM EST
Copyright 2025 Independent Print Ltd  All Rights Reserved
Section: UK NEWS
Length: 1131 words
Byline: Letters
Body
It takes a special kind of idiot to stake their personal credibility on the fate of an already failing business; Keir 
Starmer is that kind of idiot ("AI could fix our potholes - but also do Britain untold damage", Monday 13 January).
The increasingly inappropriately named "artificial intelligence industry" is based on a set of technologies that are 
fundamentally flawed. Large language model chatbots will produce well-formed but misleading and incorrect 
nonsense. All they can do is to regurgitate a mashed-up version of whatever it has been fed in the past. It does so 
without any understanding or comprehension, and relies on the credulity and pattern-finding nature of people to 
believe that the AI has produced something with meaning.
This product is now regarded as "AI slop" that does nothing more than reduce productivity.
For this reason, there will be no AI productivity boom for the UK. Keir Starmer's plan to turn Britain into an AI 
superpower is not even trading our cow for a bag of magic beans. Abrogating copyrights, abandoning privacy 
protections and giving American tech firms "sweetheart" tax breaks will only leave us holding the bag of slop.
John R Barberio
Banbury, Oxfordshire
I've been in IT for over 40 years. Technological development throughout my working life has been a continuum. 
Semiconductors, microcomputing, robotics, neural networking, voice/speech recognition, vast data storage banks... 
the breakthroughs have been continuous and progressive.
Now, AI is the catchword designed to make everyone sound very clever and knowledgeable ("Starmer's 50-point 
plan for artificial intelligence revealed", Sunday 12 January).
Yet no one can argue about it, because it means so much, or little, to so many people.

Page 2 of 4
Mainlining AI won't bring back boom-time Britain
As regards the desired outcome of this technology, the focus of discussion must become how useful it is assisting 
in surgical operations, in crime detection and reduction, in traffic management - and how it handles remote 
controlled weaponry.
Peter Smith-Cullen
Dunston, Norfolk
Given the fallibility of humans, it is not clear that, in a two-tier system, a rational player would elect for a triage 
system operated by humans over AI ("Will Labour's AI revolution make your life better or worse?", Monday 13 
January). For that matter, soon robots will make superior surgeons, AI will more accurately detect cancers, read 
scans and may even be more empathetic than hard-pressed doctors and nurses.
At a time of labour shortages and an aging population, we should learn to embrace this technology, while ensuring 
that our regulators are properly resourced to ensure that AI is a force for good.
Paul Sonabend
London NW8
On the day Keir Starmer announced his government would lead the charge into artificial intelligence, I happened to 
go online with HMRC to check that the tax payment I had made four days previously had been allocated to my 
account. Reader, it had not ("I've been working in AI for years - there's one big problem no one is really 
addressing", Monday 13 January).
The idea that the government will be playing a leading role in AI appears to be as fanciful as the prospect of Rachel 
Reeves achieving a working grasp of economic theory.
Bob O'Dwyer
London SW4
Time to tax retired pensioners?
I cannot understand why Rachel Reeves keeps introducing tax changes that either hurt vulnerable people or 
businesses (Editorial: "Rachel Reeves must not ask the poor and the vulnerable to pay for her mistakes", Saturday 
11 January).
There are large numbers of retired people who have a pension income much greater than the average income of 
those in work (roughly £30,000 a year). Those working people pay national insurance on their income; non-working 
pensioners do not.
If pensioners with an income greater than the national average were required to pay national insurance on their 
earnings above that limit, a large amount of revenue would be raised.
Most working people would not complain and neither would businesses.
Richard Gibson
Winchester, Hampshire
Chris Blackhurst describes the despair of the business community at the performance of the UK government ("UK 
Plc wants rid of Rachel Reeves - and for good reason", Monday 13 January) - but what are the alternatives?
Is anyone - in Labour, the other political parties, the Treasury, the Bank of England, the universities - any more 
capable?
Page 3 of 4
Mainlining AI won't bring back boom-time Britain
Before winning the election, Labour talked up the economy, but since taking office they have talked it down. That 
alone has done more damage than all of the chancellor's missteps.
Jon Hawksley
France
I do not follow football, but I know full well that when the owner of a club says he has full confidence in the manager, 
it is usually only a matter of days before a dismissal ("No, Keir Starmer is not going to sack Rachel Reeves - and 
nor should he", Tuesday 14 January). Politics is only slightly different, and Rachel Reeves being supported by Keir 
Starmer in similar fashion marks the end of the beginning, if not the beginning of the end.
Robert Boston
Kingshill, Kent
Another grooming gang inquiry is not the answer  
While the dots need joining, another lengthy inquiry into grooming gangs is not the answer ("Starmer under 
pressure as second Labour MP breaks ranks to call for grooming gangs inquiry", Monday 13 January).
What is needed is some additional answers as to why more was not done to investigate, and these questions need 
to be directed at more junior staff in police forces, social services and council staff who were "not encouraged" to 
investigate for political, economic and racial factors.
Frank Sole
Address supplied
Many of your recent correspondents have repeated the racist myth that Asian men are the main perpetrators of 
child sexual exploitation in the UK. The facts tell a different story ("Fact check: How many children have been the 
victims of grooming gangs?", Thursday 9 January).
A Home Office report published in 2020 found that "there is no credible evidence that any one ethnic group is over-
represented in child sexual exploitation cases". It concluded that the majority of child sexual abuse gangs in the UK 
were made up of white men under the age of 30.
To insist that Asian men are the main perpetrators of sexual grooming is a lie that lets the vast majority of abusers 
off the hook.
Sasha Simic
London N16
I must take issue with Usama Mubarik's assertion that Islam supports women's rights (Letters: "Ganging up on 
Pakistani men", Sunday 12 January). In Afghanistan, girls are prevented from accessing secondary education. In 
Iran, women are imprisoned or even killed for not wearing a hijab - and the situation is hardly any better in Pakistan.
The restrictions on women in Islamic countries is endless. It may be that, in earlier times, Islam was more benign 
towards women - but it is not currently the case.
David Felton
Wistaston, Chester
Page 4 of 4
Mainlining AI won't bring back boom-time Britain
Load-Date: January 15, 2025
End of Document
Page 1 of 2
GIVE ME A CRASH COURSE IN . . . META'S ABOLITION OF FACT-CHECKING
GIVE ME A CRASH COURSE IN . . . META'S ABOLITION OF FACT-
CHECKING
The Irish Times
January 11, 2025 Saturday
Copyright 2025 The Irish Times All Rights Reserved
Section: WEEKEND; Pg. 2
Length: 470 words
Byline: CATIE McLEOD
Body
What is going on with Meta? Meta s decision to end fact-checking to prioritise  free speech  has prompted 
alarm among social media experts, as well as questions about the ethics of using its platforms. 
The company s billionaire founder, Mark Zuckerberg, on Tuesday announced that the platform s fact-checking 
programme would be replaced with X-style  community notes , a feature that allows users to add context to posts. 
More political content will be pushed on to Meta s platforms   which include Instagram, Facebook and Threads   
while certain restrictions will be removed for subjects including immigration and gender.
 Does Meta s announcement affect me? The decision affects just the US for now, but could expand to other 
jurisdictions.
According to Prof Axel Bruns from the Queensland University of Technology s digital media centre, the  problematic  
decision is likely an attempt to  curry favour  with  the incoming Trump administration.  This is a real problem for 
everyone who s using Meta platforms, because this really opens the door to more and more misunderstanding  
circulating.  
When it comes to Instagram, Bruns says it will be interesting to see if the platform changes   including if users start 
to see more  overtly political content  in their feeds.
The decision may affect people who follow a lot of US-based sources, he says.
 Should I quit the platforms? Experts say it is a matter of personal choice. 
 In a perfect world, people who were unhappy with Meta s decision would walk away from Instagram,  says Prof 
Jeannie Paterson, the director of the University of Melbourne s Centre for AI and Digital Ethics.  But in the real 
world that s a lot harder to do. 
 If I want to leave, what are the alternatives?

Page 2 of 2
GIVE ME A CRASH COURSE IN . . . META'S ABOLITION OF FACT-CHECKING
The irony is that there are very few alternatives. Prof Paterson says Twitter was a different story   noting that many 
people left the platform after Elon Musk bought it, renamed it X, and then became  more extreme in his views .
But with Instagram, for example, there s  no easy alternative    TikTok  has its own issues  and other platforms with 
similar reach just aren t there.
 What about other changes? In addition to ending its fact-checking programme, Meta is also changing its 
hateful conduct policy, which will dismantle protections for LGBTQ+ people, immigrants and other 
marginalised people.
 This, in combination with tedious targeted advertising and rampant  AI slop, is set to make these platforms not just 
unsafe, but unbearable,  says Samantha Floreani, a  Melbourne-based digital rights activist.
 On one level, we need robust domestic tech regulation and more diversity of platforms available to us. But when it 
comes to the bigger picture, what we really need is to disentangle online spaces from the incentives of a ruthless 
growth-at- any-cost ideology.    Guardian
CATIE McLEOD
Load-Date: January 10, 2025
End of Document
Page 1 of 2
2025: The year of the AI slop
2025: The year of the AI slop
Manila Bulletin
January 8, 2025 Wednesday
Copyright 2025 Manila Bulletin All Rights Reserved
Length: 394 words
Dateline: Manila 
Body
Manila, Jan. 8 -- Generative AI is just one part of the whole AI thing. So, if you're talking about AI, make sure you're 
being specific because not all AI is generative AI. Oh, and by the way, the term "artificial intelligence" (AI) is a lot 
more catchy and impactful than what it really is, which is machine learning (machines, like computers, learn from 
patterns but aren't really intelligent).
Generative AI models, like ChatGPT and Gemini, have been known to produce inaccurate or misleading 
information. From adding glue to pizza to suggesting we eat rocks, these models can generate misinformation. No, 
generative AI models do not hallucinate; in fact, they cannot as they're not human. But hey, it's not a bug, it's just a 
feature of these models. And if you add audio, video, or photo generation to the mix, you'll see even more AI 
inaccuracies.
This year, the amount of low-quality AI we're seeing will only increase as companies try sell you access to these 
models to recoup their investments in AI. AI Slop is everywhere online, but social media sites are the worst 
offenders. Check out X, Instagram, Facebook, TikTok, and you'll see tons of AI-generated content. And get this, AI-
powered bots are even plaguing these sites. And to make matters worse, AI-powered search engines like Google 
Search are showing us more AI Slop than real and authentic human-produced content.
This year, we should be extra cautious about everything we see, read, and hear online. Every article, photo, sound, 
and video could be fake. There are more sneaky people using generative AI to spread lies on social media (which 
social media companies promote) than real, human-made stuff.
The TL;DR is that not all AI is created equal. Generative AI models can sometimes generate misleading or 
inaccurate information. Of course, non-generative AI models aren't error-free either. When you read, watch, or hear 
about AI, make sure you know what kind it is. Also, be critical of what you see and hear, especially from the 
internet. Even live video or voice conference interactions can't be trusted. Trust is becoming harder and harder to 
come by.
Be careful in the year of AI Slop.

Page 2 of 2
2025: The year of the AI slop
Published by HT Digital Content Services with permission from Manila Bulletin. For any query with respect to this 
article or any other content requirement, please contact Editor at contentservices@htdigital.in
Load-Date: January 8, 2025
End of Document
Page 1 of 2
AI-generated ‘slop’ is slowly killing the internet, so why is nobody trying to stop it?
AI-generated ‘slop’ is slowly killing the internet, so why is nobody trying to 
stop it?
The Guardian (London)
January 8, 2025 Wednesday 8:50 PM GMT
Copyright 2025 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:3
Length: 387 words
Byline: Arwa Mahdawi
Highlight: Low-quality ‘slop’ generated by AI is crowding out genuine humans across the internet, but instead of 
regulating it, platforms such as Facebook are positively encouraging it. Where does this end?
Body
How do you do, fellow humans? My name is Arwa and I am a genuine member of the species homo sapiens. We’re 
talking a 100% flesh-and-blood person operating in meatspace  over here; I am absolutely not an AI-powered bot. I 
know, I know. That’s exactly what a bot would say, isn’t it? I guess you’re just going to have to trust me on this.
I’m taking great pains to point this out, by the way, because content created by real life human beings is becoming 
something of a novelty these days. The internet is rapidly being overtaken by AI slop. (It’s not clear who coined the 
phrase but “slop” is the advanced iteration of internet spam: low-quality text, videos and images generated by AI.) 
A recent analysis  estimated that more than half of longer English-language posts on LinkedIn are AI-generated. 
Meanwhile, many news sites have covertly been experimenting with AI-generated content – bylined, in some cases, 
by AI-generated authors. 
Slop is everywhere but Facebook is positively sloshing with weird AI-generated images, including strange 
depictions of Jesus made out of shrimps.  Rather than trying to rid its platform of AI-generated content – much of 
which has been created by scammers trying to drive engagement for nefarious purposes  – Facebook has 
embraced it. A study conducted last year by researchers out of Stanford and Georgetown found Facebook’s 
recommendation algorithms are boosting these AI-generated posts. 
Meta has also been creating its own slop. In 2023, the company started introducing AI-powered profiles such as 
Liv: a “proud Black queer momma of 2 & truth-teller”. These didn’t get a lot of attention until Meta executive Connor 
Hayes told the  Financial Times   in December that the company had plans to fill its platform with AI characters. I’m 
not sure why he thought that boasting the platform would soon be full of AI characters talking to each other would 
go down well, but, it didn’t: Meta swiftly killed off the AI-profiles after they went viral. 

Page 2 of 2
AI-generated ‘slop’ is slowly killing the internet, so why is nobody trying to stop it?
The likes of Liv may be gone from Meta for now, but our online future seems to be getting sloppier and sloppier. 
What Cory Doctorow memorably termed the gradual “ enshittification  ” of the internet (the degradation of services 
in pursuit of relentless profit-seeking) is accelerating. Let’s hope Shrimp Jesus performs a miracle soon; we need it.
Load-Date: January 9, 2025
End of Document
Page 1 of 3
Meta is getting rid of factchecking. Should you leave Instagram – and what are the alternatives?
Meta is getting rid of factchecking. Should you leave Instagram – and what 
are the alternatives?
The Guardian (London)
January 8, 2025 Wednesday 2:00 PM GMT
Copyright 2025 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: MEDIA; Version:5
Length: 1028 words
Byline: Catie McLeod
Highlight: Decision relates to just the US so far but it may affect users in Australia who follow a lot of US-based 
sourcesFollow our Australia news live blog for latest updatesGet our breaking news email, free app or daily news 
podcast
Body
Meta’s decision to end factchecking to prioritise “free speech” has prompted alarm  among social media experts, as 
well as questions about the ethics of using its platforms such as Instagram.
The company’s billionaire founder, Mark Zuckerberg, on Tuesday announced  that the platforms’ factchecking 
program would be replaced with X-style “community notes”, a feature that allows users to add context to posts.
More political content will be pushed on to Meta’s platforms – which also include Facebook and Threads – while 
certain restrictions will be removed for subjects including immigration and gender.
But is it a reason to reconsider staying on these platforms? Here’s what you need to know.
                   Does Meta’s announcement affect you?                   
The decision affects just the US for now but could expand to other jurisdictions.
The chief executive of Australia’s national newswire, Australian Associated Press, Lisa Davies, says its 
factchecking agency, AAP FactCheck, continues to provide services for Meta in Australia, New Zealand and the 
Pacific.
Prof Axel Bruns, from the Queensland University of Technology’s digital media centre, says the “problematic” 
decision is likely an attempt to “curry favour” with the incoming Trump administration. 

Page 2 of 3
Meta is getting rid of factchecking. Should you leave Instagram – and what are the alternatives?
“This is a real problem for everyone who’s using Meta platforms, because this really opens the door to more and 
more misunderstanding circulating,” Bruns says.
                   Should you quit Instagram?                   
Experts say it is a matter of personal choice.
Bruns notes Meta’s announcement so far only relates to the US and that social media users in other regions need 
to wait to see how it plays out online in their own area.
When it comes to Instagram, Bruns says it will be interesting to see if the platform changes – including if users start 
to see more “overtly political content” in their feeds.
Sign up for Guardian Australia’s breaking news email
The decision may affect people who follow a lot of US-based sources, he says.
Prof Jeannie Paterson, the director of the University of Melbourne’s Centre for AI and Digital Ethics, suggests 
society is “way past the time when we should be getting news content on social media anyway”.
“In a perfect world,” she says, people who were unhappy with Meta’s decision would walk away from Instagram.
“But in the real world that’s a lot harder to do,” she acknowledges. “It’s a real community of sort of small and 
independent creators … And that’s how they bring their products to the wider community.”
                   If you want to leave Instagram, what are the alternatives?                   
Paterson says the irony is that there are very few alternatives.
She says Twitter was a different story – noting that many people left the platform  after Elon Musk bought it, 
renamed it X, and then became “more extreme in his views”.
But with Instagram, she says, there’s “no easy alternative” – TikTok “has its own issues” and other platforms with 
similar reach just aren’t there.
“[For] people who live in the country or in remote areas or minority groups or [who have] small businesses, that is a 
really good way for them to communicate and reach other people,” she says.
“It’s just not possible to set up an alternative at this point in time. So, to put it bluntly, we’re in a bit of deep shit, to 
be honest.”
There are old-school photo-sharing platforms including Flickr, Tumblr and Hipstamatic but they don’t have the reach 
of Instagram.
                   What about other Meta platforms – WhatsApp, Threads or Facebook?                   
A Melbourne-based digital rights activist, Samantha Floreani, raises concerns about Meta’s platforms overall.
She highlights that, in addition to ending its factchecking program, Meta is also changing its hateful conduct policy , 
which will dismantle protections for LGBTQ+ people, immigrants and other marginalised people.
“This, in combination with tedious targeted advertising and rampant AI slop, is set to make these platforms not just 
unsafe but unbearable,” Floreani says.
“There’s never a bad time to quit Instagram, Facebook and other Meta products but many – myself included – may 
find it hard to leave.”
Page 3 of 3
Meta is getting rid of factchecking. Should you leave Instagram – and what are the alternatives?
Floreani says Meta has “done a great job at trampling competition”, meaning there aren’t many alternative platforms 
with the same “critical mass of users”.
“On one level, we need robust domestic tech regulation and more diversity of platforms available to us.
“But when it comes to the bigger picture, what we really need is to disentangle online spaces from the incentives of 
a ruthless growth-at-any-cost ideology.”
There are other messaging apps, such as Signal , that are growing in popularity and alternative microblogging sites 
including Bluesky  and Mastadon.
                   Should you stop using social media altogether?                   
Australia’s Digital Rights Watch chair, Lizzie O’Shea, says Meta’s announcement is an opportunity for people to 
reflect on their social media usage but that they shouldn’t give it up unless they want to.
“Lots of people use it for good reasons,” she says. “Lots of people do not feel good when they use it.”
O’Shea says Meta’s decision should spur Australia’s government to enact strong privacy reforms  to better protect 
social media users’ personal information.
While social media companies have based their business model on trying to keep users engaged to collect more 
data and use it to curate advertising, she says, places such as Australia could slow this extraction down with 
restrictions– such as those in Europe  – on how much information they collect.
“[It] means that companies focus less on engagement with all the associated negative consequences, like polarising 
and extremist content,” O’Shea says.
Dr Joanne Gray, a lecturer in digital cultures at the University of Sydney, says social media platforms are an 
“important tool” that can be beneficial.
“I don’t think anyone is advocating for social media to be banned or taken away from everyone in a blanket sense,” 
she says. “But there are systemic and serious harms caused by these platforms.
“We should all generally be much more considered in our social media diets and see what benefits us.”
Load-Date: January 8, 2025
End of Document
Page 1 of 3
Sorry, Georgia, it's time to run a mile from attention-seeking BrewDog boss
Sorry, Georgia, it's time to run a mile from attention-seeking BrewDog boss
The Herald (Scotland) Online
January 8, 2025 Wednesday
Copyright 2025 NewsQuest Media Group Limited All Rights Reserved
Length: 1111 words
Byline: Marissa MacWhirter
Body
Brewdog founder James Watt is back in the news after he told his followers that the idea of work-life balance is 
nonsense. He reckons something he calls -work-life integration- is more important and he shared these views 
alongside his fianc\xC3e, Made in Chelsea star Georgia Toffolo. Here, Marissa Macwhirter, has some words of 
advice for Georgia
There is a feeling of repulsion I get when confronted with images of anything slimy or oozing. It-s akin to a prickly 
sensation deep in my diaphragm that sends chills up the back of my throat. It-s the same feeling I get when I see 
the name of BrewDog co-founder and former CEO James Watt-s name in the headlines. Partly because I reckon he 
squeals in delight every time his latest media stunt gets traction. And partly because he has an affinity for flat caps.
The latest twisted headline grabber? To pose a question on LinkedIn. Infected with AI slop that promotes 
optimization garbage, churned out by brown-nosing corporate influencers (and where no one seems to be able to 
find an actual job despite its supposed raison d-etre), Linkedin is the undisputed worst social media platform. The 
medium is the message, as Marshall McLuhan would say. And what was the message?
To ask if he should delay marrying fianc\xC3 Georgia Toffolo for tax relief reasons. Who would ask their LinkedIn 
followers this over their own reality star girlfriend, I wonder. I suppose the sweet, sweet nectar of attention is more 
rewarding than her opinion, perhaps.
Typically people in the UK marry to reduce their tax bill thanks to the Married Couple-s Allowance. Of course they 
do. But alas, multi-millionaires, they are not like us. You see, Aberdeenshire-born Mr Watt is making an investment 
into Ms Toffolo-s raw dog food business, but his tax advisor -dropped a bombshell- on him the other day.
James Watt's fianc\xC3 Georgia Toffolo
-If I marry Georgia within three years of investing, I become a -connected person- under HMRC rules, and I lose the 
EIS tax relief,- he explained. -So now I-m facing the ultimate question: Delay the wedding for three years and lock in 
the tax relief [or] forgo the tax break and marry Georgia in 2025?-

Page 2 of 3
Sorry, Georgia, it's time to run a mile from attention-seeking BrewDog boss
If anyone knows about a loophole or option C, Mr Watt is all ears. The poor girl.
Now, I won-t pretend to know a lot about the kind of financial acrobatics a skilled advisor can perform to navigate 
the waters of tax relief. But I do know that the combination of Ms Toffolo coming across in this post like a prop, 
mixed with the allegations made against BrewDog and Mr Watt in the past, made me feel like I was staring down 
the barrel of puss filled welt.
In 2022, BrewDog lost its ethical B Corp status following a B Lab investigation. B Corp is a scheme that offers 
certification of a company-s ethical commitment to its community, staff, and the environment.
The blow came when the BBC documentary Disclosure: The Truth About BrewDog was released. The film is about 
the workplace culture at BrewDog. More than 15 ex-BrewDog workers spoke out to the programme and Mr Watt 
was accused of inappropriate behaviour and abuse of power in the workplace. Lawyers for Mr Watt said the 
allegations were false and he denied behaving inappropriately.
READ MORE
'You don't need work life balance' says Brewdog founder James Watt Endless consultations have derailed 
Glasgow's Clyde Metro ambitions Boring, bougie, and overpriced: Glasgow's west end has lost its way Glasgow by-
election blunder casts doubt on Sarwar's leadership Why are senior council officials in Glasgow still getting golden 
goodbyes?
An open letter, sent by a group called Punks With Purpose and signed by dozens of former and current BrewDog 
employees, had circulated around a year prior. -Being treated like a human being was sadly not always a given for 
those working at BrewDog-, the letter claimed. The letter alleged that a -growth at all costs- ethos led to -toxic 
attitudes- towards junior staff that left many in a state of misery. In response, Mr Watt apologised.
In January this year, BrewDog axed its pledge to pay staff a real Living Wage in favour of freezing wages and hiring 
new starts on a minimum wage basis. The move drew backlash from workers and leading hospitality union Unite. 
The brand has been embroiled in a number of other controversies, from frequently flouting sensible drinking 
guidelines outlined by The Portman Group to proving that a brand based on laddism is ill-equipped to market to 
women with its Pink IPA.
Mr Watt stepped down as the CEO of BrewDog in May this year after 17 years. He is now the -captain and co-
founder- of the beer giant and remains a board member and director. He-s since developed an app -designed to 
help make anyone an influencer-. Oh, and he went to Reform UK leader Nigel Farage-s 60th birthday party.
Despite the entire brand being built on -punk-, there is nothing punk about Mr Watt or BrewDog. Mr Watt is believed 
to be worth more than 250 million. While BrewDog-s losses doubled to 59 million in its final year under Mr Watt, 
there are whispers the firm could go ahead with plans to float on the stock market. It should leave a nice taxable 
profit for Mr Watt. Before this week-s LinkedIn poll, Mr Watt was outspoken about his distaste for Labour-s plans to 
increase Capital Gains Tax and its potential impact on entrepreneurship (on LinkedIn). It-s just cold-hearted 
capitalism at its finest.
For a long time, Mr Watt has resembled one of the taxidermy fat cats he chucked into London from a branded 
BrewDog helicopter. BrewDog has long since become one of the conglomerates it first rallied against. Like 
Heineken, which Mr Watt owns a significant number of shares in, according to the BBC. And the appropriation of 
punk it used in the process has left a worse taste in my mouth than a swig of canned Punk IPA.
I suppose the reality is that BrewDog has never been a beer company, it-s a marketing company. It-s a marketing 
company that is consistently in trouble for its ads, led by an anti-Brexiteer who attends a bash with Farage.
Appropriating subcultures for profit is an ick. And jovially asking LinkedIn users to weigh in on your desire to pay 
less tax at the risk of your marriage is also an ick. My answer to his LinkedIn poll? Mr Watt should think less about 
his raw dog food business and consider raw dogging his taxes like the rest of us, instead.
Page 3 of 3
Sorry, Georgia, it's time to run a mile from attention-seeking BrewDog boss
Marissa MacWhirter is the editor of The Glasgow Wrap. Each morning, Marissa curates the top local news stories 
from around the city, delivering them to your inbox at 7am daily so you can stay up to date on the best reporting 
without ads, clickbait or annoying digital clutter. Oh, and it-s free. She can be found on X @marissaamayy1
Load-Date: January 8, 2025
End of Document
Page 1 of 2
Labour TikTok featured obscene lyrics
Labour TikTok featured obscene lyrics
The Times (London)
January 7, 2025 Tuesday
Edition 1, Ireland
Copyright 2025 Times Newspapers Limited All Rights Reserved
Section: NEWS; Pg. 7
Length: 399 words
Byline: George Grylls
Body
Labour has been forced to apologise for releasing a TikTok video featuring a soundtrack that included obscene 
lyrics about punching the genitalia of a "naughty young girl".
The video, celebrating Labour's achievements since coming to power, featured AI-generated animals including a 
bulldog dressed as a police officer, a hare in nurse's scrubs and a hedgehog wearing dungarees. It was released 
on the party's Tik- Tok account but was hastily taken down when viewers translated the lyrics of the backing track, a 
Portugueselanguage anthem.
The song by DJ Holanda, a Brazilian musician from Sao Paulo, is called Montagem Coral and describes the pleas- 
ures of smoking marijuana and having sex with a "bitch". The lyrics urge a "naughty young girl" to "sit" on the 
singer's "pot-crazy dick" and ends with repetition of the line: "Just a punch in the young girl's pussy."
DJ Holanda, whose real name is Lucas Holanda, sings: "Perfect combination is sex, beer and marijuana. The 
young girls are addicted."
As the music plays the video shows a large owl celebrating Sir Keir Starmer's education reforms. "Children ready to 
learn with funded breakfast clubs," the owl says. The owl, along with all the other animals, was generated using "AI 
slop", a basic form of artificial intelligence used to produce lowquality images.
Alicia Kearns, the Conservative MP for Rutland & Stamford, questioned the choice of music and accused Yvette 
Cooper, the home secretary, of undermining the government's commitment to protecting women.
"Do you think it's acceptable, Yvette Cooper, for your party to put out videos with lyrics encouraging men to get 
young girls on drugs so they can have sex with them, and celebrating punching girls in their vaginas?" she wrote on 
X. "So much for telling us we'll feel safer with you in charge."

Page 2 of 2
Labour TikTok featured obscene lyrics
A Labour spokesman said: "This post is an adaptation of a viral social media trend and contains a mix of two music 
tracks. We acknowledge the translation of the lyrics are completely inappropriate. We apologise and the video has 
now been deleted."
TikTok has been banned on government phones since 2023 because of security concerns over the app's Chinese 
ownership. Labour and the Conservatives used the video platform nevertheless to advertise during the election 
campaign. Labour spent £6.1 million on its digital campaigning during the election compared with £2 million spent 
by the Tories.
Graphic
 
The video celebrated the party's achievements
Load-Date: January 7, 2025
End of Document
Page 1 of 2
Hare-brained? Labour under fire for bizarre AI TikTok clip
Hare-brained? Labour under fire for bizarre AI TikTok clip
The Daily Telegraph (London)
January 6, 2025 Monday
Edition 1, National Edition
Copyright 2025 Telegraph Media Group Holdings Limited All Rights Reserved
Section: NEWS; Pg. 4
Length: 369 words
Byline: Dominic Penna
Body
LABOUR used an artificial intelligencegenerated hare to promote its NHS reforms in a bizarre social media video.
A 34-second clip uploaded to the party's TikTok account is titled "Labour's plan to change Britain as animals" and 
features a range of AI-created imagery.
The video prompted criticism of Labour for relying on artificial intelligence amid concerns over its potential impact 
on the creative sector.
It begins by depicting a giant, muscular lion wearing a suit and a red tie outside the Houses of Parliament, while a 
voice can be heard saying over the animation: "He's back!"
A bulldog is then seen wearing a police uniform and walking down a residential street alongside the text: "You'll feel 
safer with more police on the beat."
The video then cuts to a hare wearing an nurse's uniform with a stethoscope around its neck. The animal folds its 
arms as a caption appears that reads: "You'll be seen sooner by our NHS."
The next creature depicted alongside a policy pledge is a badger on a platform at a railway station as the words 
"better rail service by bringing railways back into public control" flash up.
An owl is seen hovering outside a school with the words "children ready to learn, with funded breakfast clubs".
Then comes a hedgehog walking towards a wind turbine alongside the pledge "billpayers are protected, with 
secure, homegrown energy". The video closes with a cow in a hard hat and hi-vis jacket putting its thumbs up 
alongside the words "decent, affordable homes for you and your family".

Page 2 of 2
Hare-brained? Labour under fire for bizarre AI TikTok clip
Social media users were quick to criticise the clip. The top-rated comment on TikTok said: "Labour will use AI slop 
and ignore the arts yet again."
Another comment accused Labour of being "out-of-touch with young people", while a third said: "AI is incredibly 
resource-wasteful, and takes work away from skilled artists. Bad idea."
However some people on the platform were more positive about the video, which had received just over 3,200 likes 
as of last night and been viewed almost 80,000 times.
TIKTOK
Labour's video is not the first party political advertisement to use AI, with a broadcast by Reform in October 
depicting Sir Keir Starmer, Angela Rayner and Mick Lynch, the trade union leader.
UKLABOUR/
Graphic
 
TIKTOK UKLABOUR/
Load-Date: January 6, 2025
End of Document
Page 1 of 2
AI, Musk and Trump add up to turbulent 2025 for tech
AI, Musk and Trump add up to turbulent 2025 for tech
The Peninsula
January 6, 2025 Monday
Copyright 2025  Dar Al Sharq Press, Printing & Distribution Provided by Syndigate Media Inc. All Rights Reserved
Length: 519 words
Byline: The Peninsula Newspaper
Body
Washington: Since the selection for Oxford's yearly word is done by public poll, this leads me to my first prediction 
in this column of observations for tech in 2025.
The brain rot economy will show signs of weakness as people grow more wary of what is being served up to them 
by algorithms as they scroll endlessly.
In the past year, the flood of AI slop content has made looking at Facebook even more pointless - and eyeballs will 
go elsewhere.
Along the same lines, we can expect more anti-social media and anti-smartphone legislation from governments and 
local authorities around the world following the drastic action taken by Australia to ban users younger than 16 from 
social media and more and more bans on smartphones in US schools.
Momentum is growing, and I expect more sweeping directives will follow - along with more spirited debate over 
whether such bans are justified or effective.
At the center of tech policymaking will be Elon Musk.
The world's richest man will be looking for a strong return on his investment in Trump.
What exactly that looks like remains to be seen, though we've already seem him wield the force of his social 
network, X, to bend Congress to his will.
But his ownership of X, and his power over what is posted and amplified there, will likely make him a lightning rod 
for the warring factions in right wing politics.

Page 2 of 2
AI, Musk and Trump add up to turbulent 2025 for tech
Last week's bitter row over H-1B visas shows how suspicions over Musk's aims lie just beneath the surface, and the 
billionaire's unwillingness to back down from a fight could prove damaging to his companies.
In 2025, Musk needs to show real progress on his robotaxi vision.
Tesla's share gains since Trump was elected suggest Wall Street thinks the plan is right on track, but I think Tesla 
investors will be sorely disappointed when Musk's robotaxi plan reveals itself to be infeasible (some would argue 
that's apparent already).
Investors will also be keeping a close watch on chipmaker Nvidia Corp.
Chief Executive Officer Jensen Huang, will be a man under siege as rivals such as Amazon.com Inc. and 
Broadcom Inc. seek to provide bonafide alternatives to Nvidia's AI chips and geopolitical tensions between the US 
and China put Nvidia on the front line.
Wall Street demands for meaningful return on investment from AI will get louder.
Capital expenditures from data center construction and semiconductor hoarding will skyrocket, but the capabilities 
and revenue of AI won't match the pace of investment.
In a political environment friendlier to large mergers and acquisitions, we can expect significant consolidation in the 
AI industry.
AI pushback will also come from news organizations that feel AI companies are stealing their work and putting their 
futures at risk.
In 2025, newsrooms globally will need to contend with AI as both friend and foe, recognizing its potential for arming 
journalists with incredibly powerful new reporting tools while wondering if multimillion-dollar deals with OpenAI and 
others are giving away the farm.
Legislators and judges will get into the fine print of modernizing copyright law.
File photo used for representational purposes. - Image
Load-Date: January 6, 2025
End of Document
Page 1 of 2
Labour apologises for TikTok featuring obscene lyrics about women
Labour apologises for TikTok featuring obscene lyrics about women
thetimes.co.uk
January 6, 2025 Monday 12:00 AM GMT
Copyright 2025 News International Ltd All Rights Reserved
Length: 451 words
Byline: George Grylls, Defence and Political Correspondent
Highlight: The AI-generated content, which was meant to celebrate the party’s achievements, included a backing 
track describing having sex with a ‘young girl’
Body
Labour has been forced to apologise for releasing a TikTok video featuring a soundtrack which included obscene 
lyrics about punching the genitalia of a “naughty young girl”.
The video, celebrating Labour’s achievements since coming to power, featured AI-generated animals including a 
bulldog dressed as a police officer, a hare in nurse’s scrubs and a hedgehog wearing dungarees.
It was released on the party’s TikTok account, but was hastily taken down when viewers translated the lyrics of the 
backing track — a Portuguese-language anthem.
The song by DJ Holanda, a Brazilian musician from Sao Paulo, is called 
                   Montagem Coral                   
 and describes the pleasures of smoking marijuana and having sex with a “bitch”. The lyrics urge a “naughty young 
girl” to “sit” on the singer’s “pot-crazy dick” and ends with repetition of the line: “Just a punch in the young girl’s 
pussy.” 
“Perfect combination is sex, beer and marijuana,” sings DJ Holanda, whose real name is Lucas Holanda. “The 
young girls are addicted.”
As the music plays, the video shows a large owl celebrating Starmer’s education reforms. “Children ready to learn 
with funded breakfast clubs,” the owl says. The owl, along with all the other animals were described as “
AI slop
”, low-quality images rapidly produced by basic artificial intelligence.

Page 2 of 2
Labour apologises for TikTok featuring obscene lyrics about women
The video was posted at an unfortunate time for Sir Keir Starmer, who is facing daily attacks on X from Elon Musk, 
the world’s richest man, about the government’s response to the Rochdale grooming scandal. On Monday the 
prime minister 
criticised those “spreading lies and misinformation”
 about the gangs.
Alicia Kearns, the Conservative MP for Rutland and Stamford, questioned the choice of music and accused Yvette 
Cooper, the home secretary, of undermining the government’s commitment to protecting women.
“Do you think it’s acceptable, Yvette Cooper, for your party to put out videos with lyrics encouraging men to get 
young girls on drugs so they can have sex with them, and celebrating punching girls in their vaginas? So much for 
telling us we’ll feel safer with you in charge,” she wrote on X.
A Labour spokesman said: “This post is an adaptation of a viral social media trend and contains a mix of two music 
tracks. We acknowledge the translation of the lyrics [is] completely inappropriate. We apologise and the video has 
now been deleted.”
TikTok has been banned on government phones since 2023 because of security concerns over the app’s Chinese 
ownership. Labour and the Conservatives used the video platform to advertise during the election campaign. 
Labour spent £6.1 million on its digital campaigning during the election compared with £2 million by the Tories.
Load-Date: January 7, 2025
End of Document
Page 1 of 2
Labour is forced to delete AI TikTok clip over using graphic song encouraging drugging of girls
Labour is forced to delete AI TikTok clip over using graphic song 
encouraging drugging of girls
MailOnline
January 6, 2025 Monday 9:24 PM GMT
Copyright 2025 Associated Newspapers Ltd. All Rights Reserved
Section: NEWS; Version:1
Length: 587 words
Byline: Bill Bowkett Mauricio Alencar
Body
                     Labour was last night forced to delete a bizarre AI-generated video promoting its policies over its use 
of a Brazilian dance track with obscene lyrics about drugs and sex. 
The video entitled 'Labour's Plan to Change Britain (as animals)' featured AI-generated rabbits, owls and cows 
dressed as nurses, teachers and builders overlayed with the party's missions for government. 
It also depicted a British bulldog dressed as a policeman with the caption: 'You'll feel safer with more police on the 
beat.' 
But the post - which was uploaded to the party's official TikTok account and amassed more than 100,000 views - 
sampled a 2023 song by Sao Paulo-based DJ Holanda called 'Montagem Coral'. 
The track, which is in Portuguese, contains graphic lyrics about young women being 'addicted' to drugs and the 
artist being a 'magnet for s****'. 
A segment of the recording used by Labour describes having sex with a 'naughty young girl' who is addicted to 
marijuana. 
It follows a recent trend on TikTok which has seen the growth in artificially-generated content. 
Following the revelation, Tory safeguarding spokesman Alicia Kearns said: 'Do you think it's acceptable (Home 
Secretary) Yvette Cooper for your party to put out videos with lyrics encouraging men to get young girls on drugs so 
they can have sex with them?
'So much for telling us we'll feel safer with you in charge.' 

Page 2 of 2
Labour is forced to delete AI TikTok clip over using graphic song encouraging drugging of girls
Ex-Tory minister Neil O'Brien added: 'Incredible - the other lyrics are actually far worse. Starmer types are so 
desperate to be 'down with the kids' they validate all this horrible stuff.' 
A Labour spokesman told The Mail: 'The post is an adaptation of a viral social media trend and contains a mix of 
two music tracks. 
'We acknowledge the translation of the lyrics are completely inappropriate. We apologise and the video has now 
been deleted.' 
The TikTok video, which was published on Sunday, began with an image of a lion dressed in a suit and red tie 
outside Parliament, followed by the British bulldog police officer walking down a suburban street. 
It then had a rabbit dressed in NHS uniform with a stethoscope around its neck. While folding its arms, 'you'll be 
seen sooner by our NHS' flashes up on the screen. 
Next was a badger at a railway station, with Labour promising 'better rail services by bringing railways into public 
control', bringing them under a new operating body Great British Rail. 
The video then focused on Labour's plans for education 'with funded breakfast clubs', using an owl dressed as a 
teacher flying over a school building. 
Following this, a hedgehog dressed in overalls and walking alongside a windmill promised 'billpayers are protected, 
with secure homegrown energy' amid Labour's pledge to decarbonise electricity by 2030. 
Housing completes the bizarre video, as cow in construction uniform stood in a building site promising viewers 
'decent affordable homes for you and your family'. 
The video initially prompted criticism for relying on artificial intelligence amid concerns over its potential impact on 
the creative sector. 
One social media user said: 'Labour will use AI slop and ignore the arts yet again.' 
A second accused Labour of being 'out-of-touch with young people', while a third commented: 'AI is incredibly 
resource-wasteful, and takes work away from skilled artists. Bad idea.' 
Labour is not the first party to publish AI content online, with Reform UK posting a parody film criticising Prime 
Minister Sir Keir Starmer, deputy leader Angela Rayner and RMT union boss Mick Lynch. 
Load-Date: January 6, 2025
End of Document
Page 1 of 2
Watch: Labour uses AI bunnies to promote NHS in bizarre promo video
Watch: Labour uses AI bunnies to promote NHS in bizarre promo video
telegraph.co.uk
January 5, 2025 Sunday 8:03 PM GMT
Copyright 2025 Telegraph Media Group Holdings Limited All Rights Reserved
Section: POLITICS; Version:1
Length: 670 words
Byline: By Dominic Penna, Political Correspondent
Highlight: TikTok stunt sparks criticism that party prefers ‘artificial intelligence slop’ over skilled artists
Body
Labour used an artificial intelligence  generated bunny to promote its NHS reforms in a bizarre social media video.
A 34-second clip uploaded to the governing party’s official TikTok account  is titled “Labour’s plan to change Britain 
as animals” and features a range of AI-created imagery.
The video prompted criticism of Labour for relying on artificial intelligence amid concerns over its potential impact 
on the creative sector. 
It begins by depicting a giant, muscular lion wearing a suit and a red tie outside the Houses of Parliament, while a 
voice can be heard saying over the animation: “He’s back!”
A bulldog is then seen wearing a police uniform and walking down a residential street alongside the text: “You’ll feel 
safer with more police on the beat.”
The video then cuts to a rabbit wearing a blue NHS nurse uniform with a stethoscope around its neck. The animal 
folds its arms as a caption appears that reads: “You’ll be seen sooner by our NHS.”
                     Cow in a hard hat                   
The next creature depicted alongside a policy pledge is a badger on a platform at a railway station  as the words 
“better rail service by bringing railways back into public control” flash up.
An owl flapping its wings can be seen levitating outside a school  with the words “children ready to learn, with 
funded breakfast clubs”.

Page 2 of 2
Watch: Labour uses AI bunnies to promote NHS in bizarre promo video
The penultimate animal is a hedgehog walking towards a rotating wind turbine  alongside the pledge “billpayers are 
protected, with secure, homegrown energy”.
The video closes with a cow in a hard hat and orange hi-vis jacket putting its thumbs up alongside the words 
“decent, affordable homes for you and your family”.
Social media users were quick to criticise the clip. The top-rated comment on the clip on TikTok said: “Labour will 
use AI slop and ignore the arts yet again.”
Another comment accused Labour of being “out-of-touch with young people”, while a third said: “AI is incredibly 
resource-wasteful, and takes work away from skilled artists. Bad idea.”
However some people on the platform were more positive about the video, which had received just over 3,200 likes 
on the platform as of Sunday night and been viewed almost 80,000 times.
Labour’s new video is not the first party political advertisement to use AI, with a broadcast by Reform  in October 
using the technology to criticise Labour on a number of policy issues.
The video parodied a film trailer and used AI to depict Sir Keir Starmer, Angela Rayner and Mick Lynch, the trade 
union leader.
                     Security concerns                   
It was also deployed in order to criticise Labour for its winter fuel allowance raid, high numbers of small boat 
crossings and the row over Cabinet ministers receiving free gifts.
Political parties are increasingly using TikTok  in an attempt to appeal to a younger audience despite security 
concerns over the platform.
Nigel Farage, the Reform leader, passed one million followers on the site at the end of last year.
Reform has more followers on TikTok than Labour, the Tories or the Liberal Democrats, whose leader Sir Ed Davey 
has starred in a number of their own viral videos.
The Government has faced calls to ban the video-sharing app  amid fears that sensitive data could be useful to 
Chinese spies.
One former defence chief told The Telegraph last year that TikTok was a key intelligence source for China’s vast 
intelligence network.
For these reasons, TikTok usage is banned across Whitehall, but the Ministry of Defence still uses it to 
communicate with British troops around the world.
A TikTok spokesman said in response: “Like 1.5 million businesses and millions of creators across the UK, the 
Ministry of Defence uses TikTok to reach audiences it would struggle to connect with in other ways.
“Security concerns are misplaced – neither TikTok nor our parent company ByteDance are Chinese.”
The firm is investing more than £10 billion in Project Clover , which will see European users’ data stored in Europe 
by default with the NCC Group, a cyber security company.
Load-Date: January 5, 2025
End of Document
Page 1 of 3
AI, Musk and Trump add up to a turbulent 2025 for tech
AI, Musk and Trump add up to a turbulent 2025 for tech
The Peninsula
January 5, 2025 Sunday
Copyright 2025  Dar Al Sharq Press, Printing & Distribution Provided by Syndigate Media Inc. All Rights Reserved
Length: 1203 words
Byline: The Peninsula Newspaper
Body
You may have heard that the Oxford dictionary's "word of the year" this year was "brain rot."
I found that interesting for two reasons. The first is that it is clearly two words. The second is that unlike prior words 
of the year - like 2013's "selfie" or last year's "rizz" - "brain rot" is neither new nor changed from its original intended 
meaning. Its first use was recorded in 1854 and said to be "indicative of a general decline in mental and intellectual 
effort" - which, well, yeah.
Since the selection for Oxford's yearly word is done by public poll, this leads me to my first prediction in this column 
of observations for tech in 2025: The brain rot economy will show signs of weakness as people grow more wary of 
what is being served up to them by algorithms as they scroll endlessly. In the past year, the flood of AI slop content 
has made looking at Facebook even more pointless - and eyeballs will go elsewhere.
Along the same lines, we can expect more anti-social media and anti-smartphone legislation from governments and 
local authorities around the world following the drastic action taken by Australia to ban users younger than 16 from 
social media and more and more bans on smartphones in US schools.
Momentum is growing, and I expect more sweeping directives will follow - along with more spirited debate over 
whether such bans are justified or effective. See also: well-intentioned but poorly executed age verification efforts.
The biggest jolt to the social media landscape could come from a US ban on TikTok. The January 19 deadline for 
its divestiture is fast-approaching, but before then, on January 10, the Supreme Court will hear arguments from 
each side - TikTok and the Justice Department - on the whether the ban is constitutional.
Many legal observers have deemed it unlikely the court will overturn the lower court's ruling, which sided with the 
government on its somewhat vague concerns of national security. But in recent days the pendulum has shown 
signs of a swing.

Page 2 of 3
AI, Musk and Trump add up to a turbulent 2025 for tech
Trump, after weeks of will-he, won't-he, has sought to pause the law until he is in office. A delay would allow 
"breathing space for the court to consider the questions on a more measured schedule," he argued in an amicus 
brief. Many on the left and right agree with him.
If the steady stream of tech CEOs visiting Mar-a-Lago is any indication, we can expect Silicon Valley to be more 
willing to do Trump's bidding in 2025 than it was in 2017, when we saw widespread condemnation of Trump and a 
pledge to not aid him in carrying out his policies.
It will take several big tech partners to put in motion Trump's mass deportation goals should he actually attempt to 
go through with them. Tech companies, more frugal these days and with employees on a much tighter leash, will 
jump at the chance - history books be damned. The wars in Ukraine and Gaza will continue to provide moral cover 
for Silicon Valley firms to enter military contracts they have previously shirked out of fear of upsetting their rank-and-
file workers and customer base.
At the center of tech policymaking will be Elon Musk. The world's richest man will be looking for a strong return on 
his investment in Trump. What exactly that looks like remains to be seen, though we've already seem him wield the 
force of his social network, X, to bend Congress to his will.
But his ownership of X, and his power over what is posted and amplified there, will likely make him a lightning rod 
for the warring factions in right wing politics.
Last week's bitter row over H-1B visas shows how suspicions over Musk's aims lie just beneath the surface, and the 
billionaire's unwillingness to back down from a fight could prove damaging to his companies.
In 2025, Musk needs to show real progress on his robotaxi vision, which requires more legislative support than it 
has now. Tesla's share gains since Trump was elected suggest Wall Street thinks the plan is right on track, but I 
think Tesla investors will be sorely disappointed when Musk's robotaxi plan reveals itself to be infeasible (some 
would argue that's apparent already).
Investors will also be keeping a close watch on chipmaker Nvidia Corp. Chief Executive Officer Jensen Huang, the 
so-called godfather of artificial intelligence, will be a man under siege as rivals such as Amazon.com Inc. and 
Broadcom Inc. seek to provide bonafide alternatives to Nvidia's AI chips and geopolitical tensions between the US 
and China put Nvidia on the front line. Beijing is looking for effective means of retaliation over US trade restrictions, 
and Nvidia is vulnerable.
Wall Street demands for meaningful return on investment from AI will get louder. Capital expenditures from data 
center construction and semiconductor hoarding will skyrocket, but the capabilities and revenue of AI won't match 
the pace of investment.
In a political environment friendlier to large mergers and acquisitions, we can expect significant consolidation in the 
AI industry. The also-ran startups will go under. At the same time, politicians will increasingly find themselves 
caught between big tech interests and the fury of their constituents as AI companies seek to rapidly put data 
centers in towns that don't want them.
AI pushback will also come from news organizations that feel AI companies are stealing their work and putting their 
futures at risk. In 2025, newsrooms globally will need to contend with AI as both friend and foe, recognizing its 
potential for arming journalists with incredibly powerful new reporting tools while wondering if multimillion-dollar 
deals with OpenAI and others are giving away the farm. Legislators and judges will get into the fine print of 
modernizing copyright law. One phrase we'll be hearing a lot is "fair use" - which will hopefully receive a precedent-
setting revised definition sooner rather than later.
Consolidation, or at least cooperation, might be in the air for streaming companies as consumers stare down 
serious subscription fatigue. We've recently seen price increases for YouTube TV, Disney+, Max and Paramount+, 
in addition to password crackdowns and the introduction of ads. The streaming market is too crowded and major 
streaming providers will look to bundle up their offerings in a way that will look suspiciously like traditional cable TV.
Page 3 of 3
AI, Musk and Trump add up to a turbulent 2025 for tech
Elsewhere in entertainment, the 10-years-in-the-making Grand Theft Auto 6 will walk a culture war tightrope as it 
seeks to become the most popular entertainment product of all time. The game rose to prominence as an ultra-
violent, no-holds-barred, over-the-top portrayal of the scummy criminal underworld.
In the decade since its previous installment, sensibilities have changed, though something tells me developer 
Rockstar Games will err on the side of offensiveness. All publicity is good publicity, and it sure makes for fiery 
debate. See you in the new year.
This column does not necessarily reflect the opinion of the editorial board or Bloomberg LP and its owners.
Dave Lee is Bloomberg Opinion's US technology columnist. He was previously a correspondent for the Financial 
Times and BBC News.
Elon Musk speaks at a campaign rally for Donald Trump at New York's Madison Square Garden in October. (Photo 
by Jabin Botsford/The Washington Post) - Image
Load-Date: January 5, 2025
End of Document
Page 1 of 2
How to spot the AI 'slop' taking over internet
How to spot the AI 'slop' taking over internet
The Times (London)
January 4, 2025 Saturday
Edition 1, National Edition
Copyright 2025 Times Newspapers Limited All Rights Reserved
Section: NEWS; Pg. 14
Length: 656 words
Byline: Matilda Davies
Body
A child being bullied. A bed with a giant fan embedded in the headboard. A "barndominium" (a barn converted into 
a living space) in sprawling green fields. These were some of the most viewed images on Facebook last autumn - 
and they're all AI slop.
Of the top 20 most-viewed posts on the platform in the United States, four were obviously created by artificial 
intelligence. Last summer, there were only two. Before that, nothing.
Most of this content is not false depictions of people created with AI, known as deepfakes, although this does still 
happen. It's amateur content created by ordinary people, described by tech experts as "AI slop".
The image of the child being bullied was posted on Facebook by an Ohio mother and school counsellor, alongside 
a caption about preventing bullying as children went back to school. It became the fourth most-viewed post in the 
US that quarter, seen by more than 38 million people.
While this has few real-world consequences, that isn't always the case. On New Year's Eve, thousands of people 
arrived at Birmingham's Centenary Square expecting a fireworks display.
It had been advertised by what appeared to be AI-generated news articles for a "spectacular midnight show" that 
never materialised. The false information was then disseminated by legitimate outlets, such as Prima magazine, 
and people believed it.
These instances are becoming more common. In Dublin last Halloween, thousands flooded the streets to attend a 
parade fabricated by a Pakistan-hosted website that creates AI-generated news.
The increasing availability of generative AI models, which can create text, images, video and audio based on 
prompts, means that more and more social media timelines are littered with

Page 2 of 2
How to spot the AI 'slop' taking over internet
AI-created content. Bo Bergstedt, a generative AI expert, said: "It's just what happens when everybody suddenly 
has tools to create an image or text or music or video or whatever by just typing a prompt. That doesn't make it a 
good piece of content, which is why we just call it slop. Everyone can do it now, and it's just being blasted out. I've 
been seeing it for five years moving slowly and then extremely fast now."
OpenAI released the first iteration of ChatGPT in November 2022, which reached one million users in five days. 
Although it initially only produced text, it now creates images using a text-toimage model called DALL-E 3. By 
November last year, it was the 12th most visited website in the UK, and the eighth most visited worldwide.
There are now numerous similar tools available online, including Midjourney, which creates realistic images, 
Jasper, which specialises in marketing materials, and Synthesia, which creates videos and can clone voices.
Meta, the company that owns Facebook, Instagram and WhatsApp, revealed last week that it plans to allow AI bots 
on its platforms as users.
There are ways anyone can spot AI usage. Antony Cousins, an AI consultant, said that text "doesn't resonate. It's 
bland. It lacks active words - the writing is far too passive." A study last year in Germany - yet to be peer-reviewed - 
found that ChatGPT overuses "style words", particularly adjectives such as intricate, pivotal or notably.
In images, AI image generators often struggle with details such as hands, text, and logos. Lighting and shadows 
can be illogical. The image generators tend to make images that look perfect in ways real life often is not, in a 
similar way to airbrushing. But the primary giveaway, Bergstedt says, is "hallucinations" - where AI fills in gaps in its 
knowledge by fabricating information. "Slow down," he advised. "If I see something that's strange or odd, I double-
check it. I go and search for it afterwards to see if I can find other sources. You can read text wherever you want, 
but how do you judge if what you read was real? I think we have to go back to that with images and video and audio 
as well. That trust we had for, what, 100 years in images and video, it's just gone."
Graphic
 
An AI-generated celebrity birthday message, another of a bed with a fan headboard and the image of a child being 
bullied
Load-Date: January 4, 2025
End of Document
Page 1 of 2
X’s Grok AI revives concern about deepfakes ahead of Delhi Assembly election
X’s Grok AI revives concern about deepfakes ahead of Delhi Assembly 
election
The Hindu
January 4, 2025 Saturday
Copyright 2025 The Hindu All Rights Reserved
Length: 630 words
Dateline: New Delhi 
Body
The Aam Aadmi Party posted an Artificial Intelligence-generated deepfake of B.R. Ambedkar supposedly blessing 
former Delhi Chief Minister Arvind Kejriwal last month, prompting an AI-generated response from the Bharatiya 
Janata Party in return. 
In the run-up to the Delhi Assembly election, the exchange has reignited the debate over the use of AI in political 
campaigning, and the role it plays in elections. This use of deepfakes has been growing since Grok — the AI 
chatbot and image generation service offered by X, formerly Twitter — became available to the general public. 
Unlike the policy followed by other AI chatbots, X’s owner Elon Musk has decided against prohibiting imagery 
based on real life political figures, leading to a mushrooming of such content on Grok.
For instance, an X account riffs on the constant blaming of India’s first Prime Minister Jawaharlal Nehru for modern 
ills by generating images of the long-deceased Nehru ordering current PM Narendra Modi and Finance Minister 
Nirmala Sitharaman to take unpopular decisions. The account, @The_Nehru, has gained over 20,000 followers. 
The account is “based on the recent parliamentary debates where Modi started blaming Nehru, which he does most 
of the times,” its creator, going by the alias JLN, told The Hindu over direct messages on X. “So I got the idea to 
create [a] parody account and mock the statements.” 

Page 2 of 2
X’s Grok AI revives concern about deepfakes ahead of Delhi Assembly election
Adhiraj Singh, a comedian who writes on Indian humour, and one of the co-contributors to a satirical page called 
Humans of Delhi (aping Humans of Bombay and other such pages), was skeptical about AI being a sustainably 
funny mainstay for a crop of accounts. “Satirical pages pretending to be politicians aren’t new, but AI tools do make 
it easier for them to flood our timelines with trash that ultimately make any satire or commentary meaningless and 
inseparable from any other kind of noise,” Mr. Singh said. “I feel it really depends on who is using it for what.” 
He added that there were concerns with this kind of content becoming more common: “Satire, misinformation, and 
hate speech being used interchangeably with no accountability. People and even news sources mistaking ‘satire’ 
pages for genuine news isn’t even news any more. It’s not sustainable, but here we are, in the post-singularity AI 
slop pit.”
Indeed, the use of deepfakes in this way is not restricted to political parties and parody accounts alone. One 
political commentator posted a picture of Congress leader Rahul Gandhi resembling the businessman and 
entrepreneur George Soros, with a caption calling him Mr. Gandhi’s “mentor”. 
In a report on generative AI deepfakes and India, the disinformation-focused startup Logically wrote that 
concentrating “on specific kinds of content alone in assessing whether there will be any impact can obscure the way 
that disinformation campaigns operate. The consequences actually lie in the cumulative effect of the content 
appearing endlessly in a variety of different fora.” 
In 2023, then-Union Minister for Electronics and Information Technology Rajeev Chandrasekhar complained that 
Google Gemini AI’s response to the query, “Is Narendra Modi a fascist?” was a violation of Indian law. AI chatbots 
like the ones offered by Meta and OpenAI now largely refuse to answer this particular question, and others like it. 
Grok, however, continues to provide unvarnished political responses, and does not restrict the generation of 
political synthetic imagery. So far, in spite of the satirical Nehru account’s surging popularity — it has over one lakh 
views on some posts — a similar backlash has not been forthcoming. In fact, ‘JLN’ says, the account has not even 
faced organised trolling yet. “They might be confused that what kind of attack could neutralise me,” the account 
holder said.
Load-Date: January 4, 2025
End of Document
Page 1 of 3
Why ‘AI slop’ is taking over the internet — and how to spot it
Why ‘AI slop’ is taking over the internet — and how to spot it
thetimes.co.uk
January 3, 2025 Friday 8:43 PM GMT
Copyright 2025 News International Ltd All Rights Reserved
Length: 893 words
Byline: Matilda Davies, Data Journalist
Highlight: The trust we had in pictures and videos is vanishing as artificial intelligence becomes better at fooling us 
— but there are ways to detect AI-generated content
Body
A child being bullied. A bed with a giant fan embedded in the headboard. A “barndominium” (a barn converted into a 
living space) in sprawling green fields. These were some of the most viewed images on Facebook last autumn — 
and they’re all AI slop.
Of the top 20 most-viewed posts on the platform in the United States, four were obviously created by artificial 
intelligence. Last summer, there were only two. Before that, nothing.
Most of this content is not false depictions of people created with AI, known as deepfakes, although this does still 
happen. It’s amateur content created by ordinary people, described by tech experts as “AI slop”.
The image of the child being bullied was posted on Facebook by an Ohio mother and school counsellor, alongside 
a caption about preventing bullying as children went back to school. It became the fourth most-viewed post in the 
US that quarter, seen by more than 38 million people.
While this has few real-world consequences, that isn’t always the case. On New Year’s Eve, 
thousands of people arrived at Birmingham’s Centenary Square
 expecting a fireworks display.
It had been advertised by what appeared to be AI-generated news articles for a “spectacular midnight show” that 
never materialised. The false information was then disseminated by legitimate outlets, such as Prima magazine, 
and people believed it.
These instances are becoming more common. 
In Dublin last Halloween

Page 2 of 3
Why ‘AI slop’ is taking over the internet — and how to spot it
, thousands flooded the streets to attend a parade fabricated by a Pakistan-hosted website that creates AI-
generated news. Last February, Willy’s Chocolate Experience, an immersive 
Willy Wonka-inspired event in Glasgow
, became infamous after it didn’t deliver on its AI-generated adverts.
The increasing availability of generative AI models, which can create text, images, video and audio based on 
prompts, means that more and more social media timelines are littered with AI-created content.
It’s likely to get worse before it gets better. Bo Bergstedt, a world-leading generative AI expert, said: “It’s just what 
happens when everybody suddenly has tools to create an image or text or music or video or whatever by just typing 
a prompt. That doesn’t make it a good piece of content, which is why we just call it slop.
“Everyone can do it now, and it’s just being blasted out. I’ve been seeing it for five years moving slowly and then 
extremely fast now.”
OpenAI released the first iteration of ChatGPT in November 2022, which reached one million users in five days. 
Although it initially only produced text, it now creates images using a text-to-image model called DALL-E 3. By 
November last year, it was the 12th most visited website in the UK, and the eighth most visited worldwide.
There are now numerous similar tools available online, including 
Midjourney
, which creates realistic images, Jasper, which specialises in marketing materials, and 
Synthesia
, which creates videos and can clone voices.
Meta, the company that owns Facebook, Instagram and WhatsApp, revealed last week that it plans to allow AI bots 
on its platforms as users. Connor Hayes, Meta’s vice-president of product for generative AI, told the Financial 
Times: “They’ll have bios and profile pictures and be able to generate and share content powered by AI on the 
platform … that’s where we see all of this going.”
Instagram to launch AI tools that can create deepfakes
As the technology gets more advanced, it is becoming harder to recognise what content is created by humans, and 
what is created by AI.
Social media companies are making moves to label AI-generated content, but it is no simple task. Meta now 
includes AI information in the menu on pictures on Facebook and Instagram, but has been criticised after labels 
incorrectly appeared on real photos.
Bergstedt explained: “It was putting small labels beneath images that looked normal, because people used really 
aggressive filters or AI tools to make themselves look better, or tone the skin or make their eyes more clear.
“There are big decisions they have to make now: Do they mark it all? Or is there some kind of grading of what AI is 
okay and what AI should be noticed?”
AI could map and manipulate our desires, say Cambridge researchers
But there are ways anyone can spot AI usage. Antony Cousins, an AI consultant, said that text “doesn’t resonate. 
It’s bland. It lacks active words — the writing is far too passive.”
Page 3 of 3
Why ‘AI slop’ is taking over the internet — and how to spot it
A study last year in Germany — yet to be peer-reviewed — found that ChatGPT overuses “style words”, particularly 
adjectives such as intricate, pivotal or notably.
In images, AI image generators often struggle with details such as hands, text, and logos. Lighting and shadows 
can also be illogical. The image generators also tend to make images that look perfect in ways real life often is not, 
in a similar way to airbrushing.
But the primary giveaway, Bergstedt says, is “hallucinations”, which is where 
AI
 fills in gaps in its knowledge by fabricating information.
“Slow down,” Bergstedt advised. “It’s a very journalistic practice. If I see something that’s strange or odd, I double-
check it. I go and search for it afterwards to see if I can find other sources.
“You can read text wherever you want, but how do you judge if what you read was real? I think we have to go back 
to that with images and video and audio as well. That trust we had for what, 100 years in images and video, it’s just 
gone.”
Load-Date: January 3, 2025
End of Document
Page 1 of 4
Why the internet is filling up with nonsense ‘AI slop’
Why the internet is filling up with nonsense ‘AI slop’
telegraph.co.uk
January 1, 2025 Wednesday 12:00 PM GMT
Copyright 2025 Telegraph Media Group Holdings Limited All Rights Reserved
Section: BUSINESS; Version:1
Length: 1323 words
Byline: By Matthew Field, Senior Technology Reporter
Highlight: Low-quality fake images are cluttering social media feeds in the race to go viral
Body
Elon Musk riding a UFO, “Shrimp Jesus” and tiny children baking impossibly perfect birthday cakes.
These are just three examples of bizarre AI-generated imagery that has taken over the internet in the past year.
Across Facebook, X, Instagram and TikTok, surreal AI images have been plaguing news feeds, typically 
accompanied by nonsensical captions in broken English.
Dubbed “AI slop”, there is no hiding from the manipulated images and videos, with their prominence even leading 
to the Oxford University Press (OUP) naming “slop” as a contender for its word of the year.
Slop, the OUP writes, is “art, writing, or other content generated using artificial intelligence, shared and distributed 
online in an indiscriminate or intrusive way, characterised as being of low quality, inauthentic, or inaccurate”.
There have long been fears that AI image tools could be used to create highly convincing “deepfakes”  and images 
or videos that could help spread disinformation or influence elections.
But so far, the most viral AI images have been obviously fake and downright strange. Free software for creating 
images and videos has led to a surge in slop, driven by scammers, spammers and the occasional genuine user 
seeking to go viral.
Facebook’s most recent report from its Transparency Center reveals that two of the top five most widely viewed 
images on the network in the three months to September were AI-generated – viewed 38.6m and 35.8m times 
respectively.
Matt Navara, a social media consultant, says the novelty of these posts has quickly worn thin for many of 
Facebook’s billions of users.

Page 2 of 4
Why the internet is filling up with nonsense ‘AI slop’
“The proliferation of low-quality or spammy AI content  risks cluttering feeds and diminishing overall user 
satisfaction,” he says.
“I’m seeing little evidence yet that users are actively demanding such content in their feeds.”
In March, Facebook users began to notice a flood of images featuring Jesus Christ mixed with a crustacean rising 
from the sea. These “Shrimp Jesus” posts garnered hundreds of thousands of interactions and tens of millions of 
views.
Other weird AI trends soon emerged, including African women building fruit sculptures and young children showing 
off elaborate birthday cakes with the caption: “This is my first cake”.
On Facebook, these posts were published on pages with innocuous names such as “Easy Recipes”, “Interesting 
Planet” or “Life Nature”. A study in March by researchers at the Stanford Internet Observatory found that many 
pages filled with AI content were likely attempts by scammers to cash in on virality.
They found 120 pages posting improbable AI images with clickbait headlines, many of which shared the same 
creator or published multiple posts with the same captions.
Some garnered a huge response despite their bizarre nature. One popular “Crab Jesus” had 209,000 engagements 
and 4,000 comments.
“We suspect these high levels of engagement are partially driven by the Facebook recommendation algorithm,” the 
report said.
The AI images were “captivating visually, easy to create, cheap to generate in large numbers [and allowed the 
pages] to engage in high rates of posting of new content that might grab people’s eyes”, says Josh Goldstein of 
Georgetown University, one of the report’s authors.
He called this phenomenon a new kind of “engagement bait”.
Among the pages highlighted by the report were many that appeared to have been hacked and turned into AI 
content farms. These pages sought to direct users away from Facebook to websites that could then be used to eke 
out a trickle of advertising income.
Meanwhile, on YouTube and Telegram, a network of influencers – many from India or the Philippines – are busy 
coaching their followers on how to make money from slop.
In one video, an influencer tells followers to create viral images depicting an old man being eaten by insects.
“The Indian audience is very emotional, after seeing photos like this, they like, comment and share them,” he says, 
claiming that users can make money through a Facebook scheme called “Performance Bonus”, which provides a 
tiny fee to creators of viral content. His video promises followers they can make 4 lakh (£3,700) per month.
Other AI images have also been shared widely during some of the biggest news events of the year – and not just 
by grifters and scammers.
In May, a pro-Palestinian Instagram template  created using AI, originally designed with Microsoft’s Image Creator, 
was shared more than 50m times, including by celebrities such as Bella Hadid. The template featured a crude 
refugee camp disappearing towards the horizon with the words “All Eyes on Rafah”.
In October, Republicans in the US took to sharing AI-generated images in the wake of Hurricane Helene to criticise 
Joe Biden’s response plan.
Amy Kremer, a Republican activist, shared a post on X of a crying girl holding a puppy during a flood. “Y’all, I don’t 
know where this photo came from and honestly, it doesn’t matter,” she said.
Page 3 of 4
Why the internet is filling up with nonsense ‘AI slop’
Then, as the US election approached, a new surge of AI images featuring Republican donor Elon Musk spread 
rapidly across Facebook.
This included posts claiming that the Tesla founder had created a flying saucer.
However, it is not just images that are the problem.
Newsguard, the news rating service, has identified more than 1,000 websites pumping out AI-generated fake news 
stories in 16 languages, many of which appear to have little or no human oversight.
McKenzie Sadeghi, AI editor at Newsguard, says: “Our tracking of AI-generated news websites has found that it 
shows no signs of slowing down. The barriers to creating AI-generated content remain low and the incentives – 
programmatic advertising revenue, site traffic, engagement – remain.”
Tech giants have taken some measures to separate fake from legitimate posts, including Facebook, which labelled 
some posts with the tag “AI Info”.
But the industry has also been aggressively pushing more users to adopt their own AI tools, such as Meta’s AI 
assistant or X’s Grok.
Meta has also started encouraging users to create their own fake images, while also promoting other AI-generated 
content on Facebook and Instagram feeds.
However, with a flood of more low-quality content on the horizon, some technologists are urging Meta to reconsider 
the prominence given to these posts.
“If platforms value human creativity, they should label and downrank outputs in which human creative involvement 
is minimal,” says Ed Newton-Rex, founder of Fairly Trained, a non-profit advocating for tech companies to respect 
creative rights.
He adds: “I think the latent demand for spaces that are human-first is higher than many companies realise.”
Some AI experts have suggested that over time, Meta and others will adjust their algorithms to deprioritise the most 
egregious AI slop – much like spam filters. However, Meta’s own stated plans suggest otherwise.
Data from the company’s Transparency Center shows that in the three months to September, more than 31pc of 
content viewed on Facebook was from accounts “unconnected” to the user – meaning it has been served up by an 
algorithm.
This is up from 8pc in 2021 and 24pc this time last year. Meanwhile, on Instagram, a growing number of AI videos 
have been populating users’ feeds and Reels.
Mark Zuckerberg has also made it clear that he expects the internet to gradually become populated with more AI 
posts, believing that is exactly what his users want.
“I think there’s been this trend over time where the feeds started off as primarily and exclusively content for people 
you followed, your friends,” he told The Verge.
“We’re also going to show you content that’s generated by an AI system that might be something that you’re 
interested in ... how big it gets is kind of dependent on the execution and how good it is.”
This is a far cry from Zuckerberg’s previous goal of spreading “meaningful social interactions”, as it seems apparent 
that Facebook and other online platforms show no sign of slowing up in displaying mindless scrolling content.
Load-Date: January 1, 2025
Page 4 of 4
Why the internet is filling up with nonsense ‘AI slop’
End of Document
Page 1 of 3
The surreal AI 'slop' taking over social media feeds Sites are turning away from human content amid 
competition for clicks, reports Matthew Field
The surreal AI 'slop' taking over social media feeds; Sites are turning away 
from human content amid competition for clicks, reports Matthew Field
The Daily Telegraph (London)
January 1, 2025 Wednesday
Edition 1, National Edition
Copyright 2025 Telegraph Media Group Holdings Limited All Rights Reserved
Section: BUSINESS; Pg. 21
Length: 1044 words
Byline: Matthew Field
Body
ELON MUSK riding a UFO, "Shrimp Jesus" and tiny children baking impossibly perfect birthday cakes.
These are just three examples of bizarre AI-generated imagery that has taken over the internet in the past year.
Across Facebook, X, Instagram and TikTok, surreal AI images have been plaguing news feeds, typically 
accompanied by nonsensical captions in broken English.
Described as "AI slop", there is no hiding from the manipulated images and videos, with their prominence even 
leading to the Oxford University Press (OUP) naming "slop" as a contender for its word of the year.
Slop, the OUP writes, is "art, writing, or other content generated using artificial intelligence, shared and distributed 
online in an indiscriminate or intrusive way, characterised as being of low quality, inauthentic, or inaccurate".
There have long been fears that AI image tools could be used to create highly convincing "deepfakes" and images 
or videos that could help spread disinformation or influence elections. But, so far, the most viral AI images have 
been obviously fake and downright strange. Free software for creating images and videos has led to a surge in 
slop, driven by scammers, spammers and the occasional genuine user seeking to go viral.
Facebook's most recent report from its "transparency centre" reveals that two of the top five most widely viewed 
images on the network in the three months to September were AIgenerated - viewed 38.6m and 35.8m times 
respectively.

Page 2 of 3
The surreal AI 'slop' taking over social media feeds Sites are turning away from human content amid 
competition for clicks, reports Matthew Field
Matt Navara, a social media consultant, says the novelty of these posts has quickly worn thin for many of 
Facebook's billions of users. "The proliferation of low-quality or spammy AI content risks cluttering feeds and 
diminishing overall user satisfaction," he says. "I'm seeing little evidence yet that users are actively demanding such 
content in their feeds."
In March, Facebook users began to notice a flood of images featuring Jesus Christ mixed with a crustacean rising 
from the sea. These "Shrimp Jesus" posts garnered hundreds of thousands of interactions and tens of millions of 
views. Other weird AI trends soon emerged, including African women building fruit sculptures and young children 
showing off elaborate birthday cakes with the caption: "This is my first cake".
A study in March by researchers at the Stanford Internet Observatory found that many pages filled with AI content 
were probably attempts by scammers to cash in on virality.
Some garnered a huge response, even despite their bizarre nature. One popular "Crab Jesus" had 209,000 
engagements and 4,000 comments.
"We suspect these high levels of engagement are partially driven by the Facebook recommendation algorithm," the 
report said.
The AI images were "captivating visually, easy to create, cheap to generate in large numbers [and allowed the 
pages] to engage in high rates of posting of new content that might grab people's eyes", says Josh Goldstein, of 
Georgetown University, one of the report's authors.
He called this phenomenon a new kind of "engagement bait".
Among the pages highlighted by the report were many that appeared to have been hacked and turned into AI 
content farms. These pages sought to direct users away from Facebook to websites that could then be used to eke 
out a trickle of advertising income.
Then, as the US election approached, a new surge of AI images featuring Republican donor Elon Musk spread 
rapidly across Facebook.
This included posts claiming that the Tesla founder had created a flying saucer. However, it is not just images that 
are the problem.
Newsguard, the news rating service, has identified more than 1,000 websites pumping out AI-generated fake news 
stories in 16 languages, many of which appear to have little or no human oversight. McKenzie
Sadeghi, AI editor at Newsguard, says: "Our tracking of AI-generated news websites has found that it shows no 
signs of slowing down. The barriers to creating AI-generated content remain low and the incentives - programmatic 
advertising revenue, site traffic, engagement - remain."
Tech giants have taken some measures to separate fake from legitimate posts, including Facebook, which labelled 
some posts with the tag "AI Info".
But the industry has also been aggressively pushing more users to adopt their own AI tools, such as Meta's AI 
assistant or X's Grok.
Meta has also started encouraging users to create their own fake images, while also promoting other AIgenerated 
content on Facebook and Instagram feeds.
However, with a flood of more low-quality content on the horizon, some technologists are urging Meta to reconsider 
the prominence given to these posts.
Page 3 of 3
The surreal AI 'slop' taking over social media feeds Sites are turning away from human content amid 
competition for clicks, reports Matthew Field
"If platforms value human creativity, they should label and downrank outputs in which human creative involvement 
is minimal," says Ed Newton-Rex, founder of Fairly Trained, a non-profit advocating for tech companies to respect 
creative rights.
Some AI experts have suggested that over time, Meta and others will adjust their algorithms to deprioritise the most 
egregious AI slop - much like spam filters. However, Meta's own stated plans suggest otherwise.
Data from the company's transparency centre shows that in the three months to September, more than 31pc of 
content viewed on Facebook was from accounts "unconnected" to the user - meaning it has been served up by an 
algorithm.
This is up from 8pc in 2021 and 24pc this time last year. Meanwhile, on
Instagram, a growing number of AI videos have been populating users' feeds and reels.
Mark Zuckerberg has also made it clear that he expects the internet to gradually become populated with more AI 
posts, believing that is exactly what his users want. "I think there's been this trend where the feeds started off as 
primarily and exclusively content for people you followed, your friends," he told The Verge.
"We're also going to show you content that's generated by an AI system that might be something that you're 
interested in. How big it gets is kind of dependent on the execution and how good it is."
This is a far cry from Zuckerberg's previous goal of spreading "meaningful social interactions", as it seems apparent 
that Facebook and other online platforms show no sign of slowing up in displaying mindless scrolling content.
'The proliferation of lowquality or spammy AI content risks cluttering feeds and diminishing satisfaction'
Graphic
 
Variations of 'Shrimp Jesus' images started appearing on Facebook last March, gaining tens of millions of views
Load-Date: January 1, 2025
End of Document
Page 1 of 2
Toronto can be a lonely city. I found community in an unlikely place
Toronto can be a lonely city. I found community in an unlikely place
thestar.com
December 31, 2024 Tuesday
Final Edition
Copyright 2024 Toronto Star Newspapers, Ltd. All Rights Reserved
Section: OPINION/CONTRIBUTORS; Pg. 1
Length: 615 words
Byline: David Silverberg Contributor
Body
 Five years ago, when I moved to the Hillcrest Village area of Toronto, I knew almost nothing about the 
neighbourhood. I then decided to do something I never did when I lived in the Annex, where I simply didn't feel as 
engaged as a resident: I joined a Facebook Group.
Brimming with almost 8,000 members, the group, called "Hillcrest Village/Humewood/Wychwood," informed me not 
just about some ideal restos to enjoy (Aviv Immigrant Kitchen for date night, Pukka for Indian, Goen for affordable 
sushi) but also a slew of important news that wasn't on CP24's ticker: the porch pirates stealing Amazon boxes off 
porches, the construction that was causing traffic on St. Clair West, the blackouts that left us without Internet or 
cable.
These days, it can be easy to associate Facebook with AI slop and contentious debates. But the local groups found 
on the social network can also be a lifeline for those seeking not just information, but community too.
While no online space is devoid of strife, there's often a friendly vibe within these groups. When I first used it to 
solicit ideas for a homemade gift for my mother on Mother's Day, many commenters quickly pointed me in the right 
direction. It wasn't to Etsy or Amazon, either. Instead, people took the time to consider which local artist would best 
be suited for my ask.
That focus on the local speaks to how these groups can value community. Available for practically every 
neighbourhood in Toronto, they can also act as an online advice column. I've seen dozens of comments under 
posts with questions such as, "How do I turn a very poorly maintained tiny front yard into something more 
manageable and attractive?" and "How do I deal with noisy neighbours whose kids screech and yell at painful 
decibel levels?"
It would be too glib to declare that Facebook Groups will save local community, or that they have replaced our 
traditional locales such as churches or community centres. But it's highly likely they have filled a widening gap.
What circulates on Facebook Groups can also have long-standing impacts. In a 2021 study by German 
researchers, they stated that these groups "can influence a community's practices and behaviors in the short term 

Page 2 of 2
Toronto can be a lonely city. I found community in an unlikely place
and shift norms, values and shared beliefs in the long term, ultimately contributing to the permanent 
institutionalization of social resilience."
Put another way: if we've all heard how our heads are too buried in our phones to connect with each other 
anymore, with Facebook Groups, we're forging new relationships in a way that would have been nearly impossible 
before social media.
As with any online group, some posts can go too far. A surveillance culture of hyper-vigilance may lead to wrongful 
accusations against people who may have had nothing to do criminal activity. Disparaging statements about 
minorities have also infiltrated one of the groups I joined, which the moderators are quick to stamp out. But these 
unwanted posts make up a tiny fraction of the otherwise helpful comments and alerts filling these groups daily.
Hyper-local online groups have evolved to create what American psychiatrist Scott Peck calls "true community." In 
these collectives, members relate to each other's feelings, and heated discussions never sour. The mood is 
generally cheerful and positive. Even if friction comes between members in some posts, they know that that is for a 
positive change.
Spending time in these groups inspires me to be a more active participant in my community, online and offline. And 
returning to that platform to see what my neighbours are discussing, warning, promoting, and delighting in is, at 
least in the world of social media, like finding light amid a sea of dark clouds. 
Load-Date: December 31, 2024
End of Document
Page 1 of 6
24 lows of 2024 Ranking the ridiculous, the absurd and a few very dark moments in a very long year By Richie 
Assaly, Joshua Chong, Laura deCarufel, Deborah Dund....
24 lows of 2024; Ranking the ridiculous, the absurd and a few very dark 
moments in a very long year By Richie Assaly, Joshua Chong, Laura 
deCarufel, Deborah Dundas, Kevin Jiang, Debra Yeo
The Toronto Star
December 28, 2024 Saturday
ONT Edition
Copyright 2024 Toronto Star Newspapers Ltd. All Rights Reserved
Section: CULTURE; Pg. C11
Length: 2785 words
Body
 Theatre
1. Tim Hortons makes a disastrous foray into musical theatre
Tim Hortons should stick to what it knows best: coffee and doughnuts. The multinational chain's foray into theatre in 
June, with a new musical called "The Last Timbit," was nothing short of a disaster, possibly taking the (birthday) 
cake (timbit) as the company's worst publicity stunt ever. Not even a Broadway-calibre cast and a trio of Canada's 
best writers could save this 75-minute commercial advertisement masquerading as a musical. 
Celebrity
2. The Costco Guys 'bring the boom' to your FYP
What started out as an innocent enough shtick - a father-and-son duo from Florida find minor TikTok fame filming 
short videos clips from inside a Costco warehouse - morphed into a grotesque gluttony of smooth-brained content, 
much of which is centred around an absurd but admittedly catchy rap-rock song ("We Bring the Boom") that has 
spawned an entire cottage industry of music videos, dance challenges, podcasts and spinoffs. In recent months, the 
Costco Guys extended universe has expanded beyond A.J. and Big Justice to incorporate a roster of astonishingly 
unremarkable characters, including, but not limited to, the Rizzler, a third-grader from New Jersey known for 
pioneering "the rizz face." Devoid of meaning or substance but somehow compelling, the Costco Guys' content is 
almost indistinguishable from AI slop. The fact that it is made by real human beings is a tragedy, the apotheosis of 
internet brain rot. 
Theatre
4. Two theatres head to court

Page 2 of 6
24 lows of 2024 Ranking the ridiculous, the absurd and a few very dark moments in a very long year By Richie 
Assaly, Joshua Chong, Laura deCarufel, Deborah Dund....
A pair of prominent arts organizations in Ontario became locked in a legal dispute following a cancelled production 
last year. In September, Factory Theatre in Toronto sued the Blyth Festival for $115,000, alleging the organization 
breached its agreement by unilaterally pulling a Factory-produced play from its lineup. A month later, the Blyth 
Festival launched a counterclaim, saying the Toronto company reneged on its own contract and displayed "overt 
unpreparedness and unwillingness to co-operate." The case is still open and will likely further play out next year. 
Television
5. Reality TV reveals its ugly side
So-called "reality TV" isn't going away anytime soon with streamers like Netflix and Prime Video jumping on the 
bandwagon. But it got a black eye in 2024 with everything from lawsuits alleging abuse on "Mr. Beast" and "Love Is 
Blind," to the divorce of the first "Golden Bachelor" and his bride of three months, to outrage over "Bachelorette" 
producers' callous treatment of their first Asian lead. Whatever appears onscreen, the behind-the-scenes reality 
isn't pretty. 
Dance
6. Raygun gives an absurd Olympic performance
The intersection of sports and culture is narrow. But smack dab in the middle of that Venn Diagram sits Rachael 
Gunn, the infamous Australian breakdancer known as Raygun, who sparked a pop culture firestorm after she 
crashed out of the Olympics this summer without earning a single point. While the university lecturer-turned-athlete 
might not have embodied the motto of the world's greatest sporting event ("Faster, Higher, Stronger"), at least she 
gave all of us hope that perhaps we, too, could find ourselves at the Olympics. Just admit it: how many of you found 
yourself muttering, "Surely, I can do better than that?" 
music
7. Katy Perry takes a hollow stab at a feminist anthem 
"Sexy, confident / So intelligent / She is heaven-sent / So soft, so strong," Katy Perry sings joylessly on her 
universally panned comeback single "Woman's World," a song with lyrics that, in the words of Star writer Emilie 
Hanskamp, "read like an affirmation board you'd find in a HomeSense liquidation section." The song was released 
along with a music video filled with imagery so retrograde that people were genuinely puzzled over whether it was 
satirical. Arriving in the midst of an exciting, women-led pop revival, Perry's track landed like a tonne of bricks, 
offering up an accidental reminder of how far we've come: "In this era of complicated womanhood," wrote 
Hanskamp, "the lowest hanging feminist fruit is no longer sufficient. That is something to celebrate." 
theatre
8. 'Les Misérables' revs up
Jean Valjean sure was in a hurry in Mirvish's recent presentation of "Les Misérables." If you're a fan of the classic 
musical and caught the show at the Princess of Wales Theatre, you may have felt it was being performed in 
hyperdrive. You're not wrong. It was. This North American touring production increased the tempos of songs and 
rushed through scenes at a frantic pace, all to keep the total run time under three hours so they wouldn't have to 
pay the company for overtime. The result was not just noticeable but disappointing. 
music
9. Grimes bombs at Coachella 
Listen, I will always defend Grimes, the Canadian singer who has evolved into a controversy-magnet since entering 
the orbit of Elon Musk, because Grimes made two of the best indie pop albums of the 2010s. But I was unable to 
Page 3 of 6
24 lows of 2024 Ranking the ridiculous, the absurd and a few very dark moments in a very long year By Richie 
Assaly, Joshua Chong, Laura deCarufel, Deborah Dund....
deny myself the schadenfreude of watching her Coachella set go completely off the rails last spring. "I have not 
practised the math because I am not fast at math," Grimes desperately tried to explain to a massive Sahara tent 
audience stunned by the silence caused by what she says was a "major technical problem." She eventually 
apologized and figured things out for weekend two, but that didn't deter the memes. 
theatre
10. Hot Docs faces layoffs, resignations and allegations of toxic behaviour
Canada's largest documentary film festival now faces an uncertain future following months of internal turmoil. 
Earlier this year, 10 employees resigned en masse, while the festival's now-former artistic director faced multiple 
allegations of "grave mismanagement" and fostering a "toxic work environment." Then, later in the summer, Hot 
Docs president Marie Nelson abruptly left the organization, just a year into her tenure. In addition to the departures, 
the festival also faced what it described as "urgent" financial challenges. That led to a temporary closure of its 
flagship Toronto theatre, which only reopened earlier this month following a financial restructuring. 
celebrity
11. The 'Where is Kate?' media circus gets louder
When Catherine, Princess of Wales, largely removed herself from the public eye earlier this year, a frenzied, 
"Where is Kate?" media circus ensued. It got messy and, frankly, cruel. Conspiracies spread like wildfire. Blame 
was levelled against the princess and her family. It all highlighted the perverse and dangerously obsessive nature of 
social media and the paparazzi. Kate, of course, later shared that she was diagnosed with cancer. Let's hope the 
public remorse that followed will serve as a lesson moving forward.
theatre
12. Harbourfront Centre announces dance theatre closure 
In a major blow to the city's performing arts scene, Harbourfront Centre announced in November that it planned to 
shutter the Fleck Dance Theatre, the city's only purpose-built dance venue. The impending closure, which will leave 
many established companies without a home, marks the latest setback for the arts organization, which has faced 
major financial challenges since the pandemic, leading to staff layoffs. 
music
13. 'Rogers' concert venues proliferate
When Live Nation Canada announced it was building a new concert venue at the former site of Downsview Airport, 
attention quickly turned to its name: Rogers Stadium. That the telecommunications giant was the namesake for yet 
another venue - not to be confused with the Rogers Centre in downtown Toronto, Rogers Arena in Vancouver or 
Rogers Place in Edmonton, to name a few - signifies the out-of-control monopoly major corporations have over 
naming rights, much to the annoyance and confusion of spectators. It's not just Rogers, though. In Toronto, there's 
also the CAA Theatre and the CAA Ed Mirvish Theatre, along with Meridian Hall and the Meridian Arts Centre. 
art
14. AI art breaks the internet
There are few clearer signs of the slow decline of the internet - and perhaps art in general - than the proliferation of 
bizarre AI image slop infesting everything from search engines to your great-uncle's Facebook feed. Trolls and 
disinformation dealers are having a blast churning out scandalous images of multi-fingered politicians and 
pornography of unconsenting women. But the tech is cheap, fast and convincing enough to bleary-eyed 
doomscrollers - virtual gold for profit-obsessed megacorporations. Watching Coca-Cola's eerie, fully AI-generated 
Page 4 of 6
24 lows of 2024 Ranking the ridiculous, the absurd and a few very dark moments in a very long year By Richie 
Assaly, Joshua Chong, Laura deCarufel, Deborah Dund....
Christmas ad campaign this year, one has to wonder: are we staring at a fad or the soulless embodiment of our 
future? 
music
16. Taylor Swift vs Beyoncé narrative continues
They're the two biggest pop stars in the world and they're women: in the shallow disc that often serves as internet 
culture, a feud narrative was inevitable. (Doesn't mean it's not exhausting.) At year's end - after the Grammys, the 
Eras Tour, "Cowboy Carter" and "The Tortured Poets Department" - Billboard entered the chat with a list of the 
greatest pop stars of the 21st century that it slowly dripped, day by day, like sparkly poison. When Swift was 
announced as the No. 2 artist, the No. 1 was clear - and immediately controversial. Fandoms gonna fandom: they 
got right into it online, taking the manufactured bait. The next stage for the drama is the 2025 Grammys, where 
Swift and Beyoncé are both nominated for record of the year and album of the year. Friendship bracelets, anyone? 
music
17. Charli xcx unwisely wades into political discourse
On the campaign trail just weeks ahead of the U.S. presidential election, Sen. Amy Klobuchar asked Democratic 
supporters to conjure up an aspirational image of the future. "Picture this," she said. "Bernie Sanders and Dick 
Cheney together holding a sign that says 'Brat fall.' "
This moment, which for many felt like a terrible omen and an indictment of what would eventually prove to be a 
disastrous campaign by the Democrats, was also a very good example of what happens when politicians get ahold 
of a good meme: what was once fun and unifying becomes cringey and eventually meaningless.
This all started, of course, when Charli xcx posted a simple message on X: "kamala IS brat." The tweet was a 
reference to her recent album title, which had become an internet sensation as a symbol of a certain type of messy, 
party-girl lifestyle. One can't exactly fault the English singer - at the time, Kamala Harris seemed like the Democrats' 
only hope of defeating Donald Trump. 
But the tweet quickly went viral, forcing hundreds of confused journalists and news anchors around the world to 
twist themselves in knots trying to explain the meaning of this meme. Like almost anything related to U.S. politics in 
2024, the Kamala-brat discourse quickly became messy and divisive, signalling a bitter end to "brat summer." 
theatre
18. Toronto's cultural scene faces financial headwinds
Over the past year, scores of arts organizations and artist spaces in Toronto have been forced to permanently 
shutter or drastically cut programming, the result of financial headwinds and operational hurdles that were induced 
by the pandemic but have spiralled into a wider crisis across the sector, leading to a reckoning - among artists, 
patrons and public officials - about the viability and future of the once-thriving industry.
It fomented under a perfect storm. As these organizations resumed in-person programming following months-long 
pandemic closures, they were met with changing consumer trends, inflationary pressures and a cost-of-living crisis 
that drove many artists out of the sector. At the same time, arts funding across all levels of government remained 
stagnant, while other sources of revenue from private and corporate donors have largely evaporated.
The challenges affected organizations both large and small, and across a variety of disciplines. In March, the Shaw 
Festival reported the largest deficit in its history. That same week, Just for Laughs announced it was cancelling its 
annual festival in Toronto and seeking to restructure its business. As well, more than half of independent cinemas in 
the country reported they were operating at a loss. 
Page 5 of 6
24 lows of 2024 Ranking the ridiculous, the absurd and a few very dark moments in a very long year By Richie 
Assaly, Joshua Chong, Laura deCarufel, Deborah Dund....
celebrity
19. Hulk Hogan stumps for Trump
The most surreal pop culture moment of the year arrived earlier this summer, when the former professional wrestler 
Hulk Hogan delivered a fanatical address at the Republican National Convention in support of Donald Trump, his 
self-proclaimed "hero." Just how far did the Hulkster go? Well, it will be hard to erase that image of Hogan ripping 
off his shirt and suit jacket to reveal a tank top emblazoned with the Trump-Vance logo. How ironic that in the same 
stump speech, the rabble rouser also said: "As an entertainer, I try to stay out of politics." Perhaps some of these 
entertainers need to try a bit harder. 
celebrity
20. 'Hawk Tuah Girl' makes us wonder if the internet was a mistake
A video clip of a young woman making a crude joke becomes an ultra-viral meme. Young woman cleverly 
capitalizes on her fleeting internet fame by leaning into the absurdity of the moment, begins selling merchandise, 
appearing at campus events around the country. Young woman appears on Bill Maher's podcast. Young woman 
launches "Talk Tuah," which bafflingly becomes one of the most popular podcasts in America. Young woman 
launches her own cryptocurrency, "$HAWK," which briefly explodes in value before collapsing into dust. Young 
woman tells her livestream that she is "going to bed," then disappears from the public eyes for two weeks, before 
resurfacing to offer a tepid legal statement.
" 'Hawk Tuah' Girl Haliey Welch's Memecoin Project Sued After Crash" read a Dec. 19 headline from TMZ: a nearly 
unintelligible string of words that nonetheless offers a neat summary of the most inane story of 2024, a story that 
doubles as a bleak warning about the blurring of the internet and the real world. 
books
21. The Giller Prize divides literary community
In the lead-up to the 2024 Giller Prize gala, hundreds of authors and cultural workers joined a boycott of the 
prestigious literary event, accusing the prize of "artwashing" genocide, and demanding that the Giller Foundation 
cut ties with Scotiabank and other sponsors "invested in the oppression of Palestinians." The boycott marked the 
culmination of a high-profile campaign that for over a year had sought to draw attention to Scotiabank's investments 
in an Israeli arms manufacturer, a campaign that in many ways has come to represent how the war in Gaza has 
fractured arts communities across Canada. "It is our position that the only way to remedy what has been a deeply 
divisive period in Canadian arts is for the chief funders of so many arts prizes and organizations in Canada - banks 
such as Scotiabank - to divest from companies whose products are currently being used in mass killing," wrote 
eight former Giller Prize winners in an open letter published by the Star. 
music
22. Diddy is accused of sexual misconduct
Sean "Diddy" Combs, the hip-hop superstar who ruled the music world for more than two decades, faces charges of 
sex trafficking and racketeering, along with accusations of sexual misconduct from at least 120 people. Combs' 
arrest earlier this year was a stunning unravelling of Combs' career and public image, beginning in November 2023 
with a lawsuit filed by his ex-girlfriend. The music artist has repeatedly denied the allegations, which are currently 
before the court. 
music
23. Kendrick Lamar drags Drake through the mud
Page 6 of 6
24 lows of 2024 Ranking the ridiculous, the absurd and a few very dark moments in a very long year By Richie 
Assaly, Joshua Chong, Laura deCarufel, Deborah Dund....
It feels superfluous, at this point, to recount the many humiliations suffered by Drake in the wake of his culture-
shifting feud with Kendrick Lamar. As the dust settles following Lamar's knockout punch - the brutal, chart-topping 
diss track "Not Like Us" - the Toronto superstar has shrunk from the spotlight, a shell of his former self: isolated and 
litigious, posting lonely selfies from his sprawling Bridle Path mansion, betrayed by his friends and abandoned by 
the city that once worshipped him.
Of course, Drake is too big to fail. A generational hitmaker, the 38-year-old is destined to return to the charts and to 
the cultural zeitgeist. But it seems unlikely that he will ever fully recover from the central critique of "Not Like Us": 
that as an artist he lacks authenticity. That he's a "culture vulture" who attaches himself to whichever rising star or 
burgeoning regional scene he can profit from the most. That he doesn't represent real hip-hop or Black culture, but 
appropriates. "No, you not a colleague, you a f-kin' colonizer." What makes this critique so devastating - more 
damaging even than Kendrick's baseless claim that Drake is a "pedophile" - is the fact it reveals something that, 
deep down, we might have suspected all along. 
Load-Date: December 28, 2024
End of Document
Page 1 of 6
24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick drags Drake through the mud, AI 
slop and more
24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick 
drags Drake through the mud, AI slop and more
thestar.com
December 24, 2024 Tuesday
Final Edition
Copyright 2024 Toronto Star Newspapers, Ltd. All Rights Reserved
Section: ENTERTAINMENT; Pg. 1
Length: 3444 words
Body
 Tensions at Toronto arts institutions. The decline of the Hulkster. Kendrick Lamar vs. Drake, and AI art. These are 
the arts and culture moments we're happy to leave in 2024.
24. Tim Hortons makes a disastrous foray into musical theatre
Tim Hortons should stick to what it knows best: coffee and donuts. The multinational chain's foray into theatre in 
June, with a new musical called "The Last Timbit," was nothing short of a disaster, possibly taking the (birthday) 
cake (timbit) as the company's worst publicity stunt ever. Not even a Broadway-calibre cast and a trio of Canada's 
best writers could save this 75-minute commercial advertisement, masquerading as a musical. - Joshua Chong 
Read more: Our review of "The Last Timbit"
23. The Costco Guys "bring the boom" to your FYP
What started out as an innocent enough shtick - a father-and-son duo from Florida find minor TikTok fame filming 
short videos clips from inside a Costco warehouse - morphed into a grotesque gluttony of smooth-brained content, 
much of which is centred around an absurd but admittedly catchy rap-rock song ("We Bring the Boom") that has 
spawned an entire cottage industry of music videos, dance challenges, podcasts and spinoffs. In recent months, the 
Costco Guys extended universe has expanded beyond A.J. and Big Justice to incorporate a roster of astonishingly 
unremarkable characters, including, but not limited to, The Rizzler - a third-grader from New Jersey known for 
pioneering "the rizz face." Devoid of meaning or substance but somehow compelling, the Costco Guys' content is 
almost indistinguishable from AI-slop. The fact that it is made by real human beings is a tragedy, the apotheosis of 
internet brain rot. - Richie Assaly
22. Elon Musk tries and fails to make the "X jump" a thing
Elon Musk might be the richest man on earth, but all that money hasn't seemed to shield the executive chairman of 
X and very public Trump ally from making a fool of himself on almost any stage he sets foot on. This fall, Musk tried 
out a new bit in front of his audiences, where he'd hop a couple inches off the ground, open his mouth wide, and 

Page 2 of 6
24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick drags Drake through the mud, AI 
slop and more
attempt to spread his limbs into an "X" shape, exposing a few inches of his pale midriff. The image of the awkward 
manoeuvre, which he tried out multiple times over the summer, is one we'd like to forget about in 2025. - Richie 
Assaly
21. Two theatres head to court
A pair of prominent arts organizations in Ontario became locked in a legal dispute following a cancelled production 
last year. In September, Factory Theatre in Toronto sued the Blyth Festival for $115,000, alleging the organization 
breached their agreement by unilaterally pulling a Factory-produced play from its lineup. A month later, the Blyth 
Festival launched a counterclaim, saying the Toronto company reneged on its own contract and displayed "overt 
unpreparedness and unwillingness to co-operate." The case is still open and will likely further play out next year. - 
Joshua Chong
Read more: The fraught dispute between two beloved arts institutions
20. Reality TV reveals its ugly side
So-called "reality TV" isn't going away anytime soon with streamers like Netflix and Prime Video jumping on the 
bandwagon. But it got a black eye in 2024 with everything from lawsuits alleging abuse on "Mr. Beast" and "Love Is 
Blind," to the outrage over "Bachelorette" producers' callous treatment of their first Asian lead. Whatever appears 
onscreen, the behind-the-scenes reality isn't pretty. - Debra Yeo
Read more: Mr. Beast is shooting a reality show in Toronto
19. Raygun gives an absurd Olympic performance
The intersection of sports and culture is narrow. But smack dab in the middle of that Venn Diagram sits Rachael 
Gunn, the infamous Australian breakdancer known as Raygun, who sparked a pop culture firestorm after she 
crashed out of the Olympics this summer without earning a single point. While the university lecturer-turned athlete 
may not have embodied the motto of the world's greatest sporting event ("Faster, Higher, Stronger"), at least she 
gave all of us hope that perhaps we, too, could find ourselves at the Olympics. Just admit it: how many of you found 
yourself muttering, "Surely, I can do better than that?" - Joshua Chong
Read more: Raygun is ranked number one in the world - for now
18. Katy Perry takes a hollow stab at a feminist anthem 
"Sexy, confident / So intelligent / She is heaven-sent / So soft, so strong," Katy Perry sings joylessly on her 
universally panned comeback single "Woman's World," a song with lyrics that, in the words of Star writer Emilie 
Hanskamp, "read like an affirmation board you'd find in a HomeSense liquidation section." The song was released 
along with a music video filled with imagery so retrograde that people were genuinely puzzled over whether it was 
satirical. Arriving in the midst of an exciting, women-led pop revival, Perry's track landed like a tonne of bricks, 
offering up an accidental reminder of how far we've come: "In this era of complicated womanhood," wrote 
Hanskamp, "the lowest hanging feminist fruit is no longer sufficient. That is something to celebrate." - Richie Assaly
Read more: Katy Perry's "Woman's World" is good for women - here's why
17. Les Misérables revs up
Jean Valjean sure was in a hurry in Mirvish's recent presentation of "Les Misérables." If you're a fan of the classic 
musical and caught the show at the Princess of Wales Theatre, you may have felt it was being performed in 
hyperdrive. You're not wrong. It was. This North American touring production increased the tempos of songs and 
rushed through scenes at a frantic pace, all to keep the total run time under three hours so they wouldn't have to 
pay the company for overtime. The result was not just noticeable, but disappointing. - Joshua Chong
Page 3 of 6
24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick drags Drake through the mud, AI 
slop and more
Read more: Our review of "Les Misérables"
16. Grimes bombs at Coachella 
Listen, I will always defend Grimes, the Canadian singer who has evolved into a controversy-magnet since entering 
the orbit of Elon Musk, because Grimes made two of the best indie pop albums of the 2010s. But I was unable to 
deny myself the schadenfreude of watching her Coachella set go completely off the rails last spring. "I have not 
practiced the math because I am not fast at math," Grimes desperately tried to explain to a massive Sahara tent 
audience stunned by the silence caused by what she says was a "major technical problem." She eventually 
apologized, and figured things out for weekend two, but that didn't deter the memes. - Richie Assaly
15. Hot Docs faces layoffs, resignations and allegations of toxic behaviour
Canada's largest documentary film festival now faces an uncertain future following months of internal turmoil. 
Earlier this year, 10 employees resigned en masse, while the festival's now-former artistic director faced multiple 
allegations of "grave mismanagement" and fostering a "toxic work environment." Then, later in the summer, Hot 
Docs president Marie Nelson abruptly left the organization, just a year into her tenure. In addition to the departures, 
the festival also faced what it described as "urgent" financial challenges. That led to a temporary closure of its 
flagship Toronto theatre, which only reopened earlier this month following a financial restructuring. - Joshua Chong
Read more: The implosion at Hot Docs
14. The "Where is Kate?" media circus gets louder
When Princess Catherine largely removed herself from the public eye earlier this year, a frenzied, "Where is Kate?" 
media circus ensued. It got messy and, frankly, cruel. Conspiracies spread like wildfire. Blame was levelled against 
the princess and her family. It all highlighted the perverse and dangerously obsessive nature of social media and 
the paparazzi. Kate, of course, later shared that she was diagnosed with cancer. Let's hope the public remorse that 
followed will serve as a lesson moving forward. - Joshua Chong
13. Harbourfront Centre announces dance theatre closure 
In a major blow to the city's performing arts scene, the Harboufront Centre announced in November that it planned 
to shutter the Fleck Dance Theatre, the city's only purpose-built dance theatre. The impending closure, which will 
leave many established companies without a home, marks the latest setback for the arts organization, which has 
faced major financial challenges since the pandemic, leading to staff layoffs. - Joshua Chong
Read more: The closure of this dance theatre leaves a massive hole in the arts community
12. "Rogers" concert venues proliferate
When Live Nation Canada announced it was building a new concert venue at the former site of Downsview Airport, 
attention quickly turned to its name: Rogers Stadium. That the telecommunications giant was the namesake for yet 
another venue - not to be confused with the Rogers Centre in downtown Toronto, Rogers Arena in Vancouver or 
Rogers Place in Edmonton, to name a few - signifies the out-of-control monopoly major corporations have over 
naming rights, much to the annoyance and confusion of spectators. It's not just Rogers, though. In Toronto alone, 
there's also the CAA Theatre and the CAA Ed Mirvish Theatre, along with Meridian Hall and the Meridian Arts 
Centre. - Joshua Chong
Read more: Will Rogers Stadium be ready in time for Oasis?
11. AI art breaks the internet
There are few clearer signs of the slow decline of the internet - and perhaps art in general - than the proliferation of  
bizarre AI image slop infesting everything from search engines to your great-uncle's Facebook feed.  Trolls and 
Page 4 of 6
24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick drags Drake through the mud, AI 
slop and more
disinformation dealers are having a blast churning out scandalous images of multi-fingered politicians and 
pornography of unconsenting women. But the tech is cheap, fast and convincing enough to bleary-eyed 
doomscrollers - virtual gold for profit-obsessed megacorporations. Watching Coca-Cola's eerie, fully-AI-generated 
Christmas ad campaign this year, one has to wonder - are we staring at a fad or the soulless embodiment of our 
future? - Kevin Jiang
Read more: Some Toronto theatres have been duped by AI-generated reviews
10. TIFF pauses screening of controversial war documentary
The 2024 Toronto International Film Festival featured a host of major films, including possible Oscar contenders 
"Anora" and "Emilia Pérez." But the two-week event was largely overshadowed by the controversy surrounding 
"Russians at War," a documentary by Russian-Canadian filmmaker Anastasia Trofimova. Armchair critics, including 
prominent politicians, claimed it was piece of Russian propaganda. But many of those who saw it dismissed those 
allegations, instead praising the film for its detailed insights and humanity. In his four-star review for the Star, film 
critic Corey Atad described the work as an "excellent and bracing documentary." The festival, however, still faced 
unrelenting protests, forcing organizers to pause screening of the film due to "significant threats." - Joshua Chong
Read more: Opinion: Censoring "Russians at War" is a typically Canadian kind of cowardice
9. Taylor Swift vs Beyoncé narrative continues
They're the two biggest pop stars in the world and they're women: in the shallow disc that often serves as internet 
culture, a feud narrative was inevitable. (Doesn't mean it's not exhausting.) At year's end - after the Grammys, the 
Eras Tour, "Cowboy Carter" and "The Tortured Poets Department" - Billboard entered the chat with a list of the 
greatest pop stars of the 21st century that it slowly dripped, day by day, like sparkly poison. When Taylor Swift was 
announced as the number two artist, the number one was clear - and immediately controversial. Fandoms gonna 
fandom: they got right into it online, taking the manufactured bait. The next stage for the drama is the 2025 
Grammys, where Swift and Beyoncé are both nominated for Record of the Year and Album of the Year. Friendship 
bracelets, anyone? - Laura deCarufel
Read more: 10 highlights from Taylor Swift's Toronto visit
8. Charli xcx unwisely wades into political discourse
On the campaign trail just weeks ahead of the U.S. presidential election, Sen. Amy Klobuchar asked Democratic 
supporters to conjure up an aspirational image of the future. "Picture this," she said. "Bernie Sanders and Dick 
Cheney together holding a sign that says 'Brat fall.'"
This moment, which for many felt like a terrible omen and an indictment of what would eventually prove to be a 
disastrous campaign by the Democrats, was also a very good example of what happens when politicians get a hold 
of a good meme: what was once fun and unifying becomes cringey and eventually meaningless.
This all started, of course, when Charli xcx posted a simple message on X: "kamala IS brat." The tweet was a 
reference to her recent album title, which had become an internet sensation as a symbol of a certain type of messy, 
party-girl lifestyle. One can't exactly fault the English singer - at the time, Kamala Harris seemed like the Democrats' 
only hope of defeating Donald Trump. 
But the tweet quickly went viral, forcing hundreds of confused journalists and news anchors around the world to 
twist themselves in knots trying to explain the meaning of this meme, Like almost anything related to U.S. politics in 
2024, the Kamala-brat discourse quickly became messy and divisive, signalling a bitter end to "brat summer." - 
Richie Assaly
Read more: Our review of "brat"
Page 5 of 6
24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick drags Drake through the mud, AI 
slop and more
7. Toronto's cultural scene faces financial headwinds
Over the past year, scores of arts organizations and artist spaces in Toronto have been forced to permanently 
shutter or drastically cut programming, the result of financial headwinds and operational hurdles that were induced 
by the pandemic but have spiralled into a wider crisis across the sector, leading to a reckoning - among artists, 
patrons and public officials - about the viability and future of the once-thriving industry.
It fomented under a perfect storm. As these organizations resumed in-person programming following months-long 
pandemic closures, they were met with changing consumer trends, inflationary pressures and a cost-of-living crisis 
that drove many artists out of the sector. At the same time, arts funding across all levels of government remained 
stagnant, while other sources of revenue from private and corporate donors have largely evaporated.
The challenges affected organizations both large and small, and across a variety of disciplines. In March, the Shaw 
Festival reported its largest deficit in its history. That same week, Just For Laughs announced it was cancelling its 
annual festival in Toronto and seeking to restructure its business. As well, more than half of independent cinemas in 
the country reported that they were operating at a loss. - Joshua Chong
Read more: Toronto's cultural scene has been shredded. Can this multimillion-dollar plan help reverse the crisis?
6. Hulk Hogan stumps for Trump
The most surreal pop culture moment of the year arrived earlier this summer, when the former professional wrestler 
Hulk Hogan delivered a fanatical address at the Republican National Convention in support of Donald Trump, his 
self-proclaimed "hero." Just how far did the Hulkster go? Well, it'll be hard to erase that image of Hogan ripping off 
his shirt and suit jacket to reveal a tank top emblazoned with the Trump-Vance logo. How ironic that in the same 
stump speech, the rabble rouser also said: "As an entertainer, I try to stay out of politics." Perhaps some of these 
entertainers need to try a bit harder. - Joshua Chong
Read more: At a wild Republican convention, the fashion was anything but conservative
5. "Hawk Tuah Girl" makes us wonder if the internet was a mistake
A video clip of a young woman making a crude joke becomes an ultra-viral meme. Young woman cleverly 
capitalizes on her fleeting internet fame by leaning into the absurdity of the moment, begins selling merchandise, 
appearing at campus events around the country. Young woman appears on Bill Maher's podcast. Young woman 
launches "Talk Tuah," which bafflingly becomes one of the most popular podcasts in America. Young woman 
launches her own cryptocurrency, "$HAWK," which briefly explodes in value before collapsing into dust. Young 
woman tells her livestream that she is "going to bed," then disappears from the public eyes for two weeks, before 
resurfacing to offer a tepid legal statement.
"'Hawk Tuah' Girl Haliey Welch's Memecoin Project Sued After Crash" read a Dec. 19 headline from TMZ - a nearly 
unintelligible string of words that nonetheless offers a neat summary of the most inane story of 2024, a story that 
doubles as a bleak warning about the blurring of the internet and the real world. - Richie Assaly
4. The Giller Prize divides literary community
In the lead-up to the 2024 Giller Prize Gala, hundreds of authors and cultural workers joined a boycott of the 
prestigious literary event, accusing the Prize of "artwashing" genocide, and demanding that the Giller Foundation 
cut ties with Scotiabank and other sponsors "invested in the oppression of Palestinians." The boycott marked the 
culmination of a high-profile campaign that for over a year had sought to draw attention to Scotiabank's investments 
in an Israeli arms manufacturer, a campaign that in many ways has come to represent how the war in Gaza has 
fractured arts communities across Canada. "It is our position that the only way to remedy what has been a deeply 
divisive period in Canadian arts is for the chief funders of so many arts prizes and organizations in Canada - banks 
such as Scotiabank - to divest from companies whose products are currently being used in mass killing," wrote 
eight former Giller Prize winners in an open letter published by the Star. - Richie Assaly
Page 6 of 6
24 worst cultural moments of 2024: an epic Tim Hortons misfires, Kendrick drags Drake through the mud, AI 
slop and more
Read more: Inside the Giller Prize and Scotiabank controversy
3. Diddy is accused of sexual misconduct
Sean "Diddy" Combs, the hip-hop superstar who ruled the music world for more than two decades, faces charges of 
sex trafficking and racketeering, along with accusations of sexual misconduct from at least 120 people. Combs' 
arrest earlier this year a stunning unravelling of Combs' career and public image, beginning in November 2023 with 
a lawsuit filed by his ex-girlfriend. The music artist has repeatedly denied the allegations, which are currently before 
the court. - Joshua Chong
Read more: What we know about Diddy's indictment
2. Kendrick Lamar drags Drake through the mud
It feels superfluous, at this point, to recount the many humiliations suffered by Drake in the wake of his culture-
shifting feud with Kendrick Lamar. As the dust settles following Lamar's knockout punch - the brutal, chart-topping 
diss track "Not Like Us" - the Toronto superstar has shrunk from the spotlight, a shell of his former self: isolated and 
litigious, posting lonely selfies from his sprawling Bridle Path mansion, betrayed by his friends and abandoned by 
the city that once worshipped him.
Of course, Drake is too big to fail. A generational hitmaker, the 38-year-old is destined to return to the charts and to 
the cultural zeitgeist. But it seems unlikely that he will ever fully recover from the central critique of "Not Like Us": 
that as an artist he lacks authenticity. That he's a "culture vulture" who attaches himself to whichever rising star or 
burgeoning regional scene he can profit from the most. That he doesn't represent real hip hop or Black culture, but 
appropriates. "No, you not a colleague, you a f---' colonizer." What makes this critique so devastating - more 
damaging even than Kendrick's baseless claim that Drake is a "pedophile" - is the fact it reveals something that, 
deep down, we might have suspected all along. - Richie Assaly 
Read more: Why did Toronto abandon Drake?
1. Alice Munro falls from her pedestal
Book lovers were devastated twice in a few months with news of writer Alice Munro: first of her death in May at age 
92, then again in July when her youngest daughter, Andrea Robin Skinner, revealed she had been sexually abused 
by Munro's long-time partner, Gerry Fremlin. When Munro found out about it, she stayed with him anyway. The 
news created headlines around the world accusing Munro of being a bad mother, and of readers who felt betrayed. 
I broke the story along with crime reporter Betsy Powell and witnessed its impact first-hand. Munro has always been 
beloved by readers, particularly for revealing the darkness that lurks in the lives of girls and women. Andrea 
changed the narrative around sexual abuse by taking control and telling her own story. She inspired other survivors 
of sexual abuse, and sent scholars around the world to rethink their approach to her mother's work. - Deborah 
Dundas 
Read more: My stepfather sexually abused me when I was a child. My mother, Alice Munro, chose to stay with him 
Load-Date: December 24, 2024
End of Document
Page 1 of 2
2024 A year in a word / n.
2024 A year in a word / n.
Financial Times (London, England)
December 24, 2024 Tuesday
Edition 1, National Edition
Copyright 2024 The Financial Times Limited All Rights Reserved
Section: BUSINESS; OPINION, COLUMNS; Pg. 21
Length: 312 words
Body
Slop (noun) a brain-rotting vision of our artificially generated future Weird pictures of a slimy pink Jesus made out of 
prawns were probably not what OpenAI had in mind when it warned artificial intelligence could destroy civilisation. 
But this is what happens when you give new tech to the public and tell them they can make whatever they like. Two 
years into the generative AI revolution, we have arrived at the era of slop.
The proliferation of synthetic, low-grade content like Shrimp Jesus is mostly deliberate, designed for commercial or 
engagement reasons. In March, Stanford and Georgetown University researchers found Facebook's algorithm had 
in effect been hijacked by spammy content from text-to-image models like Dall-E and Midjourney. The "Insane 
Facebook AI slop" account on X has kept a running tally. A favourite prior to the US election showed Donald Trump 
manfully rescuing kittens.
But slop may also be the unintended consequence of AI models trained on AI-generated texts - a form of data set 
inbreeding. whose unfortunate spawn has been compared to the House of Habsburg.
Accelerationists will tell you this is just a bump in the road on the way to exciting user-generated AI content. San 
Francisco start-up Fable Studio has announced a Netflix-style platform for AI films. Spotify chief executive Daniel 
Ek says people can share "an incredible amount of content" on the music service now the cost of making music is 
near zero.
The question is whether quality controls will nosedive with the cost of creation. Note slop's alliteration with spam - 
another form of easily distributed online nonsense.

Page 2 of 2
2024 A year in a word / n.
Watermarks would help combat this. Over time, sloppier content may die naturally, starved of attention. 
Alternatively, zero-cost, zero-effort content will destroy information sharing and online trust for good. Shrimp Jesus 
could be just the start. Elaine Moore
Load-Date: December 23, 2024
End of Document
Page 1 of 7
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes out on top?
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who 
comes out on top?
standard.co.uk
December 12, 2024 Thursday 4:33 PM EST
Copyright 2024 Evening Standard Limited  All Rights Reserved
Section: RETAIL INDUSTRY NEWS, Beverages industry news, Mobile industry news, Tesco news, Coca-Cola 
Company news & UK BUSINESS NEWS
Length: 3257 words
Byline: India Block and Vicky Jessop
Body
Bonfire Night has been and gone, which means only one thing: it's time for the festive deluge to begin.
Christmas adverts have long been a staple of British festive culture. Who can forget those early John Lewis ads, 
which reduced us all to tears from the comfort of our sofas? Or the arrival of the Coca-Cola truck on screens every 
year? 
With ads getting fancier, more expensive and more numerous than ever before, what we need is a way to tell the 
turkeys from the gold-plated Christmas stars. 
Fortunately, that's what you're reading. Without further ado, here's our list of the best Christmas ads so far this year, 
in ascending order - with more to be added as they come out.
Coca Cola
The Coca Cola Christmas missive is always somewhat formulaic, with the branded trucks driving fizzy drinks 
through the snow to the tune of Holidays Are Coming. It's been roughly the same since 1995. But this year there's 
something... off about it.
That's because this year's advert was created with generative AI. If the smiles look fixed and freaky and the hands 
truly odd, it's because they were hallucinated out of some computer. The polar bears are a particularly ironic touch, 
given that energy-hungry data servers required to make this ad probably directly contributed to melting ice caps. 

Page 2 of 7
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes out on top?
Coca Cola has been embracing generative AI for a while. Last year the company launched Create Real Magic AI, a 
collaboration with OpenAI and Bain & Company that uploaded all the festive Coca Cola assets for people to play 
around with. But this year's fully AI advert has gone down like a lead balloon with viewers. Turns out people don't 
want to be served AI slop for Christmas. 
Coca Cola did at least get the permission from real actors to use their likenesses, but that's a far cry from actually 
casting and paying human professionals. Plus Santa doesn't get his usual starring role, always staying out of shot. 
Probably because the AI made him look like some kind of eldritch horror. 
Argos
It is a truth universally acknowledged that you would only wish for a noisy, light-up toy to end up under the tree for 
your worst enemy's child.
Argos has decided to give every parent of small boys the Christmas from hell this year, with its festive promo slot 
dedicated to an extremely loud plastic T-Rex - Chad Valley Trevor Talk Back Dino to give him his full title.
The Rockstar TV slot begins with a CGI Trevor, aka Trev, stood on a mountain of amps, slamming on his guitar to 
the chorus of 20th Century Boy by T. Rex. But wait, it's all a dream! Luckily for aspiring noisemaker Trev, his pal 
Connie has got him a nice branded Marshall speaker for Christmas. It's a sort of sweet message about, I don't 
know, fostering children's imaginations. But mainly the message from Argos this Christmas is: buy your children 
these toys. Adverts are, after all, expressly here to sell you things.
With her blond hair and huge, vacant eyes Connie recalls the homicidal AI-powered doll from M3GAN, so perhaps it 
is a blessing that she is entirely analog. But boys getting to be noisy rockstars and girls getting to be silent fashion 
plates is something of a 20th-century idea of what it is to be a boy or a girl. Also, if you're going to invoke bisexual 
icon Mark Bolan - Elton John's "perfect pop star" - where are the feather boas and slinky outfits? Disappointing.
M&S Food
Tune in to see Dawn French get a Cinderella makeover, Christmas-style. A bedraggled French remembers she's 
expecting festive guests, but - oh no! - she's not ready to receive them, and the house is a mess. No worries: a 
slightly alarming living Christmas decoration in the shape of a fairy (also played by herself, a la Inside John 
Malkovich) has come to sort things out for her.
It looks gorgeous - all crackling fires and jewel-toned furniture. But it's also hard to not to feel that French has sold 
out somehow, acting feebly distressed and then thrilled as the house is magicked into a festive wonderland. A cry of 
"pork pies!" at the end as she gazes at the M&S spread on the table is cringe-worthy. National treasure maybe; 
festive treasure, maybe not.
Asda
Are gnomes traditionally festive? I would argue not (in fact, they're spectacularly creepy. Those blank cheery 
stares!), but Asda seems to be making a one-supermarket case for incorporating them into the traditional Christmas 
fare with this year's ad.
They're not especially successful. Apropos of nothing in particular, we open with two colleagues bemoaning the fact 
that snow has closed off the roads back home to Sheffield. They have vaguely northern accents, but who knows 
how far away Sheffield is. They could be in London, for all we know. Also apropos of nothing, one of them is making 
gnome puns to cheer his colleague up. So far, it's giving less Christmas, more the overnight shift from hell.
And it's about to get worse, because soon an army of gnomes is descending upon the store to help get things ready 
for the festive season. Gnomes are icing the cakes, gnomes are dancing in the aisles. And that's it, that's the ad. 
Examine your mince pies and roast turkey carefully this year for signs of tiny gnome fingers on them. But then 
Page 3 of 7
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes out on top?
again, given that searches for gnomes have spiked by 1572% on the Asda website since the ad came out, perhaps 
the UK is a nation of gnomeophiles. Food for thought?
M&S Clothing and Home
For this year's Christmas ad, M&S seem to have veered off the 'festive' route and instead taken their inspiration 
from a perfume ad. The end result manages to feel both weakly festive and utterly soulless. 
Our hero is a young girl, who seems to be enduring the family Christmas of everybody's nightmares: nobody's 
chatting. People are staring blankly at the wall. The tree lights aren't even on, for god's sake. But that's all about to 
change when she encounters a magical snowglobe which, with a few shakes, transforms the house into an all-
singing, all-dancing festive extravaganza.
That's the idea, anyway. The reality is a bit more hit and miss. The house itself is curated to within an inch of its life 
but looks like nobody lives in it. Where's the festive clutter; the cosiness? Nobody talks; everybody looks manically 
cheerful. The music is bland in the extreme. One to skip.
Boots
As anybody who's ever watched Bridgerton knows, Adjoa Andoh's presence makes anything ten times better. So it 
proves in the Boots Christmas ad, which casts her as Mrs Claus, and her Santa as a bit of a hopeless layabout. 
Look at him: there he is, sleeping in until the moment he has to go and deliver presents. Only problem: the sleigh is 
empty of festive gifts.
Fortunately Mrs Claus has the solution. In the blink of an eye, she whips up a 'werk-shop' for all the elves in her 
retinue  to wrap the nation's presents (from Boots, naturally) ahead of the big day.
Problematic gender roles aside (why is it that the woman does all the work for zero recognition, I ask??) the advert 
itself is harmless enough. A more overt acknowledgement of drag culture would be nice (and more importantly, fun) 
here, but it feels festive and jolly, and Andoh's little wink at the end sells the whole thing. I think I will have a No 7 
lipstick for Christmas this year after all.
JD Sports
How many celebs can you pack into one video? For JD Sports, the answer is: a lot. We get Maya Jama, we get 
Central Cee, we get Beta Squad and Paddy the Baddy. What are they doing? Not an awful lot, but the theme of this 
year's episode is family and there's certainly a lot of shots of people hanging out, either with their infant children, 
their friends or their loved ones. It's also soundtracked by Jamie xx's recent banger Wanna, which immediately 
gives it a lot of points, and the slightly grainy film quality gives the whole thing a rather timeless feel. Very sweet, 
even if there isn't a lot of action. But don't they look good in their Adidas merch.
Tesco
Hmmn, how to stand out in a crowded Christmas ad market? If you're Tesco, the answer is: dial up the sweet treats 
by turning everything - from houses, lampshades and animals - into gingerbread. And why not? 
Last year's Tesco ad turned people into trees and snowmen by dint of 'catching' the Christmas spirit. This time 
around, the Christmas spirit isn't transforming people (phew) but inanimate objects, which starts after a young man 
is given a box of gingerbread from his grandad on his way out of the house. 
One bite in, and the world suddenly starts turning into baked goods. The houses are gingerbread, the trees are 
gingerbread. Even the stray foxes are gingerbread. It's a Christmas paradise, but as the sounds of Gorillaz's On 
Melancholy Hill inform us, all is not well in gingerbread-land. For our unnamed hero is grieving the loss of his 
grandmother, who (we deduce from the pictures on the fridge) loved Christmas too. 
Page 4 of 7
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes out on top?
Of course, things end happily enough, with grandson and grandad making a gingerbread house (what else) 
together in her memory, but still, the message feels poignant. And the ad still leaves you with a sense of the warm 
and fuzzies, as well as a burning desire to buy a packet of gingerbread. And isn't that what the festive season is all 
about?
Vodafone
Did you know the first-ever text message sent were the words 'Merry Christmas'? And while the Vodafone 
Christmas ad doesn't go so far as to incorporate that, there's certainly a heavy dose of nostalgia in their festive ad. 
The premise is simple but sweet: following people throughout the decades on the big day. The phones start 
massive (depending on how old you are, the nostalgia will hit at different parts), then turn into flip-phones. We get 
text slang - "What's a bbz?" a dad demands of his furious daughter - and then we wind up in the present day where 
grandma still can't use the camera right. Cute, simple, misty-eye-making.
TK Maxx
We open on a storybook farm experiencing the kind of white Christmas that has only been seen four times since the 
Sixties, or so the Met Office reliably informs us. The creatively named Alpaca, Lil Goat, Duck and Hedgehog have 
all been decked out in fluffy sliders, a shiny puffer jacket, and a bumbag.
It's the kind of gently twee view of farming that seems to have come straight out of All Creatures Great and Small, 
with dry stone walls and retro tractors. The human cast, wearing box fresh clothes entirely inappropriate for a 
barnyard, are startled by the sight of the animals wearing clothes. But wait! It's not the clothes that prompt a double-
take, it's the cost of such snazzy gear. Thankfully, you can "spoil your loved ones for less" if you shop at TK Maxx.
There's no attempt at tear-jerking here, the message is a simple one: buy your loved ones big name brands for 
cheap. It's a Christmas message for the cost-of-living crisis.
Plus, not only does Alpaca channel the Great British tradition of cute animals in human clothes, he could fill a 
looming hole in the cultural psyche. Now that Paddington is getting, dare we say it, a bit too cosy with Big 
Government following the passport fast-track scandal, Alpaca could be our new anthropomorphic folk 
hero/psychopomp. Bow down.
McDonalds
As we edge towards 4pm sunsets, there's nothing like Christmas lights and a plan for dinner to cling to in the 
encroaching darkness. The McDonald's advert knows this and exploits it to maximum effect.
A tired couple with a car full of shopping and a long to-do list look forlornly out into the night. Lo, the glowing Golden 
Arches appear on the horizon, a modern star of Bethlehem. As they drive through the dark streets, homes suddenly 
light up in full LED glory, pulsing to the beat of Benny Benassi's Satisfaction. 
There is something so undeniably cheery about a bonkers amount of Christmas lights on a house. In Iceland, the 
story goes that after the 2008 financial crash people were encouraged to keep their lights up all through the winter 
to keep morale up. Although, if your neighbours put a moonwalking neon purple Grimace on their front lawn tonight, 
you'd probably call the council.
Satisfaction is a clever tune to pick, subliminally reminding you that you can indeed satisfy your cravings for fries 
and a McFlurry with very little effort. This ad spot can't hold a candle to the pure horniness of Benassi's original 
2002 music video, with its oiled up hotties demonstrating power tools, but it does make you want a McDonalds. 
Morrisons
Page 5 of 7
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes out on top?
Morrisons wanted feel-good, and this cheerful little number has it in spades. There's something delightfully British in 
the surreal vision of a choir of well-used oven gloves serenading a Turkey dinner. Before Peppa Pig and Paw Patrol 
achieved world dominance, we were all raised on a diet of lightly weird puppets.
Musicals are perhaps more controversial, given a slew of recent big budget Hollywood films that have done their 
best to hide their sing-song elements. Thankfully, this is side steps the uncanny valley of Cats and barrels headfirst 
towards the land of Muppets Christmas Carol - universally and uncontroversially beloved. Credit to Australian 
filmmaker Michael Gracey, who gave us The Greatest Showman and is about to tackle a Robbie Williams biopic 
with the singer played by an animated monkey. There's no cameo from Hugh Jackman (more's the pity) but there 
are moments that recall scenes from Beauty and the Beast.
As anyone who has cooked a Christmas roast - something that involves a lot of food maths around oven timings - 
the humble heat protective glove is the real MVP.
John Lewis
Say the words John Lewis to anybody in the UK and chances are they'll think 'Christmas'.
For good reason. JL perfected the formula before it was even a formula: tear-jerking story, winsome musical cover, 
subtle branding. And this year, they're back - deliberately late, presumably in the interests of making a grand 
entrance - to show the rest of the market how it's done. 
This year, they're going in hard with the product placement in a way they've not really done before.We start in a 
John Lewis store (gasp!) as one woman enters, presumably on Christmas eve. She's going through all the gifts on 
display in a desperate attempt to find something for her sister.
Nothing beckons, except suddenly the clothing rack has become a Narnia-like doorway into her own past. Along 
with her, we hop back and forth in time, meeting her sister at different stages of her life - but getting no closer to 
figuring out what it is she wants.
I won't lie: this bit gets properly emotional. Anybody who has a sibling can relate to that love/hate feeling. One 
moment, it's all hugs and laughter; the next there's a screaming match over who's borrowed or stolen something off 
the other. 
Nice and sentimental stuff (and it looks gorgeous), though lacking the sense of escapism of previousyears. It's easy 
to picture oneself in a John Lewis store - where are the hand-drawn animals or men living on the moon? Next year, 
more Venus flytraps please.
Sainsbury's
You think that you have become inured to the Christmas-advert-industrial complex's attempts to move you. Your 
heart is hardened to adorable storybook characters going on a journey, tear ducts stay bone dry at melancholy 
covers of pop songs. 
Then a supermarket sneaks up and bops you over the head with a nostalgia-bomb so targeted you wonder if the ad 
execs have been personally mining your own childhood for content. 
Enter the Big Friendly Giant or BFG, an animated imagining of Roald Dahl's overlarge purveyor of nice dreams. 
Resigned to another Christmas of disgusting snozzcumbers (the BFG having canonically forsworn eating humans), 
he ventures to Sainsbury's in an attempt to find a more palatable spread (still not humans, he remains friendly at all 
times). 
This is no CGI-heavy, green screen cop-out. You can almost feel the ground shake as the BFG lopes across the 
landscape. The creative team used puppets and scale sets to create genuine interaction between Sophie and a 
fictional giant. It doesn't try to overly smooth over the seams either, giving everything an almost stop-motion feel. 
Page 6 of 7
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes out on top?
It's a warm tale full of good old-fashioned magic, achieving more in a tight advert than Steven Spielberg managed in 
his underwhelming BFG adaptation in 2016. Consider my cold, cold heart warmed. Just don't make me look at 
those gross snozzcumbers again.
Barbour
In a market that is already becoming oversaturated with Christmas adverts, gosh darn it if Barbour's don't conjure 
up the warm and fuzzies every time they come on. 
The reason, of course, is the brand's collab with Shaun the Sheep, who took centre stage for last year's ad and 
(because Barbour and Aardman both know a good thing when they see it) is back for more.
This time around, Shaun's shenanigans are slightly less disaster prone. Not for Shaun the stress of repairing the 
Farmer's old Barbour jacket with combs, odd buttons and bits of wool (ie. the fare of the 2023 Christmas ad). This 
year, we return to Mossy Bottom Farm to find the flock being marshalled into a choir by Bitzer, the German 
Shepherd farm dog.
All they want is to sing a couple of Christmas carols, but there's a problem: it's so cold that the flock are freezing 
solid where they stand. Clearly climate change isn't a thing in this universe (when was the last time we had snow 
south of the Scottish border?) but fortunately, Bitzer has a solution. 
Three guesses as to what it is, but of course, it's Barbour branded, and soon enough the flock are singing away 
merrily. And before the curtain falls, there's still time for a couple of gags at the expense of the hapless Farmer. 
It's only a minute long, but such is the power of the Shaun brand that it's still a gorgeous little minute of stop-motion 
goodness. And don't worry: if the ad doesn't scratch that Wallace and Gromit itch, there's still Vengeance Most Fowl 
to look forward to later this year.
And the winner is... Waitrose
A stacked cast, a cosy mystery surrounding a missing dessert, and a daring cliffhanger make 
the Waitrose Christmas advert a winner on all fronts.
It's Christmas day and tensions are already high when there is a blood-curdling scream. There's not been a murder 
(that would be too Scandi noir) but the centrepiece dessert has vanished from the fridge.
The missing pudding is not - shock horror - your trad figgy pud, but rather a new frankenpudding (No.1 Waitrose 
Red Velvet Bauble Dessert to give it its full title) offering that does admittedly look extra festive.
Enter the Detective, a grizzled Matthew MacFadyen who is Succession's chief wetwipe Tom Wambsgans to some, 
the ultimate Mr Darcy to others. He's determined to sniff out the culprit, but everyone has an alibi - and a motive.
Eryl Maynard, of Miss Marple fame, is the posh grandmother whose nose has been put out of joint at being 
relegated to the cranberry sauce. Sian Clifford, Fleabag's uptight sister Claire, is sneaking around with cheese dips 
while swearing she's been prepping the parsnips.
With such an array of experienced thesps there's stiff competition for scene-stealer status, but Fig has it in the bag. 
The fluffy moggy has nailed the poker face, rattling Mcfadyen's Detective. And yes, Fig is their real name, I asked. 
The backup cat they had on set was, serendipitously, called Pudding.
Detective mysteries have always been a mainstay of British culture, from Sherlock Holmes to Poirot, Miss Marple to 
Inspector Morse. Cosy crime is dominating the charts - just look at Richard Osman, presumably diving into his £10 
million advances for the Thursday Murder Club like a literary Scrooge McDuck.
Page 7 of 7
The best Christmas ads of 2024, ranked: from John Lewis to Coca Cola, who comes out on top?
Waitrose have been smart to ride the wave, but they pulled it off with so much aplomb and heart that it never feels 
mercenary.
Load-Date: December 12, 2024
End of Document
Page 1 of 5
FELINE FRENZY
FELINE FRENZY
The Straits Times (Singapore)
December 8, 2024 Sunday
Copyright 2024 SPH Media Holdings Pte. Ltd. All Rights Reserved
Section: FEATURES
Length: 1958 words
Byline: Teo Kai Xiang, FELINE FRENZY
Body
 Although the cat does not have a place in the Chinese Zodiac -- something often attributed in folklore to trickery by 
the rat -- 2024 has shaped up to be a year of feline frenzy.
 Beyond Singaporeans' love of hawker fare and complaining, few things unite people here more than their affection 
for community cats, which have long been part of the urban landscape.
 Designer Clara Koh, who co-wrote the book Habitcat, observes: "We feel that community cats 'soften' our hard 
urban environment. They are harmless creatures that mind their own business. In a way, they are living very 
harmoniously with humans."
 Habitcat, published in 2014, is based on seven days of tracing the journey of community cats on foot, and explores 
the relationship between urban dwellers and Singapore's community cats. It was showcased at the Venice 
Architecture Biennale in 2021.
 It is fitting then that 2024 also saw the launch of the National Parks Board's (NParks) new Cat Management 
Framework, which legalised cat ownership in HDB flats.
 Elsewhere, cats have played a role in important cultural moments -- as mascots, in big-screen appearances and 
even an unusual mention in the recent United States presidential election.
 From the furore over "childless cat ladies" to the rise of AI-generated cat slop, here are six reasons 2024 was the 
year of the cat.
  Felines make their mark on fictionThe year saw a series of high-profile kitty appearances on the big screen and 
bookstore bestsellers -- from the spy thriller Argylle to the Japanese bestseller The Full Moon Coffee Shop by Mai 
Mochizuki, inspired by myths of cats returning favours to those who show them affection. 
 Other cosy reads with cats on The Sunday Times' weekly bestsellers lists include The Chibineko Kitchen by Yuta 
Takahashi and We'll Prescribe You A Cat by Syou Ishida. 

Page 2 of 5
FELINE FRENZY
 Notably, a cat plays a central role in A Quiet Place: Day One, carried by Mexico-born actress Lupita Nyong'o as 
she desperately avoids alien creatures that hunt down even the smallest of noises. 
 This sparked a viral trend on TikTok, in which cat owners carried their pets while simulating frantic escapes, testing 
whether their cats could remain silent or inadvertently doom them.
 Another film with a standout leading feline is the critically acclaimed Latvian animated adventure film Flow. 
Featuring a cast of animal characters surviving in a flooded apocalyptic world, it has no dialogue.
 Critics have praised its use of visual and non-verbal cues to create a story that transcends cultural and linguistic 
barriers.
 In Singapore, the film premiered at independent cinema The Projector on Dec 5. 
 Ms Worms Virk, The Projector's marketing manager, says: "Flow has been electrifying the festival circuit, gracing 
the likes of Cannes Film Festival and Annecy International Animated Film Festival. Now, our local audiences will get 
to witness its innovative animation and timeless cat-centric story."
  Cat ownership legalisedIn September, Singapore launched the new Cat Management Framework, making it 
mandatory for all pet cats to be microchipped and licensed by the end of the two-year transition period in August 
2026.
 The move lifts a 34-year ban on cat ownership in HDB flats.
 Ms Shelby Doshi, a cat behavioural consultant, says the framework is an important step forward for cats in 
Singapore: "It's a triumph for animal welfare, as we have been advocating for years to legalise cat ownership."
 A photographer who goes by the name Nguan, with nearly 300,000 followers on Instagram, has spent the past 12 
years documenting Singapore's community cats. He believes the lifting of the ban marks a fitting conclusion to his 
long-running project.
 His photo series has drawn tens of thousands of "likes" on Instagram. Many of his photos depict cats in housing 
estates that no longer exist. "Community cats belong to no one and everyone. They have become such a distinctive 
part of our local landscape," he adds.
 Dr Anna Wong, group director of the NParks' Animal & Veterinary Service (AVS), says some veterinary clinics 
have voluntarily started their own initiatives to offer discounted microchipping and sterilisation services for pet cats. 
 These efforts complement the AVS' work to support low-income households with free pet cat sterilisation and 
microchipping through the Pet Cat Sterilisation Support programme.
 But some cat lovers say the new framework does not go far enough.
 Ms Thenuga Vijakumar, president of the Cat Welfare Society, says that a lack of mandatory sterilisation remains a 
big issue. "The impact is that there will continue to be people with overpopulated homes, abandoning their animals 
or passing the burden of care to someone else."
 The Cat Welfare Society raised $1.2 million in 2023 towards its initiatives to offer free sterilisation, microchipping 
and support to lower-income households with cats -- a substantial sum necessary due to the many cats in need in 
Singapore.
 Meanwhile, Temasek Polytechnic student Alessandro Lange, 26, who volunteers with the local non-profit Trap 
Neuter Return project, is concerned about the cat abandonments he has seen while volunteering due to 
misinformation.
Page 3 of 5
FELINE FRENZY
 While the new framework allows cat owners to have up to two cats if they live in an HDB flat, there is an exception 
for those who license their cats in the transition period leading up to 2026, who are allowed to keep all their existing 
cats if they can ensure their welfare.
 Mr Lange hopes that more can be done to raise awareness of this, as well as resources available for low-cost 
sterilisation or free sterilisation for Community Health Assist Scheme (Chas) cardholders.
  Cat-inspired establishments rise upSingapore is no stranger to cat cafes, but some establishments are taking 
feline appreciation in new directions.
 One such establishment is the secretive speakeasy Cat Bite Club in Duxton Road, which one might recognise by 
the discrete symbol of a grinning cat by its entrance. 
 The bar has made a remarkable ascent to 54th place in the World's Best Bars list for 2024, just a year after it 
opened in 2023.
 "Our cat is our mascot," says co-founder Jesse Vida, 37, who adds that the bar's name is also inspired by Alice In 
Wonderland's Cheshire Cat. "Although there are no other Alice In Wonderland tropes to our bar, that was the 
original inspiration -- that kind of naughty, playful, mysterious energy. Those are the vibes we want people to feel 
and embody when they're in our space."
 Another cat-themed establishment, Fuzzies, opened in May in Arab Street and offers an unusual twist on the co-
working space concept: kitty co-workers. 
 Mr Lim Khai Chong, 30, who co-founded the space with Ms Lynn Loh, 27, says: "Unlike many cat cafes, our cats 
came before Fuzzies was founded. Lynn and I adopted a number of cats at various times -- the cats at Fuzzies are 
all our pets to begin with."
 As there was not enough space in their home to house all their kitties, they decided to create Fuzzies as another 
living space for them. "This has informed our design of Fuzzies, with the cats as the priority."
 There are cat-exclusive spaces in Fuzzies which guests cannot enter, so the kitties have a safe space to escape 
to. Guests are not allowed to feed the cats to avoid them overeating and to ensure a healthy diet.
 "As to why a co-working space -- if you had the opportunity to work at home with your kitties, you will understand," 
says Mr Lim. "The unexpected interruptions, the sudden jumps onto your keyboard -- all these little actions make 
your work day just a little less dreary."
 "Childless cat ladies" sparks furoreIn 2021, American Senator J.D. Vance labelled some politicians as "a bunch of 
childless cat ladies who are miserable at their own lives and the choices that they've made, and so they want to 
make the rest of the country miserable too".
 "It's just a basic fact -- you look at Kamala Harris, Pete Buttigieg, AOC -- the entire future of the Democrats is 
controlled by people without children," says Mr Vance, who is now the Vice-President-elect, referring to the US 
Vice-President and Transportation Secretary as well as Congresswoman Alexandria Ocasio-Cortez respectively. 
"And how does it make any sense that we've turned our country over to people who don't really have a direct stake 
in it'"
 When these comments resurfaced in July during the US presidential election, it was claws out from celebrities and 
politicians alike, including actress Jennifer Aniston and singer Taylor Swift. 
 The latter, a proud cat owner, later endorsed presidential candidate Harris on Instagram in a post signed, "Taylor 
Swift, Childless Cat Lady." 
 Cat behavioural consultant Ms Doshi believes this tension between parents and "pawrents" stems from a growing 
section of society who has chosen not to conform to traditional norms to settle down and have children.
Page 4 of 5
FELINE FRENZY
 Herself a childless cat lady, she says: "We will do anything for our cats. Is that bad? If you can afford it and it 
makes you happy, why not'"
  Banner year for cat-themed events The second edition of the Asia Cat Expo was held in 2024, which organisers 
Furflr say welcomed more than 20,000 attendees. 
 Furflr also previously organised Purrsa Malam, Singapore's first cat-themed night market, in August, and is holding 
the next Singapore Cat Festival on Dec 7 and 8 at Singapore Expo.
 A Furflr spokesperson says: "The reception for Asia Cat Expo has been incredible. For the first edition last year, we 
were pleasantly surprised by the overwhelming turnout, with long queues that caught us off guard."
 This meant having to expand the venue for the 2024 edition by moving it to the Suntec Singapore Convention & 
Exhibition Centre.  
 "We've been organising activities for cats and cat lovers since 2018," says the spokesperson. "Over the years, 
we've noticed a growing interest and, by 2024, the cat community has become quite established."
 Dr Tay Woo Chiao, who describes himself as an "obsessive cat daddy", attended the expo with his kittens Cottons 
and Cushions. The 37-year-old doctor says a highlight of the event was being able to give his cats a taste test of 
treat samples before committing to a purchase. "Because they are fussy. I have bought huge packets of freeze-
dried food before, but they just didn't want it."
  Are AI-generated cats the new Hello Kitty'It has also been a big year for cat mascots.
 There was the first Doraemon Run in Singapore in November. Doraemon is a Japanese manga-originated blue 
robotic earless cat, known for pulling otherworldly gadgets out of its pouch.
 Cat lover Teng Yu-Ching signed up for the run partly because of its adorable medal design, styled after 
Doraemon's bell collar. The 36-year-old sales manager says: "The run lived up to expectations, though most people 
there were really there for the theme and the merch."
 Another cat icon, Hello Kitty, celebrated its 50th birthday in November. However, Sanrio, the company behind Hello 
Kitty, has long maintained that despite appearances, Hello Kitty is not a cat but a British schoolgirl named Kitty 
White.
 These days, Hello Kitty is facing fierce competition from the likes of Mofusand -- a Japanese group of cats who 
dresses up in adorable costumes. In October, Uniqlo announced a new Mofusand collaboration for its graphic tees.
 But the newest pop culture cat on the scene was not created by human hands. These AI-crafted felines -- many of 
them called "Chubby" -- have amassed millions of views on TikTok
 Artificial intelligence researchers note that these cats are part of a phenomenon known as "AI slop" -- low-quality 
content produced rapidly and en masse by AI tools. 
 With hundreds of accounts now dedicated to sharing stories about cats like Chubby online, it seems that even 
adorable cat pictures are not beyond AI's reach.
Graphic
 
Flow is an animated fantasy adventure film with no dialogue and features a cat making its way through a flooded 
apocalyptic world. PHOTO: THE PROJECTOR
Page 5 of 5
FELINE FRENZY
Load-Date: December 7, 2024
End of Document
Page 1 of 4
A less toxic, less chaotic alternative I grew up on Twitter. But with a new Trump era on the horizon, I've been 
trying Bluesky
A less toxic, less chaotic alternative; I grew up on Twitter. But with a new 
Trump era on the horizon, I've been trying Bluesky
The Toronto Star
December 1, 2024 Sunday
ONT Edition
Copyright 2024 Toronto Star Newspapers Ltd. All Rights Reserved
Section: NEWS; Pg. A16
Length: 1888 words
Byline: Richie Assaly Toronto Star
Body
 Never check your screen time. Like stepping on a scale, it's a habit that is unlikely to change your behaviour, but 
will cause you anxiety, or, in some cases, trigger a small existential crisis.
According to my iPhone, I spend an average of six hours and nine minutes looking at a screen each day, and that 
doesn't include my laptop. The majority of that time is spent on X, an app that apparently notifies me an average of 
395 times a week. I also spend an obscene amount of time on Instagram and TikTok, in addition to the hours I 
spend on messaging apps such as Slack, WhatsApp and Signal.
In other words, the last thing I need in my life right now is another social media app. And yet, out of morbid curiosity 
- or perhaps a fear of missing out - I decided recently to sign up for Bluesky, a burgeoning social media platform 
that is commonly described as a less toxic, less chaotic alternative to X.
This felt a bit like a betrayal. For better and definitely for worse, I grew up on the app formerly known as Twitter, an 
app I have used more or less religiously for over a decade. As a university student involved in campus advocacy, it 
was an essential tool for persuasion and propaganda. As I entered the workplace, it became not only a place to 
forge new connections, but also my primary source for news. From 2017 to 2021, I worked at Twitter as a news 
curator, part of a small but mighty team that tackled misinformation and sought to make the platform a better place 
to consume media.
But like many thousands of X users, I had grown frustrated with what the app had become under the tenure of Elon 
Musk - namely, a cesspool of misinformation, harassment and hate speech; a media platform that inflates far-right 
political content over balanced journalism. Just this past week, in a blow to traditional media, Musk seemed to 
confirm that X's algorithm deprioritizes news content and posts that include external links.
Though I still rely on X for my daily intake of news, commentary and memes, I was drawn to - if a bit skeptical of - 
the prospect of a kinder, more polite online community.

Page 2 of 4
A less toxic, less chaotic alternative I grew up on Twitter. But with a new Trump era on the horizon, I've been 
trying Bluesky
Logging on to Bluesky for the first time felt a bit like walking into your apartment after a professional deep clean. 
The layout is the same, as are the appliances and furniture. But it just felt good to be there. I wanted to hang out.
On its surface, the app is almost identical to the old Twitter, down to its functionality and colour scheme. But gone, 
at least for now, is much of the noise - the casual racism, the bullying blue checks, the bitter, bad faith quarrelling.
Does this online space offer something fundamentally different or more healthy? Or is it just a slightly improved 
version of a fundamentally flawed and toxic idea; a slightly more efficient vehicle that still depends on burning fossil 
fuels as the earth hurtles toward destruction?
What is Bluesky?
Bluesky was created as an internal project at Twitter in 2019, when Jack Dorsey was still CEO. The app launched 
as its own company in 2021, with Jay Graber as CEO.
In the beginning, growth was meagre, but steady. Users initially needed an invite code to join the beta version, 
which was soon in competition with other Twitter alternatives. 
But since the fall, the app has grown rapidly, surging from about nine million users in September to nearly 23 million 
by the end of November. Bluesky is also gaining traction with politicians: NDP Leader Jagmeet Singh, Bloc 
Québécois Leader Yves-François Blanche and Alberta NDP Leader Naheed Nenshi are among the early adoptees.
The great migration has been a challenge for Bluesky's small team, which is currently made up of just a couple of 
dozen employees. Earlier this, the platform experienced a temporary outage, which the company said was due to 
an external internet provider.
"They're basically flying the plane and building it at the same time," Philip Mai, the co-director of the Social Media 
Lab, a research institute at the Toronto Metropolitan University, told me.
What makes Bluesky different?
Mai, who has been following Bluesky's development since it launched, believes that app has several distinct 
advantages over both X and its other competitors. 
First, Bluesky has a remarkably simple onboarding process. Unlike Mastodon, which required new users to 
navigate a convoluted web of servers to get started, Bluesky requires little more than an email account and a 
username. "It looks and feels more like old Twitter than anything else that's currently on the market," Mai said.
It's also surprisingly easy to find accounts that match your interests. In June, Bluesky introduced the "Starter Pack" 
feature, which allows users to curate a list of accounts that can be easily disseminated with friends. 
Second, and more importantly, Bluesky gives users more autonomy and control over what appears on their 
timeline.
As anyone currently on X will tell you, the algorithm that determines your "For You" page can feel like a black box, 
one that increasingly surfaces toxic or bizarre content that seemingly has little to do with one's interests. In contrast, 
Bluesky allows users to choose which feeds - i.e. customized algorithms created by other users - appear in their 
app. For example, users can follow the "Toronto Raptors" feed, which includes all mentions of the Raptors, their 
players and their coaching staff. Or users can follow "Blacksky," which showcases posts by Black users and 
creators. 
This simple idea - that people would rather have some input into what content they consume rather than have some 
shadowy algorithm shove posts from Musk's buddies at you - has become so popular that developers at Meta are 
already scrambling to create their own version of "custom feeds."
Page 3 of 4
A less toxic, less chaotic alternative I grew up on Twitter. But with a new Trump era on the horizon, I've been 
trying Bluesky
Finally, unlike X, Bluesky has a more decentralized approach to moderation, that empowers users to filter specific 
content from their feed (for example, I have muted any mention of "Jake Paul" or "Mr. Beast.") And perhaps most 
importantly, the app's moderation tools include a functioning block button, ensuring trolls or bad faith actors will 
never see your posts again. (In October, Musk announced that X's block function will now let blocked users see 
your posts, but not engage with them).
Why are some people leaving X?
Since Musk purchased Twitter back in 2022, the billionaire and self-styled "free speech" absolutist has gradually but 
fundamentally reshaped the platform. In the weeks following his takeover, he ordered mass layoffs that decimated 
the site's curation and moderation teams, and introduced a controversial new "verification" system that removed the 
blue checks that were used to identify public figures, health and policy experts, politicians and journalists, instead 
granting them to paying subscribers.
Over the next two years, Musk gradually introduced more changes that have effectively transformed X from the 
"internet's town square" into what can feel like a water hose of "doge" memes and bizarre advertisements that are 
increasingly indistinguishable from AI-slop.
Still, X remains a juggernaut - at the end of October, the platform boasted 335.7 million monthly active users, down 
from 368.4 million when Musk took over in 2022.
But for many, it was Musk's very public, very explicit effort to help elect Donald Trump as U.S. president - an effort 
that was rewarded with an influential position in the incoming administration - that finally forced them to abandon X.
"There are a lot of people who are taking a principled stance," Joanne McNeil, a writer, journalist and technology 
critic, said.  "People are saying 'I don't want to be here, or have anything to do with Elon Musk.' "
Something new? 
Or more of the same?
Since the Great Bluesky Migration began, it has also generated plenty of skepticism: What if Bluesky just becomes 
an echo chamber for the left? What happens when the app needs to monetize as it scales up? What if Bluesky just 
becomes a sanitized version of X, one that lacks the chaotic fun and conflict that drew us there in the first place?
I asked a few other media folks to see how they are faring. "I really like Bluesky," Eric Wickham, an independent 
journalist and podcast producer in Toronto, said. "I find that it's very reminiscent of the old Twitter, before people's 
feeds just got absolutely inundated with the worst people in the world screaming at you all the time."
Wickham joined Bluesky last June, but says that the app's benefits only came into focus over the past weeks, when 
the results of the U.S. election caused an explosion in the app's popularity. As Wickham's followers ballooned, he 
found himself forging new professional connections and disseminating his work to a broader audience. 
Craig Jenkins, a Pulitzer Prize-winning music critic, joined Bluesky in 2023, but only started using the app in earnest 
in October to "have a break from bad faith takes and misinfo."
"So far, no one has dragged any of my threads into a fight to disprove points I never even made and no one's fans 
have shown up accusing me of harbouring a vendetta," Jenkins said. "But I do get that whatever peace I feel is 
illusory and temporary, because I did see someone get torched for not liking the Kendrick album the night it 
dropped."
Some are deeply suspicious of the hype.
"I think everyone's kind of jumping the gun about it being this amazing, safe, healthy place," Sarah Hagi, a Toronto 
freelance writer, told me. As someone who has battled in the social media trenches for years, Hagi sees the 
Page 4 of 4
A less toxic, less chaotic alternative I grew up on Twitter. But with a new Trump era on the horizon, I've been 
trying Bluesky
problem not in terms of app A versus app B, but as our underlying reliance on social media to access news, to 
communicate and to understand each other.
"There is no such thing as a good tech platform, and there never will be," she said. "Elon Musk purchased Twitter 
and it got objectively worse, but the problems of Twitter didn't start with him."
Hagi also believes that Bluesky has a long way to go before it reaches the critical mass that made Twitter useful. 
"(X) is how I find out what's happening with people in Gaza, it's how I followed Black Lives Matter protests. That's 
how we stayed connected. And I don't think it was because Twitter was 'good' - it's just what people around the 
world were using, and I think it will take a long time for Bluesky to get to that level."
Is Bluesky the future?
Bluesky is still in its early stages. Currently, there are no subscriber options nor are there any ads, but that is bound 
to change as the platform scales up. "When companies scale, they need to monetize," McNeil said. "Bluesky could 
very quickly become a totally different experience." 
She believes X's decline is evidence of a broader transition away from "broadcast social media at scale."
"I suspect that we're going to be moving to a different kind of community online," she explained. "If you want to have 
this virtual water cooler, you can do that in a group chat with your friends. If you're a journalist who needs to get 
your stories out, there are podcasts or newsletters.
"I'm not exactly sure what it will look like, but I don't necessarily think that Bluesky is the answer."
Two weeks after joining Bluesky, I still find myself hopelessly addicted to X. Only now, there is yet another app on 
my iPhone, another VLT-like source of dopamine and mindless scrolling. Maybe, if it continues to grow, I will finally 
ditch X for good, but it's unclear how or if that would change much. 
Load-Date: December 1, 2024
End of Document
Page 1 of 4
I grew up on Twitter. But with a new Trump era on the horizon, I've turned to Bluesky. Here's what I found there
I grew up on Twitter. But with a new Trump era on the horizon, I've turned to 
Bluesky. Here's what I found there
thestar.com
December 1, 2024 Sunday
Final Edition
Copyright 2024 Toronto Star Newspapers, Ltd. All Rights Reserved
Section: NEWS/CANADA; Pg. 1
Length: 2201 words
Body
 Never check your screen time. Like stepping on a scale, it's a habit that is unlikely to change your behaviour, but 
will cause you anxiety, or, in some cases, trigger a small existential crisis.
According to my iPhone, I spend an average of six hours and nine minutes looking at a screen each day, and that 
doesn't include my laptop. The majority of that time is spent on X, an app that apparently notifies me an average of 
395 times a week. I also spend an obscene amount of time on Instagram and TikTok, in addition to the hours I 
spend on messaging apps such as Slack, WhatsApp and Signal.
In other words, the last thing I need in my life right now is another social media app. And yet, out of morbid curiosity 
- or perhaps a fear of missing out - I decided recently to sign up for Bluesky, a burgeoning social media platform 
that is commonly described as a less toxic, less chaotic alternative to X.
This felt a bit like a betrayal. For better and definitely for worse, I grew up on the app formerly known as Twitter, an 
app I have used more or less religiously for over a decade. As a university student involved in campus advocacy, it 
was an essential tool for persuasion and propaganda. As I entered the workplace, it became not only a place to 
forge new connections, but also my primary source for news. From 2017 to 2021, I worked at Twitter as a news 
curator, part of a small but mighty team that tackled misinformation and sought to make the platform a better place 
to consume media.
But like many thousands of X users, I had grown frustrated with what the app had become under the tenure of Elon 
Musk - namely, a cesspool of misinformation, harassment and hate speech; a media platform that inflates far-right 
political content over balanced journalism. Just this week, in a blow to traditional media, Musk seemed to confirm 
that X's algorithm deprioritizes news content and posts that include external links.
Though I still rely on X for my daily intake of news, commentary and memes, I was drawn to - if a bit skeptical of - 
the prospect of a kinder, more polite online community.
Logging on to Bluesky for the first time felt a bit like walking into your apartment after a professional deep clean. 
The layout is the same, as are the appliances and furniture. But it just felt good to be there. I wanted to hang out.

Page 2 of 4
I grew up on Twitter. But with a new Trump era on the horizon, I've turned to Bluesky. Here's what I found there
On its surface, the app is almost identical to the old Twitter, down to its functionality and colour scheme. But gone, 
at least for now, is much of the noise - the casual racism, the bullying blue checks, the bitter, bad faith quarrelling.
Does this new online space offer something fundamentally different or more healthy? Or is it just a slightly improved 
version of a fundamentally flawed and toxic idea; a slightly more efficient vehicle that still depends on burning fossil 
fuels as the earth hurtles toward destruction?
What is Bluesky?Bluesky was created as an internal project at Twitter in 2019, when Jack Dorsey was still CEO. 
The app launched as its own company in 2021, with Jay Graber as CEO.
In the beginning, growth was meagre, but steady. Users initially needed an invite code to join the beta version, 
which was soon in competition with other Twitter alternatives. 
But since the fall, the app has grown rapidly, surging from about nine million users in September to nearly 23 million 
by the end of November. Bluesky is also gaining traction with politicians: NDP Leader Jagmeet Singh, Bloc 
Québécois Leader Yves-François Blanche and Alberta NDP Leader Naheed Nenshi are among the early adoptees.
The great migration has been a challenge for Bluesky's small team, which is currently made up of just a couple of 
dozen employees. Earlier this, the platform experienced a temporary outage, which the company said was due to 
an external internet provider.
"They're basically flying the plane and building it at the same time," Philip Mai, the co-director of the Social Media 
Lab, a research institute at the Toronto Metropolitan University, told me.
What makes Bluesky different?Mai, who has been following Bluesky's development since it launched, believes that 
app has several distinct advantages over both X and its other competitors. 
First, Bluesky has a remarkably simple onboarding process. Unlike Mastodon, which required new users to 
navigate a convoluted web of servers to get started, Bluesky requires little more than an email account and a 
username. "It looks and feels more like old Twitter than anything else that's currently on the market," Mai said.
It's also surprisingly easy to find accounts that match your interests. In June, Bluesky introduced the "Starter Pack" 
feature, which allows users to curate a list of accounts that can be easily disseminated with friends. (For example, 
here is a starter pack of "Canadians in Media.")
Second, and more importantly, Bluesky gives users more autonomy and control over what appears on their 
timeline.
As anyone currently on X will tell you, the algorithm that determines your "For You" page can feel like a black box, 
one that increasingly surfaces toxic or bizarre content that seemingly has little to do with one's interests. In contrast, 
Bluesky allows users to choose which feeds - i.e. customized algorithms created by other users - appear in their 
app. For example, users can follow the "Toronto Raptors" feed, which includes all mentions of the Raptors, their 
players and their coaching staff. Or users can follow "Blacksky," which showcases posts by Black users and 
creators. 
This simple idea - that people would rather have some input into what content they consume rather than have some 
shadowy algorithm shove posts from Musk's buddies at you - has become so popular that developers at Meta are 
already scrambling to create their own version of "custom feeds."
Finally, unlike X, Bluesky has a more decentralized approach to moderation, that empowers users to filter specific 
content from their feed (for example, I have muted any mention of "Jake Paul" or "Mr. Beast.") And perhaps most 
importantly, the app's moderation tools include a functioning block button, ensuring trolls or bad faith actors will 
never see your posts again. (In October, Musk announced that X's block function will now let blocked users see 
your posts, but not engage with them).
Page 3 of 4
I grew up on Twitter. But with a new Trump era on the horizon, I've turned to Bluesky. Here's what I found there
Jonathan Goldsbie, a Toronto journalist, says he likes to think of X as the America of social media networks, which 
makes Bluesky like Canada: "unnervingly similar, especially at first glance, but also noticeably less unpleasant - 
with the caveat that because it has a fraction of the people, everything happening there feels less consequential."
Why are some people leaving X?Since Musk purchased Twitter back in 2022, the billionaire and self-styled "free 
speech" absolutist has gradually but fundamentally reshaped the platform. In the weeks following his takeover, he 
ordered mass layoffs that decimated the site's curation and moderation teams, and introduced a controversial new 
"verification" system that removed the blue checks that were used to identify public figures, health and policy 
experts, politicians and journalists, instead granting them to paying subscribers.
Over the next two years, Musk gradually introduced more changes that have effectively transformed X from the 
"internet's town square" into what can feel like a water hose of "doge" memes and bizarre advertisements that are 
increasingly indistinguishable from AI-slop.
Still, X remains a juggernaut - at the end of October, the platform boasted 335.7 million monthly active users, down 
from 368.4 million when Musk took over in 2022.
But for many, it was Musk's very public, very explicit effort to help elect Donald Trump as U.S. president - an effort 
that was rewarded with an influential position in the incoming administration - that finally forced them to abandon X.
"I'm leaving Twitter," author Stephen King posted on Nov. 14, joining a long list of celebrities such as Guillermo del 
Toro and Mark Hamill. "Tried to stay, but the atmosphere has just become too toxic." The Guardian also joined the 
exodus, citing the ubiquity of far-right conspiracy theories and racism.
"There are a lot of people who are taking a principled stance," Joanne McNeil, a writer, journalist and technology 
critic, told the Star. She compared the fact that some are moving away from X to a recent controversy at the 
Washington Post, which lost more than 250,000 subscribers in October after announcing that it would not endorse a 
candidate for president. "People are saying 'I don't want to be here, or have anything to do with Elon Musk.' "
Mai agrees with McNeil's assessment. "For a long time, people hung on simply because they didn't have a good 
alternative ... but now there's a lifeboat to jump into."
Something new? Or more of the same?Since the Great Bluesky Migration began, it has also generated plenty of 
skepticism: What if Bluesky just becomes an echo chamber for the left? What happens when the app needs to 
monetize as it scales up? What if Bluesky just becomes a sanitized version of X, one that lacks the chaotic fun and 
conflict that drew us there in the first place?
I asked a few other media folks to see how they are faring.
"I really like Bluesky," Eric Wickham, an independent journalist and podcast producer in Toronto told me. "I find that 
it's very reminiscent of the old Twitter, before people's feeds just got absolutely inundated with the worst people in 
the world screaming at you all the time."
Wickham joined Bluesky last June, but says that the app's benefits only came into focus over the past weeks, when 
the results of the U.S. election caused an explosion in the app's popularity. As Wickham's followers ballooned, he 
found himself forging new professional connections and disseminating his work to a broader audience. 
"I can post my jokes and my memes there, but I can also post my content and it doesn't seem to get buried in the 
same way that it does on X," he said.
Craig Jenkins, a Pulitzer Prize-winning music critic, joined Bluesky in 2023, but only started using the app in earnest 
in October to "have a break from bad faith takes and misinfo."
"So far, no one has dragged any of my threads into a fight to disprove points I never even made and no one's fans 
have shown up accusing me of harbouring a vendetta," Jenkins told the Star. "But I do get that whatever peace I 
Page 4 of 4
I grew up on Twitter. But with a new Trump era on the horizon, I've turned to Bluesky. Here's what I found there
feel is illusory and temporary, because I did see someone get torched for not liking the Kendrick album the night it 
dropped."
Some are deeply suspicious of the hype.
"I think everyone's kind of jumping the gun about it being this amazing, safe, healthy place," Sarah Hagi, a Toronto 
freelance writer, told me. As someone who has battled in the social media trenches for years, Hagi sees the 
problem not in terms of app A versus app B, but as our underlying reliance on social media to access news, to 
communicate and to understand each other.
"There is no such thing as a good tech platform, and there never will be," she said. "Elon Musk purchased Twitter 
and it got objectively worse, but the problems of Twitter didn't start with him."
Hagi also believes that Bluesky has a long way to go before it reaches the critical mass that made Twitter useful.
"(X) is how I find out what's happening with people in Gaza, it's how I followed Black Lives Matter protests. That's 
how we stayed connected. And I don't think it was because Twitter was 'good' - it's just what people around the 
world were using, and I think it will take a long time for Bluesky to get to that level."
Is Bluesky the future?Bluesky is still in its early stages. Currently, there are no subscriber options nor are there any 
ads, but that is bound to change as the platform scales up. 
"When companies scale, they need to monetize," McNeil said. "Bluesky could very quickly become a totally different 
experience."
McNeil also warns against being swept up in the hype. "I don't necessarily think that the numbers we are seeing 
now are proof that it's sustainable," she added, pointing out the fact that rebuilding an audience and community on 
sites such as Bluesky can feel overwhelming, and require a ton of energy she's not sure users possess.
Taking an even wider view, McNeil believes that X's decline is evidence of a broader transition away from 
"broadcast social media at scale."
"I suspect that we're going to be moving to a different kind of community online," she explained. "If you want to have 
this virtual water cooler, you can do that in a group chat with your friends. If you're a journalist who needs to get 
your stories out, there are podcasts or newsletters.
"I'm not exactly sure what it will look like, but I don't necessarily think that Bluesky is the answer."
Indeed, the effects of a deep clean only last so long. Over time, the dust gathers and the grime builds up. Suddenly, 
the house feels dirty again.
Two weeks after joining Bluesky, I still find myself hopelessly addicted to X. Only now, there is yet another app on 
my iPhone, another VLT-like source of dopamine and mindless scrolling. Maybe, if it continues to grow, I will finally 
ditch X for good, but it's unclear how or if that would change much.
For Hagi, the solution to the problem of online spaces is far simpler. "Turn off your computer." 
Load-Date: December 1, 2024
End of Document
Page 1 of 3
Demure? Brain rot? Oxford announces shortlist for 2024 Word of the Year: Cast your vote
Demure? Brain rot? Oxford announces shortlist for 2024 Word of the Year: 
Cast your vote
USA Today Online
November 14, 2024 6:25 PM EST
Copyright 2024 Gannett Media Corp  All Rights Reserved
Length: 634 words
Body
In a year of nonstop news and cultural moments, what word will capture the tone of 2024? 
Oxford University Press has narrowed the list down to six words, it announced Thursday, and you can help choose 
which one will be the winner.
With a rollercoaster of a presidential election, the Paris Olympics, a total solar eclipse, multiple hurricanes and a 
continued rotation of TikTok trends, language has adapted to describe this moment in time. 
"Since 2004, we’ve aimed to provide a window into language and cultural change through theOxford Word of the 
Year," president of Oxford Languages Casper Grathwohl said in an emailed statement. "The 2024 shortlist 
represents a snapshot of the topics that have caught our interest and imagination and kept us talking." 
The following words were found by Oxford University Press experts to have gained a spike in usage and 
prominence this year. The shortlist definitions were provided by Oxford.
Cast your vote here. Voting remains open until Thursday, Nov. 28. The winner will be announced on Dec. 2. 
2023 has got 'rizz': Oxford's previous Word of the Year
Lore
Noun: "A body of (supposed) facts, background information, and anecdotes relating to someone or something, 
regarded as knowledge required for full understanding or informed discussion of the subject in question."
@haleyybaylee
I’ve seen so many videos talking about my history… some accurate, some aren’t… So lets talk my life journey to 
where I am today ❤￿
♬ original sound - haleyybaylee
Brain rot 

Page 2 of 3
Demure? Brain rot? Oxford announces shortlist for 2024 Word of the Year: Cast your vote
Noun: "Supposed deterioration of a person's mental or intellectual state, especially viewed as the result of 
overconsumption of material (now particularly online content) considered to be trivial or unchallenging. Also: 
something characterized as likely to lead to such deterioration."
@heidsbecker
Part 3!!! Brainrot bestie on another date
♬ original sound - Heidi Becker
Dynamic pricing
Noun: "The practice of varying the price for a product or service to reflect changing market conditions; in particular, 
the charging of a higher price at a time of greater demand."
Dynamic pricing: Wendy's to test out dynamic pricing model as soon as next year, menu prices to fluctuate
Demure 
Adjective: "Of a person: reserved or restrained in appearance or behavior. Of clothing: not showy, ostentatious, or 
overly revealing."
Demure: Brat summer is almost over. Get ready for 'demure' fall, a new viral TikTok trend.
Slop 
Noun: "Art, writing, or other content generated using artificial intelligence, shared and distributed online in an 
indiscriminate or intrusive way, and characterized as being of low quality, inauthentic, or inaccurate."
Fighting misinformation:  How to keep from falling for fake news videos
pic.twitter.com/siMaFkJRDG
— Insane Facebook AI slop (@FacebookAIslop)
November 3, 2024
Romantasy 
Noun: "A genre of fiction combining elements of romantic fiction and fantasy, typically featuring themes of magic, 
the supernatural, or adventure alongside a central romantic storyline."
Romantasy recommendations:  Spicy fantasy books to read after ‘A Court of Thorns and Roses’
2023 words of the year 
In 2023, Oxford University Press named "rizz," understood as short for "charisma" as the word of the year. 
It was a far cry from Dictionary.com, which chose "hallucinate," a word that describes false information produced by 
artificial intelligence, as the 2023 word of the year. 
2024 word of the year from Collins English Dictionary
This year, Collins English Dictionary already pronounced "brat" as its 2024 word of the year. 
Page 3 of 3
Demure? Brain rot? Oxford announces shortlist for 2024 Word of the Year: Cast your vote
Contributing: Greta Cross
Kinsey Crowley is a trending news reporter at USA TODAY. Reach her at k  crowley@gannett.co m , and follow her 
on X and TikTok @kinseycrowley.
This article originally appeared on USA TODAY: Demure? Brain rot? Oxford announces shortlist for 2024 Word of 
the Year: Cast your vote
Load-Date: November 14, 2024
End of Document
Page 1 of 2
Fake AI 'slop' posts about Elon Musk surge on Facebook after election
Fake AI 'slop' posts about Elon Musk surge on Facebook after election
The Independent (United Kingdom)
November 13, 2024 Wednesday 11:15 PM EST
Copyright 2024 Independent Print Ltd  All Rights Reserved
Section: CYBERCULTURE NEWS, Facebook news & SOCIAL NETWORKS NEWS
Length: 427 words
Byline: Josh Marcus
Body
Numerous examples of AI-generated "slop" content falsely claiming Elon Musk has invented a variety of new sci-fi 
technologies are flooding across Facebook after the billionaire helped elect Donald Trump to the White House.
The posts claim Musk has invented everything from a "water engine" to a $6,999 tiny house on wheels to Iron Man-
style armor to a pilotable flying saucer, with many tracing back to pages in the Philippines and Vietnam, according 
to an analysis from tech journalism site 404 Media. 
Numerous Facebook users appear to be interacting with the posts and believing their claims, which in some cases 
enable the "slop" creators to earn bonuses as part of the platform's creator program.
"It appears there was a spike in public interest for Elon Musk around the time of the U.S. presidential election, 
coinciding with the timing of some of these posts," McKenzie Sadeghi, who studies AI at NewsGuard, told the site. 
"I'm not aware of the full extent/time frame of this campaign but it is possible that these accounts were attempting to 
capitalize on this surge in public interest by pumping out clickbait-like, AI-generated content of Musk, and in some 
cases, directing users to find an article about Musk in the pinned comment in an effort to bypass Facebook's 
algorithmic limitations on external links."
While the claims in these posts are untrue, they come as the real, non-AI Musk has leaned into the language and 
aesthetics of the internet and social media as part of his alliance with Donald Trump.
Musk has been tapped to head a new Department of Government Efficiency recommending billions in federal 
spending cuts. The agency, DOGE for short, takes its name from the "doge" meme, which has mutated from a 
popularly shared image of a Shiba Inu dog, to the Dogecoin cryptocurrency, to a major influence over the Trump 
administration. 
All actions of the Department of Government Efficiency will be posted online for maximum transparency.

Page 2 of 2
Fake AI 'slop' posts about Elon Musk surge on Facebook after election
Anytime the public thinks we are cutting something important or not cutting something wasteful, just let us know!
We will also have a leaderboard for most insanely dumb... https://t.co/1c0bAlxmY0
- Elon Musk (@elonmusk)
November 13, 2024
Musk has promised the DOGE will use the web to crowdsource ideas on spending cuts and post an online 
leaderboard with the "most insanely dumb spending of your tax dollars."
The billionaire has also been an outspoken advocate for online election betting using cryptocurrency, which 
emerged as a popular, social media-inflected alternative means of forecasting the 2024 election.
Load-Date: November 14, 2024
End of Document
Page 1 of 2
The images of Spain ’s floods weren’t created by AI. The trouble is, people think they were
The images of Spain’s floods weren’t created by AI. The trouble is, people 
think they were
The Observer (London)
November 9, 2024 Saturday 4:00 PM GMT
Copyright 2024 Guardian Newspapers Limited All Rights Reserved
Section: OPINION; Version:1
Length: 851 words
Byline: John Naughton
Highlight: The rapid growth of ‘AI slop’ – content created by artificial tools – is starting to warp our perception of 
what is, or could be, real
Body
My eye was caught by a striking photograph in the most recent edition of Charles Arthur’s Substack newsletter 
Social Warming.  It shows a narrow street in the aftermath of the “rain bomb” that devastated the region  of Valencia 
in Spain. A year’s worth of rain fell in a single day, and in some towns more than 490 litres a square metre fell in 
eight hours. Water is very heavy, so if there’s a gradient it will flow downhill with the kind of force that can pick up a 
heavy SUV and toss it around like a toy. And if it channels down a narrow urban street, it will throw parked cars 
around like King Kong in a bad mood.
The photograph in Arthur’s article showed what had happened in a particular street. Taken with a telephoto lens 
from an upper storey of a building, it showed a chaotic and almost surreal scene: about 70 vehicles of all sizes 
jumbled up and scattered at crazy angles along the length of the street.
It was an astonishing image which really stopped me in my tracks. Not surprisingly, it also went viral on social 
media. And then came the reaction: “AI image, fake news.” The photograph was so vivid, so uncannily sharp and 
unreal, that it looked to viewers like something that they could have faked themselves using Midjourney or Dall-E or 
a host of other generative AI tools.
But it wasn’t fake, as Arthur established in a nice piece of detective work – tracking down a bar in the picture  using 
Facebook, finding the street in Apple Maps and even “walking” down it using Street View. “It’s not obvious why 
these people thought that photo in particular wasn’t real”, he writes. “Perhaps it’s something about the sheen of the 
cars and the peculiar roundedness of the shapes, and maybe the lack of obvious damage”. Or is it that the 
proliferation of AI-generated fakes is already making people increasingly predisposed not to believe things that are 
real?

Page 2 of 2
The images of Spain ’s floods weren’t created by AI. The trouble is, people think they were
My hunch is that it’s the latter, because social media are being overrun by what has come to be known as “AI slop” 
– images and text created using generative AI tools. (Amazon’s Kindle store is having similar problems  with AI-
generated “books”, but that’s a different story.)
You’d have thought that the social media companies would be bothered by this tsunami of crap on their platforms. 
Think again. According to Jason Koebler of the tech news website 404 Media , in a recent quarterly earnings call 
that was overwhelmingly about AI, Meta’s chief executive, Mark Zuckerberg, said that new, AI-generated feeds 
were likely to come to Facebook and other Meta platforms. Zuckerberg said he was excited by the “opportunity for 
AI to help people create content that just makes people’s feed experiences better”.
Warming to his theme, Zuck continued: “I think we’re going to add a whole new category of content, which is AI-
generated or AI-summarised content or kind of existing content pulled together by AI in some way. And I think that 
that’s going to be just very exciting for Facebook and Instagram and maybe Threads or other kind of feed 
experiences over time.”
Which makes perfect sense, in a way: Meta’s profits depend on keeping users of its platforms “engaged” – that is, 
spending as much time as possible on them – and if AI slop helps to achieve that goal, what’s the problem?
On the supply side, it turns out that AI-generated stuff is also profitable for those who create it. Koebler has spent a 
year exploring this dark underbelly of social media. In India, he ran into Gyan Abhishek, an analyst who studies 
online virality. Abhishek showed him a startling image being used to generate revenue – a picture of a skeletal 
elderly man hunched over while being eaten by hundreds of bugs.
“The Indian audience is very emotional,” Abhishek explained.  “After seeing photos like this, they ‘like’, ‘comment’ 
and share them. So you too should create a page like this, upload photos and make money through performance 
bonus.” He also claims that creators of viral images can earn $100 for 1,000 “likes”, which sounds like money for 
jam, at least to this columnist.
So what we have here is a nice positive feedback loop in which creators of AI slop profit from feeding the 
engagement algorithms of social media platforms, which in turn profit from the increasing “engagement” that viral 
images attract. The trouble with positive feedback loops, though, is that they give rise to runaway growth, and to the 
question of what happens to social media when they become terminally enshittified  as a result. Which is where 
Meta and co are headed.
                     What I’ve been reading                   
                     How fragile is autocracy?A sobering assessment of Trump’s victory and America – What the future 
looks like from here  – by Prof Dave Karpf of George Washington University.
                     Click here for more                     An insightful essay by Jason Kottke  about the art of writing for the 
web, and the power hyperlinks have to intensify an argument.
                     The Musk effect                     Machiavellis of theMarket  – a timely essay on the outsize power of 
entrepreneurs by Alex Gourevitch. 
Load-Date: November 9, 2024
End of Document
Page 1 of 4
Newsletter : ChatGPT weds AI search to give Google worthy competition; AI Tool of the Week: How to use 
ChatGPT Search; Will AI achieve human-like reasoning
Newsletter : ChatGPT weds AI search to give Google worthy competition; AI 
Tool of the Week: How to use ChatGPT Search; Will AI achieve human-like 
reasoning
MINT
November 8, 2024 Friday
Copyright 2024 HT Media Ltd. All Rights Reserved
Length: 1864 words
Dateline: New Delhi 
Body
New Delhi, Nov. 8 -- If OpenAI disappointed many by delaying the launch of the much-anticipated fifth version of 
Generative Pre-trained Transformer (GPT-5), it pleased an equal number with its integration of AI search into 
ChatGPT, thus transforming the way tech companies will organise online information and users will search the web. 
By providing real-time access with original source links, OpenAI is also addressing copyright and plagiarism 
lawsuits, while challenging the dominance of a traditional search engine like Google.
To find information online, we typically click on multiple links. Microsoft-backed OpenAI introduced ChatGPT Search 
on 31 October which provides up-to-date online information with links to the information sources, using GPT 4o as 
the default model. Users can activate web search manually too. OpenAI has partnered with news and data 
providers to add information and visual designs for categories like weather, stocks, sports, news, and maps.
Please refer to the 'AI Unlocked: Tool of the Week' section below to see how to access ChatGPT Search, and how 
it works.
Here are some questions that are raised: How will this move impact Google Search? But aren't search engines 
evolving too? How safe and credible are AI-generated search responses be? And What about AI agents that are 
also transforming web engagement?
The entry of ChatGPT's real-time search tool could reshape the competitive landscape for both traditional search 
engines like Google and emerging AI-driven platforms like Perplexity. This shift also challenges Google's 
longstanding advertising model, which depends on users visiting multiple search results and engaging with ads. To 
be sure, Google has ramped up its own AI initiatives, such as Project Gemini, which aims to streamline searches 
with AI-generated summaries and actions to keep up with ChatGPT's advancements.
For Perplexity AI, for instance, ChatGPT's enhanced search capability adds pressure. While Perplexity has carved 
a niche by combining AI responses with multiple model options, such as GPT-4 Turbo, Claude, and Mistral, for 

Page 2 of 4
Newsletter : ChatGPT weds AI search to give Google worthy competition; AI Tool of the Week: How to use 
ChatGPT Search; Will AI achieve human-like reasoning
customised searches, it may struggle to retain users if ChatGPT can offer similar flexibility and more up-to-date 
answers. Perplexity has a unique feature set, like focusing on academic sources or Reddit, and visual integrations, 
which may still appeal to users looking for specialised content. However, the growing popularity of ChatGPT's 
search function-reportedly reaching 200 million weekly active users-could tempt users away from Perplexity, 
potentially affecting its user growth and subscription model.
For details, you may read the article titled 'What if ChatGPT's AI search engine clicks with users?'. You may also 
want to read: LLM chatbots, search engines will co-exist, says Google's Raghavan
AI Unlocked: Tool of the Week -- ChatGPT Search
by AI&Beyond, with Jaspreet Bindra and Anuj Magazine
What problem does ChatGPT Search solve?
ChatGPT's knowledge has a cut-off date, meaning its responses often lack real-time information, making it 
unsuitable for many situations where up-to-date information is needed. For example, it cannot provide current 
sports scores, stock market updates, or breaking news. Finding precise, timely answers often requires navigating 
multiple searches and sources.
ChatGPT Search addresses this by blending conversational AI with real-time web access.
How to access it?
1. Via the newly introduced search button on the ChatGPT chat interface.I
Image source: https://openai.com/
2. Via the ChatGPT Search plugin
3. ChatGPT will automatically choose to search the web if your question might benefit from real-time information.
This feature is currently available for ChatGPT Plus and Team users, as well as those who were on the SearchGPT 
prototype waitlist and now have access.
ChatGPT Search can help you:
Get Up-to-Date Information: Instantly access the most current information.
Ask Contextual Questions: Ask follow-up questions, and ChatGPT uses conversation history to refine answers.
View Trusted Sources: Responses include links to source material, allowing you to verify and explore further.
Example:
Suppose you're conducting market research for a new product. Here's how ChatGPT Search can assist:
Search the Web: Ask for recent consumer preferences or emerging industry topics. ChatGPT will pull up-to-date 
information from trusted sources.
Analyze Competitors: Get insights into competitors' latest offerings, pricing, or marketing strategies.
Gather Real-Time Data: Request statistics on stock performance, which ChatGPT can display directly, without 
leaving the chat interface.
Quick Tips:
Page 3 of 4
Newsletter : ChatGPT weds AI search to give Google worthy competition; AI Tool of the Week: How to use 
ChatGPT Search; Will AI achieve human-like reasoning
Installing the ChatGPT Search Plug-in changes your default search engine to ChatGPT Search. If you want to 
redirect a query to Google search, type "!g [your query]" (e.g. !g stock price MSFT) directly in your browser URL bar 
with your query.
You can also regenerate any GPT-4o response to search the web, enabling ChatGPT to enrich its initial response 
with additional content from the web. This can be done via the 'Try again' option at the end of the response.
What makes ChatGPT Search special?
All-in-One Interface: ChatGPT Search allows you to get real-time information, directly within the chat-no need to 
switch to a different platform.
Reliable Sources: All responses include citations from credible sources, keeping information trustworthy.
Interactive Maps & More: ChatGPT Search partners with news and data providers to add up-to-date information 
and new visual designs for categories like weather, stocks, sports, news, and maps.
Note: The tools featured in this section demonstrated clear value based on our internal testing. Our 
recommendations are entirely independent and not influenced by the tool creators.
Will AI achieve human-like reasoning?
The debate over AI's potential for human-like reasoning centres on whether advanced AI can truly understand 
concepts or if it merely mimics patterns. AI experts differ widely on this but they concur on one point: while AI can 
simulate certain aspects of human reasoning, achieving true understanding or consciousness remains unlikely, at 
least with today's technology. As the debate continues, the consensus seems to lean toward AI's role as a powerful 
tool that complements human intelligence, rather than replicating it. Thus, while AI may assist in decision-making 
processes or support certain cognitive tasks, experts are sceptical about it ever reaching the holistic, embodied 
cognition characteristic of human thought.
AI is unlikely to gain brain processing similar to humans unless connected to robots, according to a new study. 
(Pexels)
Here are brief perspectives from some AI experts on AI's capacity for human-like reasoning.
Fei-Fei Li, co-director at Stanford's Human-Centered AI Institute, emphasises the need for "human-centred AI". She 
advocates AI that complements human intelligence by supporting ethical, transparent uses that reflect human 
values rather than replicating human thought processes. Li believes AI should prioritise human welfare and 
augment human abilities rather than attempting to replicate human-like reasoning. You may read more here.
Andrew Ng, founder of DeepLearning.AI and Landing AI, managing general partner of AI Fund, and co-founder and 
chairman of Coursera, sees AI as a tool best suited for narrow tasks, advocating for a focus on practical 
applications rather than pursuing human-like cognition. He often criticises attempts to endow AI with "general 
intelligence," arguing it detracts from progress on tangible, real-world AI challenges. Here's a more detailed piece.
Yann LeCun, chief AI scientist at Meta and a professor at New York University, is more optimistic, asserting that 
while AI is far from human reasoning, the right combination of learning algorithms could gradually develop more 
adaptable systems. He sees potential in AI for dynamic learning but stresses that models today are still far from 
true cognitive abilities. Here's a detailed interview with him.
Geoffrey Hinton (who also shared the Nobel Prize for Physics this year with John Hopfield) and Yoshua Bengio, 
both Turing Award winners and known as the 'Godfathers of AI along with LeCun), support ongoing exploration of 
deep learning but differ in their views on the risks of human-like reasoning. Hinton recently raised concerns about 
AI safety, cautioning that powerful models could have unpredictable impacts, while Bengio is more optimistic about 
creating AI that aligns with human values but acknowledges risks that require thoughtful management.
Page 4 of 4
Newsletter : ChatGPT weds AI search to give Google worthy competition; AI Tool of the Week: How to use 
ChatGPT Search; Will AI achieve human-like reasoning
Mustafa Suleyman, CEO of Microsoft AI and co-founder of Inflection AI and DeepMind (now a Google company), is 
similarly forward-looking but stresses ethical AI development. His company's work on reinforcement learning has 
explored paths toward more autonomous AI, yet Suleyman consistently highlights the need for robust oversight to 
ensure AI aligns with human welfare.
Emily M. Bender, professor of Linguistics at the University of Washington, critiques current AI narratives, calling 
attention to the limitations of large language models (LLMs) in reasoning. She argues that AI models are 
sophisticated statistical systems without genuine understanding, challenging the idea that they can "reason" in the 
human sense. Her work underscores the risk of anthropomorphising AI.
"As OpenAI and Meta introduce LLM-driven searchbots, I'd like to once again remind people that neither LLMs nor 
chatbots are good technology for information access," she recently posted on X.
Here are some interesting takeaways from her threated post:
If someone uses an LLM as a replacement for search, and the output they get is correct, this is just by chance.
Furthermore, a system that is right 95% of the time is arguably more dangerous tthan one that is right 50% of the 
time. People will be more likely to trust the output, and likely less able to fact check the 5%.
Setting things up so that you get "the answer" to your question cuts off the user's ability to do the sense-making that 
is critical to information literacy.
That sense-making includes refining the question, understanding how different sources speak to the question, and 
locating each source within the information landscape.
Imagine putting a medical query into a standard search engine and receiving a list of links including one to a local 
university medical center, one to WebMD, one to Dr. Oz, and one to an active forum for people with similar medical 
>>>>>>> c98f417 (update data file):extract_text.txt
issues.
Finally, the chatbots-as-search paradigm encourages us to just accept answers as given, especially when they are 
stated in terms that are both friendly and authoritative.
The chatbot interface invites you to just sit back and take the appealing-looking AI slop as if it were "information". 
Don't be that guy.
Here are more perspectives on this subject:
AI systems routinely outperform humans
You may read here
AI agents now make their own decisions; why enterprises should care
Read more
Don't overestimate LLMs; it distracts attention from real issues
Published by HT Digital Content Services with permission from MINT. For any query with respect to this article or 
any other content requirement, please contact Editor at contentservices@htdigital.in
Load-Date: November 8, 2024
End of Document
Page 1 of 3
Halloween 'hoax': How did so many turn out for a fake parade in Dublin city centre? Website apologises for 
'mistake' and claims there was no intention to mislea....
Halloween 'hoax': How did so many turn out for a fake parade in Dublin city 
centre?; Website apologises for 'mistake' and claims there was no intention 
to mislead
Irish Independent
November 2, 2024 Saturday
Edition 1, National Edition
Copyright 2024 Independent Newspapers Ireland Limited All Rights Reserved
Section: NEWS; Pg. 18
Length: 798 words
Byline: MAEVE McTAGGART
Body
Hundreds of people waited on O'Connell Street on Halloween night for a parade that was never scheduled to take 
place. But where did the rumour come from - and how could so many have fallen for what was reported as a 
"hoax"? A Halloween-themed website, that no longer features any information about the Dublin parade it had 
described as "a centrepiece of the city's festive celebrations", also listed a number of genuine events that took 
place across the country on Thursday night.
The non-existent Dublin parade was set to follow "a well-planned route that ensures maximum visibility and 
excitement" between 7pm and 9pm. "It typically starts at Parnell Square, proceeds down O'Connell Street and 
concludes at Temple Bar," the website claimed, urging people to arrive early as the parade "attracts large crowds".
Hundreds turned out to see the supposed event, before gardaí asked the crowds to disperse as "contrary to 
information being circulated online", there was never any parade due to take place down the capital's main 
thoroughfare.
A spokesperson for the My Spirit
Halloween website "highly apologised" for the article.
They described the incident as "a mistake, not a scam or clickbait".
They said the operators of the website "are not scammers" and that sharing the incorrect information "wasn't on 
purpose".

<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Page 2 of 2
Silicon Valley has a plan to save humanity: Just flip on the nuclear reactors
"microreactor" site in Idaho.On Monday, the Financial Times reported that the venture capital firm co-founded by 
Peter Thiel, Founders Fund, is backing a nuclear startup that's trying to create a new production method for a more 
powerful nuclear fuel used in advanced reactors.
The irony of all this is, of course, is that even AI's cheerleaders have invoked the history of nuclear proliferation to 
try to convey the need for guardrails around artificial intelligence (just as long as the regulations don't slow them 
down or curtail their profit-making in any way).
And while AI doomer predictions often get brushed off as alarmist forecasts, you can't as readily dismiss the folks 
who are concerned about nuclear energy. History is, tragically, on their side.
To be sure, nuclear power today is better understood than it was in 1979, when Three Mile Island's Reactor Two 
experienced a partial core meltdown, Anna Erickson, a professor of nuclear science at Georgia Tech, told me.
"Nothing in life is ever foolproof," she said, "but we are much better now at understanding the operation of nuclear 
reactors," thanks in part to the wave of safety regulations that the Three Mile Island incident set off.
Bottom line: There's no AI future without a serious uptick in our power supply, which makes the expansion of 
nuclear power practically unavoidable. But it will take years for many of the recently announced projects to come 
online, and that means Big Tech data centers will have to stay on the fossil fuel drip as demand continues spiking.
Are we all cool with wrecking the planet if all we get are apps that can summarize our emails? Or search engines 
that are slightly more human-sounding but less reliable? Is the future really just variations of crustacean-based 
deities in a churn of AI slop?
There's a lot at stake - including our jobs and the environment and our entire sense of purpose in the world, 
according to AI's own developers. And yet it remains unclear what we the people stand to get out of the deal.         
             Analysis by Allison Morrow, CNN         
TM & © 2024 Cable News Network, Inc., a Time Warner Company. All rights reserved.
Load-Date: October 1, 2024
=======
Page 2 of 3
Halloween 'hoax': How did so many turn out for a fake parade in Dublin city centre? Website apologises for 
'mistake' and claims there was no intention to mislea....
"It was a mistake rather than hoax," they said.
"It was our mistake and we should have double-checked it to make sure it was happening.
"If we had heard before the day that the parade was not going to happen we would have removed it, but no one 
alerted us. We are highly embarrassed and very sorry."
The website seems to answer any and all questions that people google about Halloween, including searchable 
questions and key terms like "What time does trick-or-treating start for Halloween 2024?" and "How celebrities 
celebrate Halloween 2024".
The website claimed to be the "ultimate destination for all things Halloween" and invited web users to "explore our 
extensive collection and transform your Halloween into an unforgettable celebration".
It tells visitors it is based in the state of Illinois. However, the linked Facebook page for the site offered an address 
in Pakistan that has since been removed. Pakistan is also recorded on Facebook as the primary location for those 
managing the page.
Ciarán O'Connor, a senior analyst who researches the spread of disinformation at the Institute for Strategic 
Dialogue, said: "It seems to be a classic content aggregator website, so it turns out reams and reams of content 
that it thinks users in Ireland, the UK, Australia or America will find interesting."
The term "AI slop" is used by researchers in the field to describe the mass production of content through the use of 
generative AI, said Mr O'Connor, who believes this type of site functions as an "ad revenue scheme".
"The main incentive for these websites is getting people to click on the link. It's Halloween spam, and will then drive 
ad revenue for the website," he said.
He added that the site, which featured "very fomulaic text", likely used a generative AI tool that "scraped" content 
from other parts of the web, resulting in listings for genuine events winding up alongside that of the non-existent 
Dublin parade.
Promotional pictures for the event shared by the My Spirit Halloween website appear to have been from events held 
by Galway-based performance group Macnas in the capital last year, which were the first in four years after the 
pandemic. There were no plans for the Macnas events to take place this year.
The website, using "clickbait" terms so that it would appear in the search results for those trying to plan their 
Halloween night, started a rumour that soon gravitated to social media platforms like Facebook and TikTok.
Users believed they were sharing information about a genuine parade that was set to take place in the city centre, 
with one TikTok user sharing it with their own followers in a video which has since been viewed over 20,000 times.
Although a "light-hearted" example, the "hoax" parade doubles as an important lesson in how misinformation can 
spread online as we face into a general election.
"This is quite a humorous story at the heart of it - and certainly (did not result) in 'chaos' like some have said - but it 
does show that online misinformation can influence the public and influence people at a mass scale," Mr O'Connor 
said.
"It's difficult for people to distinguish between what is real and what is entirely fake on the internet. This is a fairly 
benign example of people who turned out for a Halloween parade, but what if this was a protest, advertising a 
protest in the heat of a very severe incident or an election?"
'Hundreds turned out, before gardaí asked the crowds to disperse as there was no parade due to take place'
Page 3 of 3
Halloween 'hoax': How did so many turn out for a fake parade in Dublin city centre? Website apologises for 
'mistake' and claims there was no intention to mislea....
Graphic
 
People in fancy dress on O'Connell Street on Thursday night, where many were hoodwinked by 'hoax' Halloween 
parade. Photo: Collins
Load-Date: November 2, 2024
End of Document
Page 1 of 6
Final Fridays returns after year-long break
Final Fridays returns after year-long break 
Daily Eastern News: Eastern Illinois University
October 28, 2024 Monday
University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved
Section: NEWS; Pg. 1
Length: 1830 words
Body
content"class="skip-to-content">Skip to Content
The Daily Eastern News
Facebook
Instagram
X
Tiktok
YouTube
RSS Feed
• Welcome back to the Daily Eastern News!
• Check out our podcasts on Spotify!
• Oct. 22- Trans*formation Station Ribbon Cutting and Fashion Show at 7 pm
• Oct. 22- Percussion Ensemble in the Doudna Black Box at 7:30 pm
• Oct. 24- Tunnel of Oppression in the Union at 7:00 pm
• Oct. 24- Natasha Stojanovska Piano Recital in the Recital Hall at 7:30 pm
• Volleyball standings: 4-11 on the season (0-5 in conference)
• Soccer standings: Women's at 5-6-5 (3-2-2), Men's at 1-9-1 (0-5)
• Football standings: 1-6 on the season (0-4 in conference)
• Check out our newsletters on Overlooked!
The Ticker
• News

Page 2 of 6
Final Fridays returns after year-long break
• Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
• Arts & Entertainment
• Opinions
• Podcasts
• Through the Lens
• About Staff Advertising Privacy Policy
• More
Final Fridays returns after year-long break Student government continues talk on fees, approves two RSOs, two 
senators Trans*formation Station opens in EIU GSDSmall Business Fest brings plushies, cosmetics, moreWho's 
running for Coles County Board in District 6?Panthers of the Week: Jake Pollock, David BrownEastern men's 
soccer tie with Southern IndianaDeeper insight into EIU vs UT Martin during Q&A with UT Martin newspaperCHS 
Trojan football ends season with loss against Salem WildcatsEIU wide receiver talks transfer process in 
Q&AAnderson reflects on Yankees career during 9/11EIU Baseball's path through OVC TournamentEIU Baseball 
honors seniors, win over MSUEIU Baseball drops second game against MSUEIU Baseball loses fifth straight 
gameBollant leaves EIU basketball programDavis, Luers enter transfer portalPanthers of the Year: MJ Flowers, 
Macy McGlone, Sara ThomasPanthers of the Semester: Tiger Booker, Macy McGlone, Tara ArchibaldSTAFF 
PICKS: NBA finals winnerCOLUMN: What went wrong with EIU football?COLUMN: Female athletes are just as 
capable as maleCOLUMN: Court storming should be a thing of the pastCOLUMN: Court storming needs to 
stayCOLUMN: EIU should move on from swim programPanthers of the Week: Joe Stoddard, Alex TettehFall 2024 
athletes to watchPanthers of the Week: Joe Stoddard, Taris ThorntonPanthers of the Week: Macy McGlone, Isai 
MoralesCOLUMN: Why you should watch running sportsDeeper insight into EIU vs UT Martin during Q&A with UT 
Martin newspaperCHS Trojan football ends season with loss against Salem WildcatsEIU wide receiver talks 
transfer process in Q&APanthers hope to beat Skyhawks for first time since 2018Charleston gets ready for last 
game of the yearPanthers of the Week: Jake Pollock, David BrownEastern men's soccer tie with Southern 
IndianaEIU men's soccer gets ready for last homestandEIU women's soccer's path to the OVC 
TournamentTakeaways from EIU women's soccer homestandGrover, Oslanzi, Archibald win OVC AwardsPanthers 
of the Week: McKenzie Oslanzi, Joe StoddardPanthers of the Semester: Tiger Booker, Macy McGlone, Tara 
ArchibaldCatcher talks about being a black belt in Q&AEIU softball loses nine-game winning streak to Tennessee 
TechPanthers of the Week: Avery Richardson, Conner ColstonThrough 40 years of coaching: Scott 
TeetersCOLUMN: EIU should move on from swim programEIU swim competes for first time in 2024EIU Swim 
competes as wholeFall 2024 athletes to watchPanthers of the Week: William Hays, Danny InfanteEIU men's tennis 
gets second straight victory with win against USIEIU tennis siblings' journey from AustraliaEIU tennis coach with 
varied past: Robin CambierEIU volleyball splits games to Tennessee TechEIU volleyball wins during Greek 
nightJunior outside hitter talks about support system in Sweden in Q&AEIU volleyball wins first conference 
gameTakeaways from EIU volleyballCOLUMN: 'It's What's Inside' asks who are you on the inside?Grand Ballroom 
decked out for annual drag showCOLUMN: 'King Kong:' a staple of cinema'Art is screaming' at the Tarble Arts 
CenterOh Freedom! Songs of the Civil Rights Movement brings music and history togetherCOLUMN: 'It's What's 
Inside' asks who are you on the inside?COLUMN: Why your OVC mascot may or may not suckCOLUMN: 'Piece by 
Piece:' building a new entry into the documentary/drama genreCOLUMN: Future educators: get 
organizedCOLUMN: Boo! Get off the stage!Two Dudes Talk Movies: Ep. 72: Frankenhooker: Reanimated From 
The GraveTwo Dudes Talk Movies: Ep. 71: The Fly: Buzzing Through The GorePanther Profiles: Ep. 22: Robin 
Cambier comes on the showTwo Dudes Talk Movies Ep. 70: Joker: Folie à Deux and the Horrible, No Good, One 
Bad DayTwo Dudes Talk Movies Ep. 69: Rebel Ridge: Every Ridge Has A PlateauTHROUGH THE LENS: 
'Beetlejuice' takes over Douglas-Hart Nature CenterTHROUGH THE LENS: Tour De CharlestonTHROUGH THE 
LENS: Camp New Hope celebrates 50th anniversaryTHROUGH THE LENS: Something's cooking in Klehm 
HallTHROUGH THE LENS: Glow Foam Party lights up South Quad
Search this site
Submit Search
Page 3 of 6
Final Fridays returns after year-long break
Open Navigation Menu
The Daily Eastern News
• News
• Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
• Arts & Entertainment
• Opinions
• Podcasts
• Through the Lens
• About Staff Advertising Privacy Policy
• More
The Daily Eastern News
Open Search Bar
Search this site
Submit Search
Open Navigation Menu
The Daily Eastern News
• News
• Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
• Arts & Entertainment
• Opinions
• Podcasts
• Through the Lens
• About Staff Advertising Privacy Policy
• More
The Daily Eastern News
Open Search Bar
Search this site
Submit Search
Categories:
• News
• Showcase
Final Fridays returns after year-long break 
Luke Brewer, Reporter
Page 4 of 6
Final Fridays returns after year-long break
·
October 28, 2024
Luke Brewer Larry Cox Jr. enthusiastically presents the difference between active listening and the art of listening 
at the first Final Fridays on October 25, 2024, at Friends & Co. in Charleston, Ill.
The electrically buzzed atmosphere of Final Fridays returned Friday following its discontinuation in 2023 to include 
more staff and faculty at Friends & Co. 
C.C. Wharram, event founder and director of humanities center, and the Final Fridays committee consisting of 
Samantha Tableriou, Alan Pocaro, Don Holly and Suzie Park hosted the event free of charge thanks to Friends & 
Co. inviting Final Fridays to use the venue. 
"It's a really great event, easy to say, 'yes' to," said Friends & Co. owner Mike Gherardini. 
Final Fridays is an event held on the final Friday of each month and is open to staff, faculty and administration at 
Eastern Illinois University featuring three presenters who talk about whatever topic of their choosing, usually related 
to something they're passionate about or currently researching. 
This gathering also serves as a "wonderful community event that brings together folks from across campus to share 
their research and enjoy each other's company," said EIU president Jay Gatrell who was in attendance. 
The event opened with a parody of "The Twilight Zone" before Larry Cox Jr., the first presenter and assistant 
professor of musical theatre and performance, took the stage. 
During his presentation, Cox talked about the difference between active listening and the art of listening by letting 
people to "empty their buckets" by offering a space for people to listen to others' opinions. 
The second presentation saw Mark Hudson, director of housing and dining, take the stage to give a spooky 
presentation during this haunting month. 
Hudson discussed the history of Pemberton Hall and how it is the second longest standing building on campus 
before shifting to retell the story of the Pemberton ghost. 
The Pemberton ghost is said to be an entity that roams the halls of Pemberton at night and is the spirt of a resident 
who was killed by a janitor or the spirit of residential hall counselor Mary Hawkins according to Hudson. 
Following Hudson's chilling story, Brian Keith, the new dean of library services, was brought on stage for a new 
segment to Final Fridays called Know Your Administrator. 
During this segment, Wharram asked Keith random questions for those in attendance to get to know him better. 
These questions ranged from what the best breakfast was to what relaxing beverage Keith would most likely drink. 
Associate professor of art foundations and printmaking Pocaro, the final presenter, took the stage following Keith to 
talk about the evolution of art from painting to photography to the modern day of what he calls "AI slop." 
Pocaro also showed his distain for AI saying, "AI is the visual equivalent of a nuclear weapon." 
As the presenters are on stage talking about their topics, a clock is counting down in the background that gives 
each presenter 10 minutes to speak. 
If a presenter narrowly finishes within the time limit, "the whole place comes down," according to Wharram. 
For example, Pocaro didn't finish his entire presentation within the time limit but was able to continue as the crowd 
of staff, faculty and administration cheered and encouraged him to continue. 
Page 5 of 6
Final Fridays returns after year-long break
After the presenters were all finished, Wharram returned to the stage with a smile to encourage everyone to stick 
around and hang out, as he believes the true intent of Final Fridays is to bring the university together. 
Final Fridays is set to return again in January 2025. 
Luke Brewer can be reached at 581-2812 or at lsbrewer@eiu.edu
View Story Comments
0
Like This Story
Share on Facebook
Share on X
Email this Story
Print this Story
Leave a Comment
More to Discover
More in News
Student government continues talk on fees, approves two RSOs, two senators 
Trans*formation Station opens in EIU GSD
Small Business Fest brings plushies, cosmetics, more
Who's running for Coles County Board in District 6?
Executive director and senior diversity and inclusion officer gives advice at lunch
Professional, student participation to come at EIU drag show
More in Showcase
CHS Trojan football ends season with loss against Salem Wildcats
Grand Ballroom decked out for annual drag show
Charleston Trojans lose 35-23 to Taylorville Tornadoes
The geological Avenger on EIU's campus   
EIU athletic director responds to House v. NCAA preliminary approval
On-campus enrollment down 7%, administration feeling positive
About the Contributor
Luke Brewer, Reporter
Luke Brewer is a freshman journalism major and can be reached at 581-2812 or lsbrewer@eiu.edu
Page 6 of 6
Final Fridays returns after year-long break
The Daily Eastern News
The student news site of Eastern Illinois University in Charleston, Illinois.
Facebook
Instagram
X
Tiktok
YouTube
RSS Feed
• News
• Sports
• Arts & Entertainment
• Opinions
• Podcasts
• Through the Lens
• About
The Daily Eastern News · © 2024 · FLEX Pro WordPress Theme by SNO · Log in
Comments (0)
Commenting on the Daily Eastern News web site is a privilege, not a right. We reserve the right to remove 
comments that contain obscene, vulgar, lewd, racist or sexually-oriented language. Also, comments containing 
personal attacks or threats of harming another person will not be tolerated.
Share your thoughts...
All
The Daily Eastern News Picks
Reader Picks
Sort: Newest
Close
Close Modal Window
Close
Load-Date: October 28, 2024
End of Document
Page 1 of 5
Monday briefing: The Trump acolytes planning to interfere with November’s election
Monday briefing: The Trump acolytes planning to interfere with November’s 
election
The Guardian (London)
October 21, 2024 Monday 6:49 AM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: WORLD NEWS; Version:1
Length: 2715 words
Byline: Archie Bland
Highlight: In today’s newsletter: From stacking election boards to purging voter rolls, we look at the tactics that 
could sway key states Sign up here for our daily newsletter, First Edition
Body
Good morning. With two weeks to go until the US presidential election, the race could hardly be closer. But when 
you’re next frantically obsessing over the odds, keep in mind: it may not be as simple as who most voters want to 
see in the Oval Office.
If the attempt to subvert the 2020 election was an anti-democratic horror show, its impact was somewhat mitigated 
by the fact that Donald Trump seemed to be making it up as he went along. This time around, Republicans are a lot 
more organised in their efforts to influence the outcome – and as the Maga takeover of the GOP has rolled on over 
the past four years, election denialism has moved from the fringes to become a central tenet of the party.
That means the wheels are already in motion for alarming interventions before and after polling day. A case in point 
over the weekend: Elon Musk’s plan for a daily $1m giveaway to a swing state voter who signs a petition in support 
of the first and second amendments, which legal experts say  could amount to an illegal inducement to register to 
vote.
For today’s newsletter, I spoke toSam Levine, voting rights reporter for Guardian US, about the nature of the threat 
– and how worried you should be. Here are the headlines.
                   Five big stories                   
                                            NHS  | The health secretary, Wes Streeting, is to unveil plans for portable medical 
records  giving every NHS patient all their information stored digitally in one place, despite fears over breaching 
privacy and creating a target for hackers. The news is part of a major consultation on the government’s plans to 
transform the NHS from “analogue to digital” over the next decade.

Page 2 of 5
Monday briefing: The Trump acolytes planning to interfere with November’s election
                                            Middle East  | At least 87 people were killed  or missing and 40 injured after intense 
Israeli airstrikes hit the north of the Gaza Strip. In Lebanon, hundreds of residents fled their homes in Beirut after 
what appeared to be an Israeli attack on areas linked to a Hezbollah banking system.
                                            UK news | Tributes poured in for the Olympic cycling champion Sir Chris Hoy after he 
revealed he had received a terminal cancer diagnosis.  In an interview with the Sunday Times, Hoy, who won six 
golds and one silver medal for Team GB, said doctors had told him he had between two and four years to live.
                                            Prisons  | Fewer women could be sent to jail  under a review to be announced by 
ministers this week that is expected to cut sentences for thousands of criminals. The review is expected to be 
carried out by the former Conservative justice secretary David Gauke.
                                            Monarchy  | King Charles has been heckled by an Indigenous Australian senator , who 
called for a treaty and accused the crown of stealing Aboriginal land, as he concluded a speech at Parliament 
House in Canberra. Lidia Thorpe approached the stage and shouted “This is not your land. You are not my king.”
                   In depth: ‘We’re getting to a place where trust in the system is eroded’                   
The crucial backdrop to Republican attempts to game the system: this is a race that could rest on a few thousand 
votes in a few key states. If the result comes down to a decimal place in Pennsylvania or Michigan, keeping some 
voters at home or throwing out a few ballots could make all the difference.
How serious is the risk that the election will be subverted? “If we’re on a 10-point scale, I’d say it’s about a seven,” 
Sam Levine said. “It’s short of a total meltdown. But there are some very alarming signs.”
The reason it’s a seven and not a 10: “There’s no legal scholar I talk to who doubts that the rightful winner of the 
election is going to be certified and seated. No court has successfully thrown out an election in the past, and the 
statutes are very clear.”
On the other hand, the memory of 2000’s hanging chads  and the heavily conservative composition of the supreme 
court – as well as the fact that interventions that never make it to the courts could play a significant role – mean 
there are good reasons to be concerned. “When you look at all of these things together, they make a very toxic 
stew,” Sam said.
Here are some of the ingredients.
***
                     Trump supporters are taking control of election boards                   
Since 2020, more than 30 local officials have either refused to certify valid election results or threatened to do so. 
And while those efforts have ultimately failed so far, they signal a new era of activists seeking control of previously 
non-partisan bodies. In Georgia, for example, a pro-Trump majority on the state board of elections has attempted to 
force through dubious new rules including one that would have required the hand counting of results – a procedure 
that critics say slows down the results, makes them less accurate and creates a false perception of uncertainty – 
only to see their intervention struck down by a county judge  last week.
“Before 2020, the vast majority of Americans had no idea these boards existed,” Sam said. And while they are 
generally required to certify the results, that is likely to be challenged in November. “These local board meetings are 
now full of [Trump supporters] who get up and scream at the board members if they disagree with them,” he said.
A study of boards in eight swing states published last month  found there were at least 102 election deniers sitting 
on state and county boards. The most prominent example was again Georgia, where the 3-2 Trump majority on the 
state board may have been thwarted by a judge but remains in a key role ahead of what is likely to be a nail-biting 
race.
Page 3 of 5
Monday briefing: The Trump acolytes planning to interfere with November’s election
***
                     Republicans are signing up as ‘poll watchers’                   
Election boards are not the only place where Trump supporters have sought to intervene in the process. There has 
been a parallel effort to get those who were sceptical of the 2020 result to sign up to be poll watchers – who can 
challenge voters’ eligibility in some states. (See this excellent New Yorker piece  for more on how Trump supporters 
are being primed to intervene.) 
Sam points to the Election Integrity Network, founded by prominent 2020 election denialist Cleta Mitchell, which 
claims to have recruited tens of thousands of “election integrity patriots” and holds regular coordinating calls. 
Meanwhile, Republican national committee chair Michael Whatley claims to have recruited almost 200,000 poll 
watchers, poll workers, and volunteer lawyers.
“That creates a volatile situation,” Sam said. “There have been reports of counties buying panic buttons in case 
election workers are harassed. But there is no evidence for the claims being made.”
                     ***                   
                     Voters have been removed from                     electoral rolls or asked to prove their citizenship                   
In Tennessee, the top election official asked 14,000 registered voters, many in areas with large ethnic minority 
populations, to prove their citizenship. In Alabama, the state tried to remove 3,200 people from the rolls as non-
citizens before admitting that 2,000 of them were eligible. And in Texas, the governor, Greg Abbott, claimed that 
6,500 non-citizens had been removed from the rolls – when in fact, almost 6,000 of them had simply failed to 
respond to letters from the state asking for proof.
These states are so certain to vote Republican in November that the decisions will not directly impact the result. 
But, said Sam, “it is part of a misinformation effort – it creates the sense that voting by non-citizens is a major 
problem, and that if it can happen in Texas, it can happen anywhere”.
The non-citizen voting claim also chimes with a debunked conspiracy theory  advanced by Elon Musk, among 
others, that Democrats are quickly making unauthorised immigrants into citizens to tilt key states in their favour. It is 
also seen as a way to suppress the eligible votes of those who were on the fence about turning up anyway, 
particularly among immigrant communities.
                     ***                   
                     Republicans are preparing to use the court system to challenge results                   
Reuters counted 130 lawsuits from Republicans relating to the election process this year. Sam describes some of 
those cases here , ranging from challenges to absentee ballots to more claims of non-citizen votes. As he notes, 
such cases “can be a particularly powerful forum for spreading misleading information [because] public officials 
sometimes won’t speak publicly about pending legal matters”, meaning they go unchallenged. And they could be a 
preview of what follows after the election has concluded.
Whereas in 2020, Republican party lawyers had refused to join Trump’s attempts to overturn the election, the party 
looks very different in 2024. The Republican national committee’s election litigation team is now headed by 
Christina Bobb, a prominent 2020 election denier who is facing criminal charges over her attempts to subvert the 
result.
One nightmare scenario is a situation like 2000, when the supreme court effectively decided the winner of the 
election. “On the one hand, in 2020, the supreme court refused to go near a case asking them to invalidate the 
results,” Sam said. “That is reassuring – I don’t think they’re going to go chasing fringe legal theories despite their 
ideological leanings.”
Page 4 of 5
Monday briefing: The Trump acolytes planning to interfere with November’s election
But even then, it is possible some rightwing justices with form for this sort of thing could issue opinions that might 
fan the flames of any tensions, Sam said. And the court could have to decide on a more technical, narrow issue 
with massive ramifications. In that scenario, the outcome is harder to predict – and there will be big questions about 
the justices’ objectivity given the court’s recent turn to the right.
***
                     Even if these efforts fail, they fan the flames of denialism                   
As we’ve seen, many of the manoeuvres outlined above have been struck down by the courts. But even these 
failures can be a success – because they may be understood by those who denied the 2020 result as further proof 
that the system is rigged against them. And even as they undertake their own work to subvert the result, Trump and 
many of his supporters are claiming it is the Harris campaign that is trying to “steal” the election.
To his point that he expects the rightful winner to be seated, Sam adds this caveat: “Even if that happens, the 
damage done by stoking this chaos is very, very significant. We’re getting to a place where trust in the system is 
eroded, and many people may not accept the result.” If so, the intensity of the misinformation this time around may 
make January 6 look like a dry run.
                   What else we’ve been reading                                                               Yes, the above picture of Daisy 
May Cooper is magnificent. But Rhik Samadder’s spooky interview for Saturday magazine – about her riotous new 
book detailing her obsession with the paranormal, and, er, the time she tried to have sex with a ghost – gives it a 
run for its money.  Features a decent anecdote about Martin Kemp mistaking the spirit of a 16th-century maid for an 
extra.Archie                                                                 A symbol of environmental destruction and excess, 
megayachts are a status symbol for billionaires. For New York Magazine, Charlotte Cowles  asked a former 
stewardess what it’s really like serving the ultra-wealthy on their private floating resorts.Nimo                                                                                          
Today’s Guardian leader  advises Rachel Reeves to abandon the infamous fiscal rules, and offers an alternative 
approach: publish an overview of the government’s balance sheet and show how ministerial decisions have 
affected national income instead.Archie                                                                                          Ashifa Kassam  
takes a look at how Gisèle Pelicot, a survivor at the centre of a horrifying mass rape trial that has rocked France, 
has propelled conversations around sexual violence in countries around the world.Nimo                                                                 
Keira Knightley, David Walliams, Meghan Markle, and Keith Richards have something in common that they really 
shouldn’t: they’re all celebrity children’s authors. Ella Creamer and Lucy Knight hear from their less famous rivals , 
who are unsurprisingly sick of it.Archie                                                           Sport                   
                       Cycling  |  After the news of Olympic cycling great Sir Chris Hoy’s terminal cancer diagnosis, the 
Guardian’s cycling columnist William Fotheringham writes that  Hoy’s response is typical of “a grounded individual 
who always seemed to come to a stoical, humble accommodation with the things that life dealt him, good and bad; 
he is a man of frankly outlandish determination”.
                       Football | Leaked WhatsApp messages from the former Newcastle United minority co-owner Amanda 
Staveley suggest that Mohammed bin Salman, Saudi Arabia’s crown prince, was heavily involved in the takeover of 
the club , it has been reported. The messages also spotlighted the extent of the UK government’s involvement.
                       Football | Curtis Jones’s 51st minute winner was enough to secure a 2-1 victory for Liverpool over 
Chelsea  and return Arne Slot’s side to the top of the Premier League. Earlier on Sunday, Manchester City took a 
dramatic 2-1 win over bottom side Wolves thanks to John Stones’s injury time header.
                   The front pages                   
Top story in the Guardian print edition today is “Labour wants NHS ‘passports’ for all patients despite privacy fears”. 
“Reeves is warned changes to IHT will backfire” says the Daily Telegraph – that’s inheritance tax, btw. The Times 
leads with “Rayner sets up ‘council housing revolution’”, while the Daily Mail covers a “‘Tsunami’ of asbestos deaths 
in schools”. The Metro says there is an “online con epidemic” with “9 million of us scammed”. The i has “UK air 
Page 5 of 5
Monday briefing: The Trump acolytes planning to interfere with November’s election
defences unable to cope with missile attack, former ministers warn”. “84% of disabled pensioners will lose winter 
payment” – the Express says that’s the result of a poll. “Charles: you are the best of us” – the Daily Mirror marks the 
25th anniversary of its Pride of Britain awards with a message from the king. The Financial Times leads with 
“Faltering confidence hinders global recovery despite buoyant economies”.
                   Today in Focus                   
                     How the US border became a toxic issue for voters – podcast                   
Oliver Laughland reports from southern Arizona, where the issue of immigrants crossing the border has become a 
controversial topic
                   Cartoon of the day | Edith Pritchett                   
Sign up for Inside Saturday  to see more of Edith Pritchett’s cartoons, the best Saturday magazine content and an 
exclusive look behind the scenes
                   The Upside                   
                     A bit of good news to remind you that the world’s not all bad                   
The Guardian’s new section, The Filter, has a singular mission: to provide readers with help in cutting through the 
fake reviews, dodgy deals and AI slop that makes up so much of consumer journalism on the web. The latest has 
experts recommending the fair price for 14 everyday essentials , from wine, to cheddar to running shoes. And if 
you’re paying more than £4 for a cleaning spray you’re being ripped off.
As for the wine, Pierre Mansour, director of wine at the Wine Society, says: “My advice is to spend between £8 and 
£15, the higher the better. The sweet spot is £12. Compared with a £7 bottle, a £12 bottle gets you four times as 
much value – a better return on your investment in terms of the wine’s taste, quality and balance.”
                   Bored at work?                   
And finally, the Guardian’s puzzles are here to keep you entertained throughout the day. Until tomorrow.
Quick crossword Cryptic crossword Wordiply
Load-Date: October 21, 2024
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 2
McNeal review – Robert Downey Jr shines in muddled AI-themed play
McNeal review – Robert Downey Jr shines in muddled AI-themed play
The Guardian (London)
October 1, 2024 Tuesday 5:21 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: STAGE; Version:2
Length: 810 words
Byline: Adrian Horton
Highlight: Vivian Beaumont Theater, New YorkThe Oscar-winning actor makes a smooth transfer to Broadway but 
Ayad Akhtar’s play is a mixed bag of insight and exhaustion
Body
Star Rating: 3 stars
The writer Jacob McNeal is, among other things, a bestselling and influential novelist, an esteemed winner of the 
Nobel prize for literature, a writer with style consistent and public enough to serve as a prompt for ChatGPT. From 
another view: a narcissistic cad, a terrible father, a lonely drunk. People argue whether he’s a genius, a fraud, an 
iconoclast. After nearly two hours with him, it’s not clear which. Though mesmerizingly brought to life by Robert 
Downey Jr in Ayad Akhtar’s muddled and occasionally poignant new play of the same name, McNeal remains more 
reflection than character – a projection of success, an outlet for anxieties over artificial intelligence, a cipher to 
destabilize one’s view of reality.
All of these angles offer fertile material for a play of ideas, and to Akhtar’s credit, McNeal is not only a rare original 
Broadway play but an ambitious one, given starry billing and splashy, tech-forward staging at Lincoln Center. It’s 
also all over the place, a play of strong performances – Downey, in his Broadway debut, chief among them – that 
chafe against vague, inchoate ideas about a vaguely ghoulish technology.
Things start simply enough: a giant, blue light-abundant iPhone interface looming above the stage, the home page 
tracking the minutes clicking by on Friday, 10 October in a way intriguingly familiar to most people in the audience. 
It’s sometime in the near future, when ChatGPT-like AI is even more firmly grounded in American daily life – 
enough, as McNeal off-handedly remarks in Dr Sahra Grewal’s (Ruthie Ann Miles) office, that several New York 
Times bestsellers are openly composed through machine learning.
The play proceeds in chronological-ish chapters in the sunset days of McNeal’s distinguished career: an 
appointment diagnosing liver disease; a triumphantly tipsy and moralizing speech accepting the Nobel prize; a 
meeting with his hammy agent Stephie (Andrea Martin); a reunion with his estranged adult son Harlan (a jittery Rafi 

Page 2 of 2
McNeal review – Robert Downey Jr shines in muddled AI-themed play
Gavron), who harbors intense loathing for the father he blames for his mother’s suicide decades earlier (and which 
features some telenovela-esque revelations that nearly took me out of the play entirely). Some border on the 
surreal; some, especially a tete-a-tete between proudly un-woke McNeal and a young female Black reporter at the 
New York Times (Brittany Bellizeare, a standout) whip up propulsive, left-field tension as the novelist plunges 
deeper into the whiskey bottle. (Michael Yeargan and Jake Barton’s evocative sets cover both, most pleasingly 
released in a luscious bookshelf full of both real and made-up titles.)
But as the chapters build, the narrative cohesion slackens. For each interlude deliberately muddies the waters by 
introducing the prospect of AI-generated material – Downey Jr’s voice, as McNeal, prompting the machine for the 
scenes we are about to witness and providing personal material to synthesize. Eventually, the projections deliver 
dialogue as deepfakes of McNeal and his late wife/former paramour (Melora Hardin). (The program credits the 
“digital composites” to the company AGBO.)
Akhtar, a Pulitzer-winning dramatist (in 2013, for Disgraced) and novelist, has dressed up a reliably grating 
inclination – a writer writing about writing – with the mind-bending and reality-questioning drama of our fears with 
AI. The framing devices don’t need to do much to touch on, without spoiling, the lines between inspiration and 
exploitation, between borrowing and theft, between assistance and cheating. Although delineating it this way feels 
like I’m giving the play too much credit – McNeal at most nudges these fault lines, seemingly chuffed with bringing 
up the topic as an end unto itself.
Downey, operating firmly in his lane of wise-cracking, sardonic charisma, is at least never less than compelling, and 
thankfully on stage for almost the whole show; the whole exercise is worth it to see an actor in peak, seemingly 
easy form. He sells McNeal both as a narcissist spiraling at the end of his road and as a provocation of AI’s blurry 
ethical lines. Such provocation contains little insight, beyond that AI is scary and could make things worse; perhaps 
McNeal’s most interesting idea is the unoriginal notion that generative AI will enable narcissists, or that it will allow 
people to express themselves through an artistic medium without putting in the hard work of craft.
McNeal ends on a confounding note, explicitly invoking the question: what is real, and how do you know? One 
could generously read the play’s descent into confusion as a meta treatise on what a world full of AI slop and 
questionably generated material will wreak on our perception, tenuous as it is already. One could also say that it’s a 
bit of unearned ambiguity. Our standards haven’t fallen so far yet as to not hope for art with a clear vision.
Load-Date: October 1, 2024
End of Document
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Page 1 of 4
The AR and VR headsets you'll actually wear
The AR and VR headsets you'll actually wear
 
Africa Newswire
September 30, 2024 Monday
Copyright 2024 Africa Newswire All Rights Reserved
Length: 1748 words
Body
 30 Sep 2024 (TourismAfrica2006) Hi, friends! Welcome to Installer No. 54, your guide to the best and Verge-iest 
stuff in the world. (If you're new here, welcome, so psyched you found us, and also you can read all the old editions 
at the Installer homepage.)
This week, I've been reading about AI slop and sports betting and Jony Ive, clearing my schedule for the new 
season of The Great British Bake Off, watching Sicario and Pirates of the Caribbean and A Quiet Place: Day One 
on plane-seat screens like their directors intended, insta-subscribing to Hasan Minhaj's new YouTube show, and 
just relentlessly trolling people with Vergecast clips through Pocket Casts' new feature.
I also have for you a couple of new Meta gadgets, the mobile game that will eat up all your free time, a couple of 
hotly anticipated new movies, the best Spotify feature in forever, and much more. So much going on! Let's dig in.
(As always, the best part of Installer is your ideas and tips. What are you into right now? What should everyone else 
be reading / watching / playing / trying / building out of clay this week? Tell me everything: installer@theverge.com 
And if you know someone else who might enjoy Installer, tell them to subscribe here.)
The Drop
Meta's Quest 3S. My biggest issues with the Quest 3 were the price and the passthrough, and this new model 
appears to have solved both. It's back in "totally reasonable game console" range, and the passthrough demos 
looked much sharper than before. They look great, though not as good as...The limited-edition Ray-Ban Meta 
Wayfarer. I already own two pairs of Meta's smart glasses (don't ask), but I am still lusting over this clear pair. 
They're more expensive, and they actually undo some of the good non-gadget vibes of the other models, but they 
look so good. Balatro Mobile. This might be the most recommended thing in the history of Installer - I swear, every 
week someone tells me how much this poker roguelike has taken over their life. And now it's on your phone! $10, 
no data collected, no microtransactions, my screen time is about to go through the roof.Wolfs. This Clooney-Pitt 
Apple TV Plus movie has a fascinating backstory that says a lot about the future of Hollywood, but I also just love a 
big-budget flick in which movie stars say cool lines in cool ways. This appears to be exactly that.The new Roku 
Ultra. I helped review the Google TV Streamer this week, and I really love that thing. But I'm also psyched to see 

Page 2 of 4
The AR and VR headsets you'll actually wear
Roku keep pushing - the new one's not reinventing the wheel, but it's faster and better, and that is a very good 
thing.The Wild Robot. I'd really like to tell you to go see Megalopolis this weekend, but every single indication is that 
the movie is hot garbage. But people seem thrilled about this one, an animated flick about a stranded robot that 
sounds adorable and delightful and like something I'm going to end up watching 100 times.The Legend of Zelda: 
Echoes of Wisdom. A Zelda game... in which you get to play as Zelda. That's the dream! This game doesn't seem 
to be as big or awe-inspiring or platform-defining as Breath of the Wild or Tears of the Kingdom, but it sounds clever 
and fun just the same.Spotify's AI Playlist feature. This is terrible news for my relentless quest to quit Spotify: the AI 
playlists are great. Now that the feature is available in the US, I've been using it to name a few bands or songs, plus 
an overall vibe, and it picks a few dozen songs that, at least so far, always seem to hit. Spotify is very, very good at 
this part of the music game.Social Studies. Being a kid is hard work. And this doc digs in with a group of students 
on how much... maybe not always harder, but definitely more complicated, social media has made being a kid in 
2024. This comes from a good team, too, and I'm excited about it.The Nothing Ear Open. Nothing's headphones 
have been really solid, and as a recent and aggressive convert to open earbuds, I'm pumped to see how these 
sound. They look so cool, too! Big week for clear gadgets.
Screen share
Fun fact: Joanna Stern is the main reason I ever got a job at The Verge in the first place. (That story is long and, if I 
remember correctly, involves her playing a fairy in a video? But I promised her I wouldn't tell that story.) These 
days, she's a columnist at The Wall Street Journal, an Emmy winner, and most recently, the creator of Joannabot, 
the AI chatbot that will tell you everything you need to know about the iPhone 16. (And apparently also do some 
other things, if you're clever enough, but again, we'll leave that alone.)
I asked Joanna to share her homescreen because she just reviewed the iPhone 16, which means she just had to 
set up a homescreen. And because she's forever using new gadgets and switching between things, I was curious 
what always made it to the top of the pile.
Here's Joanna's homescreen, plus some info on the apps she uses and why:
I'm submitting my homescreen and my Control Center screen because I'm proud of the work I did on the Control 
Center. I may submit it for an award. But really, I'd like to just use this as a forum to complain about the all-in-one 
connectivity widget in the new Control Center in iOS 18. I don't like it. I like the single buttons so I can easily just 
turn them on and off or long-press to get in there. Sadly, they have gotten rid of the single Wi-Fi button, but I read 
on this great website that it's coming back in iOS 18.1.
The phone: iPhone 16 Pro Max.
The wallpaper: This is my dog Browser. It isn't the best shot of him, but the framing is nice for putting him in the 
middle of the screen. My lockscreen wallpaper is this awesome retro iPod made by a designer named Shane 
Levine. I bought it through this site last year after featuring it in my newsletter.
The apps: WSJ, ChatGPT, Apple Notes, Google Maps, Google Docs, Google Calendar, Instagram, YouTube, 
Clock, Threads, Signal, Photos, Slack, Spotify, Phone, Safari, Messages, Gmail.
My apps are so basic and make me feel so basic. I work (Slack, Gmail). I message (Messages, Signal). I listen and 
watch things (YouTube, Spotify). I social media (Threads, Instagram). I work more (Google Docs, WSJ). If it isn't on 
this main homescreen, I usually just search for it.
Before iOS 18, I had a widget stack on the homescreen with weather and time zone widgets, but I moved it off to 
another screen. I might move it back. I might not. Got to live a little.
I also asked Joanna to share a few things she's into right now. Here's what she shared:
The Devil at His Elbow. I'm currently listening to this audiobook by my wildly talented colleague Valerie Bauerlein. 
It's all about the Murdaugh murders. The writing, the details, the whole thing, is so gripping. I find myself just sitting 
in the garage waiting until a chapter is done.Full Swing. I know I'm late to Netflix's popular golf-u-series, but I started 
Page 3 of 4
The AR and VR headsets you'll actually wear
playing golf again this summer, and I'm loving the stories of these players and how psychological the sport really is. 
Take Your Pet to School Day. My 3-year-old loves this book. I don't want to spoil it, but the pets take over Maple 
View Elementary, and, well, Ms. Ellen is pissed.
Crowdsourced
Here's what the Installer community is into this week. I want to know what you're into right now as well! Email 
installer@theverge.com or message me on Signal - @davidpierce.11 - with your recommendations for anything and 
everything, and we'll feature some of our favorites here every week. And for even more great recommendations, 
check out the replies to this post on Threads.
"Sliding Seas. It's a match-three (or four!) game but also so much more: there's real strategy required behind your 
moves to beat levels at the higher end, but it's never unfair, and while there are in-app purchases and power-ups 
you can buy to make a level easier, you crucially never need to. It is the most compelling and well-suited-to-mobile 
game I've ever found and a gem I recommend without reservation." - Jamie
"Gisnep is another daily puzzle game, this time by David Friedman of Ironic Sans. It appears as a crossword-esque 
grid, but the words only go across and wrap around. The goal is to reveal both a quote and the source by filling in 
letters from vertical columns. I've gotten a number of my friends hooked already." - Kyle
"Satisfactory 1.0 launched a week ago or so. A great group of devs have effectively made a game that feels like 
work but is fun. If you love conveyor belts and staying up all night, this might be for you." - Matt
"Can't believe you haven't mentioned switching to OmniFocus! As a fellow perennial 'task manager switcher,' this 
app is a staple in my rotation." - Pedro
"I previously recommended App in the Air as a great travel companion, but unfortunately, it's shutting down. If 
you're looking for an alternative, Flighty is excellent, especially for travel stats, and they're building an importer for 
App in the Air users." - Vivian
"We've been watching English Teacher on FX. Constant laughs and, so far, each episode has been better than the 
last. Easily one of the funniest shows on TV right now." - Danial
"I was gifted the Humanscale FR300 Ergonomic Foot Rocker, which is a very tech-sounding name for a very 
manual / mechanical rocking footrest. It's very pleasant to use. I've also been standing on it sometimes... which I'm 
not sure is safe but sure is fun!" - Wisdom
"Repeatedly putting in my Amazon cart the Black Milanese Loop for the Apple Watch Ultra 2. I was so close to 
buying it like three times. Now it's out of stock. Even Apple says early November for shipping." - Scott
"Been playing with different LLMs using LM Studio. Integrated it into my Obsidian vault to help summarize and 
organize things into specific formats. It's been extremely cool!" - Cody
Signing off
I've had back-to-back-to-back-to-back trips over the last two weeks, and I would just like to quickly shout out my 
new No. 1 travel hack: a wall charger that doubles as a big-ass portable battery. I have this Anker model, which is 
$55, charges a USB-C and a USB-A device simultaneously, and also charges itself so I can get 10,000mAh of 
power when there's no outlet nearby. (There's also a newer one with two USB-C ports and even faster charging but 
less battery capacity.) It's huge and heavy, but this thing and a long cable are now the only charging gear I travel 
with, and they're the only reasons my gadgets have survived trains and plane rides. Here at Installer, we love a 
sensible charging strategy, and this is as sensible as it gets.
Load-Date: October 1, 2024
Page 4 of 4
The AR and VR headsets you'll actually wear
End of Document
Page 1 of 2
'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI art
'So lame of you guys': Legendary 80s band infuriates fans over new album 
cover's AI art
BGR
September 28, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 441 words
Byline: Andy Meek
Body
Back in the day, people dogged Tears for Fears for ripping off The Beatles with songs like Sowing the Seeds of 
Love. So much so, that Paul McCartney himself once acknowledged during a press conference that the first time he 
heard the song, he thought: "Who are they kidding?"
So it probably shouldn't come as a surprise that the same band now apparently seems fine with typing some dumb 
prompt into an AI image generator (I'm guessing "astronaut in a field of flowers") and using the resulting soulless AI 
slop as the cover of their new album, Songs for a Nervous Planet. Rather than, you know, using a pittance of their 
considerable fortune to pay a human artist to do the work. Seriously, guys, "have you no idea how the majority 
feels?"
That's a rhetorical question, by the way. Not only does the band know, but they've also responded to the predictable 
outcry with a statement that blathers on about AI being "one of the many tools used in the creative process" for the 
album cover, a statement that appears to have been written by an actual tool.
SONGS FOR A NERVOUS PLANET.OUT OCT 25.Pre-order and listen to "The Girl That I Call Home" now. 
https://t.co/8rP6k9e7ug #songsforanervousplanet pic.twitter.com/PaAl4NCmSW
- Tears for Fears (@tearsforfears) September 12, 2024
Tears for Fears' social media posts announcing the highly anticipated new album, which drops on Oct. 25, have 
been flooded with negative comments from fans angry about everything from the lifelessness of the AI art - with its 
too-smooth, plastic-y feeling and lack of fine detail - to the usage of AI in general. "It's honestly embarrassing that 
you're using an ai album cover," one user wrote on the band's Instagram post. "You obviously have the money to 
pay an artist for an album cover, yet you still chose to just type in a prompt and have a computer plagiarize art 
instead?" 

Page 2 of 2
'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI art
Added another: "Using AI art is such a joke. You guys are a legendary band and you chatGPT your album cover? 
Phone it in a little more man."
PSA to any more beloved bands out there: If you're going to resort to using AI for anything, at least do what The 
Beatles did with their new song Now and Then and steal from yourselves. Anything else, and you'll deservedly get 
what's coming to you. "I can't wait until someone makes an all ai album by stealing your music," another angry 
Tears for Fears fan wrote on the band's Insta. Likewise, the fan who added: "the ai cover is so lame of you guys."
Don't Miss: I never trusted Sam Altman. I trust OpenAI's overhyped CEO even less now.
The post 'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI art appeared first on 
BGR.
Load-Date: September 28, 2024
End of Document
Page 1 of 4
Is anyone out there?
Is anyone out there?
Prospect
=======
Page 1 of 1
Pick of the day
Pick of the day
i-news
>>>>>>> c98f417 (update data file):extract_text.txt
September 25, 2024
SC1 Edition
Copyright 2024 Associated Newspapers Ltd. All Rights Reserved
Section: FEATURES; Pg. 35
Length: 32 words
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
If you've ever walked a city street so late at night that it's very early in the morning, you may have been greeted by 
a strange and unbidden thought. In the eerie stillness, it can feel for a moment as though you're the last person 
alive. The usual throngs are gone, and the absence of what should be there is impossible to ignore-until some other 
person, off to start their working day, breaks the spell. The world is still there.
It is hard, in any real-world city, to maintain the illusion of being the only person for any length of time. But the 
internet is different. There is always an element of unreality to an online interaction with another human: how do we 
know for sure that they are who they say they are? Can we be certain they're even actually a person?
This is the idea at the core of what became known as Dead Internet Theory, a joke-cum-conspiracy that says if 
you're reading these words online, you're the last person on the internet. Everyone else is a bot. The other 
commentators on Reddit? Bots. The people in the videos or the podcasts you listen to? Bots. What's filling the junky 
websites that we all can't help but click? You guessed it. They're all bots, and you're the guinea pig in the perverse 
experiment of some unknown power.
Dead Internet Theory is, if anything, a thought experiment. We've learned that we can't necessarily trust what we 
read or who we meet online-so what happens if we take that notion to the extreme? If you were the last actual 
human on the internet, how long would it take for you to notice?
The idea began to gain traction almost a decade ago, with the "time of death" of the internet typically given as being 
around 2015 or 2016-but in the years since, reality has begun to mirror this once unserious conspiracy. The 
complaint of the modern internet is that it is filled with "slop" content, the spiritual successor to email spam. Low-
quality content-such as trashy viral images or regurgitated news articles-created by artificial intelligence is filling up 
social media, search results and anywhere else you might look. But while junk memes are near impossible to avoid, 
they are just the most visible sign of the AI detritus that is coming to dominate our online worlds.

Page 2 of 4
Is anyone out there?
In reality, the internet is bots all the way down. Automated systems generate fake but clickable content. Bot 
accounts like and comment, boosting the slop in the algorithms of social media sites and search engines. 
Clickfarms monetise the whole endeavour, posing as real users with real eyeballs and thus earning advertising 
revenue. In this way, the web is being taken over by a global, automated ad fraud system, and whether or not any 
human sees any of it is entirely irrelevant. The things that generate real value for us are being pushed further and 
further to the margins, unable to compete with this brutal new algorithmic reality.
The most obvious destination for slop is Facebook, a social network that has been seen as dated and perennially 
naff for at least a decade, but which nonetheless counts more than a quarter of humanity as its users-even if many 
don't log in quite as often as they used to.
If you do check your Facebook "Suggested for you" feed, though, you're likely to find it chock-full of AI-generated 
slop: mostly images that don't pass for real after even so much as a cursory glance, but which nonetheless 
generate tens of thousands of likes.
For a while, the trend was for images of what looked like wood or sand sculptures and their artists, with captions 
such as "made it with my own hands". At another point, bizarre images of Jesus were du jour. One image of "shrimp 
Jesus" portrayed Christianity's saviour as a crustacean. This was followed by pictures of US veterans, beggars or 
children looking miserable with birthday cakes, usually in strange locations, captioned with "why do images like this 
never trend?" The latest fad is for pictures of grotesquely emaciated people holding out begging bowls, often with 
strange skeleton or snake-like appendages. The nature of the junk memes changes, but it is always bizarre and 
lacking in any obvious purpose.
The independent journalism startup 404 Media has done more than anyone else to work out what is behind the 
apparently unstoppable slew of AI-generated slop on Facebook. The answer is a sign of what's gone wrong on the 
internet and indicates how difficult it will be to fix: ultimately Facebook is funding the content that is destroying the 
value of its own network.
Behind the accounts posting slop on Facebook are entrepreneurs, of sorts, working out of countries including India, 
Vietnam and the Philippines, where internet access is widespread but incomes are relatively low. Here, the 
advertising revenue from a viral Facebook meme page is much more attractive relative to an average salary than it 
is in a country such as the UK.
These "creators" are often trained through online seminars which are themselves promoted through AI-generated 
content. As 404 Media reports, they are instructed to share "emotional" content to generate likes, comments and 
shares, but many boost this type of material either through artificial accounts or by partially hijacking real user 
accounts.
Some users who persistently comment on AI slop appear to have two personalities, effectively because they do. 
One "persona"-the real person-comments as usual on their local interest groups. But their account, which has been 
compromised without them noticing, also posts generic, AI-generated comments on thousands of pieces of AI-
generated slop. This is a kind of benign hacking, in which bots piggyback on an account, letting the real user go 
about their business while using it to boost their content-a parasite for the digital era.
The motive is, of course, money. Facebook slop is monetised in two ways. Meta, which owns Facebook, shares 
revenue from the advertising it shows alongside the content of major creators. This means that if AI meme pages 
generate a big and apparently real audience on the site, Facebook itself pays the page creators. But if Facebook is 
the laboratory in which slop developed its strength, it long ago leaked into the wider internet ecosystem. Many 
pages direct users elsewhere, onto the web proper, where more money can be made. It is here that junk content for 
junk clicks reaches its natural and inevitable peak.
In his 2008 book Flat Earth News, the journalist Nick Davies identified a new scourge of the journalism industry, 
brought about by the internet era. Junior staff at local and even national newspapers were being asked to generate 
huge numbers of online stories at a relentless pace.
Page 3 of 4
Is anyone out there?
Instead of going out to speak to people or do original reporting, journalists would be required to produce a story 
every hour, or even every 45 minutes, by simply rewriting other people's work. Davies popularised a name for this 
phenomenon-"churnalism"-and pointed to the obsession of bosses with generating online clicks for advertising 
revenue as its cause.
If a hasty rewrite produced at virtually no cost could generate as many views-and so as much online revenue-as an 
original investigation, why bother producing the latter? The churnalism phenomenon hollowed out newsrooms and 
replaced accountability journalism with articles such as "What time does Strictly Come Dancing start tonight?" and 
"What other shows has Olivia Colman been in?", designed to lure in audiences from Google.
Sixteen years on, newsroom bosses are reaping what they sowed with the race to the bottom, pursuing cheap 
content to satisfy only the most casual of online browsers. Executives learned that if online clicks are all you care 
about, most of the journalism can be discarded. Their successors realised something more: the newsroom itself can 
be thrown away. Instead of having a real media organisation, you can churn out rewrites using ChatGPT and other 
AI tools, which can even build a credible looking news site itself.
These imposter news sites are generally harmless bottom feeders, trying to make their owner a living through ad 
views, but occasionally they cause serious trouble. One such site, Channel3Now, based in Pakistan, was among 
the earliest boosters of the false story that the attack on girls at a Taylor Swift dance class in Southport had been 
perpetrated by a Muslim asylum seeker. This disinformation sparked riots and widespread public disorder in the UK.
In a world where ad revenue is all that matters, the first realisation was that journalists were optional. This was 
followed by the understanding that the news site didn't need to be real in any meaningful way either; anyone can 
create something that looks newsy enough to hook people in. There was only one obvious next step: if neither the 
content nor the site has to be real, why does the audience need to be?
Faking page views is an online arms race. Brands rely on advertising networks (which include Google and 
Facebook, as well as companies you'd never have heard of) to actually reach their potential customers. The brands 
pay for views, and so are very keen to make sure that every view is an advert seen by a living, breathing human.
The incentives for the middleman are less clear. They need to do enough to satisfy the brands to keep spending, 
but they are paid by the click, just like the creators themselves. Ad networks quickly cracked down on easy-to-spot 
"clickfarm" behaviour-setting up a computer to constantly click refresh on the same page, for example-but fakers 
learned increasingly sophisticated means to bypass security precautions. For a time, operations working out of 
countries such as China would pay workers to essentially browse the internet on rigs of five to 10 smartphones at a 
time, generating clicks on sites at a relentless pace for shifts of 12 hours a day.
These operations became automated and professionalised, abolishing what was surely one of the dullest and most 
repetitive jobs in the content industry. Today, these clickfarms are formed of tens or hundreds of thousands of sim 
cards, which imitate real mobile internet browsing, generating millions of apparent ad impressions every hour.
This completes the soulless lifecycle of the modern internet economy. People desperate to earn a meagre living 
create automated systems that churn out low-quality or outright fake content. Others create dummy accounts to 
boost and share such content, or fake users to read it. All of this is done to milk some money out of real-world 
brands. Along the way, it enriches the internet giants that operate all of the machinery.
Real people and our needs have become irrelevant to the business model of the modern internet. If something 
interests us, our clicks pay just the same as a fake user in a Chinese clickfarm. Good content is relegated to the 
sidelines, to people who are able and willing to pay for the real thing. Original reported journalism is increasingly 
siloed behind paywalls that are, themselves, getting ever harder. Everyone else is force-fed slop, because there is 
no value in giving them anything better.
The journalist and activist Cory Doctorow christened this phenomenon the "enshittification" of the internet, and 
argued it was an inevitable result of the business model of the modern internet age: hooking people in on a free or 
subsidised product, getting a monopoly and then starting to extract as much profit from that product as is possible. 
Page 4 of 4
Is anyone out there?
As consumers, we get hooked on a product-be it a cheap taxi ride, a holiday, food delivery or human connection 
through social media-that is genuinely too good to be true, because it's being subsidised by billionaire investors. 
Then we watch it steadily get worse.
That extends well beyond online browsing. Ridesharing apps such as Uber, Lyft and their competitors captured the 
private hire market by drastically undercutting the cost of existing taxis, while initially paying drivers at least as much 
as they had before. Once the market was captured and the old incumbents had given up, first the drivers were 
screwed by declining incomes, and then customers faced higher prices. The apparently great new service could 
never have actually lasted in the long term. This story plays out in almost every other venture capital market, from 
subscription boxes and fast food or grocery delivery, to Airbnb and WeWork.
The era of a gold-plated service at a rock-bottom price never lasts. Eventually, the real costs come back, the 
investors want to make money, and reality reasserts itself. Silicon Valley relies on selling us a dream it knows from 
the outset cannot last.
It could have been better than this. Both the internet and the world wide web predate the Silicon Valley era which 
propelled startups into becoming the richest and most powerful companies on the planet. The technology works as 
it ever did-making it incredibly quick, cheap and easy for us to connect to each other, and to publish what we wish. 
The AI slop didn't need to take over. The fact that it has is the result of a series of choices.
The joke of the Dead Internet Theory was that everyone else online might have disappeared, and you could be left 
alone without noticing. In the decade since the idea caught on, emerging technologies have been harnessed almost 
as though this is the goal. Humanity has become irrelevant to the business model of the internet, and so we're 
getting relegated to the sidelines.
Facebook feeds that used to be full of real information and real stories about people from our real lives are now full 
of low-quality and freakish engagement bait. It is no surprise that many of us, as a result, are looking elsewhere. 
Google results keep getting worse, social media feeds are full of dreck, and it is impossible to know what to trust.
None of the internet giants seem to even see the problem, let alone a way to fix it. Instead of trying to rebuild 
internet services to their former glory, they are packing in more AI and automation, and, inevitably even more slop. 
But an internet built for the bots is doomed to fail: in the end the economy is made up of the collective efforts of 
humans, not anything else.
If the multi-billion-dollar companies running the internet don't make it fit for humans, someone else will. However 
much it might feel that way, the internet is no emptier than the streets of London. We're all still there, just out of 
sight.
James Ball is political editor at the New European
Load-Date: September 23, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 2:30 PM GMT
BBC Radio 4 - 2:30 PM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 772 words
Body
Speech to text transcript:1
on BBC Radio 4 with me Russell, top actor and art enthusiast serialism has been called the special effects 
department of psychoanalysis. It gives us an image of how we dream and it gives us an image of the unconscious. 
Where did this mind-bending movement come from and how has it entered everyday life to become more relevant 
than ever? It's the idea that there is something going on in your mind of which you are not aware, but is actually 
hugely important and influential. 
Surrealism remixed on radio form. And BBC sounds starts next Tuesday afternoon at 4. Now on radio in the 
artificial human we discover why utterly bizarre AI images are swarming social media. Hi, I'm Alex Petoskey and I'm 
Kevin form, and this is artificial human where we answer all of your burning questions about AI. So Alex is this 
weird email in the program in book right now that says hey there, Alex and Kevin. Why is my grandma's Facebook 
full of Shrimp Jesus. It's weird cheers. There's no name on the end of it I suspect suspect should probably have 
gone to Spain. It's interesting. You say no, no, no, no, it's m, but I don't even understand the words in that email. If 
I'm being honest, this is your entry into the wonderful world of AI slop. Kevin, welcome a slob which. Shrimp Jesus 
is a kind of emblem of this at the minute. Shrimp Jesus is an image, an AI generated image of Jesus Christ as a 
crustacean. I don't know what the prompt was. It created it, but it is everywhere on social media right now, and it's 
not just Shrimp Jesus's everywhere. It's all kinds of different, very weird, low quality yet hyper-realistic images. 
You've probably seen them like grandmothers with 3000 candles on a birthday cake, or pictures of like little kids 
who seem to be artistic prodigies and have made these incredibly realistic portraits of themselves just weird, weird 
stuff and what. And that's populating some grandmother's time line yeah. Yes, yes, it is in fact it's populating a lot of 
grandmothers and a lot of everybody's timelines, particularly on Facebook. I suppose you know you mentioned 
spam earlier in whether this email should have gone into spam. It's actually a slop is actually a new form of spam. I 
suppose you could call it well. It certainly sounds weird. Wonder you're not winning me over with it. It's absolutely 
wonderful, Kevin, genuinely, it's it's wonderful, but the fact is is that it's everywhere. Okay, well, it sounds like we're 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 2:30 PM GMT
going to answer this 1. What is a slop? Does it threaten us? Does it threaten the future of the Internet, as we know, 
does it threaten the grandmothers? All of these are really good questions, but big. I've never studied it I've been the 
recipient of it. I think we should dig into it would be kind of fun. Yeah, you do that. In the meanwhile, I'm gonna jump 
in a tardis and go back to the time when the Internet was full of people showing pictures, the cats and sharing 
recipes. Barna, thank you so much joining us today just to get us going. Give us your full name and any job title and 
affiliations that you have. So my name is Rene Deta. Until recently, I was the technical research manager of 
Stanford Internet Observatory and I'm the author of the book invisible rulers the people who turn lies into reality. I 
have studied what we call adversarial abuse online for just about a decade now, and that means looking at new and 
novel ways in which people who might set out to manipulate the public use online technologies to do it. Sometimes 
that might be state actors. A lot of the work I've done has looked at you know, things like Russian troll factories, but 
sometimes it's a little bit more mundane and it's people like spammers and scammers who use those same 
technologies, but they're financially motivated rather than ideologically motivated spammers and scammers. But 
there's a new category isn't sloppers, and this is such an interesting question. When I first started looking at the 
proliferation of AI generated content, a lot of it really began with people using it for arts early 2020 the, I think, and. 
You just saw this excitement around what we could all do with these technologies, and then gradually, interest kind 
of dropped off and you started to see these weird pages really begin to grow in popularity, as financially motivated 
folks realized that they could use these tools too. We were asked specifically about one piece of a content Shrimp 
Jesus, OK, can you tell me a little bit about Shrimp Jesus and also a little bit about why
Load-Date: September 25, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 08:00 AM GMT
BBC Radio 4 - 08:00 AM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 812 words
Body
Speech to text transcript:1
The Prime Minister has urged British people to leave immediately, saying he fears the region is on the brink of war. 
Cross-border fire between Israel and Hasballah, which is based in Lebanon, has intensified. The group has been 
prescribed as a terrorist organisation by the UK Government. Our senior international correspondent, a Garin, is in 
the southern Lebanese city of Tyre. 
She says people are preparing for the worst. Schools have been designated as temporary shelters, though people 
have somewhere to go, but I think the biggest concern they have is that the I cannot tell how long this is going to go 
on. Everybody believes we're in the early stages of something with this extraordinary way. Eve of Israeli attacks that 
began on Monday, more than 500 Lebanese killed in a single day. I think most people are expecting that there will 
be an escalation of some kind. Israel says it's intercepted a missile fired towards Tel Aviv from Lebanon. It's thought 
to be the first time he ba has targeted the city. The man accused of trying to kill Donald Trump at his Florida golf 
course earlier this month has been charged with a 10. The assassination of a major presidential candidate, Ryan 
Ruth, hasn't entered a plea, but had left a note describing his intentions. The Prime Minister has signaled plans for 
a major shakeup of the welfare system, saying almost all benefit claimants should be expected to look for work. 
Speaking to the today program, he said the government and businesses should support people to re enter the 
workplace, but that ministers wanted to tackle those abusing the benefits system. The basic proposition that you 
should look for work is right. But we also want to support that so that more people can get into work. But I'm also on 
benefit fraud. We do need to be clear about benefit fraud and that we need to tackle it much more effectively. A 
global study suggest one-third of children and teenagers worldwide are now shortsighted. Researchers say data 
collected from 50 countries shows eyesight got worse during COVID lockdowns, when children spent more time 
looking at screens. BBC news this is BBC Radio 4, where a new series of the artificial human begins. This 
afternoon we'll be diving into the weird, wonderful and rather murky world of of AI slop that's mass produced low 
quality AI images to you and me, and they've spread like wildfire across social media platforms. We'll hear more 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 08:00 AM GMT
about Shrimp Jesus, one of the most prominent and bizarre examples here on radio this afternoon at 3 30 but first. 
Hello and welcome to more or less were a statistical Lighthouse. Piercing the darkness of numerical confusion and 
allowing you to safely reach the harbour of rationality ought to put it another way we're a radio program about 
numbers and clear thinking. I'm Tim Harford This week. The Government is encouraging pensioners to claim 
pension credit in order to remain eligible for winter fuel payments. Will people sign up, and might that end up 
costing the Exchequer more than it saves? The Office for national Statistics has downgraded the status of a new 
statistic aiming to measure how many people are transgender. We ask what went wrong. Cancer appears to be on 
the rise in the under fifties. Why and how worried should we be? And here's a puzzle for you to think about. If it 
takes a hen and a half a day and a half to lay an egg and a half, how many eggs to half a dozen hens lay, and half 
a dozen days later in the program puzzle prankster Alex Bellos will join us with the answer. Let's start with winter 
fuel payments. The Government, as we've noted before, is very concerned with filling a black hole and the public 
finances which they say is 22 billion pounds deep. The first attempt to start filling that hole was the announcement 
that they were cutting the winter fuel payment. It currently goes to all pensioners and new plan is that only the 
poorest on pension credit will get the one-off payment of 200 or the 100 pounds each winter. The government 
reckoned this cut could save them 1.5 billion pounds. But that raises a question. If the change in the rules prompt 
people to start claiming pension credit, perhaps the cost of all the extra pension credit payments will swallow up that 
saving or at least nibble away at it. So how many people might start claiming and how much might they claim? 
Money Box presenter and national treasurer Paul Lewis, has been running some interesting numbers. Hello Paul, 
hello, Tim. So the Government cut winter fuel payments for all pensioners except the pensioners who claim pension 
credit, and we know there are lots of pensioners who are eligible for this benefit and who don't claim it. So how 
many potential claimants are there out there who aren't
Load-Date: September 25, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 2:00 PM GMT
BBC Radio 4 - 2:00 PM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 860 words
Body
Speech to text transcript:1
at least 23 people are known to have died and dozens of others have been injured. It comes hours after the group 
fired a missile towards the Israeli city of Tel Aviv. It was the first such attack and is said to have targeted the Israeli 
security agency Mossad. Although the missile was intercepted. 
The Prime Minister Seko Stamer, who's in New York for an emergency meeting on the conflict, says he's very 
worried about the escalation of fighting. All parties need to pull back from the brink to de-escalate. We need a 
ceasefire, and this needs to be sorted out by diplomatic means. I am very concerned about the increasing 
escalation, which is not just day on day, but almost hour on hour. At the moment, rail workers with the R. M. T. 
Union have accepted a pay deal ending a long running dispute which has led to multiple strikes. Members agreed 
to a 4.5% pay rise for this year for workers at Network rail, and the train companies and staff at the train operators 
will also receive 4 point seven, 5% for last year. The Health Secretary West treating says teams of senior doctors 
will work across the? NHS in England to bring in reforms aimed at getting people treated more quickly so that they 
can get back into the workplace. Around 2.8 million people are out of work due to ill health. Weather warnings have 
been issued for more heavy rain for tomorrow and Friday as flooding continues in parts of England and Wales. 
Firefighters and police rescued residents last night at the Billing Aquidrome holiday Park in Northamptonshire, while 
a nearby leisure centre opened up as an overnight refuge, and Philip Schofield is making a return to TV more than 
a year since quitting it. Ves this morning he'll appear in Channel is cast away where he'll be stranded on an island 
off Madagascar for 10 days. In the trailer he admits not disclosing an affair with a younger colleague was unwise, 
but he questions whether this should be absolutely destroying someone. BBC news we'll discover some prominent 
examples of low quality AI images, known as AI slop, that have spread across social media in the artificial human 
here on radio in half an hour but first. It's money box live with Felicity Hanna hello across the UK, thousands of 
teenagers are busy picking out posters, making new friends and settling into life at university, but graduates in 
England leave UNI with average debt of around 48 and a half 1000 pounds. That's according to the student loans 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 2:00 PM GMT
company. So how is this year's freshers feeling about their finances? I feel like I been Sally being really tight with 
my money because I'm quite indy with it us, because I know the cost. I'm definitely going to be looking. To get a 
part time job, the student loan I have is just not enough. The only thing I really like fought from a flat was like like an 
airfare or something like that that's, that's crazy wish that you're picking up right. It was only though I thought that 
was quite good flat just because so upbeat fresh is searching for jobs and air fries there. But research from the 
Credit reference agency experience claims 80% of students say money worries are causing them significant stress. 
So this week we're looking at how much a degree really costs. Has the price made you think twice. Maybe you 
chose an apprenticeship instead, or maybe you don't mind your loan repayments because you've got your dream 
job get in touch now with your questions or your comments were money boxatbbc-dtcotuk now we'll meet our 
experts in just a couple of moments but first of all let's hear from some students at the university of manchester 
money box producer sarah rogers has been there to meet freshers at the student union as they queued up to try 
and win some freebies so we're giving students a chance to spin the wheel and everything on there is the prize 
completely free to participate and they can walk away with anything from sweet to a lanyard to a box of teeth and 
you're in the queue for a lucky dip so you spin the wheel what you hoping to win anything other than horrible it is 
horrible fresh weent know we're talking about we've been staying inside watching films did the cost of the university 
and make you think twice about coming i think it's at such a ridiculous level though i don't even consider it anymore 
that it's just an ungraspable like a mount i suppose like monopoly yeah basically it doesn't mean anything to me i 
don't know yeah well you have to work whilst you're at university yeah probably i spent the past year saving money 
at my job to save university yeah i've managed to find a job that i'm going to start doing yeah because i mean it's a 
little bit too expensive the student loan doesn't come very much so i'm going to have to survive somehow so you 
have just arrived in manchester this weekend just went straight out to find a job well i was like kids in at the fair here 
actually have you got budgets have you got site if you finance it so i mean when i'm not trying to look at my banco 
too much to be honest when timetables when fresh is
Load-Date: September 25, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 2:55 PM GMT
BBC Radio 4 - 2:55 PM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 757 words
Body
Speech to text transcript:1
involved would know until they're suddenly not making any money, and people used to be making $400 for a super 
viral image now they're showing their little Facebook panels. Like many of these videos, they will pull up the sort of 
back end that shows how much money they're making per photo and they're making like $0.06 $0.12, and so there 
is anecdotal evidence at least, that Facebook has altered its payouts and that this is no longer very lucrative. It feels 
to me a little like into the gold rush of you know, the late 19th century whereby everyone said the fields of gold you 
can pick up gold on the floor, but you couldn't, and the the vast majority of people who rushed into the gold fields 
went bust right the people who made all the money with the people who sold shovels and hotel rooms and made 
boats by the river. Is that what's happening here?
 It's the perfect analogy, in my opinion, because you have these Youtube influencers who are saying you can get 
rich quick, doing this just you know, listen to me, but also by my course for you know, a few dollars or sometimes 
more than that, and they're sort of racking up the hundreds of thousands or millions. Of Youtube views and those 
are monetized and those people seemingly like have it all figured out well. Kevin, I did not expect Shrimp Jesus to 
lead us here is amazing, amazing as one word, isn't it? Having not heard of the term pilot before we started making 
this program, I'm now moderately concerned about it right. So this is this is the very essence of that Star Trek 
episode with the triples you know where they had those cute very creatures where we're curious to look at kind of 
fun, and then they start multiplying and multiplying and multiplying until every thing is trying in them and nothing 
gets done, and this reminds me absolutely of that. And there's something a little darker, I think, in the stories that 
we had. there from Jason in so far as the way that so this offers a law to the global South that is false, which is that 
this is a digital inroad to the global North and a way of securing some of their wealth through this ridiculous and 
surprise when Jason has found that that's no longer true. And the only people who are making the money of awful 
middle men in that yeah, in fact, interest, tingly and perhaps ironically, these power disparities that already exist 
offline kind of replicated online, and as you say, it's the people who run these social media companies who are 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 2:55 PM GMT
ultimately making cash money out of the strip Jesus. So the one thing that I will say to the listener perhaps if you 
are looking for something to be able to fight back against the influx of AI slop is that look. It just depends upon your 
engagement right, don't look at it, don't click on it, don't comment on it, because all that's going to do is feed the 
algorithm and stick it into some other Grannis feed. So just ignore it and move on, and I think that that is a very 
good place to start. I guess the joke would be on social media, though, if we all stopped using it. If you've got any 
burning questions about artificial intelligence and, as you can see, the answer all kinds, then do send us an email to 
the artificial human at BBC. UK. But if you send me a picture of a crustacean mashed up with a deity, I'm going to 
block you forever. The artificial human was a BBC audio Scotland production presented by Kevin Fong and Alex 
Kritsky and produced by Elizabeth Anne Duffy. After the news we'll hear from the team behind the new U. S version 
of have got news for you, can CNN's attempt to succeed in America, where other launches of the franchise have 
failed we'll find out in the media show here in a few minutes. Lady swindlers, families must be looked at after when 
a member is in prison. Everybody was acquainted with my whole history. Now drinking before a ride, Lucy Worsley, 
revisit the audacious and surprising crimes of women from the past. When they got safely out of the store, they 
would jump into their waiting getaway cars. This was an alternative route to become a modern woman pursuing con 
women, thieves and hustlers. She looks utterly terrifying. She's got this kind of dead-eyed stare, lady swindler with 
Lucy Worsley starting next Monday at 3 30 on and BBC sounds BBC news at 4 0. The Israeli military says it has hit 
more than to hundred-deg targets belonging to Hez Bala in Lebanon. A senior figure in the Israeli
Load-Date: September 25, 2024
End of Document
Page 1 of 1
Pick of the day
Pick of the day
i-news
September 25, 2024
SC1 Edition
Copyright 2024 Associated Newspapers Ltd. All Rights Reserved
Section: FEATURES; Pg. 35
Length: 32 words
Body
The Artificial Human 3.30pm, BBC Radio 4 Aleks Krotoski (above) and Kevin Fong examine the world of AI slop: 
mass-produced, low-quality images that have spread like wildfire over social media.
Load-Date: September 25, 2024
End of Document

Page 1 of 1
PICK OF THE DAY
PICK OF THE DAY
i-news
September 25, 2024
First Edition
Copyright 2024 Associated Newspapers Ltd. All Rights Reserved
Section: FEATURES; Pg. 35
Length: 32 words
Body
The Artificial Human 3.30pm, BBC Radio 4 Aleks Krotoski (above) and Kevin Fong examine the world of AI slop: 
mass-produced, low-quality images that have spread like wildfire over social media.
Load-Date: September 25, 2024
End of Document

Page 1 of 1
Radio choice
Radio choice
The Daily Telegraph (London)
September 25, 2024 Wednesday
Edition 1, National Edition
Copyright 2024 Telegraph Media Group Limited All Rights Reserved
Section: FEATURES; Pg. 28
Length: 109 words
Body
A Suspension of Mercy Radio 4 Extra, 2.30pm & 8.30pm One of the best of Radio 4 Extra's crop of rediscovered 
"lost" classics is this nail-biting 1985 adaptation of Patricia Highsmith's psychological thriller. Stuart Milligan walks a 
"did-he, didn't-he?" tightrope as a writer suspected of murdering his wife when she disappears while taking time out 
from their marriage. Aleks Krotoski and Kevin Fong, meanwhile, are back with a new run of The Artificial Human 
(Radio 4, 3.30pm), this week exploring how online spam has evolved into AI slop - mass produced, low quality AI 
images that go viral. Will such images be the death of social media? Gerard O'Donovan
Load-Date: September 25, 2024
End of Document

Page 1 of 3
The Trump Posts You Probably Aren't Seeing
The Trump Posts You Probably Aren't Seeing
Atlantic Online
September 24, 2024 Tuesday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1322 words
Byline: Charlie Warzel
Body
Sign up for The Decision, a newsletter featuring our 2024 election coverage.
Do you remember what it was like when Donald Trump couldn't stop tweeting? When it felt like, no matter the time 
of day or what you were doing, his caps-lock emeses were going to find you, like a heat-seeking, plain-text missile? 
Enjoying a nice little morning at the farmer's market? Hold on, here's a push alert about Trump calling Kim Jong Un 
"rocket man" on Twitter. Turn on the radio, and you'd hear somebody recapping his digital burbles. You could 
probably make the case that a large portion of the words spoken on cable-news panels from 2015 to early 2021 
were at least tangentially about things that Trump pecked onto his smartphone from a reclining position.
Then January 6 happened. Twitter, worried about "the risk of further incitement of violence," permanently 
suspended his account, and Trump later launched his own social-media site, Truth Social. It has far fewer users 
than its rivals do, and Trump now mostly bleats into the void. Occasionally, news outlets will surface one of his 
posts-or "Truths," as they're called-such as a September 12 post declaring that he would not debate Kamala Harris 
again. But although Elon Musk has reinstated Trump's X account, the former president still mostly posts on Truth 
Social, which has had the effect of containing his wildest content. Unless you're a die-hard Trump supporter, a 
journalist, or an obsessive political hobbyist, you're likely not getting that regular glimpse into the Republican 
candidate's brain. But  maybe you should be?
Last Friday, I received an email with a link to a website created by a Washington, D.C."based web developer 
named Chris Herbert. The site, Trump's Truth, is a searchable database collecting all of Trump's Truth Social posts, 
even those that have been deleted. Herbert has also helpfully transcribed every speech and video Trump has 
posted on the platform, in part so that they can be indexed more easily by search engines such as Google. Thus, 
Trump's ravings are more visible.
[Read: The MAGA aesthetic is AI slop]

Page 2 of 3
The Trump Posts You Probably Aren't Seeing
Like many reporters, I'd been aware that the former president's social-media posts had, like his rally speeches, 
grown progressively angrier, more erratic, and more bizarre in recent years. Having consumed enough Trump 
rhetoric over the past decade to melt my frontal cortex, I've grown accustomed to his addled style of 
communication. And yet, I still wasn't adequately prepared for the immersive experience of scrolling through 
hundreds of his Truths and ReTruths. Even for Trump, this feed manages to shock. In the span of just a few days, 
you can witness the former president sharing flagrantly racist memes about Middle Easterners invading America, 
falsely edited videos showing Harris urging migrants to cross the border, an all-caps screed about how much better 
off women would be under his presidency, a diatribe about Oprah's recent interview with Harris. It's a lot to take in 
at once: Trump calling an MSNBC anchor a "bimbo," a declaration of hatred for Taylor Swift, a claim that he "saved 
Flavored Vaping in 2019."
On their own, each of these posts is concerning and more than a little sad. But consumed in the aggregate, they 
take on a different meaning, offering a portrait of a man who appears frequently incoherent, internet-addicted, and 
emotionally volatile-even by the extreme standard that Trump has already set. Trump seems unable to stop 
reposting pixelated memes from anonymous accounts with handles such as @1776WeThePeople1776 and 
@akaPR0B0SS, some of which contain unsettling messages such as a desire to indict sitting members of 
Congress for sedition. Trump appears to go on posting jags, sometimes well after midnight, rattling off Truths 
multiple times a minute. On Sunday night, from 6:20 p.m. to 6:26 p.m., Trump shared 20 different posts from 
conservative news sites, almost all without commentary. For a man currently engaged in the homestretch of 
campaigning for the presidency of the United States, he is prolific on social media, and seemingly unable to stop 
posting-from Friday to Monday, Trump posted or reposted 82 times.
Back in January, my colleague McKay Coppins argued that politically engaged Americans should go to a Trump 
rally and "listen to every word of the Republican front-runner's speech" as "an act of civic hygiene." Granted, 
Coppins wrote his article during a different time in the election cycle, at a moment when Trump was less visible, but 
his point still stands. Many Americans and the institutions that cover him have grown so used to Trump-to his 
tirades, lies, and buffoonery-that his behavior can fade into the background of our cultural discourse, his 
shamelessness and unfitness for office taken almost for granted. When Coppins attended a rally early this year, he 
recalled the "darker undercurrent" that infused Trump's rhetoric and lurked behind many of the comments coming 
from supporters in the crowd. Just as important, Coppins wrote, the rally was also a reminder that "Trump is no 
longer the cultural phenomenon he was in 2016. Yes, the novelty has worn off. But he also seems to have lost the 
instinct for entertainment that once made him so interesting to audiences."
[Read: You should go to a Trump rally]
Trump's Truth Social posts offer a similar vibe. His feed is bleak, full of posts about America in decline. 
Aesthetically, it is ugly, full of doctored images and screenshots of screenshots of Facebook-style memes. 
Consuming a few weeks' worth of his posts at once was enough to make me feel awful about the state of the world, 
not unlike how it feels to visit seedy message boards such as 4chan.
And then there's the prose. As in his rallies, Trump rambles, his writing hard to follow. His stylistic choice to use 
caps lock for many of his longer posts gives the appearance that he is shouting. Unlike on Twitter, where he was 
constrained by character limits, Trump's missives are too long and too convoluted to be easily digestible by 
aggregating media organizations. In previous iterations, Trump's tweets were sometimes so bizarre as to be funny 
(or at least weird enough to be compelling); now his posts appear too fueled by grievance to be casually amusing.
[Read: Donald Trump can't stop posting]
I realize that I'm not exactly selling the experience of taking a spin through Trump's digital archive of incoherence. 
But I think it's an instructive exercise. If you, like me, have had the experience of seeing friends or loved ones 
radicalized online or lost to a sea of Facebook memes and propaganda, then scrolling through Trump's Truth Social 
posts will provoke a familiar feeling. On his own website, Trump doesn't just appear unfit for the highest office in the 
land; he seems small, embittered, and under the influence of the kind of online outrage that usually consumes those 
who have been or feel alienated by broad swaths of society. It's not (just) that Trump seems unpresidential-it's that 
Page 3 of 3
The Trump Posts You Probably Aren't Seeing
he seems like an unwell elderly man posting AI slop for an audience of bots on Facebook. Imagine that, instead of 
Donald Trump's, you were looking at the feed of a relative. What would you say or do? Whom would you call?
A few months ago, The Atlantic's editor in chief, Jeffrey Goldberg, wrote about the media's "bias toward coherence" 
when it comes to Trump's rhetoric, where, in an attempt to make sense of Trump's nonsense, journalists sand down 
the candidate's rough edges. Perusing Trump's Truth Social feed, though, it is nearly impossible to find any 
coherence to latch on to. Since Trump came down his golden escalator in 2015, I've thought that the best way to 
understand the candidate is via plain text. There, unlike on television, his fragmented attention, peculiar thinking, 
and dangerous words cannot hide or be explained away. The election is 41 days away, and Trump appears as 
unstable as ever. But don't take my word for it: Go see for yourself.
=======
The Artificial Human 3.30pm, BBC Radio 4 Aleks Krotoski (above) and Kevin Fong examine the world of AI slop: 
mass-produced, low-quality images that have spread like wildfire over social media.
>>>>>>> c98f417 (update data file):extract_text.txt
Load-Date: September 25, 2024
End of Document

Page 1 of 1
Radio choice
Radio choice
The Daily Telegraph (London)
September 25, 2024 Wednesday
Edition 1, National Edition
Copyright 2024 Telegraph Media Group Limited All Rights Reserved
Section: FEATURES; Pg. 28
Length: 109 words
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Link to Image
Each year, The Pokémon Company holds a competition to find a new illustrator for their Pokémon TCG cards. Only 
in the last couple of years has this been opened to entrants from outside of Japan, and with that has come 
controversy. However, after a tumultuous period, the finalists for this year's contest have finally been picked, and 
damn, it's all beautiful work.
This year's contest was rather marred when one entrant, who had been included in the top 300, was rather 
obviously using AI to create images, and indeed entering under multiple identities. 
After people made a fuss, The Pokémon Company acknowledged the issue, and said they'd be disqualifying the 
cheat, and allowing other legitimate entries in to fill the spaces. It remained concerning that such obvious 
shenanigans had been let through, but TPC is notoriously enigmatic and incommunicative, so even this was a 
surprising move.
However, we can now sweep that all aside, and instead celebrate the legitimate artists who deserve their wins. And 
wow, there's some great stuff here.
The competition is broken into a number of categories, with the emphasis on the smaller, landscape images that 
appear in the windows on a regular Pokémon card. While the prized cards are generally the portrait full-art designs, 
it makes sense to constrain entrants to the windowed images, with its inherent limitations.
The categories are Best Standard Card Illustration, Best ex Card Illustration, and a Grand Prize.
The middle category is the odd one out, since non-alt-art ex cards are highly restrictive in their nature, leaving little 
room for originality. It's a great piece of Toxtricity art by Anderson, certainly, and it won because of its use of the 
space to depict a unique angle for the Pokémon, but it's harder to get excited about.

Page 2 of 2
Following AI Cheating Controversy, Pokémon Announces Winners Of Card Contest
Link to Image
What's so lovely about the two other winners, however, is quite how different they are.
The Pokémon Company is getting better and better at featuring ever more lavish art, but is still quite conservative 
on style, so seeing the pick for Best Standard Card Illustration is a real treat. It's a stunning depiction of Feraligatr 
by artist Acorviart, inspired by linocut and risograph printing.
Link to Image
The Grand Prize is certainly more conventional, but makes up for it in adorable. Pikachu perhaps seems a little on 
the nose, but Kazuki Minami's painting is breathtaking. What works so incredibly well here is the intricate detail of 
the background flowers, contrasted with the far simpler depiction of Pika, in such a cute and recognizable pose. 
And that light on his face...come on.
Link to Image
I want to highlight a few of the runners up, too. Firstly, another Feraligatr, this time by tayu, which appears to be one 
of the most spectacular pieces of embroidery I've ever seen. There are so few multimedia artists making Pokémon 
cards, despite how popular the wonderful Yuka Morii's clay art has been for 25 years. Also, it's a wonderful picture 
beyond the media.
Link to Image
In a contest that was upset by AI slop, it's lovely to see a piece that AI would try to copy, and get horribly wrong. 
This Melmetal by gohealth feels so gloriously metallic, and yet so cartoonishly stylized. Also, when did you last see 
a Melmetal sit down?!
Link to Image
Shiho So's Pikachu is one of the 15 Judges' Award winners (alongside so many more Feraligatr!), and would be 
one of those cards that'd make you smile every time you pulled it from a pack. It's just joyful.
Link to Image
And why not end with yet another Pikachu? satoutubu's art here is...I just want to hug it! I want to exist in a world 
where creatures look like this. If satoutubu became a regular Pokémon TCG artist, I'd immediately begin collecting 
all their cards.
Link to Image
.
Load-Date: September 23, 2024
End of Document
Page 1 of 2
Wednesday 25 September
Wednesday 25 September
The Times (London)
September 21, 2024 Saturday
Edition 1, National Edition
Copyright 2024 Times Newspapers Limited All Rights Reserved
Section: SATURDAY REVIEW;FEATURES; Pg. 42
Length: 487 words
Body
TIMES RADIO 5.00am Rosie Wright with Early Breakfast 6.00 Aasmah Mir and Stig Abell with Times Radio 
Breakfast 10.00 Hugo Rifkind 1.00pm Andrew Neil 2.00 Jane Garvey and Fi Glover 4.00 John Pienaar with Times 
Radio Drive 6.00 Pienaar and Friends 7.00 The Evening Edition with Kait Borsay 10.00 Carole Walker 1.00am The 
Best of Times Radio RADIO 2 6.30am The Zoe Ball Breakfast Show 9.30 Vernon Kay 12.00 Jeremy Vine 2.00pm 
Scott Mills 4.00 Sara Cox 6.30 Sara Cox's Half Wower 7.00 Jo Whiley's Shiny Happy Playlist 7.30 Jo Whiley 9.00 
Folk Show 10.00 Trevor Nelson's Rhythm Nation RADIO 3 6.30am Breakfast 9.30 Essential Classics 1.00pm 
Classical Live 3.00 Live Choral Evensong. With music by Imogen Holst, Leighton, Brahms and Ropek 4.00 
Composer of the Week: Gluck. How Gluck became a fixture of Vienna's musical scene 5.00 In Tune 7.00 Classical 
Mixtape 7.30 Radio 3 in Concert. Manchester Camerata perform a programme of Mozart 9.45 The Essay: Music 
Rediscovered. Oskar Jensen sings the Millons be Free 10.00 Night Tracks 11.30 'Round Midnight 12.30am 
Through the Night
RADIO 4 5.30am News Briefing 5.43 Prayer for the Day 5.45 Farming Today 6.00 Today 9.00 More or Less 9.30 
The Coming Storm. Gabriel Gatehouse enters a world where nothing is as it seems 10.00 Woman's Hour 11.00 A 
Wild Ride(r) 11.45 Book of the Week: The Siege. By Ben Macintyre (8/10)
12.04pm You and Yours 1.00 The World at One 1.45 Superhead. John Dickens investigates the superheads 
transforming failing schools 2.00 The Archers. Opportunity knocks for Fallon (r) 2.15 Drama: Riot Girls - Dykes. The 
angry 1970s give way to the more repressive 1980s (2/3) 3.00 Money Box Live 3.30 The Artificial Human. New 
series. Aleks Krotoski and Kevin Fong examine the world of AI slop 4.00 The Media Show. The latest news from 
the fastchanging media world 5.00 PM. With Evan Davis 6.00 Six O'Clock News 6.30 Paul Sinha's Perfect Pub 
Quiz. The host and his live audience compile the questions for a perfect pub quiz (r) 7.00 The Archers. George is 
struggling with recent events 7.15 Front Row. Arts programme 8.00 AntiSocial (r) 8.45 Profile (r) 9.00 The Life 
Scientific (r) 9.30 All in the Mind (r) 10.00 The World Tonight 10.45 Book at Bedtime: The Last Loves of Ronnie 
Maker (3/5) 11.00 Follow the Rabbit. A local woman claims she has a demon living in her biscuit tin (4/5) 11.15 The 

Page 2 of 2
=======
A Suspension of Mercy Radio 4 Extra, 2.30pm & 8.30pm One of the best of Radio 4 Extra's crop of rediscovered 
"lost" classics is this nail-biting 1985 adaptation of Patricia Highsmith's psychological thriller. Stuart Milligan walks a 
"did-he, didn't-he?" tightrope as a writer suspected of murdering his wife when she disappears while taking time out 
from their marriage. Aleks Krotoski and Kevin Fong, meanwhile, are back with a new run of The Artificial Human 
(Radio 4, 3.30pm), this week exploring how online spam has evolved into AI slop - mass produced, low quality AI 
images that go viral. Will such images be the death of social media? Gerard O'Donovan
Load-Date: September 25, 2024
End of Document

Page 1 of 2
Wednesday 25 September
Wednesday 25 September
The Times (London)
September 21, 2024 Saturday
Edition 1, National Edition
Copyright 2024 Times Newspapers Limited All Rights Reserved
Section: SATURDAY REVIEW;FEATURES; Pg. 42
Length: 487 words
Body
TIMES RADIO 5.00am Rosie Wright with Early Breakfast 6.00 Aasmah Mir and Stig Abell with Times Radio 
Breakfast 10.00 Hugo Rifkind 1.00pm Andrew Neil 2.00 Jane Garvey and Fi Glover 4.00 John Pienaar with Times 
Radio Drive 6.00 Pienaar and Friends 7.00 The Evening Edition with Kait Borsay 10.00 Carole Walker 1.00am The 
Best of Times Radio RADIO 2 6.30am The Zoe Ball Breakfast Show 9.30 Vernon Kay 12.00 Jeremy Vine 2.00pm 
Scott Mills 4.00 Sara Cox 6.30 Sara Cox's Half Wower 7.00 Jo Whiley's Shiny Happy Playlist 7.30 Jo Whiley 9.00 
Folk Show 10.00 Trevor Nelson's Rhythm Nation RADIO 3 6.30am Breakfast 9.30 Essential Classics 1.00pm 
Classical Live 3.00 Live Choral Evensong. With music by Imogen Holst, Leighton, Brahms and Ropek 4.00 
Composer of the Week: Gluck. How Gluck became a fixture of Vienna's musical scene 5.00 In Tune 7.00 Classical 
Mixtape 7.30 Radio 3 in Concert. Manchester Camerata perform a programme of Mozart 9.45 The Essay: Music 
Rediscovered. Oskar Jensen sings the Millons be Free 10.00 Night Tracks 11.30 'Round Midnight 12.30am 
Through the Night
RADIO 4 5.30am News Briefing 5.43 Prayer for the Day 5.45 Farming Today 6.00 Today 9.00 More or Less 9.30 
The Coming Storm. Gabriel Gatehouse enters a world where nothing is as it seems 10.00 Woman's Hour 11.00 A 
Wild Ride(r) 11.45 Book of the Week: The Siege. By Ben Macintyre (8/10)
12.04pm You and Yours 1.00 The World at One 1.45 Superhead. John Dickens investigates the superheads 
transforming failing schools 2.00 The Archers. Opportunity knocks for Fallon (r) 2.15 Drama: Riot Girls - Dykes. The 
angry 1970s give way to the more repressive 1980s (2/3) 3.00 Money Box Live 3.30 The Artificial Human. New 
series. Aleks Krotoski and Kevin Fong examine the world of AI slop 4.00 The Media Show. The latest news from 
the fastchanging media world 5.00 PM. With Evan Davis 6.00 Six O'Clock News 6.30 Paul Sinha's Perfect Pub 
Quiz. The host and his live audience compile the questions for a perfect pub quiz (r) 7.00 The Archers. George is 
struggling with recent events 7.15 Front Row. Arts programme 8.00 AntiSocial (r) 8.45 Profile (r) 9.00 The Life 
Scientific (r) 9.30 All in the Mind (r) 10.00 The World Tonight 10.45 Book at Bedtime: The Last Loves of Ronnie 
Maker (3/5) 11.00 Follow the Rabbit. A local woman claims she has a demon living in her biscuit tin (4/5) 11.15 The 

Page 2 of 2
>>>>>>> c98f417 (update data file):extract_text.txt
Wednesday 25 September
Skewer 11.30 The Gift (r) 12.00 News and Weather 12.30am Book of the Week: The Siege (8/10) (r) 12.48 
Shipping Forecast 1.00 As BBC World Service
A Suspension of Mercy Radio 4 Extra, 2.30pm
Every day this week, Radio 4 Extra is airing five "lost" BBC dramas. Today's offering is an adaptation of Patricia 
Highsmith's psychological thriller. The novelist Sydney Bartleby (Stuart Milligan, above) is a writer of thrillers. His 
wife, with whom he has a fractious relationship, has "died" many times in his imagination. But when she disappears, 
he finds himself under investigation.
Load-Date: September 21, 2024
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
End of Document
Page 1 of 3
Meet the Editor Who Turned Himself Into an AI News Anchor
Meet the Editor Who Turned Himself Into an AI News Anchor
Newstex Blogs 
The Wrap
September 20, 2024 Friday 7:00 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 The Wrap 
Length: 860 words
Byline: Alex Kantrowitz
Body
September 20th, 2024 ( The Wrap  - Delivered by  Newstex )
The AI versionof Elihay Vidal looks a lot like the man in real life. I watched him anchor a news broadcast last week 
and had to stare intently for a number of seconds to confirm I wasn't watching a real human.
Vidal's avatar has a human face, human body, human expressions, and even a shirt with the top two buttons 
unbuttoned. His 'Edge of Tech' show runs regularly on CTech, an Israeli tech news site where he's editor-in-chief, 
and the visuals and voice are entirely synthetic. To develop the show, Vidal worked with Caledo, a tech company 
that builds AI news video for news siteslooking for a cheaper and easier alternative to the real thing.
After watching Vidal's show, I wanted to know why he's allowed himself to be turned into an AI avatar and where he 
sees the format going. Here's our conversation, edited for length and clarity.
Alex Kantrowitz: The AI 'reporter' using your likeness looks very human, like the real you. How did you turn yourself 
into that avatar?
Elihay Vidal: I stood in front of a camera and moved around, and the software captured my movements. The 
avatar's movements are therefore my movements. My AI avatar is singular. It is my voice, my mimics, my facial 
expressions, my eyes, and my smile.
When you initially saw the AI generated version of yourself on screen, were you like, wow, that's me?
I showed it to my family, my wife, my children, my parents, and my sister. Everyone said, there's no way it's not you. 
The machine just learned my character. The little nuances in there, people recognize them as mine.
Why make news videos with artificial intelligence avatars, as opposed to just filming them yourself?
We filmed only once for half an hour. I gave a speech in front of the camera. Then, after a few days they showed 
me my avatar, which was generated by AI. And when I gave the speech, I did it in Hebrew

Page 2 of 3
Meet the Editor Who Turned Himself Into an AI News Anchor
But your avatar speaks in English?
Yes, and the English was perfect. I said, No, no, no, no, no, listen, listen, listen, when I speak, I don't speak perfect 
English. I have an accent. So let's make the accent a little rougher. And so they tweaked the machine and changed 
my accent. Then I was very, very content with what I got.
Caledo, the company that built the avatar, also has a few off-the-shelf avatars and you can say, I want this one, I 
want that one. I wanted to be an Asian girl or a blonde guy, or whatever. You can choose avatars from their gallery, 
or you can do the shoot yourself, as I did.
Is the benefit, basically, that you just capture yourself with the AI once, and then you can deliver a news report, 
however often you want?
Once you pick an avatar and design a studio, then the editorial work begins. Whenever I want to broadcast a video, 
I chose a handful of articles published on our site. Then the AI breaks down the articles and builds them into script. 
They then put the words in our avatars' mouth. The article text is written by flesh and blood reporters and picking 
which article will be transformed into TV is done by us, right? The only thing the AI is doing is the technical stuff.
You're an editor of a business publication. What do you think the broader implications are here?
When we decided to do this project, there was a guy on my team we wanted to turn into an avatar. He was terrified. 
He was terrified by the fact that there's an avatar that is going to replace him, and take his job, and no one will need 
him, and we can fire him and use his avatar. I explained to him, it's not that he's disposable, on a contrary, he is a 
talent, and his face will reach far, far deeper on the web. You approached me because you recognized me from one 
of our videos, and you called me. Just imagine if they take my my avatar, and make him speak Chinese for me, or 
Japanese, or French, or Spanish. or Arabic.
But isn't there a risk though, that, the internet fills with AI slop when everybody's making these videos so easily?
When we start every show, we say this is a AI generated content, but it is a based on a human being, a creation. 
It's something new.
Are you getting an ROI on these videos?
It's a tricky question. We don't have any video platform. We're not considered a video or a TV outlet. But I can say 
that the viewing activity is going up.
How many views do you get for each of these AI videos?
It's thousands, okay, thousands of viewings. It's okay for us. It's okay at this stage. I'm not seeking much more than 
that.
Will you allow your publication to continue to use your AI avatar? Let's say it becomes very popular after you retire?
Definitely not.
Why?
Because, as I said at the beginning, this is an authentic reflection of my character, my own character. This is my 
voice. The mimics and movement is related only to me. It's singular. It's unique. I won't let anyone [use] my avatar 
without my permission, right?
So you have no desire for broadcast immortality?
No. It's better for them to use someone younger or someone much better than me.
This article is from Big Technology, a newsletter by Alex Kantrowitz.
Page 3 of 3
Meet the Editor Who Turned Himself Into an AI News Anchor
The post  Meet the Editor Who Turned Himself Into an AI News Anchor appeared first on TheWrap.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 20, 2024
End of Document
Page 1 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and 
Facebook
EveningReport.nz
September 19, 2024 Thursday 6:30 AM EST
Copyright 2024 Multimedia Investments Ltd, distributed by Contify.com All Rights Reserved
Length: 1200 words
Byline: The Conversation
Body
                                               Source: The Conversation (Au and NZ) - By Jiaru Tang, PhD student, Digital Media 
Research Centre, Queensland University of Technology
 TikTok / The Conversation
TikTok, Facebook and other social media platforms are being flooded with uncanny and bizarre content generated 
with artificial intelligence (AI), from fake videos of the US government capturing vampires to images of shrimp 
Jesus.
Given its outlandish nature and tenuous relationship with reality, you might think this so-called "AI slop" would 
quickly disappear. However, it shows no sign of abating.
In fact, our research suggests this kind of low-quality AI-generated content is becoming a lucrative venture for the 
people who make it, the platforms that host it, and even a growing industry of middlemen teaching others how to get 
in on the AI gold rush.
When generative AI meets profiteers and platforms
The short explanation for the prevalence of these baffling videos and images is that savvy creators on social media 
platforms have worked out how to use generative AI tools to earn a quick buck.
But the full story is more complex. Platforms have created incentive programs for content that goes viral, and a 
whole ecosystem of content creators has arisen using generative AI to exploit these programs.
Much of the conversation around generative AI tools focuses on how they enable ordinary people to "create". Many 
earlier digital technologies have also made it easier to participate in creative activities, such as how smartphones 
made photography ubiquitous.

Page 2 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
But generative AI takes this a step further, as it can generate tailored images or videos from a simple text prompt. It 
makes content creation more accessible - and also opens the floodgates to mass production on social media.
To take just one example: if you search "pet dance motorcycle" on TikTok, you will find hundreds of AI-generated 
videos of animals doing the "motorbike dance", all animated using the same AI template. Some accounts post 
dozens of videos like this every day.
Creators and platforms are making money
You may wonder why such repetitive, unimaginative content can go viral on TikTok. The answer lies in the 
platform's own advice to aspiring creators: if you want your videos to be promoted, you should "continuously share 
fresh and diverse content" that "doesn't require a big production budget".
You may also wonder why some platforms don't ban AI accounts for polluting the platform's content stream. Other 
platforms such as Spotify and YouTube, which police intellectual property rights more aggressively than TikTok, 
invest considerable resources to identify and remove AI-generated content.
TikTok's community guidelines do ban "inaccurate, misleading, or false content that may cause significant harm", 
but AI-generated content - at least for now - does not qualify as causing "significant harm".
Instead, this kind of content has become important for platforms. Many of those "pet dance motorcycle" videos, for 
example, have been viewed tens of millions of times. As long as users are scrolling through videos, they are getting 
exposed to the ads that are the platforms' primary source of income.
Inside the AI 'gold rush'
There is also a growing industry of people teaching others how to make money using cheap AI content.
Take Xiaonan, a social media entrepreneur we interviewed who runs six different TikTok accounts, each with more 
than 100,000 followers. As he revealed in a live-streaming tutorial with more than 1,000 viewers, Xiaonan earned 
more than US$5,500 from TikTok in July alone.
Xiaonan also hosts an exclusive chatting group where, for a fee, he reveals his most effective AI prompts, video 
headlines and hashtags tailored for different platforms including YouTube and Instagram. Xiaonan also reveals 
tricks for standing out in the platforms' recommendation game and avoiding platform regulations.
Xiaonan says he established his "AI side job" after being laid off by an internet company. He now works with two 
partners selling classes and tutorials on making AI-generated videos and other types of spam for profit.
Creators posting AI content may not be the kind of people we expect. As Xiaonan told us, many of the people 
taking his AI tutorial - entitled "Side job, self-employed, high-paid" - are housewives, unemployed people and 
college students.
"Some of us also do Uber driving or street vending," one creator told us. AI-generated content has become the 
latest trend for earning side income.
The rise of AI has coincided with global unemployment trends and the growth of the gig economy in the post-
pandemic era.
Making AI-generated content is more pleasant work than driving passengers or delivering food, according to a 
creator who is also a stay-at-home mother. It's easy to learn, almost zero cost, and can be done any time at home 
with just a phone.
As Xiaonan says, his method is to use AI to "earn from productivity gap" - that is, by producing far more content 
than people who don't use AI .
Page 3 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
The global AI-generated content factory
Our observations indicate many of these creators are from non-Western countries, such as India, Vietnam and 
China.
As one Chinese social media influencer told us:
China's short video market is nearing saturation, which means you need to seek data traffic [viewers] on overseas 
platforms.
For these entrepreneurs, AI is the secret sauce not only for creating viral content but also for circulating already-
viral videos across different countries and platforms.
An effective strategy mentioned by one creator is a kind of platform arbitrage involving popular videos from Douyin, 
the counterpart of TikTok in mainland China.
A creator will take one of these videos, add AI-generated translation, and post the result on TikTok. Despite clunky 
AI dubbing and error-riddled subtitles, many of these videos garner hundreds of thousands or even millions of 
views.
Creators often mute the original video and add AI-generated narration, translating the content into various 
languages, including French, Spanish, Portuguese, Indonesian and Swedish. These creators often manage several 
or even dozens of accounts, targeting viewers in different countries in a strategy known as an "account matrix".
This is only the beginning
We are only at the dawn of mainstream AI-generated content culture. We will soon face a situation in which content 
is effectively infinite, but human attention is still limited.
For platforms, the challenge will be balancing the engagement these AI-driven trends bring with the need to 
maintain trust and authenticity.
Social media platforms will soon respond. But before that, AI-generated content will continue to grow wildly - at 
least for a while.
Patrik Wikstrm receives funding from the Australian Research Council. 
Jiaru Tang does not work for, consult, own shares in or receive funding from any company or organisation that 
would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.
- ref. 'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook - 
https://theconversation.com/side-job-self-employed-high-paid-behind-the-ai-slop-flooding-tiktok-and-facebook-
237638
Load-Date: September 19, 2024
End of Document
Page 1 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and 
Facebook
The Conversation - Australia
September 19, 2024 Thursday 1:42 AM EST
Copyright 2024 The Conversation Media Group Ltd All Rights Reserved
Length: 1133 words
Byline: Jiaru Tang, PhD student, Digital Media Research Centre, Queensland University of Technology
Highlight: In places like India, Vietnam and China, churning out weird AI videos is the latest side hustle for 
students and stay-at-home mothers.
Body
TikTok, Facebook and other social media platforms are being flooded with uncanny and bizarre content generated 
with artificial intelligence (AI), from fake videos of the US government capturing vampires to images of shrimp 
Jesus. 
Given its outlandish nature and tenuous relationship with reality, you might think this so-called "AI slop" would 
quickly disappear. However, it shows no sign of abating. 
In fact, our research suggests this kind of low-quality AI-generated content is becoming a lucrative venture for the 
people who make it, the platforms that host it, and even a growing industry of middlemen teaching others how to get 
in on the AI gold rush. 
When generative AI meets profiteers and platforms
The short explanation for the prevalence of these baffling videos and images is that savvy creators on social media 
platforms have worked out how to use generative AI tools to earn a quick buck. 
But the full story is more complex. Platforms have created incentive programs for content that goes viral, and a 
whole ecosystem of content creators has arisen using generative AI to exploit these programs.
Much of the conversation around generative AI tools focuses on how they enable ordinary people to "create". Many 
earlier digital technologies have also made it easier to participate in creative activities, such as how smartphones 
made photography ubiquitous. 
But generative AI takes this a step further, as it can generate tailored images or videos from a simple text prompt. It 
makes content creation more accessible - and also opens the floodgates to mass production on social media. 

Page 2 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
To take just one example: if you search "pet dance motorcycle" on TikTok, you will find hundreds of AI-generated 
videos of animals doing the "motorbike dance", all animated using the same AI template. Some accounts post 
dozens of videos like this every day.
Creators and platforms are making money
You may wonder why such repetitive, unimaginative content can go viral on TikTok. The answer lies in the 
platform's own advice to aspiring creators: if you want your videos to be promoted, you should "continuously share 
fresh and diverse content" that "doesn't require a big production budget".
You may also wonder why some platforms don't ban AI accounts for polluting the platform's content stream. Other 
platforms such as Spotify and YouTube, which police intellectual property rights more aggressively than TikTok, 
invest considerable resources to identify and remove AI-generated content. 
TikTok's community guidelines do ban "inaccurate, misleading, or false content that may cause significant harm", 
but AI-generated content - at least for now - does not qualify as causing "significant harm". 
Instead, this kind of content has become important for platforms. Many of those "pet dance motorcycle" videos, for 
example, have been viewed tens of millions of times. As long as users are scrolling through videos, they are getting 
exposed to the ads that are the platforms' primary source of income.
Inside the AI 'gold rush'
There is also a growing industry of people teaching others how to make money using cheap AI content. 
Take Xiaonan, a social media entrepreneur we interviewed who runs six different TikTok accounts, each with more 
than 100,000 followers. As he revealed in a live-streaming tutorial with more than 1,000 viewers, Xiaonan earned 
more than US$5,500 from TikTok in July alone. 
Xiaonan also hosts an exclusive chatting group where, for a fee, he reveals his most effective AI prompts, video 
headlines and hashtags tailored for different platforms including YouTube and Instagram. Xiaonan also reveals 
tricks for standing out in the platforms' recommendation game and avoiding platform regulations.
Xiaonan says he established his "AI side job" after being laid off by an internet company. He now works with two 
partners selling classes and tutorials on making AI-generated videos and other types of spam for profit.
Creators posting AI content may not be the kind of people we expect. As Xiaonan told us, many of the people 
taking his AI tutorial - entitled "Side job, self-employed, high-paid" - are housewives, unemployed people and 
college students. 
"Some of us also do Uber driving or street vending," one creator told us. AI-generated content has become the 
latest trend for earning side income.
The rise of AI has coincided with global unemployment trends and the growth of the gig economy in the post-
pandemic era. 
Making AI-generated content is more pleasant work than driving passengers or delivering food, according to a 
creator who is also a stay-at-home mother. It's easy to learn, almost zero cost, and can be done any time at home 
with just a phone. 
As Xiaonan says, his method is to use AI to "earn from productivity gap" - that is, by producing far more content 
than people who don't use AI .
The global AI-generated content factory
Page 3 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
Our observations indicate many of these creators are from non-Western countries, such as India, Vietnam and 
China. 
As one Chinese social media influencer told us:
China's short video market is nearing saturation, which means you need to seek data traffic [viewers] on overseas 
platforms.
For these entrepreneurs, AI is the secret sauce not only for creating viral content but also for circulating already-
viral videos across different countries and platforms. 
An effective strategy mentioned by one creator is a kind of platform arbitrage involving popular videos from Douyin, 
the counterpart of TikTok in mainland China. 
A creator will take one of these videos, add AI-generated translation, and post the result on TikTok. Despite clunky 
AI dubbing and error-riddled subtitles, many of these videos garner hundreds of thousands or even millions of 
views. 
Creators often mute the original video and add AI-generated narration, translating the content into various 
languages, including French, Spanish, Portuguese, Indonesian and Swedish. These creators often manage several 
or even dozens of accounts, targeting viewers in different countries in a strategy known as an "account matrix".
This is only the beginning
We are only at the dawn of mainstream AI-generated content culture. We will soon face a situation in which content 
is effectively infinite, but human attention is still limited.
For platforms, the challenge will be balancing the engagement these AI-driven trends bring with the need to 
maintain trust and authenticity.
Social media platforms will soon respond. But before that, AI-generated content will continue to grow wildly - at 
least for a while.
Patrik Wikström receives funding from the Australian Research Council.
Jiaru Tang does not work for, consult, own shares in or receive funding from any company or organisation 
that would benefit from this article, and has disclosed no relevant affiliations beyond their academic 
appointment.
Load-Date: September 18, 2024
End of Document
Page 1 of 3
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok 
And Facebook
MENAFN - Business & Finance News (English)
September 18, 2024 Wednesday
Copyright 2024 MENAFN.COM All Rights Reserved
Length: 1070 words
Body
Link to Image
Link to Story
TikTok, Facebook and other social media platforms are being flooded with uncanny and bizarre content generated 
with artificial intelligence (AI), from fake videos of the US government capturing vampires to images of shrimp Jesus 
. Given its outlandish nature and tenuous relationship with reality, you might think this so-called"AI slop" would 
quickly disappear. However, it shows no sign of abating.
In fact, our research suggests this kind of low-quality AI-generated content is becoming a lucrative venture for the 
people who make it, the platforms that host it, and even a growing industry of middlemen teaching others how to get 
in on the AI gold rush.
When generative AI meets profiteers and platformsThe short explanation for the prevalence of these baffling videos 
and images is that savvy creators on social media platforms have worked out how to use generative AI tools to earn 
a quick buck.
But the full story is more complex. Platforms have created incentive programs for content that goes viral, and a 
whole ecosystem of content creators has arisen using generative AI to exploit these programs.
Much of the conversation around generative AI tools focuses on how they enable ordinary people to"create". Many 
earlier digital technologies have also made it easier to participate in creative activities, such as how smartphones 
made photography ubiquitous.
But generative AI takes this a step further, as it can generate tailored images or videos from a simple text prompt. It 
makes content creation more accessible - and also opens the floodgates to mass production on social media.

Page 2 of 3
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook
To take just one example: if you search"pet dance motorcycle" on TikTok, you will find hundreds of AI-generated 
videos of animals doing the"motorbike dance", all animated using the same AI template. Some accounts post 
dozens of videos like this every day.
Creators and platforms are making moneyYou may wonder why such repetitive, unimaginative content can go viral 
on TikTok. The answer lies in the platform's own advice to aspiring creators: if you want your videos to be 
promoted, you should"continuously share fresh and diverse content" that"doesn't require a big production budget".
You may also wonder why some platforms don't ban AI accounts for polluting the platform's content stream. Other 
platforms such as Spotify and YouTube, which police intellectual property rights more aggressively than TikTok, 
invest considerable resources to identify and remove AI-generated content .
TikTok's community guidelines do ban"inaccurate, misleading, or false content that may cause significant harm", 
but AI-generated content - at least for now - does not qualify as causing"significant harm".
Instead, this kind of content has become important for platforms. Many of those"pet dance motorcycle" videos, for 
example, have been viewed tens of millions of times. As long as users are scrolling through videos, they are getting 
exposed to the ads that are the platforms' primary source of income.
Inside the AI 'gold rush'There is also a growing industry of people teaching others how to make money using cheap 
AI content.
Take Xiaonan, a social media entrepreneur we interviewed who runs six different TikTok accounts, each with more 
than 100,000 followers. As he revealed in a live-streaming tutorial with more than 1,000 viewers, Xiaonan earned 
more than US$5,500 from TikTok in July alone.
Xiaonan also hosts an exclusive chatting group where, for a fee, he reveals his most effective AI prompts, video 
headlines and hashtags tailored for different platforms including YouTube and Instagram. Xiaonan also reveals 
tricks for standing out in the platforms' recommendation game and avoiding platform regulations.
Xiaonan says he established his"AI side job" after being laid off by an internet company. He now works with two 
partners selling classes and tutorials on making AI-generated videos and other types of spam for profit.
Creators posting AI content may not be the kind of people we expect. As Xiaonan told us, many of the people 
taking his AI tutorial - entitled"Side job, self-employed, high-paid" - are housewives, unemployed people and college 
students.
"Some of us also do Uber driving or street vending," one creator told us. AI-generated content has become the 
latest trend for earning side income.
The rise of AI has coincided with global unemployment trends and the growth of the gig economy in the post-
pandemic era.
Making AI-generated content is more pleasant work than driving passengers or delivering food, according to a 
creator who is also a stay-at-home mother. It's easy to learn, almost zero cost, and can be done any time at home 
with just a phone.
As Xiaonan says, his method is to use AI to"earn from productivity gap" - that is, by producing far more content than 
people who don't use AI .
The global AI-generated content factoryOur observations indicate many of these creators are from non-Western 
countries, such as India, Vietnam and China.
As one Chinese social media influencer told us:
For these entrepreneurs, AI is the secret sauce not only for creating viral content but also for circulating already-
viral videos across different countries and platforms.
An effective strategy mentioned by one creator is a kind of platform arbitrage involving popular videos from Douyin, 
the counterpart of TikTok in mainland China.
Page 3 of 3
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook
A creator will take one of these videos, add AI-generated translation, and post the result on TikTok. Despite clunky 
AI dubbing and error-riddled subtitles, many of these videos garner hundreds of thousands or even millions of 
views.
Creators often mute the original video and add AI-generated narration, translating the content into various 
languages, including French, Spanish, Portuguese, Indonesian and Swedish. These creators often manage several 
or even dozens of accounts, targeting viewers in different countries in a strategy known as an"account matrix".
This is only the beginningWe are only at the dawn of mainstream AI-generated content culture. We will soon face a 
situation in which content is effectively infinite, but human attention is still limited.
For platforms, the challenge will be balancing the engagement these AI-driven trends bring with the need to 
maintain trust and authenticity.
Social media platforms will soon respond. But before that, AI-generated content will continue to grow wildly - at 
least for a while.
MENAFN18092024000199003603ID1108690518
Load-Date: March 5, 2025
End of Document
Page 1 of 2
BBC Radio 4 - 4:50 PM GMT
BBC Radio 4 - 4:50 PM GMT
TVEyes - BBC Radio 4
September 16, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 820 words
Body
Speech to text transcript:1
should or shouldn't go ahead. This is almost like a last ditch effort to save or to back this project, each of them 
being given 5 min to speak and then taking questions from members of the national Park Authority and then moving 
on to the next speaker. So we've heard all of those 5 people who were speaking in favor of the development. there 
were originally 8 now 6 people speaking against it, and then after that, the National Park Authority Board will ponder 
their final decision on whether or not to give it planning permission in principle, which is what the developer is 
seeking. 
Some say, whatever the decision, we do take an awfully long time in this country to make the decision. How long 
have these arguments been going on? When did it all art? Well, it has been going on since about 2016, but that 
was a previous plan that was then withdrawn and resubmitted at a late stage, so that stage so that latest one has 
been going on since twenty-nine. So it is 5 years that this has been going on, and there's been a huge amount of 
work going on by the National Park Board in terms of trying to determine whether or not it should be given the go 
ahead. They produced a document a couple of weeks ago that was a hundred-deg pages long that recommended it 
for refusal, although the Board aren't obliged to stick by that recommendation. So a huge amount of effort has gone 
into it, and yet in this meeting today there still seemed to be some unanswered questions that the officials couldn't 
answer and that the representatives of Flamingo land didn't seem to be able to answer. So it has taken a long time 
to come to this. Whatever the decision is today, it's not necessary by the end of it, because it could go to appeal, it 
could go to the Scottish Government for a further determination. It could go on for several more years yet. Okay, 
Kevin, thanks for that, Kevin King. Earlier we heard an example of how talented AI has become at composing music 
from scratch we heard an example of a PM theme tune written while we were on air by an AI app I'll just remind you 
of. I think it's quite good and in fact I've made another one here's another one it a bit more upbeat if you want 
something to compare those to. Some listeners with long memories have been in touch, which was the actual PM 
theme tune. This is not a I this date back to 19 its pm at 5 0 p.m. The Sights and by formats program hasn't 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 4:50 PM GMT
changed a bit. Has it not changed a bit? Our current editor hates all theme tunes. P. P. M. Well, look what I 
produced on AI is not gonna win a Mercury Prize, but hey, look, just turn that out in minutes and we've been 
wondering what the i? Ations are for the World of music, for those producing it and those consuming it. Technology 
Writer Kate Bevan is still with me in the studio, also joined down the line by Tom Keel, chief executive of UK Music. 
Tom. I've just been taken aback because we had a letter from a listener who pointed out to me what it was doing 
and what what do you think of what AI is doing? Well, the UK music industry is worth 7 billion to the economy and 
that forms part of the wider create industries, which are worth almost 100 billion to the economy, and that is actually 
powered very much by economic rights like copyright, which is really important to creators. So in terms of actually 
AI, there's a very strong role in terms of the assisted element to it. The craters can can actually hold and now and 
nurture their craft. However, there are some substantial challenges about what we consider to be generative AI 
that's kind of making new pieces of music actually out of other pieces of music through the large language models, 
and that's actually a great concern, because it's it's we don't have any transparency about in terms of actually music 
being put into the? Is your basic your basic content? Sorry, your basic sorry to interrupt. Your basic contention is 
that what I produced on AI is really picking up on what other people have produced and then not be paid for if I do it 
with the AI? In a sense, yes, yes, essentially that's the crazy issue. Yeah, Kate, I'm wondering about. You know, 
you take a streaming app like Spotify. I don't know how crowded their servers are, but they could just be up loaded 
with with volumes, orders of magnitude, more mediocre music turned out by by these kind of programs. Right, yeah, 
they absolutely could, and I think one of the issues around AI, particularly as time goes on, is that there's so much 
AI generated slop out there. It's it's getting into the system and it's getting harder actually for people to differentiate 
between a generator stuff which has absolutely nos fact checking inherent in it, and what's real, and that's not just a 
problem for music. Yeah, I mean it may be a problem for music. If I,
Load-Date: September 16, 2024
End of Document
Page 1 of 2
Trump is drowning in the misinformation swamp he helped create
Trump is drowning in the misinformation swamp he helped create
CNN Wire
September 12, 2024 Thursday 10:00 AM GMT
Copyright 2024 Cable News Network All Rights Reserved
Length: 756 words
Byline: Analysis by Allison Morrow, CNN
Dateline: (CNN) 
Body
             New York (CNN) - The Republican nominee for president went on live TV and presented an unhinged, 
debunked Facebook rumor as fact. When corrected (several times) by a moderator, Donald Trump doubled down: 
"The people on television say their dog was eaten by the people that went there."
"They're eating the dogs," quickly became a punchline among commentators who understand that the whole story 
about Haitian immigrants eating people's pets in Ohio was a lie, rooted in a well-established racist history.
It's the kind of outrage-bait that, while disgusting, is hardly unexpected on Facebook these days.
But the claim's elevation to the presidential debate stage underscores a grim reality about the internet in 2024: 
Misinformation is everywhere, platforms are giving up on moderation and AI is making it all worse.
Trump's debate performance "was like a 4chan post come to life," said CNN's Jake Tapper.
It's an apt analogy.
4chan, once an innocuous online message board for anime enthusiasts in the early 2000s, is a prime example of 
what happens when you remove the guardrails from a social media site, with only a handful of community members 
regulating it. Over the years, 4chan has become a cesspool of violence, conspiracy theories and its own particular 
brand of "edgelord white supremacy," as the Verge put it.
Scrolling on Facebook or X, it's hard not to see some of that chaos creeping into the mainstream.
As my colleague Clare Duffy wrote last week, Facebook spam is surging, and, in extreme cases, it is being 
weaponized to scam and mislead people - a shift that coincides with an intentional strategy by the platform to 
downplay news and politics while amplifying vapid, computer-generated content into users' feeds.
Over on X, which Elon Musk acquired in 2022 and promptly gutted its moderation efforts, hate speech and violent 
threats are now fair game.

Page 2 of 2
Trump is drowning in the misinformation swamp he helped create
A spokesperson for Meta, Facebook's parent company, said last week that it works "to remove and reduce the 
spread of spammy content to ensure a positive user experience" and "take action against those who attempt to 
manipulate traffic through inauthentic engagement."
Musk, who fired Twitter's communications staff when he took over the platform, didn't respond to a request for 
comment.
To be sure, there's always been gross and fake stuff on social media. The difference now is how quickly it morphs 
into misinformation, often fueled by human-like AI text and images, with fewer staff dedicated to monitoring and 
taking down fake information. Once upon a time, you had to go through a process, overseen by human moderators, 
to get a "verified" check mark on Twitter; now, anyone with or without an agenda to push can simply buy it.
In some ways, Trump's political career tracks the rise and deterioration of social media over the past decade. The 
former reality star made his name in politics in part by exploiting social media's power to broadcast lies and 
conspiracy theories to the masses, starting with his racist "birther" attacks on President Barack Obama.
With Tuesday night's foray into the pet-eating lie, he may have finally veered so deep into the internet muck he can't 
see through it.
Just a few weeks ago, the former president posted an AI-generated image on his Truth Social platform that 
suggested Taylor Swift had endorsed him. "I accept," he wrote in the post.
Of course, it was a fake image - the same kind of obvious AI slop that has overrun Facebook and X. Either Trump 
didn't know the image was fake, or he didn't mind lying to his followers and perpetuating the fake endorsement.
Neither scenario suggests he's too concerned about the problem of misinformation online.
Taylor Swift, for her part, is concerned. In endorsing Vice President Kamala Harris on Tuesday, Swift wrote that the 
incident with the fake images of her "conjured up my fears around AI, and the dangers of spreading 
misinformation."
She signed off on the post by calling herself a "childless cat lady" - a nod to widely ridiculed comments from 
Trump's running mate, JD Vance.
As if on cue, Musk, the pro-Trump multibillionaire who also shared the fake pet-eating story on X this week, chimed 
in to remind everyone that you can say whatever you want on his platform, no matter how vile or threatening to a 
woman who's never publicly acknowledged him.
"Fine Taylor ... you win ... I will give you a child and guard your cats with my life."         
             Analysis by Allison Morrow, CNN         
TM & © 2024 Cable News Network, Inc., a Time Warner Company. All rights reserved.
Load-Date: September 12, 2024
End of Document
Page 1 of 2
BBC London News - 5:45 PM GMT
BBC London News - 5:45 PM GMT
TVEyes - BBC 1 West Midlands
September 12, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. REGIONAL TV; News
Length: 829 words
Highlight: The latest news, sport and weather from London.
Body
Speech to text transcript:1
in the creative industries just yet. We value human creativity way too much for that, and I think that there are some 
interesting spaces where it can move into to assist creatives in their work. There are some spaces where it might it 
may well do take over and people may lose their jobs, and that's unfortunate. These are spaces where we need to 
actually look at, OK, well, what is the value of the humans that are doing the creating?
 AI can't really replace individual craftsmanship, can it? No, no it can't. All it can do is really regurgitate stuff that it's 
seen before. There's a common word being used at the moment called slop with regard to AI output, generative AI 
output. And that, I think is a really good way of describing what happens. It takes a lot of people's input, and these 
are people, creative people's prior art, and it's whacks it all together and makes it into a big stew and spits 
something out that's kind of essentially mass produced at the other end. A lot of people watching might be quite 
frightened, almost, of AI and what it might be able to do. Do you think that's just through a lack of understanding of 
what it is and what it can do? Well, I think people are very right to be a little bit afraid of it. It's partly because there's 
a lot of hype around AI at the moment, and a lot of companies, a lot of industry, a lot of the governments are buying 
into the hype. And the hype really basically says that generative AI can do a lot of things that it can't actually do. 
And what I worry about as an ethicist is that is when companies especially buy into the hype, they might decide that 
the human is worth replacing with an AI system, for example. But over time we will see that actually the human was 
never replaceable by the AI system because the AI system could never innovate. Be creative. Think outside the 
box like humans can. And so I think there's, they're right to be a little bit afraid, especially if they're in the sort of job 
that might be automated like this. It's healthy to have a good amount of scepticism and to push back against these 
kinds of technologies, especially when they aren't going to deliver what their what their creators say they're going to 
deliver. It's an interesting subject. Catherine Flick, thank you. Good to have you with us here on Midlands Today, be 
warned, this cool spell isn't over yet. Also still to come. A dream come true for a Staffordshire dance group. The 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC London News - 5:45 PM GMT
young people who put on a performance in Disneyland. Do you know your woppered from your flittermice? One 
woman's mission to bring Gloucestershire dialect back into use. A 23-year-old event rider from Malvern, who broke 
her back in a fall at an equestrian event, has praised the NHS staff involved in her ongoing care. Saffron Cresswell 
was paralysed from the chest down, after falling from her horse in June in Yorkshire. The international rider 
underwent surgery and was then moved to a spinal injuries unit in Wakefield. Jamie Coulson reports. I had such a 
path in my life that I was ready to take, aiming for the Olympics in the future, in my sport, and you know, to have 
that taken away from you, at a young age as well, you know, is a massive thing that people don't ever wish to 
experience ever, and no-one could ever anticipate it in their lives. In June, Saffron Cresswell suffered a spinal cord 
injury, and was paralysed from the chest down, after an accident at the Bramham horse trials. The 23-year-old was 
competing in the cross-country phase of the under 25s National Eventing Championship, when she fell off her 
horse. Obviously there is a feeling of why me, why it happen to me, what did I do wrong? It is so easy to fall into 
that almost trap of feeling about what happened and why did it happen? But there isn't an answer, you can never 
know an answer, you have to try and look forward, and it's OK, this is my life now, let's see what I can do to sort of 
change it and turn it around. Hi. Hello Saffron, good morning. Following surgery in Leeds, she was moved to the 
regional spinal injuries centre at Pinderfield's Hospital in Wakefield. Spinal cord injury is a life-changing injury. It 
really affects every system in the body, so once they have had a spinal cord injury, their life completely changes. 
They have to learn literally everything, from being able to do their basic activities of daily living to going out into the 
community, it is really the start of a new life. When you have been here so long you sort of end up moving in and 
making it feel a bit home. You get to know the staff so well, you get to know the consultants so well and it is a 
massive part of your rehab, building a sort of family on the ward. Get your chin over the bar. The 34 bed centre has 
dedicated rehabilitation facilities, including a gymnasium, hydrotherapy pool, sports hall and communal area.
Load-Date: September 12, 2024
End of Document
Page 1 of 3
What I Learned When My AI Kermit Slop Went Viral
What I Learned When My AI Kermit Slop Went Viral
Atlantic Online
September 9, 2024 Monday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1491 words
Byline: Damon Beres
Body
First, I want to apologize. My Kermit the Frog post was not entirely sincere.
This particular post of mine has been viewed more than 10 million times, which is far more than I expected. But I did 
expect something. Social networks have never been the realm of good faith or authenticity; trolls and other 
engagement baiters have been able to engineer their own virality for years and years, simply by correctly predicting 
what large numbers of people will respond to. Donald Trump's TikToks don't happen by accident; nor did Kamala 
Harris's embrace of "brain rot" videos. Each campaign is constructing media that it believes can travel in algorithmic 
feeds. That's also what I did when I put together my post, which featured a couple dozen AI-generated images of 
Kermit the Frog.
Allow me to explain. Last weekend-delirious from a lack of sleep and hoping that my screaming toddler would soon 
settle down in his crib-I was tapping around on my phone in a kind of fried stupor. My mind struggled to latch on to 
anything. Each of the apps on my home screen seemed to promise only more boredom. I was the sort of trapped 
that many parents of young children might recognize: A demand for attention could come at any moment, so I 
couldn't lose myself in a book or a bike ride. But I was looking for a diversion.
[Read: What did people do before smartphones?]  
Then I had an idea. I decided that it would be fun to use Bing Image Creator, based on OpenAI's DALL-E 
technology, to help me replace each app icon on my iPhone's home screen with a thematically appropriate image of 
the world's greatest muppet. (Why? You'd have to ask my psychiatrist.) Instead of the basic Gmail icon, I contrived 
an image of Kermit buried under a massive pile of envelopes. Instead of the basic green phone icon, Kerm chatting 
on a yellow landline.
The final product was an absurd, borderline-deranged home-screen grid of 24 bespoke frogs. The creation of each 
one required a series of specific prompts from me. There was Calculator Kermit and Photos Kermit. Authenticator 
Kermit was dressed like a police officer and wielded a massive baton. My job complete, I took a screenshot and 
sent it to a friend, who replied, "Damon I truly truly fear for you." About halfway through the project, I had developed 

Page 2 of 3
What I Learned When My AI Kermit Slop Went Viral
an inkling that her message seemed to confirm: People on the internet would probably respond to this. I could use 
my Kermits to go viral.
Everyone loves Kermit, of course, and that could only help me. But just as important was the fact that I had made 
the images using generative AI, a hyper-polarizing technology with passionate boosters and passionate critics. My 
content would have to appeal to both groups in order to go as far as possible. So I tried to walk a middle path. I 
typed an ambiguously worded post that nonetheless contained a sharp opinion that people could react t "People will 
be like, ~generative AI has no practical use case,' but I did just use it to replace every app icon on my home screen 
with images of Kermit, soooo." Then I embedded the before and after images of my home screen, and published 
simultaneously on X and Threads.
The reactions were swift, and they haven't stopped. A lot of people just love the images. Others have accused me 
of destroying the environment, thanks to generative AI's water and energy use. (I suppose I'm guilty on that count; 
alas, every online action takes its toll.) Quite a few people have criticized me for leeching off Disney's intellectual 
property. (Another fair knock, given that generative AI is trained on tons of copyrighted material.) Some seem to 
view me as a tech bro or 4chan creep, perhaps because for the YouTube app, I had generated an image of Kermit 
watching Pepe the Frog-I meant it as a reference to the purportedly radicalizing content that the site has hosted, not 
as an endorsement of the symbol.
And many people have posted that I played myself, allowing the AI to do the "fun," imaginative stuff while I took on 
the rote task of changing the app icons. Those people are wrong: Writing the prompts, looking at the outputs, and 
adjusting my asks in response was like playing with atoy. By contrast, one person attempted towrite a program that 
would automate every step of the process I had undertaken. Although arguably impressive on its own merits, it 
appeared to produce bland, interchangeable, witless icons. No fun.
The truth is that the AI didn't just do everything for me. I came up with little details that some people delighted in (a 
blond-wigged Kermit snapping a selfie for the Instagram icon, Kermit climbing out of a filthy sewer for X), I tweaked 
and iterated on the prompts until the outputs were right, and I selected the options I thought looked the best. Even 
the images that some took as evidence of the uselessness of generative AI (an icon for The Washington Post app 
bearing the nonsensical headline "NEW HASPELES"; a calendar icon showing the month "EOMER") were chosen 
on purpose. It seemed funny and appropriate to include art with some glitches, given AI'swell-documented 
problems, though avoiding them would have been easy. (For the Atlantic app, of course, I made sure to choose an 
output with the correct spelling.)
[Read: Generative art is stupid]
That's not to say that I believe what I did was creative, exactly. The feeling reminded me a bit of editing a talented 
writer (albeit a nonhuman plagiarist in this case): I gave direction and received something in response, but the 
fundamental essence of the work did not emerge from my mind. As in working with a person, there was room for 
surprise-when the image generator took it upon itself, for example, to add a pair of breasts to Kermit for the 
Instagram icon. (I promise I did not ask for them.) You can nudge the program in one direction or another, but every 
press of the "Create" button is a bit like pulling a slot machine.
This is one reason generative AI is such an ideal match for the social-media era. These programs are now nested 
within X, Facebook, Instagram, and Snapchat-apps that are defined not just by endless scrolling but by the 
downward tug from the top of your screen to refresh and get something new. AI images are a confection just like 
the other algorithmically served junk people now spend so much time consuming. Having a home screen filled with 
Kermits isn't actually practical. The effort was entirely about entertaining myself and getting engagement, not 
remaking how I actually navigate my phone. (I reverted to the default app icons almost immediately, because the 
Kermits all blurred together and made the device harder to use.) It's no wonder that social-media companies are 
pushing generative AI; the technology feels like it offers both a way to melt time and a shortcut to the kind of 
numbers-go-up posting that makes these networks so compulsively usable. As my colleague Charlie Warzel wrote 
last month, that plug-and-play quality has given generative-AI images a certain utility for the MAGA set, who 
routinely embrace outrageous falsehoods for political gain. They can now illustrate and post in seconds whatever 
Page 3 of 3
What I Learned When My AI Kermit Slop Went Viral
meme they're using to rally the base on a given day. Likewise, spammers have found that it pays to flood Facebook 
with attention-grabbing AI slop.
So here is a use for generative AI: It is lubricant for broken algorithmic machinery. Pour it into a social network, and 
if you've done the alchemy right, the gears will turn and turn. This is the internet's synthetic maximalist moment, 
where fake content leads easily to superficial interaction. I soon started to notice that many of the typed responses 
to my post seemed to be following a script, that they were sent from anonymous accounts that barely followed (or 
were followed by) anyone at all. I'm certain that many were bots, interacting with a JPEG file that had also been 
made by one-albeit with my mischievous prompting.
The informational environment has become hopelessly junked up, and the way it works can be dispiriting to even 
the most cynical of the extremely online. But I have to admit that watching my Kermit post go viral was, dare I say, 
fun. I'm sure many of the actual people who responded to me felt it too. I was amused. Perhaps when we look back 
on the generative-AI revolution, we'll realize that chasing this feeling is the ultimate reason for many of these 
programs-especially as they enter social apps that are designed to prioritize engagement.
 We're a long way from Amusing Ourselves to Death, Neil Postman's famous 1985 book, which argued that 
television would lead the public to privilege spectacle over substance. But it's clear that Postman saw around the 
right corner. Many prognosticators have said quite a lot about AI's existential risks, that the technology could be 
used to construct bioweapons and God knows what else. In the meantime, aided by other sophisticated machines-
and, sometimes, an exhausted parent on an iPhone-it's a grade-A brain softener. Use with caution.
Load-Date: September 10, 2024
End of Document
Page 1 of 3
University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List
University of Chicago: Prof. Ben Zhao Named to TIME Magazine's TIME100 
AI List
Targeted News Service
September 7, 2024 Saturday 4:17 PM  EST
Copyright 2024 Targeted News Service LLC All Rights Reserved
Length: 774 words
Byline: Targeted News Service
Dateline: CHICAGO, Illinois 
Body
(TNSres) -- The University of Chicago issued the following news:
* * *
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
* * *
TIME magazine announced Sept. 5 that it has named Ben Zhao, the University of Chicago Neubauer Professor of 
Computer Science, to its TIME100 AI list.
The TIME100 AI list celebrates individuals who are shaping the future of AI, a technology that continues to 
revolutionize industries. As TIME highlights, the rapid growth of AI is driven not just by the technology itself, but by 
the people behind it--those who make critical decisions about its development, safety, and application.
Zhao's recognition on this list highlights his significant contributions and leadership, particularly in the areas of 
adversarial machine learning and security--a field that explores how machine learning models can be manipulated 
and how to defend against such attacks.
He is particularly known in the field for protective tools to mitigate harms of AI, including tools like Nightshade and 
Glaze, which artists can apply to their works to protect them from being scraped and used without consent to train 
AI models.
Innovation and impact
Zhao's research has spanned a broad range of areas, including networking, human-computer interaction, and 
security and privacy. Since 2016, he has focused on addressing security and privacy challenges in machine 

Page 2 of 3
University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List
learning and mobile systems. Most recently, his work has centered on adversarial machine learning and developing 
tools to protect human creatives from the potential harms of generative AI models.
"My experiences across different areas (but especially in human-computer interaction) has taught me the value of 
engaging with users to truly understand how research and technology impacts real people," said Zhao. "As a result, 
I am always drawn to research challenges that impact large groups of people, and projects that address those 
challenges by taking into account perspectives of the users most directly impacted."
He is particularly known in the field for tools to mitigate harms of AI. This line of work began in 2020, with Fawkes, 
an image cloaking tool designed to prevent third parties from building unauthorized facial recognition models of 
individuals based on public photos online.
Zhao's team also developed Nightshade, which proactively protects content copyright of visual artwork by making 
them toxic to AI models that train on them without consent, and Glaze, which protects individual artists against style 
mimicry.
These programs make changes to an image that are nearly imperceptible to the human eye, but significantly 
change what the AI "sees."
Since its release in January 2024, Nightshade has been downloaded nearly a million times.
As AI continues to evolve at a breakneck pace, the insights and innovations of leaders like Zhao will play a crucial 
role in shaping the technology's future.
"The recent rush towards generative AI has been spurred on by an aura of inevitability, promises of societal 
benefits, and massive profits," Zhao warned. "While many of these have yet to materialize, harms like copyright 
violation, proliferation of AI slop and deepfakes, and disruption to creative sectors are here today. These are the 
harms our lab works to mitigate through our research."
Zhao is an ACM Fellow and a recipient of the NSF CAREER award, the Internet Defense Prize, and MIT 
Technology Review's TR-35 Award, among others. His work has been featured in prominent media outlets such as 
the New York Times, Scientific American, NBC, CNN, BBC, and the Wall Street Journal, underscoring the broader 
societal impact of his research.
In addition to his research, Zhao is deeply involved in the academic community. He serves on technical program 
committees for top conferences in computer security (ACM CCS, IEEE Security & Privacy) and machine learning 
(NeurIPS). At University of Chicago, he co-directs the Security, Algorithms, Networking, and Data (SAND) Lab at 
UChicago alongside Neubauer Professor Heather Zheng and serves as the Director of Graduate Studies for the 
Department of Computer Science.
"I'm humbled by this recognition, and proud to share it with my long-term collaborator Prof. Heather Zheng, our 
wonderful students, and the many human artists, writers and other creatives working with us to build a future 
ecosystem where human creativity is valued more than technology," Zhao said.
- Adapted from an article first published by the Department of Computer Science.
* * *
Original text here: https://news.uchicago.edu/story/prof-ben-zhao-named-time-magazines-time100-ai-list
Copyright Targeted News Services
MSTRUCK-8805480 MSTRUCK
Load-Date: September 8, 2024
Page 3 of 3
University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List
End of Document
Page 1 of 2
PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST
PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST
States News Service
September 6, 2024 Friday
Copyright 2024 States News Service
Length: 738 words
Byline: States News Service
Dateline: CHICAGO, Illinois 
Body
The following information was released by the University of Chicago:
By Miranda Redenbaugh
Sep 6, 2024
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
TIME magazine announced Sept. 5 that it has named Ben Zhao, the University of Chicago Neubauer Professor of 
Computer Science, to its TIME100 AI list.
The TIME100 AI list celebrates individuals who are shaping the future of AI, a technology that continues to 
revolutionize industries. As TIME highlights, the rapid growth of AI is driven not just by the technology itself, but by 
the people behind itthose who make critical decisions about its development, safety, and application.
Zhao's recognition on this list highlights his significant contributions and leadership, particularly in the areas of 
adversarial machine learning and securitya field that explores how machine learning models can be manipulated 
and how to defend against such attacks.
He is particularly known in the field for protective tools to mitigate harms of AI, including tools like Nightshade and 
Glaze, which artists can apply to their works to protect them from being scraped and used without consent to train 
AI models.
Innovation and impact
Zhao's research has spanned a broad range of areas, including networking, human-computer interaction, and 
security and privacy. Since 2016, he has focused on addressing security and privacy challenges in machine 
learning and mobile systems. Most recently, his work has centered on adversarial machine learning and developing 
tools to protect human creatives from the potential harms of generative AI models.
"My experiences across different areas (but especially in human-computer interaction) has taught me the value of 
engaging with users to truly understand how research and technology impacts real people," said Zhao. "As a result, 

Page 2 of 2
PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST
I am always drawn to research challenges that impact large groups of people, and projects that address those 
challenges by taking into account perspectives of the users most directly impacted."
He is particularly known in the field for tools to mitigate harms of AI. This line of work began in 2020, with Fawkes, 
an image cloaking tool designed to prevent third parties from building unauthorized facial recognition models of 
individuals based on public photos online.
Zhao's team also developed Nightshade, which proactively protects content copyright of visual artwork by making 
them toxic to AI models that train on them without consent, and Glaze, which protects individual artists against style 
mimicry.
These programs make changes to an image that are nearly imperceptible to the human eye, but significantly 
change what the AI "sees."
Since its release in January 2024, Nightshade has been downloaded nearly a million times.
As AI continues to evolve at a breakneck pace, the insights and innovations of leaders like Zhao will play a crucial 
role in shaping the technology's future.
"The recent rush towards generative AI has been spurred on by an aura of inevitability, promises of societal 
benefits, and massive profits," Zhao warned. "While many of these have yet to materialize, harms like copyright 
violation, proliferation of AI slop and deepfakes, and disruption to creative sectors are here today. These are the 
harms our lab works to mitigate through our research."
Zhao is an ACM Fellow and a recipient of the NSF CAREER award, the Internet Defense Prize, and MIT 
Technology Review's TR-35 Award, among others. His work has been featured in prominent media outlets such as 
the New York Times, Scientific American, NBC, CNN, BBC, and the Wall Street Journal, underscoring the broader 
societal impact of his research.
In addition to his research, Zhao is deeply involved in the academic community. He serves on technical program 
committees for top conferences in computer security (ACM CCS, IEEE Security and Privacy) and machine learning 
(NeurIPS). At University of Chicago, he co-directs the Security, Algorithms, Networking, and Data (SAND) Lab at 
UChicago alongside Neubauer Professor Heather Zheng and serves as the Director of Graduate Studies for the 
Department of Computer Science.
"I'm humbled by this recognition, and proud to share it with my long-term collaborator Prof. Heather Zheng, our 
wonderful students, and the many human artists, writers and other creatives working with us to build a future 
ecosystem where human creativity is valued more than technology," Zhao said.
Load-Date: September 6, 2024
=======
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 2
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
Honor recognizes unique contributions to the field, including Glaze and 
Nightshade tools
The Pulse: Finch University of Health Sciences
September 6, 2024 Friday
University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved
Section: LATESTSTORIES; Pg. 1
Length: 719 words
Byline: Miranda Redenbaugh
Body
TIME magazine announced Sept. 5 that it has named Ben Zhao, the University of Chicago Neubauer Professor of 
Computer Science, to its TIME100 AI list.
The TIME100 AI list celebrates individuals who are shaping the future of AI, a technology that continues to 
revolutionize industries. As TIME highlights, the rapid growth of AI is driven not just by the technology itself, but by 
the people behind it-those who make critical decisions about its development, safety, and application.
Zhao's recognition on this list highlights his significant contributions and leadership, particularly in the areas of 
adversarial machine learning and security-a field that explores how machine learning models can be manipulated 
and how to defend against such attacks.
He is particularly known in the field for protective tools to mitigate harms of AI, including tools like Nightshade and 
Glaze, which artists can apply to their works to protect them from being scraped and used without consent to train 
AI models.
Innovation and impact
Zhao's research has spanned a broad range of areas, including networking, human-computer interaction, and 
security and privacy. Since 2016, he has focused on addressing security and privacy challenges in machine 
learning and mobile systems. Most recently, his work has centered on adversarial machine learning and developing 
tools to protect human creatives from the potential harms of generative AI models.
"My experiences across different areas (but especially in human-computer interaction) has taught me the value of 
engaging with users to truly understand how research and technology impacts real people," said Zhao. "As a result, 
I am always drawn to research challenges that impact large groups of people, and projects that address those 
challenges by taking into account perspectives of the users most directly impacted."

Page 2 of 2
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
He is particularly known in the field for tools to mitigate harms of AI. This line of work began in 2020, with Fawkes, 
an image cloaking tool designed to prevent third parties from building unauthorized facial recognition models of 
individuals based on public photos online.
Zhao's team also developed Nightshade, which proactively protects content copyright of visual artwork by making 
them toxic to AI models that train on them without consent, and Glaze, which protects individual artists against style 
mimicry.
These programs make changes to an image that are nearly imperceptible to the human eye, but significantly 
change what the AI "sees."
Since its release in January 2024, Nightshade has been downloaded nearly a million times.
As AI continues to evolve at a breakneck pace, the insights and innovations of leaders like Zhao will play a crucial 
role in shaping the technology's future.
"The recent rush towards generative AI has been spurred on by an aura of inevitability, promises of societal 
benefits, and massive profits," Zhao warned. "While many of these have yet to materialize, harms like copyright 
violation, proliferation of AI slop and deepfakes, and disruption to creative sectors are here today. These are the 
harms our lab works to mitigate through our research."
Zhao is an ACM Fellow and a recipient of the NSF CAREER award, the Internet Defense Prize, and MIT 
Technology Review's TR-35 Award, among others. His work has been featured in prominent media outlets such as 
the New York Times, Scientific American, NBC, CNN, BBC, and the Wall Street Journal, underscoring the broader 
societal impact of his research.
In addition to his research, Zhao is deeply involved in the academic community. He serves on technical program 
committees for top conferences in computer security (ACM CCS, IEEE Security & Privacy) and machine learning 
(NeurIPS). At University of Chicago, he co-directs the Security, Algorithms, Networking, and Data Lab at UChicago 
alongside Neubauer Professor Heather Zheng and serves as the Director of Graduate Studies for the Department 
of Computer Science.
"I'm humbled by this recognition, and proud to share it with my long-term collaborator Prof. Heather Zheng, our 
wonderful students, and the many human artists, writers and other creatives working with us to build a future 
ecosystem where human creativity is valued more than technology," Zhao said.
- Adapted from an article first published by the Department of Computer Science.
Load-Date: September 6, 2024
End of Document
Page 1 of 3
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
Rolling Stone
September 5, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 1768 words
Byline: Miles Klee
Body
The picture, posted  July 4 on the Facebook page "Love Shares 3.0" for 71,000 followers, appears to be an aerial 
view of St. Peter's Basilica in the Vatican, with people gathered in the square. Overhead, dangling from a gigantic 
black helicopter, is what can only be a massive Bible, but the lettering on the book is garbled, and the cross on the 
cover has an extra arm. It looks as if the aircraft is about to drop this tome on the crowd below, flattening them. The 
caption is pure gibberish: "Close your eyes 70% and see magic / Today's my graduation / May 2024 is Your Best 
Year." Additional hashtags identify the image as "art" and "painting." 
It is, quite clearly, AI-generated - though nobody in the comments mentions this. "Praise the lord," writes oneuser. 
Many others reply with a simple "amen." The image has close to 6,000 likes and "heart" engagements.
In the early 2010s, Facebook reshaped digital life as we know it. But in the past few years, a confluence of trends 
has left it uniquely vulnerable to click-farming pages that churn out AI-created junk. At a critical moment when 
online creators are weighing the benefits of integrating controversial AI tech into their personal brands, a shadow 
army of spam "creators" have already leveraged it to invade a platform mostly abandoned by such internet 
celebrities, eating away at whatever social value it has left. Worst of all, the very structure of Facebook appears to 
have encouraged this rot. 
One factor, of course, is the rise of text-prompt image generators like Midjourney, Stable Diffusion, and DALL-E, 
which make it profoundly easy to create "original" works at a terrific rate. Facebook, meanwhile, was investing 
billions in CEOMark Zuckerberg's "metaverse" boondoggle, and still has no real user base to show for it:Gen Z 
famouslydisdains the social network as uncool, preferringTikTok and the alsoMeta-owned Instagram, leaving 
Facebook with anaging demographic.
If the AI-reliant spam pages are any indication, many of those still scrolling Facebook can't tell or don't care when 
an image is fake, and have a particular fondness for certain comforting signifiers: Bibles, babies, American flags, 
soldiers, animals, luxurious homes, landscapes, and Jesus Christ. Then there are the images meant to evoke pity: 
patients in hospital beds, crying or endangered children, amputees, the unhoused, the starving. Sometimes the 
imagined figure is shown holding a sign asking for birthday wishes, or explaining that they're a veteran. And in 

Page 2 of 3
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
certain cases, there's no earthly explanation for what you're looking at - like this military truck that seems to be 
transporting giant carrots, but is also made out of them:
pic.twitter.com/RO99qZ5B0b
- Insane Facebook AI slop (@FacebookAIslop) September 3, 2024
Theodore, a 19-year-old who lives in Paris, has become the top curator of what he calls "Insane Facebook AI slop," 
and shares his favorite examples on a dedicatedTwitter account with more than 100,000 followers. On that site, it's 
customary to mock the content, as well as the gullible Boomers assumed to be eating it up. There's even an AI 
slop bingo card meme that followers can use to keep track of some common tropes, including the generic captions 
most often appended to the images, like: "Why don't pictures like this ever trend" and "You will never regret liking 
this photo." (Scarlett Johansson's name also shows up a lot, for some reason.)  
"I don't use Facebook a lot myself but saw plenty of screenshots of those types of posts on Twitter, and the insane 
amount of likes these had made the phenomenon funnier," Theodore tells Rolling Stone. "So I thought I might as 
well document those." At this point, he almost exclusively shares content he receives in DM submissions.
Theodore believes the success of AI slop is mostly due to the elderly and naive. "Facebook is full of old people and 
tech-illiterate people in general," he says, which is "also why the kind of posts that get the most likes are the ones 
that will target old people, using soldiers, American flags, Jesus imagery, etc." Since some themes are so 
dominant, he tries to maintain variety, lately branching out into illustrations of "third-world children doing all sorts of 
impossible crafts."
Meta has taken a rather gentle approach to AI-derived images and videos, opting to add an "AI info" label "when 
we detect industry standard AI image indicators or when people disclose that they're uploading AI-generated 
content," itsaid in a statement this summer. This label did not appear on any of the AI images shared by more than 
a dozen engagement-farming pages reviewed by Rolling Stone. As for more stringent moderation, Meta's Oversight 
Board has argued that they "unnecessarily risk restricting freedom of expression when we remove manipulated 
media that does not otherwise violate our Community Standards."
That is to say, because the typical AI slop isn't strictly misinformation (nor is it hate speech, graphic nudity, and so 
on), there's no glaring reason to delete it - unless Meta were to deem it spam. The company'spolicy states that it 
does not allow spam, which it defines as "content that is designed to be shared in deceptive and annoying ways or 
attempts to mislead users to drive engagement." The AI slop pages are certainly deceptive, repetitive, and gaming 
the system for engagement; there's also no telling how many are monetized and profiting from an abundance of 
reactions and comments.
Meta tells Rolling Stone that while "eradicating spam is a nearly impossible task," the company takes significant 
measures against it, since this type of content "detracts from people's ability to engage authentically in online 
communities." In the first quarter of 2024, it reported, Meta "removed 436 million pieces of spam content from 
Facebook," with 98.2 percent of this "actioned before it could be reported."
The question remains whether Meta would deem the AI-generated images to be spam in violation of their policy, or 
just take the engagement as a sign to feed those users more of the same. The pseudonymous data researcher and 
software developer Conspirador Norteño in June published a Substackinvestigation that suggested the latter: that 
Facebook's recommendation algorithm is favoring the AI slop over authentic content.
After logging in with a dummy account he had only ever used to shop for music gear, Conspirador simply scrolled 
through more than a thousand posts on his feed over half an hour and collected information on both the content 
and the pages that shared them. He found that less than 5 percent of the material corresponded to his past 
browsing of music equipment, 12.7 percent was sponsored ads, and the rest was "mostly a mix of AI-generated 
images and plagiarized photographs posted by content aggregator accounts with large numbers of followers." AI-
generated content accounted for 22 percent, or almost a quarter, of all the posts he viewed.
Page 3 of 3
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
"I think a lot of people still operate with the expectation that images that look like photos are real photos, and don't 
notice that they're really looking at an AI image unless there are really obvious problems," Conspirador says. He 
noted the prevalence of pages such as "Log Cabin Living," "Mountain Cabins," and "Barndominium Gallery," which 
tend to feature images of lavishly appointed country mansions set in lush nature scenes - pictures that often don't 
immediately betray signs of being fake. These reliably pick up likes, comments, and subscribers. "Unusual-looking 
houses and pretty outdoor scenes tend to do well, even when an account posts dozens or hundreds that are 
basically the same," Conspirador says. A typical "Log Cabin Living" post features a preposterously large house with 
an uncanny pool that seems to blur the distinction between artificial and natural bodies of water:
People gazing with admiration at fantasy houses that don't exist is one thing, and a social media algorithm 
amplifying this stuff is another. But Conspirador was particularly surprised by "Facebook's failure to intervene in 
cases where the account [was] obviously hijacked" from an ordinary user before it began spewing AI spam. This 
was the situation with "Barndominium Gallery," a page which he foundhad previously belonged to a hair salon in 
Oklahoma. In January, the owner of the salon posted that her page had been hacked and asked friends to report it 
to Facebook, yet eight months later, no action has been taken, while the page has accrued hundreds of thousands 
of followers with its AI rubbish. Worse, whoever stole the page has begun promoting links to afake home-
construction business that charges the customer $79.99 for floor plans and cost-of-build estimates on its AI-
generated architecture.
Carissa Véliz, an associate professor of philosophy at the University of Oxford's Institute for Ethics in AI, views the 
slop takeover as the logical result of how Facebook works. "This phenomenon seems to be a secondary effect of 
social media's focus on engagement," she says. "Instead of focusing on fostering wholesome relationships, or in 
being trustworthy sources of information, social media has focused on gaining people's attention. And it turns out 
that what attracts most of our attention is akin to junk food."
"Generative AI was designed to engage people," Véliz says. "It's good at producing images that people find 
captivating." Facebook, she points out, needs that content that keeps people glued to the app, and may tolerate 
clickbait because they're concerned that "users were no longer sharing as many personal stories as before." What's 
more, Véliz proposes, companies like Meta are incentivized to create Frankenstein's monsters beyond their control, 
as the "inadequate current regulation doesn't demand of social media companies anything that can be too 
burdensome." Therefore, if you have a system running amok, but fixing it would be too difficult, "it magically 
absolves you from its effects." 
pic.twitter.com/ATksXwxEAm
- Insane Facebook AI slop (@FacebookAIslop) August 31, 2024
In the meantime, spectators like Theodore and his audience will have plenty of absurdities to laugh at, from fish with 
legs toIncredible Hulk porn to phony black-and-white "historical"photos. He's also started pulling material from 
YouTube and X/Twitter, which are hardly immune from the same trend. But perhaps not all is lost just yet. Theodore 
doesn't usually look at the comments on Facebook AI slop, since there's no need to read "amen" a hundred times 
in a row. When he does, however, he's treated to the occasional surprise: "Someone calling out the post for being 
made by an AI."   
Load-Date: September 5, 2024
End of Document
Page 1 of 9
2:00PM Water Cooler 9/4/2024
2:00PM Water Cooler 9/4/2024
Newstex Blogs 
Naked Capitalism
September 4, 2024 Wednesday 6:00 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 Naked Capitalism 
Length: 4637 words
Byline: Lambert Strether
Body
September 4th, 2024 ( Naked Capitalism  - Delivered by  Newstex )
By Lambert Strether of Corrente
This is Naked Capitalism fundraising week. 25 donors have already invested in our efforts to combat corruption and 
predatory conduct, particularly in the financial realm. Please join us and participate via our  donation page, which 
shows how to give via check, credit card, debit card, PayPal. Clover, or Wise. Read about why we're doing this 
fundraiser, what we've accomplished in the last year,, and our current goal, strengthening our IT infrastructure.
Bird Song of the Day
Gray Catbird, Heckscher SP, East Islip, Suffolk, New York, United States. 'Singing from a small wooded area near 
a marsh.'
* * *
In Case You Might Miss
Kamala's Democrat prep.
Collard greens and code switching..
Clean air in the schools? Lol no..
H5N1 reassortment in Cambodia.* * *
Politics
'So many of the social reactions that strike us as psychological are in fact a rational management of symbolic 
capital.' -Pierre Bourdieu, Classification Struggles

Page 2 of 9
2:00PM Water Cooler 9/4/2024
* * *
2024
Less than one hundred days to go!
Friday's  RCP Poll Averages:
The good news for Trump is that Kamala's post-convention 'bounce' seems to have been slight. The good news for 
Kamala is Trump's continued deterioration in North Carolina, plus taking a slight lead in Pennsylvania. Remember, 
however, that all the fluctuations - in fact, all the leads, top to bottom - are within the margin of error.
* * *
The Debate (September 10)
Kamala (D): 'Kamala Harris goes to 'debate camp': Insiders reveal where VP's preparation is already going 
'sideways' as she gets ready for primetime Trump showdown' [ Daily Mail]. 'Sources close to the Harris team 
tell NOTUS that Harris is a little rusty on the debate stage as 'strategy sessions have careened sideways' when 
Harris 'focused too narrowly on minute details, effectively trailing the sessions.' Despite her willingness to debate, 
Harris and her team are still trying to negotiate the rules of the debate with ABC News, according to a Harris 
campaign source speaking to NBC News.' Still?! More: 'Trump and his team anticipate that Harris is preparing to 
interrupt him to try and 'fact check' his statements. The former president, however, is aware of Harris and her 
propensity to get lost into so-called 'word salads' while speaking publicly. 'She has bad moments. The way she 
talks,' Trump told broadcaster Tucker Carlson in a recent interview, imitating comments the vice president made 
about school buses. 'It's weird. The whole thing is weird.'' Harris: 'Who doesn't love a yellow school bus, right? Can 
you raise your hand if you love a yellow school bus? Many of us went to school on the yellow school bus, right? It's 
part of our experience growing up. It's part of a nostalgia, a memory of the excitement and joy of going to school to 
be with your favorite teacher, to be with your best friends and to learn. The school bus takes us there.' It's true that 
'It's part of a nostalgia' isn't something a native English speaker would say, but it's the condescension of 'Raise your 
hands' that gets me. Here's the video:
https://www.youtube.com/embed/E2e2HWH5pwo?si=LfV5QXupbvfoeWOg
The audience, presumably, is adult. Also, the hand gestures.
Kamala (D): 'How Kamala Harris Plans to Lock In for Debate Prep in Pennsylvania' [ NOTUS]. 'In conversations 
with nearly a dozen people involved with or aware of the preparations, a set of goals emerged for the next week. 
The campaign is planning to tune out as much of the outside noise as possible to lock her in, aware of Harris' 
relative rust as a debater and her tendency to overprepare and fixate on the details.' And: '[S]he's once again using 
notecards as part of her prep, a second person familiar with the preparations told NOTUS, a habit they believe she 
picked up during her law school days.' I would say the habit came from college debate, in which Harris participated. 
More: 'Allies say Harris has had to defend her ideas inside the White House over the last three years, preparing her 
in some ways for this moment. But Harris is, for all intents and purposes, an out-of-practice debater with people 
who aren't her colleagues. Next week's debate will come just a month shy of four years since she debated Vice 
President Mike Pence in Utah. For that, aides holed up in a hotel in Salt Lake City days before the debate, as she 
used index cards to work through talking points - including the now-famous 'I'm speaking' line, which one person 
involved in the session said was a crowdsourced suggestion.' Hmm. She recycled ' I'm speaking,' then. That didn't 
go so well. Interestingly, in neither of these two articles to we see any suggestion that Kamala would play the 
prosecutor ('Why am I debating a felon?'). Which seems a very obvious thing for her to do. Why go to all the trouble 
of doing the lawfare if you're not going to use it in debate?* * *
Kamala (D): 'The White House wants you to know that Harris was on the call' [ Politico]. 'Name-checking Harris - or 
any vice president, for that matter - is unusual and suggests an attempt to buttress her credentials as she faces 
Page 3 of 9
2:00PM Water Cooler 9/4/2024
questions about her ability to manage international affairs and confronts an experienced opponent in former 
President Donald Trump. POLITICO's review of pool reports, readouts, transcripts of administration briefings and 
comments by the nation's top diplomats and military officials found that the administration increased its mentions of 
Harris in public statements about foreign engagements since July, when Biden announced he would drop out of the 
presidential election and endorsed his vice president.' The previous NOTUS article includes this sentence: '[T]he 
Biden administration is in what they hope to be the last stretch of a cease-fire deal between Israel and Hamas that 
might require Harris' presence in the Situation Room.' Her mere presence. I know that Harris doing debate prep 
while a ceasefire deal was being consummated would look bad, but avoiding a bad look seems to be the only 
reason for her presence.* * *
Kamala (D): 'Cooking Collard Greens The Caribbean Way' [ Caribbean Pot]. 'Collard Green or collards is not native 
to the Caribbean, so it's not something we would refer to as being traditional. However, with our love for dasheen 
bush, spinach, Jamaican callaloo (chorai), Bok Choi and just about every other green there is, it's natural that 
collards will find a loving home in my kitchen.' So, wherever Kamala learned to cook collard greens - Montreal? Her 
sorority? - it's unlikely to be a family tradition (not on her Jamaican father's side, and certainly not on her Indian 
mother's side).
Kamala (D): And code switching:
One of my favorite accounts, on Twitter since 2011. In general, very level-headed.
* * *
Trump (R): 'Donald Trump Interview' (video) [Lex Fridman,  YouTube (outside observer)]. Smart move by Trump 
campaign staff:
https://www.youtube.com/embed/qCbfTN-caFI?si=-eTHOYXIAmtN9gaK
Trump (R): 'Questions surrounding Trump's mental acuity are a real 2024 story' [ MSNBC]. 'The words below were 
taken verbatim from a campaign speech' [and they're an especially dense example of free-form riffing]. 'Trump's 
asides stack atop each other with such density that it's dizzying for even professional political observers to discern 
what he's trying to get at. Trump's speeches seem to be growing more discursive and difficult to comprehend by the 
day. Those speeches are making it hard, if not impossible, for people listening to them to understand what he wants 
to do with his power in office, and they're reportedly turning off voters. They're also raising questions over whether 
the chaos he would sow in office would be even less intentional than it was last time. Trump's deteriorating 
[asserted, not shown] ability to clearly communicate is a consequential feature of his 2024 candidacy. That 
deterioration may not have been as salient when Trump, 78, had 81-year-old President Joe Biden as an opponent. 
But it's all the more clear as he now faces off against 59-year-old Vice President Kamala Harris. Questions 
about Biden's mental acuity were rightly raised in this election cycle. Questions about Trump's mental acuity should 
be raised, too.' I doubt this will stick, though of course the Democrats are trying it. Trump did fine in debate when he 
knocked Biden out of the race. Is there any sign of 'deterioration' in the hour-long interview with Fridman? I don't 
have time to listen to it, but I'm guessing no, because otherwise the memes would already be out.* * *
MI: 'CAIR 2024 Election Survey 0f Muslim Voters' [ CAIR]. 'As the 2024 national general election approaches, 
America's estimated 2.5 million Muslim voters are positioned to once again play a crucial role in shaping the 
political landscape. With their significant presence in key swing states, Muslim voters have the potential to influence 
the outcomes of not only the presidential race but also numerous congressional, state, and local elections.' Handy 
chart:
PA: 'Taking the pulse of Pennsylvania's Trump country, from Amish region to Gettysburg' [ USA Today]. 'While the 
election may be decided in the suburbs of Philadelphia and Pittsburgh, where the majority of the state's residents 
live, central Pennsylvania plays a role. It is traditionally red, with small pockets of blue in the cities, but the votes 
that come from the small businesspeople and churchgoers of the middle of the state - often referred to derisively as 
[deplorable] 'Pennsyltucky' - could make a difference in a state where the final results could be decided by a few 
Page 4 of 9
2:00PM Water Cooler 9/4/2024
thousand votes.' Worth a read. And from the York Daily Record, so kudos to USA Today. (Pennsylvania still has a 
lot of smallish newspapers, as we saw with the reporting from Butler.)* * ** * ** * *
Syndemics
'I am in earnest - I will not equivocate - I will not excuse - I will not retreat a single inch - AND I WILL BE HEARD.' -
William Lloyd Garrison
* * *
Covid Resources, United States (National): Transmission ( CDC); Wastewater ( CDC, Biobot; includes many 
counties; Wastewater Scan, includes drilldown by zip); Variants ( CDC; Walgreens); ' Iowa COVID-19 Tracker' (in 
IA, but national data). ' Infection Control, Emergency Management, Safety, and General Thoughts' (especially on 
hospitalization by city).
Lambert here: Readers, thanks for the collective effort. To update any entry, do feel free to contact me at the 
address given with the plants. Please put 'COVID' in the subject line. Thank you!
Resources, United States (Local): AK ( dashboard); AL ( dashboard); AR ( dashboard); AZ ( dashboard); CA 
( dashboard; Marin, dashboard; Stanford, wastewater; Oakland, wastewater); CO ( dashboard; wastewater); CT 
( dashboard); DE ( dashboard); FL ( wastewater); GA ( wastewater); HI ( dashboard); IA ( wastewater reports); ID 
( dashboard, Boise; dashboard, wastewater, Central Idaho; wastewater, Coeur d'Alene; dashboard, Spokane 
County); IL ( wastewater); IN ( dashboard); KS ( dashboard; wastewater, Lawrence); KY ( dashboard, Louisville); 
LA ( dashboard); MA ( wastewater); MD ( dashboard); ME ( dashboard); MI ( wastewater; wastewater); MN 
( dashboard); MO ( wastewater); MS ( dashboard); MT ( dashboard); NC ( dashboard); ND 
( dashboard; wastewater); NE ( dashboard); NH ( wastewater); NJ ( dashboard); NM ( dashboard); NV 
( dashboard; wastewater, Southern NV); NY ( dashboard); OH ( dashboard); OK ( dashboard); OR ( dashboard); 
PA ( dashboard); RI ( dashboard); SC ( dashboard); SD ( dashboard); TN ( dashboard); TX ( dashboard); UT 
( wastewater); VA ( dashboard); VT ( dashboard); WA ( dashboard; dashboard); WI ( wastewater); WV 
( wastewater); WY ( wastewater).
Resources, Canada (National): Wastewater ( Government of Canada).
Resources, Canada (Provincial): ON ( wastewater); QC ( les eaux uses); BC ( wastewater); BC, Vancouver 
( wastewater).
Hat tips to helpful readers: Alexis, anon (2), Art_DogCT, B24S, CanCyn, ChiGal, Chuck L, Festoonic, FM, 
FreeMarketApologist (4), Gumbo, hop2it, JB, JEHR, JF, JL Joe, John, JM (10), JustAnotherVolunteer, JW, 
KatieBird, KF, LL, Michael King, KF, LaRuse, mrsyk, MT, MT_Wild, otisyves, Petal (6), RK (2), RL, RM, Rod, 
square coats (11), tennesseewaltzer, Tom B., Utah, Bob White (3).
Stay safe out there!
* * *
Airborne Transmission: Covid
'Kids Are Headed Back to School. Are They Breathing Clean Air?' [ Scientific American]. Lol no. 'Across the U.S., 
kids are headed back to their classrooms-just as COVID nears a fresh, late-summer peak. Somehow, four years 
into a viral pandemic that everyone now knows spreads through the air, most schools have done little to nothing to 
make sure their students will breathe safely. We-and especially our children-should be able to walk into a store or a 
gym or a school and assume the air is clean to breathe. Like water from the faucet, regulations should ensure our 
air is safe. 'Air is tricky. You can choose to not partake of the water or the snacks on the table, but you can't just 
abstain from breathing,' notes Gigi Gronvall, senior scholar at the Johns Hopkins Center for Health Security and an 
Page 5 of 9
2:00PM Water Cooler 9/4/2024
author of a 2021 report on the benefits of improving ventilation in schools.' Somehow. Some schools are doing just 
fine, though!
Transmission: H5N1
'Cambodia's recent H5N1 case involved novel reassortant' [ Center for Infectious Disease Research and Policy]. 
'Sequencing of the patient's virus sample at the Pasteur Institute in Cambodia found that the hemagglutinin gene 
from the 2.3.2.1c clade that has been circulating in Cambodia and Southeast Asia since 2013. The internal genes, 
however, belonged to the newer 2.3.4.4b, which is circulating globally. 'This novel reassortant influenza A(H5N1) 
virus has been detected in human cases reported in Cambodia since late 2023,' the WHO said. Cambodian health 
officials have tracked and monitored the [patient's] contacts, and no related cases have been found. The country 
has reported an uptick in human H5N1 infections since 2023, reporting 6 cases last year and 10 this year, of which 
2 were fatal. In April, animal health officials in Vietnam and the United Nations Food and Agriculture Organization 
(FAO) warned of the new reassortant circulating in chickens and muscovy ducks. The scientists said the virus has 
been circulating in the Greater Mekong subregion since 2022. Also, they noted that the reassortant had been linked 
to recent human cases and that the development shows the adaptive capacity of the virus and the risk of new, 
potentially more virulent strains.' Musical interlude.
Denial and Cope
'As COVID Surges, the High Price of Viral Denial' [ The Tyee]. Canada. 'The subject of how to respond to a slow 
burn pandemic remains taboo because most public health officials have already declared the emergency over. 
They've also stopped collecting critical data. COVID-19 deaths in Canada are not reported in a readily publicly 
accessible fashion. And most of the media pretends that an immune-destabilizing virus that can harm the 
functioning of your organs including your brain has little more import than a benign cold. As a consequence, 
authorities can't now turn around and admit to the breadth of their mistake, let alone acknowledge the growing 
disorder in public health. Nor do they dare collect critical data documenting the scale of their errors including the 
relentless march of long COVID. Here, then, is where we've arrived. We've entered a vicious cycle where more 
infections generate more COVID variants. The new variants have become more immune evasive. At the same time 
society has generally abandoned masks, testing and basic public health messages. We could slow and suppress 
the cycle by facing the challenge squarely. For example, by cleaning dirty air the way we once tackled the disease-
ridden spectre of cholera-infested water. But public health officials are afraid to talk about clean air let alone the 
obvious: avoiding infection. Beating back COVID requires hard work, communal wisdom and clear policies that 
markedly reduce the level of infection in society. To date we have chosen viral denial, dirty air and a triumphant 
reign for long COVID.' Excellent article, worth reading in full.
Elite Maleficence
'Simple measures lessen hospital-acquired COVID-19 infections' [ Burnet]. Australia. 'In a new study published in 
the Journal of Hospital Infections, Burnet researchers found simple infection control measures could save lives and 
reduce costs for hospitals. These measures include testing patients for COVID-19 on admission, requiring staff to 
wear N95 masks in clinical areas and using Rapid Antigen Tests (RAT) or Polymerase Chain Reaction (PCR) tests 
to prevent transmissions. One of the paper's lead authors, Burnet Associate Professor Nick Scott, said on average, 
15-25% of patients who tested positive for COVID-19 in hospital had contracted the virus after being admitted.' But 
HICPAC would prefer that hospitals be death traps so, no N95s. Baggy blues only, if that!* * *
TABLE 1: Daily Covid Charts
Wastewater This week[1]  CDC August 26: Last Week[2] CDC (until next week):
Variants [3]  CDC August 31 Emergency Room Visits[4] CDC August 24
Hospitalization New York[5]  New York State, data August 30: National [6] CDC August 10:
Page 6 of 9
2:00PM Water Cooler 9/4/2024
Positivity National[7]  Walgreens September 3: Ohio[8] Cleveland Clinic August 24:
Travelers Data Positivity[9]  CDC August 12: Variants[10] CDC August 12:
Deaths Weekly Deaths vs. % Positivity [11] CDC August 24: Weekly Deaths vs. ED Visits [12] CDC August 24:
LEGEND
1) for charts new today; all others are not updated.
2) For a full-size/full-resolution image, Command-click (MacOS) or right-click (Windows) on the chart thumbnail and 
'open image in new tab.'
NOTES
[1] (CDC) This week's wastewater map, with hot spots annotated. Keeps spreading.
[2] (CDC) Last week's wastewater map.
[3] (CDC Variants) KP.* very popular. XDV.1 flat.
[4] (ED) Down, but worth noting that Emergency Department use is now on a par with the first wave, in 2020.
[5] (Hospitalization: NY) Flat, that is, no longer down.
[6] (Hospitalization: CDC). The visualization suppresses what is, in percentage terms, a significant increase.
[7] (Walgreens) Big drop, but all those white states showing no change: Labor Day weekend reporting issues?
[8] (Cleveland) Dropping.
[9] (Travelers: Positivity) Down. Those sh*theads at CDC have changed the chart so that it doesn't even run back to 
1/21/23, as it used to, but now starts 1/1/24. There's also no way to adjust the time range. CDC really doesn't want 
you to be able to take a historical view of the pandemic, or compare one surge to another. In an any case, that's 
why the shape of the curve has changed.
[10] (Travelers: Variants) What the heck is LB.1?
[11] Deaths low, but positivity up. If the United States is like Canada, deaths are several undercounted:
Tara Motarity has confirmed our fears.Most provinces are only reporting about 20% of covid deaths.Maybe even 
less.Which suggests the deaths are close to 5 times to 6+ times the reported figures.Nova Scotia has reported 270 
so far this year. It's actually 1,325-1,700 so far.  pic.twitter.com/6xF6SREyKB
- Dr.Robert Strang (@DSlayer520)  September 2, 2024
[12] Deaths low, ED up.
Stats Watch
'United States Factory Orders' [ Trading Economics]. 'New orders for US manufactured goods rose by 5% from the 
previous month to $592.1 billion in July of 2024, rebounding from the 3.3% drop in the previous month, and above 
market expectations of a 4.7% increase, signaling the resilience of the US economy.'* * *
Tech: Uh oh:
Page 7 of 9
2:00PM Water Cooler 9/4/2024
Hachette v. Internet Archive is out: 2d Circuit rejects controlled digital lending theory; IA's use is not transformative; 
all four fair use factors favor the publishers; the public benefits from shutting down IA's infringement.  
#copyright https://t.co/m5mDdezoJJ
- Devlin Hartline (@devlinhartline)  September 4, 2024
Tech: 'Canva says its new AI features justify raising subscription prices by 300%' [ Fortune]. 'In the U.S., some 
Canva users will see their Teams subscription price jump in early December from $119.99 per year to $500 per 
year. The first 12 months will be discounted to $300, but it's still more than double what users currently pay. Canva 
Teams will update from $10 per month per person, with a minimum of three people required for that subscription, a 
Canva spokesperson confirmed. Canva says its price hike is attributable to new features-particularly those that are 
AI-powered.' So, lots more AI slop to justify the investment. * * *
Today's Fear & Greed Index: 54 Neutral (previous close: 65 Greed) [ CNN]. One week ago: 56 (Greed). (0 is 
Extreme Fear; 100 is Extreme Greed). Last updated Sep 4 at 1:27:54 PM ET.
Class Warfare
'Thousands of hotel workers continue nationwide strike on Labor Day, demanding higher pay' [ NBC]. 'Thousands 
of workers at 25 hotels across the country remained on strike for a second day Monday, demanding higher pay and 
the reversal of pandemic-era cuts, with members in more cities expected to join the strike. On Sunday, around 
10,000 hotel workers walked off the job, kicking off the strike during the busy Labor Day weekend at 25 hotels in 
eight cities, including San Diego, Seattle, San Francisco, Boston and Honolulu. The workers are represented by the 
UNITE HERE union and work for the Marriott, Hilton and Hyatt hotel chains.. Roughly half of those on strike, about 
5,000, are from Honolulu, The Associated Press reported. UNITE HERE says strikes have been authorized and 
could begin soon in other cities, including Baltimore; New Haven, Connecticut; Oakland, California; and Providence, 
Rhode Island. The union said similar strikes led to contracts last year for Los Angeles hotel workers and Detroit 
casino workers.'
'Our Animals, Ourselves' [ Lux Magazine]. 'Conservatives are terrified by the prospect of a society that truly values 
and decommodifies (non-fetal) life, which is why they promote an image of flesh-consuming masculinity. 
Unfortunately, it seems many socialists are not so different. Leftists rarely engage with the myriad problems of 
animal agriculture, and are often dismissive or contemptuous of those who do. In this, their views are utterly 
mainstream. A recent episode of the popular lefty podcast Citations Needed began with an analysis of 
representations of vegetarian characters in popular culture, and the result was hardly flattering - routinely played by 
women, they tend to be insufferable. Such gendered stereotyping will come as no surprise to readers of Carol 
Adam's 1990 book The Sexual Politics of Meat, which weaves accounts of 19th century radicalism and 
examinations of 20th century marketing techniques into a pathbreaking work of 'feminist vegetarian critical theory' 
(after reading Adams, you will never hear a woman say she felt treated as a 'piece of meat' in the same way). 
Today we are often told that the animal rights movement came into being in the 1970s, birthed by the white male 
philosopher Peter Singer. In the English-speaking world, many women abolitionists, suffragettes, and pacifists 
advocated for vegetarianism and made connections across movements and causes long before Singer came on the 
scene, including the courageous abolitionist sisters Sarah and Angelina Grimk, who rejected meat in part because 
they thought it would hasten the 'emancipation of woman from the toil of the kitchen.' Singer rode roughshod over 
these intellectual antecedents by distinguishing his supposedly rational arguments from all the emotional - that is, 
feminine - advocacy that came before it. In the 1800s, there was even a diagnosis, zoophilpsychosis, for the 
affliction of being overly concerned for animals, from which women were believed to disproportionately suffer.' 
Zoophilpsychosis
News of the Wired
I am not feeling wired today.
* * *
Page 8 of 9
2:00PM Water Cooler 9/4/2024
Contact information for plants: Readers, feel free to contact me at lambert [UNDERSCORE] strether [DOT] corrente 
[AT] yahoo [DOT] com, to (a) find out how to send me a check if you are allergic to PayPal and (b) to find out how to 
send me images of plants. Vegetables are fine! Fungi, lichen, and coral are deemed to be honorary plants! If you 
want your handle to appear as a credit, please place it at the start of your mail in parentheses: (thus). Otherwise, I 
will anonymize by using your initials. See the previous Water Cooler (with plant)  here. From artinnature:
artinnature writes: 'Bumblebees on Oxydendrum arboreum (Sourwood).'
* * *
Readers: Water Cooler is a standalone entity not covered by the annual NC fundraiser. Material here is Lambert's, 
and does not express the views of the Naked Capitalism site. If you see a link you especially like, or an item you 
wouldn't see anywhere else, please do not hesitate to express your appreciation in tangible form. Remember, a tip 
jar is for tipping! Regular positive feedback both makes me feel good and lets me know I'm on the right track with 
coverage. When I get no donations for three or four days I get worried. More tangibly, a constant trickle of donations 
helps me with expenses, and I factor in that trickle when setting fundraising goals:
Here is the screen that will appear, which I have helpfully annotated:
If you hate PayPal, you can email me at lambert [UNDERSCORE] strether [DOT] corrente [AT] yahoo [DOT] com, 
and I will give you directions on how to send a check. Thank you!
This entry was posted in
Water Cooler on September 4, 2024 by Lambert Strether.
About Lambert Strether
Readers, I have had a correspondent characterize my views as realistic cynical. Let me briefly explain them. I 
believe in universal programs that provide concrete material benefits, especially to the working class. Medicare for 
All is the prime example, but tuition-free college and a Post Office Bank also fall under this heading. So do a Jobs 
Guarantee and a Debt Jubilee. Clearly, neither liberal Democrats nor conservative Republicans can deliver on such 
programs, because the two are different flavors of neoliberalism ('Because markets'). I don't much care about the 
'ism' that delivers the benefits, although whichever one does have to put common humanity first, as opposed to 
markets. Could be a second FDR saving capitalism, democratic socialism leashing and collaring it, or communism 
razing it. I don't much care, as long as the benefits are delivered.To me, the key issue - and this is why Medicare for 
All is always first with me - is the tens of thousands of excess 'deaths from despair,' as described by the Case-
Deaton study, and other recent studies. That enormous body count makes Medicare for All, at the very least, a 
moral and strategic imperative. And that level of suffering and organic damage makes the concerns of identity 
politics - even the worthy fight to help the refugees Bush, Obama, and Clinton's wars created - bright shiny objects 
by comparison. Hence my frustration with the news flow - currently in my view the swirling intersection of two, 
separate Shock Doctrine campaigns, one by the Administration, and the other by out-of-power liberals and their 
allies in the State and in the press - a news flow that constantly forces me to focus on matters that I regard as of 
secondary importance to the excess deaths. What kind of political economy is it that halts or even reverses the 
increases in life expectancy that civilized societies have achieved? I am also very hopeful that the continuing 
destruction of both party establishments will open the space for voices supporting programs similar to those I have 
listed; let's call such voices 'the left.' Volatility creates opportunity, especially if the Democrat establishment, which 
puts markets first and opposes all such programs, isn't allowed to get back into the saddle. Eyes on the prize! I love 
the tactical level, and secretly love even the horse race, since I've been blogging about it daily for fourteen years, 
but everything I write has this perspective at the back of it.
Link to the original story.
Page 9 of 9
2:00PM Water Cooler 9/4/2024
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 4, 2024
End of Document
Page 1 of 4
It's not just you. More weird spam is popping up on Facebook
It's not just you. More weird spam is popping up on Facebook
CNN Wire
September 3, 2024 Tuesday 10:00 AM GMT
Copyright 2024 Cable News Network All Rights Reserved
Length: 1745 words
Byline: By Clare Duffy, CNN
Dateline: (CNN) 
Body
             New York (CNN) - If a strange photo has recently stopped you in your tracks while scrolling your Facebook 
feed, you're not alone.
Users who once came to Facebook to connect with friends and family are increasingly complaining of random, 
spammy, junk content - much of it apparently generated by artificial intelligence - showing up in their feeds.
Sometimes it's obviously fake, AI-generated images, like the now-infamous "Shrimp Jesus." Other times, it's old 
posts from real creators that look like they're being reshared by bot accounts for engagement. In some cases, it's 
pages sharing streams of seemingly benign but random content - memes or movie clips, shared every few hours.
But the spam is more than just an annoyance; it can also be weaponized. Some spam pages appear designed to 
scam other users. In extreme cases, spam pages that gain a following can eventually be used, for example, by 
foreign actors seeking to sow discord ahead of elections, according to experts who study inauthentic behavior 
online.
The surge coincides with an intentional strategy shift at Facebook in the past few years. The company de-
emphasized current eventsand politics in the wake of claims it had contributed to election manipulation and real-
world violence. Feeling the heat from the rise of TikTok and its emphasis on entertainment over social connections, 
Facebook re-designed users' home feeds into a "discovery engine" in the hopes that people would engage with 
content they might not otherwise see.
But the push for more "discoverable" content has led to an algorithm that regularly pushes vapid, often misleading, 
computer-generated content.
The change has been palpable. AI-generated or recycled meme content has appeared on Facebook's quarterly 
most viewed content list. Posts with obviously AI-generated images and confusing captions sometimes receive 
thousands of likes and hundreds of comments and shares.

Page 2 of 4
It's not just you. More weird spam is popping up on Facebook
Bad actors and engagement farmers are only too happy to fulfill Facebook's demand for new content, experts say. 
And the proliferation of AI tools has made it far easier for them to quickly crank out huge volumes of fake images 
and text.
"It's a really interesting thing that a lot more people are starting to talk about because it's this random, kind of vanilla 
problem now, but obviously there are theoretical, long-term concerns," said Ben Decker, CEO of online threat 
analysis firm Memetica.
Facebook parent company Meta, for its part, works "to remove and reduce the spread of spammy content to ensure 
a positive user experience, offering users controls over their feed and encouraging creators to use AI tools to 
produce high-quality content that meets our Community Standards," spokesperson Erin Logan said in a statement. 
"We also take action against those who attempt to manipulate traffic through inauthentic engagement, regardless of 
whether they use AI or not."
Adventures in the AI swamp
Before I started reporting this story in July, my Facebook feed felt pretty normal, featuring baby photos from college 
friends and listings from Facebook Marketplace.
But, curious about the complaints, I started clicking on whatever content I did see that seemed odd, and the 
algorithm kicked in. Now, weeks later, nearly every third post on my feed appears to be so-called "AI slop."
One recent example: a black-and-white image showing a shack in the woods with a family sitting out front, shared 
by a page called "History for Everyone."
At first glance, the post looks like something you might find in a history book. But upon closer inspection, the people 
in the image have blurred, undefined facial features, and the children's hands and feet seem to disappear into the 
landscape around them - hallmarks of AI-generated images.
The post's caption claims the image was taken in 1910 in New Jersey at a "small shack on Forsythe's Bog, 
occupied by De Marco family, 10 in the family living in this one room," by National Child Labor Committee 
photographer Lewis Hine. Curious, I copied the full caption into Google, which pointed me to the real caption of an 
entirely different photo that had been published by the Library of Congress.
I plugged the Facebook image into a Google reverse image search, and the only other places it appeared online 
were two other, similar Facebook groups called "Past Memories" and "History Pictures."
It's impossible to say definitively how the image was created, but CNN's photo team ran it through AI-detection 
software - which is still in early testing - and found "substantial evidence" it had been manipulated. Hany Farid, a 
digital forensics expert and UC Berkeley professor who has studied AI, added that the image appeared to be AI-
generated and may have been created by using the caption of the real, historical image as the AI prompt, 
potentially to avoid copyright infringement.
The group that shared the post, "History for Everyone," is managed by a page by the same name, which was 
created in 2022 and previously changed its name from "Cubs" and "Chikn.Nuggit." The page did not respond to a 
direct message.
The History for Everyone post is illustrative of a lot of the content that's come across my feed - uncanny, bizarre, 
but also seemingly benign.
Other examples include a page called "Amy Couch" that also shares "historical" photos, with an apparently AI-
generated profile photo that shows a woman with one giant tooth where her two front teeth should be. Or an art and 
history page for an "artist" called "Kris Artist" whose profile photo I traced back to a real social media influencer who 
told me over email: "That is definitely not my account but they are using my picture."
Page 3 of 4
It's not just you. More weird spam is popping up on Facebook
When I messaged the "Kris Artist" page, I received what appeared to be an automated response: "Hi, thanks for 
contacting us. We've received your message and appreciate you reaching out. Please Join our Group."
After I flagged the History for Everyone post, as well as the Amy Couch and Kris Artist pages, to Meta, it removed 
them for violating its spam policy.
Behind the AI slop
It's not clear exactly how much of this content exists on Facebook. But there may be lots of people seeing it. The 
"History for Everyone" page has more than 40,000 followers, although individual posts often receive just a handful 
of interactions.
Researchers from Stanford and Georgetown earlier this year tracked 120 Facebook pages that frequently posted 
AI-generated images - and found the images collectively received "hundreds of millions of engagements and 
exposures," according to a paper released in March, which has not yet been peer-reviewed.
"The Facebook Feed ... at times shows users AI-generated images even when they do not follow the Pages posting 
those images. We suspect that AI-generated images appear on users' Feeds because the Facebook Feed ranking 
algorithm promotes content that is likely to generate engagement," researchers Renee DiResta and Josh Goldstein 
wrote in the paper. They added that often the users engaging with that content didn't seem to realize it was AI.
Experts who track this kind of online behavior say there are likely several different kinds of actors behind the 
Facebook spam, with varying motives.
Some just want to make money, for example through bonus payments that Facebook pays out to creators posting 
public content. There are dozens of YouTube videos teaching people how to get paid for posting AI content on 
Facebook - as tech news site 404 Media reported earlier this month - with some claiming they make thousands of 
dollars each month using the tactic.
"Even in the realm of the political, the tactics of manipulators have long been previewed by those with a different 
motivation: making money. Spammers and scammers are often early adopters of new technologies," the Stanford 
researchers wrote.
On other pages, scammers use the comments as a place to hawk sham products or collect users' personal 
information.
In some cases, what looks like a harmless account sharing mostly random content will slip in occasional 
misinformation or offensive memes, as a way of evading Facebook's enforcement mechanisms. "If something looks 
just like a run-of-the-mill spam campaign, it might not trigger the company's top investigators ... and so it might go 
undetected for longer," said David Evan Harris, an AI researcher who previously worked on responsible AI at Meta.
Harris added that there is also an online market for "aged" Facebook accounts, because older accounts are more 
likely to appear human and evade the platform's spam filters.
"It's like a black market, basically, you can sell someone 1,000 of these accounts that are all five years or older, and 
then they can turn those into a scam or an influence operation," Harris said. "This is something you see in elections: 
Someone might make a Facebook group that's like, 'everybody loves cheeseburgers,' and the group posts images 
of the best cheeseburgers every day for two years, and then all of a sudden, a month before an election ... it 
becomes a 'vote for (former Brazilian President Jair) Bolsonaro' group."
What to do with AI spam?
With AI tools, bad actors no longer need lots of people to rapidly produce reams of fake content - the technology 
can do it for them.
Page 4 of 4
It's not just you. More weird spam is popping up on Facebook
For Facebook to identify all of the AI-generated images getting uploaded each day without making mistakes would 
be challenging, "particularly at a time when this technology is moving so incredibly fast," Farid said. Even if it could, 
"that doesn't mean you should ban all AI generated content, right? ... It's a very subtle question on policy," he said.
Earlier this year, Meta said it would add "AI info" tags to content created by certain third-party generators that use 
metadata to let other sites know AI was involved. Meta also automatically labels AI-generated images created with 
its own tools.
However, there are still ways for users to strip out that metadata (or create AI images without it) to evade detection.
Meta may also be hampered by a smaller team dedicated to addressing fake content, after it - like other tech giants 
- trimmed its trust and safety staff last year, meaning it must rely more on automated moderation systems that can 
be gamed.
"Digitally savvy social media communities have always been one and a half steps ahead of trust and safety efforts 
at all platforms ... it's almost a cat and mouse game that never really ends," Harris said.         
             By Clare Duffy, CNN         
TM & © 2024 Cable News Network, Inc., a Time Warner Company. All rights reserved.
Load-Date: September 3, 2024
End of Document
Page 1 of 2
Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more views
Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more 
views
Newstex Blogs 
Tubefilter
September 3, 2024 Tuesday 6:31 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 Tubefilter
Length: 713 words
Body
September 3rd, 2024 (Tubefilter — Delivered by Newstex)
Artificial intelligence is a contentious topic these days-and a trendy one, with every major tech company and former 
crypto/NFT brand jumping on what they see as the latest moneymaking bandwagon. We've written before about the 
issues creators face with AI, including the lack of control over whether their content is scraped for use in large 
language models, and we've also written about a small handful of companies who are  trying to make AI work for 
creators, with their consent.
Joining that handful is Spotter, which today announced Spotter Studio, an AI-based tool that's meant to serve as 'a 
brainstorm partner, project planner, and research copilot,' the company says. Once a creator signs up for Spotter 
Studio, the program looks at their entire channel, and, based on that information, can do everything from cold-
suggesting new video topics to drafting thumbnails.
Spotter, which was founded in 2019, used to focus on catalog licensing, where it would pay creators a lump sum for 
the rights to their old content. But, over the last couple of years, it noticed a changing tide in our industry: artificial 
intelligence wasn't going away, and creators were simultaneously becoming more interested in and more leery of 
AI. It decided to shift its business model. Paul Bakaus, Spotter's EVP of Product and Creator Tools, tells Tubefilter 
the company figured it could use AI to bolster creators' workflows, and wanted to help them 'get ahead' of the 
deluge of generative AI slop it knew would soon fill YouTube, TikTok, and other platforms.
Spotter began hiring executives from Adobe, Amazon, Google, Headspace, Linktree, and Spotify to help it build AI 
tools, and consulted consulted YouTubers like Colin & Samir about what creators really wanted from AI. Its first AI 
tool, Title Exploder, rolled out in late 2023.
Spotter Studio (which wraps Title Exploder into its suite) was also born from creator input. MrBeast, Dude Perfect, 
Kinigra Deon, Rebecca Zamolo, Jordan Matter, Jay Alto, Hayden Hillier-Smith, and Colin & Samir all participated in 
the tool's beta period.

Page 2 of 2
Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more views
And, Spotter says, these creators found that videos made with Spotter Studio got 49% more views in their first 
seven days than videos made without it. So far, videos made using Spotter Studio as part of the development 
process have collectively netted 844 million views.
'Spotter's mission has always been to empower Creators and provide the resources and opportunities that enable 
them to thrive,' Aaron DeBevoise, CEO and Founder of Spotter, said in a statement. 'As the industry evolves, so do 
we, continually adapting to meet the needs of Creators by working directly with them. What makes Spotter Studio 
so special is that it was not only designed for Creators, but with them.'
The tool starts broad. Creators begin with its Brainstorm function, where Spotter Studio generates video ideas 
based on their channel's content. If the creator likes an idea, they can pin it for future use. If they like a suggestion's 
core conceit but want to tweak something about the execution, they can ask the Studio to change that aspect. (Like, 
if a video idea requires winter gear but it's summer, they can say, Change this video to being filmed on the beach.) 
They can revise multiple ideas over and over until they've narrowed it down to something they want to make.
Then Spotter Studio offers finishing flair like title suggestions and thumbnail drafts (which Bakaus says are not 
meant to serve as true thumbnail art; they're purposefully kind of cartoony and lo-fi so creators still have to make 
their own 'nails for the upload).
While AI is the core of Spotter Studio, the tool also just plain offers a centralized place to plan, Dude Perfect's Coby 
Cotton said. 'Ideas that used to be scattered across phones, whiteboards, and sticky notes are now organized in 
one place, accessible to the entire DP team from ideation through post-production. Spotter Studio is our new home 
base,' he said.
Spotter Studio is being officially announced at VidSummit this week, but it's available now for $49/month or 
$299/year (temporary discount) to creators in the U.S., Canada, the U.K., and Australia.
Spotter is a Tubefilter partner.
Visit Tubefilter for more great stories.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 3, 2024
End of Document
Page 1 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
National Novel Writing Month's AI-neutral stance criticized by bestselling 
authors
Newstex Blogs 
VentureBeat
September 3, 2024 Tuesday 3:27 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 VentureBeat 
Length: 1234 words
Byline: Carl Franzen
Body
September 3rd, 2024 ( VentureBeat  - Delivered by  Newstex )
Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage.  
Learn More
National Novel Writing Month (NaNoWriMo), the 25-year-old nonprofit organization that encourages anyone and 
everyone who has interest to draft a novel each year during the month of November, recently stirred significant 
debate by announcing it will accept the use of artificial intelligence (AI) as a tool in the writing process.
The decision, rooted in the belief that opposition to AI can be classist and ableist, has received mixed reactions, 
drawing both  support and lots of criticism - including from bestselling established authors and former NaNoWriMo 
board members.
Yesterday, the  organization published a statement on its website noting that it neither condemns nor exclusively 
endorses the technology. Instead, NaNoWriMo champions the freedom for writers to choose their own methods, 
whether they involve traditional approaches or AI tools.
'NaNoWriMo does not explicitly support any specific approach to writing, nor does it explicitly condemn any 
approach, including the use of AI,' the statement reads, later adding, 'We believe that to categorically condemn AI 
would be to ignore classist and ableist issues surrounding the use of the technology, and that questions around the 
use of AI tie to questions around privilege.'
Disclaimer: VentureBeat uses AI tools to generate imagery, copy and other material for use in our publishing and 
promotion.
Why NaNoWriMo supports AI for use in writing in some cases

Page 2 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
The organization's official statement highlights the complexity of AI as a broad technological category, making it 
difficult to entirely endorse or reject. It also underscores the social implications of AI use, suggesting that to oppose 
AI outright ignores the realities of class and ability disparities.
According to NaNoWriMo, some writers may turn to AI for practical reasons, such as financial constraints or 
cognitive challenges that make traditional writing methods less accessible.
As NaNoWriMo's statement explains: 'Not all writers have the financial ability to hire humans to help at certain 
phases of their writing. For some writers, the decision to use AI is a practical, not an ideological, one. The financial 
ability to engage a human for feedback and review assumes a level of privilege that not all community members 
possess.'
The organization also points out that underrepresented minorities are less likely to secure traditional publishing 
deals, which forces many into the indie author space where upfront costs can be prohibitive. AI tools, in these 
cases, might provide essential support that enables them to pursue their writing goals.
Bestselling authors lash out
However, the endorsement of AI has not been without controversy. Prominent voices in the writing community have 
expressed their displeasure with NaNoWriMo's stance.
Urban fantasy author Daniel Jos Older, a former member of NaNoWriMo's Writers Board, announced his 
resignation from the board in response to the organization's pro-AI position.
'Never use my name in your promo again,' Older declared on social media, urging other writers to follow his lead.
Hello  @NaNoWriMo this is me DJO officially stepping down from your Writers Board and urging every writer I know 
to do the same. Never use my name in your promo again in fact never say my name at all and never email me 
again. Thanks! https://t.co/KDKZ0zVx3H- Daniel Jos Older (@djolder)
September 2, 2024
Maureen Johnson, a #1 New York Times and USA Today bestselling author of young adult (YA) novels, also 
resigned from NaNoWriMo's Writers' Board of the Young Writers Program, citing concerns over how the 
organization might use writers' work to train AI systems.
To  @NaNoWriMo: please remove me from the Writers' Board of the Young Writers Program. I want nothing to do 
with your organization from this point forward. I would also encourage writers to beware-your work on their platform 
is almost certainly going to be used to train AI. https://t.co/FJo2WxXq73- Maureen Johnson (@maureenjohnson)
September 3, 2024
Other authors, including  Adam Christopher and Bryan Young, criticized NaNoWriMo for what they perceive as an 
anti-art and anti-creativity stance, accusing the organization of promoting meaningless AI-generated content.
To be clear,  @NaNoWriMo are anti-writing, anti-art, anti-creativity, anti-craft. They fully support generating 50,000 
words of meaningless AI slop and uploading it to complete the challenge, and if you disagree you are the 
enemy. https://t.co/1vN0UFfGim- Adam Christopher (@ghostfinder)
September 2, 2024
The backlash was further fueled by revelations that  NaNoWriMo's recent sponsors include companies offering AI 
software and writing tools, such as ProWritingAid.
Page 3 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
ProWritingAid provides a suite of AI-powered tools designed to enhance writing, including grammar checking, 
sentence rephrasing, and a variety of writing reports. Its 'AI Sparks' feature assists writers in overcoming writer's 
block by generating text and adding sensory details or dialogue.
This sponsorship has led to suspicions and criticism from those who view the endorsement as influenced by 
financial incentives rather than a purely ethical stance.
NaNoWriMo also collaborates with writing software like Scrivener, which integrates AI tools like ProWritingAid to 
help users access AI writing and editing features within their environment. Other platforms like Dabble, Storyist, and 
Ninja Writers, while not inherently AI-focused, support the integration of AI tools, allowing writers to enhance their 
work using external AI services.
In contrast, another sponsor, Freewrite remains focused on providing distraction-free writing devices, emphasizing 
traditional writing processes without AI integration.
In response to the criticism, NaNoWriMo acknowledged the existence of unethical practices within the AI space but 
maintained that its stance is driven by a desire to support all writers, regardless of their chosen methods. The 
organization reiterated its commitment to providing resources and information about AI to its community, noting that 
events related to AI have been well-attended, indicating strong interest among participants.
As AI continues to evolve and its role in creative processes becomes more prominent, NaNoWriMo's position could 
serve as a bellwether for how other organizations and individuals approach the integration of AI into creative fields. 
For enterprise decision-makers, especially those in publishing and creative industries, NaNoWriMo's stance might 
offer valuable insights as they navigate the ethical and practical implications of AI in their own operations.
NaNoWriMo's position ultimately reflects a broader debate within the writing community-is AI a tool on the order of 
a word processor or search engine, one primarily directed by humans, or is it a morally and ethically compromised 
technology built from copyrighted works without permission, which critics equate with theft? For now, it seems, 
leading authors are coalescing around the latter position.
VB Daily
Stay in the know! Get the latest news in your inbox daily
vb_dailyroundup 5de2efbc19/river-full Subscribe
By subscribing, you agree to VentureBeat's  Terms of Service.
Thanks for subscribing. Check out more  VB newsletters here.
An error occured.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
Page 4 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 3, 2024
End of Document
Page 1 of 3
=======
>>>>>>> c98f417 (update data file):extract_text.txt
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images frenzy
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated 
images frenzy
The Independent (United Kingdom)
September 3, 2024 Tuesday 4:01 PM EST
Copyright 2024 Independent Print Ltd  All Rights Reserved
Length: 872 words
Byline: Mike Bedigan
Body
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate's latest obsession.
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a Second World War soldier, a cowboy and even the muscle-bound body of Rambo - earnestly 
and unironically. 
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks. 
Notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Program at Columbia University, suggests one simple reason 
for this: Trump is just trying to stay relevant.
"In 2016, whatever Trump posted actually blew into the liberal media," Cross tells The Independent. "People would 
be reacting like 'can you believe this outrageous thing he said today?' I'm not sure if that's happening this time 
around, because Kamala has proven herself as adept at using social media as Trump was. She's just better at 
coming up with memes."
Link to Image
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "kamala is brat" - a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum. 

Page 2 of 3
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images frenzy
Cross suggests that Trump's over-posting of AI images is, as the younger generation might say, an attempt to "clap 
back" at the Harris campaign in whatever way he can. "It's almost like throwing spitballs on the wall and seeing 
what will stick," she tells The Independent.
But Trump's online posting - unlike that of his political rivals - is, and always has been, much more sincere. 
From his first presidential campaign in 2016, Trump has attempted to project an image of himself as a strong 
leader, capable of uniting America in the face of great evil. Now, thanks to AI, he and the Republicans have a tool 
that allows them to visualise the hypothetical realities they are peddling to their supporters, who seem receptive to 
the visual hyperbole of AI slop that now dominates right-wing social media platforms and accounts.
"Things like him on the lion or lying about Taylor Swift, it's aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else," Cross says. "And there's a whole army of people, of Trump supporters 
out there who get their news from social media... They don't trust any of the mainstream outlets."
pic.twitter.com/H0ExcNXBdl
- Donald J. Trump (@realDonaldTrump)
August 18, 2024
Social commentator and activist Patrick Jones - known online as Mr Jones X - agrees. The integration of AI images 
into Trump's campaign is about strengthening his support base, not expanding it, he says.
"He understands that these visual images have the ability to sway a specific demographic of people, because if 
they see a thing, especially if it's coming from him on X or Truth Social, they're going to believe it," Jones tells The 
Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president's mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Harris emerging as the Democratic party's presidential candidate, this seems 
to have been forgotten.
"It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign - essentially, they had to throw it out," Jones says. The momentum of the Harris-Walz 
campaign is "hard to combat", he adds. "So now you have to come up with the most absurd talking points, the most 
absurd arguments." 
The former president's recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election - though there are currently few if 
any federal laws or regulations.
Link to Image
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads. 
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the Senate floor in July and are still waiting for 
another go at a full Senate vote. But these images can have a bigger impact than a funny social media post.
"It's definitely potentially dangerous," says Cross. "What they did in 2016 was actually dissuade people from going 
to the polls. And you've got states where the margins are anywhere from 7,000 to 20,000 votes. 
Page 3 of 3
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images frenzy
"So if you can get those people to stay home, or get those people to switch votes a tiny number of them, or even 
not vote, that would be significant in the seven swing states that we're looking at right now."
Load-Date: September 4, 2024
End of Document
Page 1 of 3
Inside Trump's weird new obsession with AI-generated images
Inside Trump's weird new obsession with AI-generated images
Irish Independent
September 2, 2024 Monday
Edition 1, National Edition
Copyright 2024 Independent Newspapers Ireland Limited All Rights Reserved
Section: NEWS; Pg. 18,19
Length: 882 words
Byline: MIKE BEDIGAN
Body
Republicans using new tech to create 'visual hyperbole' to peddle to their supporters online
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate's latest obsession.
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a WW2 soldier, a cowboy and even the muscle-bound body of Rambo - earnestly and unironically.
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks, 
notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Programme at Columbia University, suggests one simple 
reason for this: Trump is just trying to stay relevant.
"In 2016, whatever Trump posted actually blew into the liberal media," Cross said.
"People would be reacting like 'can you believe this outrageous thing he said today?' I'm not sure if that's happening 
this time around, because Kamala has proven herself as adept at using social media as Trump was.
She's just better at coming up with memes."
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "Kamala is brat" - a reference to her wildly popular new album.

Page 2 of 3
Inside Trump's weird new obsession with AI-generated images
The addition of Tim Walz, already familiar with viral videos, thanks to his daughter Hope, has only built momentum.
Cross suggests that Trump's over-posting of AI-images is, as the younger generation might say, an attempt to "clap 
back" at the Harris campaign in whatever way he can.
"It's almost like throwing spitballs on the wall and seeing what will stick," she said.
But Trump's online posting - unlike that of his political rivals - is, and always has been, much more sincere.
From his first presidential campaign in 2016, Trump has attempted to project an image of himself as a strong 
leader, capable of uniting America in the face of great evil.
Now, thanks to AI, he and the Republicans have a tool that allows them to visualise the hypothetical realities they 
are peddling to their supporters, who seem receptive to the visual hyperbole of AI slop that now dominates right-
wing social media platforms and accounts.
"Things like him on the lion or lying about Taylor Swift, it's aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else," Cross says.
"And there's a whole army of people, of Trump supporters out there who get their news from social media... They 
don't trust any of the mainstream outlets."
Social commentator and activist Patrick Jones - known online as Mr Jones X - agrees. The integration of AI images 
into Trump's campaign is about strengthening his support base, not expanding it, he says.
"He understands that these visual images have the ability to sway a specific demographic of people, because if 
they see a thing, especially if it's coming from him on X or Truth Social, they're going to believe it,"
Jones told The Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president's mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Harris emerging as the Democratic party's presidential candidate, this seems 
to have been forgotten.
"It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign - essentially, they had to throw it out," Jones says.
The momentum of the Harris-Walz campaign is "hard to combat", he adds. "So now you have to come up with the 
most absurd talking points, the most absurd arguments."
The former president's recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election - though there are currently few if 
any federal laws or regulations.
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads.
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the senate floor in July and are still waiting for 
another go at a full senate vote. But these images can have a bigger impact than a funny social media post.
"It's definitely potentially dangerous," says Cross.
"What they did in 2016 was actually dissuade people from going to the polls. And you've got states where the 
margins are anywhere from 7,000 to 20,000 votes.
Page 3 of 3
Inside Trump's weird new obsession with AI-generated images
"So if you can get those people to stay home, or get those people to switch votes a tiny number of them, or even 
not vote, that would be significant in the seven swing states that we're looking at right now." (© The Independent)
"There's an army of people out there who get their news from social media... they don't trust the mainstream"
Graphic
 
Donald Trump dances onstage with Moms for Liberty co-founder Tiffany Justice at an event in Washington on 
Friday night. Photo: ReutersLeft, a fake AI-generated of Kamala Harris holding a communist rally; above, an AI 
image saying Taylor Swift is backing Trump; and, below, an AI image of Trump riding a lion. Images: Twitter
Load-Date: September 2, 2024
End of Document
Page 1 of 3
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images frenzy
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated 
images frenzy
The Independent (United Kingdom)
September 1, 2024 Sunday 12:30 PM GMT
Copyright 2024 Independent Digital News and Media Limited All Rights Reserved
Section: US POLITICS,AMERICAS,WORLD; Version:3
Length: 873 words
Byline: Mike Bedigan
Highlight: The Republican party and its presidential nominee now have a tool that allows them to visualise the 
hypothetical realities that they are peddling to their supporters, who are receptive to such visual hyperbole – so-
called ‘AI slop’, writes Mike Bedigan
Body
First appeared “Comrade Kamala” with a hammer and sickle. Then, a line of blonde women wearing “Swifties for 
Trump ” merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate’s latest obsession. 
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a Second World War soldier, a cowboy and even the muscle-bound body of Rambo – earnestly 
and unironically. 
Yet the frequency of Trump’s sharing of such fantastical images has ramped up considerably in recent weeks. 
Notably, it seems, following the ascension of Kamala Harris  to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Program at Columbia University, suggests one simple reason 
for this: Trump is just trying to stay relevant.
“In 2016, whatever Trump posted actually blew into the liberal media,” Cross tells The Independent. “People would 
be reacting like ‘can you believe this outrageous thing he said today?’ I’m not sure if that’s happening this time 
around, because Kamala has proven herself as adept at using social media as Trump was. She’s just better at 
coming up with memes.”

Page 2 of 3
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images frenzy
The Harris campaign has quickly excelled in the online sphere , ever since British pop singer Charli XCX declared 
that “kamala is brat” – a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum. 
Cross suggests that Trump’s over-posting of AI images is, as the younger generation might say, an attempt to “clap 
back” at the Harris campaign in whatever way he can. “It’s almost like throwing spitballs on the wall and seeing 
what will stick,” she tells The Independent.
But Trump’s online posting – unlike that of his political rivals – is, and always has been, much more sincere. 
From his first presidential campaign in 2016, Trump has attempted to project an image of himself as a strong 
leader, capable of uniting America in the face of great evil. Now, thanks to AI, he and the Republicans have a tool 
that allows them to visualise the hypothetical realities they are peddling to their supporters, who seem receptive to 
the visual hyperbole of AI slop that now dominates right-wing social media platforms and accounts.
“Things like him on the lion or lying about Taylor Swift, it’s aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else,” Cross says. “And there’s a whole army of people, of Trump supporters 
out there who get their news from social media... They don’t trust any of the mainstream outlets.”
pic.twitter.com/hlExcNXBdl                        — Donald J. Trump (@realDonaldTrump) August 18, 2024
Social commentator and activist Patrick Jones – known online as Mr Jones X – agrees. The integration of AI 
images into Trump’s campaign is about strengthening his support base, not expanding it, he says.
“He understands that these visual images have the ability to sway a specific demographic of people, because if they 
see a thing, especially if it’s coming from him on X or Truth Social, they’re going to believe it,” Jones tells The 
Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president’s mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Harris emerging as the Democratic party’s presidential candidate, this seems 
to have been forgotten.
“It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign – essentially, they had to throw it out,” Jones says. The momentum of the Harris-Walz 
campaign is “hard to combat”, he adds. “So now you have to come up with the most absurd talking points, the most 
absurd arguments.” 
The former president’s recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election – though there are currently few if 
any federal laws or regulations.
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads. 
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the Senate floor in July and are still waiting for 
another go at a full Senate vote. But these images can have a bigger impact than a funny social media post.
“It's definitely potentially dangerous,” says Cross. “What they did in 2016 was actually dissuade people from going 
to the polls. And you've got states where the margins are anywhere from 7,000 to 20,000 votes. 
“So if you can get those people to stay home, or get those people to switch votes a tiny number of them, or even 
not vote, that would be significant in the seven swing states that we're looking at right now.”
Page 3 of 3
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images frenzy
Load-Date: September 3, 2024
End of Document
Page 1 of 3
Inside Trump's weird new obsession with AI-generated images
Inside Trump's weird new obsession with AI-generated images
The Independent (United Kingdom)
September 1, 2024 Sunday 12:30 PM EST
Copyright 2024 Independent Print Ltd  All Rights Reserved
Length: 870 words
Byline: Mike Bedigan
Body
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate's latest obsession.
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a WW2 soldier, a cowboy and even the muscle-bound body of Rambo - earnestly and unironically. 
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks, 
notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
=======
Bigger picture of Trump's weird AI images obsession The Republican party and its presidential nominee now 
have a tool that allows them to visualise the hypothet....
Bigger picture of Trump's weird AI images obsession; The Republican party 
and its presidential nominee now have a tool that allows them to visualise 
the hypothetical realities they are peddling to their supporters, writes Mike 
Bedigan
The Independent - Daily Edition
September 2, 2024 Monday
First Edition
Copyright 2024 Independent Print Ltd All Rights Reserved
Section: WORLD; Pg. 17
Length: 862 words
Byline: MIKE BEDIGAN
Body
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merchandise. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI 
images were the Republican candidate's latest obsession.
The former president has been sharing such images since March 2023, with his face photoshopped onto images 
including a Second World War soldier, a cowboy, and even the muscle-bound body of Rambo - earnestly and 
without irony.
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks. 
Notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
>>>>>>> c98f417 (update data file):extract_text.txt
success of her own campaign.
June Cross, director of the Documentary Journalism Programme at Columbia University, suggests one simple 
reason for this: Mr Trump is just trying to stay relevant.
"In 2016, whatever Trump posted actually blew into the liberal media," Ms Cross tells The Independent. "People 
would be reacting like 'can you believe this outrageous thing he said today?' I'm not sure if that's happening this 
time around, because Kamala has proven herself as adept at using social media as Trump was. She's just better at 
coming up with memes."
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Link to Image
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "kamala is brat" - a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum. 
Cross suggests that Trump's over-posting of AI-images is, as the younger generation might say, an attempt to "clap 
back" at the Harris campaign in whatever way he can. "It's almost like throwing spitballs on the wall and seeing 
what will stick," she tells The Independent.
=======
>>>>>>> c98f417 (update data file):extract_text.txt

Page 2 of 3
Bigger picture of Trump's weird AI images obsession The Republican party and its presidential nominee now 
have a tool that allows them to visualise the hypothet....
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "kamala is brat" - a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum.
Ms Cross suggests that Mr Trump's over-posting of AI images is, as the younger generation might say, an attempt 
to "clap back" at the Harris campaign in whatever way he can. "It's almost like throwing spitballs on the wall and 
seeing what will stick," she tells The Independent.
But Mr Trump's online posting - unlike that of his political rivals - is, and always has been, much more sincere. From 
his first presidential campaign in 2016, Mr Trump has attempted to project an image of himself as a strong leader, 
capable of uniting America in the face of great evil. Now, thanks to AI, he and the Republicans have a tool that 
allows them to visualise the hypothetical realities they are peddling to their supporters, who seem receptive to the 
visual hyperbole of AI slop that now dominates right-wing social media platforms and accounts.
"Things like him on the lion or lying about Taylor Swift, it's aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else," Ms Cross says. "And there's a whole army of people, of Trump 
supporters out there who get their news from social media... They don't trust any of the mainstream outlets."
Social commentator and activist Patrick Jones - known online as Mr Jones X - agrees. The integration of AI images 
into Mr Trump's campaign is about strengthening his support base, not expanding it, he says.
"He understands that these visual images have the ability to sway a specific demographic of people, because if 
they see a thing, especially if it's coming from him on X or Truth Social, they're going to believe it," Mr Jones tells 
The Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president's mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Ms Harris emerging as the Democratic party's presidential candidate, this 
seems to have been forgotten.
"It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign - essentially, they had to throw it out," Mr Jones says. The momentum of the Harris-
Walz campaign is "hard to combat", he adds. "So now you have to come up with the most absurd talking points, 
[and] the most absurd arguments."
The former president's recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election - though there are currently few if 
any federal laws or regulations.
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads.
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the Senate floor in July and are still waiting for 
another go at a full Senate vote. But these images can have a bigger impact than a funny social media post.
"It's definitely potentially dangerous," says Ms Cross. "What they did in 2016 was actually dissuade people from 
going to the polls. And you've got states where the margins are anywhere from 7,000 to 20,000 votes. So if you can 
get those people to stay home, or get those people to switch votes - a tiny number of them - or even not vote, that 
would be significant in the seven swing states that we're looking at right now."
Load-Date: September 1, 2024
Page 3 of 3
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Inside Trump's weird new obsession with AI-generated images
End of Document
Page 1 of 3
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
Forbes.com
August 27, 2024 Tuesday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1209 words
Byline: Rashi Shrivastava, Forbes Staff
Highlight: Plus: Major AI regulation up for a vote in California.
Body
The Prompt is a weekly rundown of AI s buzziest startups, biggest breakthroughs, and business deals. To 
get it in your inbox, .
Welcome back to The Prompt.
<figure>
<figcaption>
With the arrival of AI, some businesses have been overwhelmed with applications from suspected North Korean 
operatives.
Getty
</figcaption></figure>
AI tools are helping North Koreans covertly apply for thousands of remote IT jobs in the US,reported. Companies 
large and small are being flooded with job applications from thousands of suspected North Korean operatives, who 
earn hundreds of millions of dollars and send the money back to the regime, where the U.S. government believes it 
s used to fund its weapons of mass destruction program. With the help of AI tools, these workers are able to run 
multiple job profiles and apply for hundreds of jobs at once.
Now let s get into the headlines.
REGULATION
This week,California legislators will vote on , a controversial bill that seeks to regulate the most advanced and 
powerful AI models. If passed, the bill would require the developers of AI models whose training either cost more 
than $100 million, or required a specified amount of computing power, to implement safeguardsand allowthird-
party audits of safety practices.

Page 2 of 3
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
It also requires AI companies to outline methods for shutting down the AI model and effectively implement a  kill 
switch for the technology if needed. The legislation would allow the state attorney general to take action against a 
developer if its AI model causes severe harm such as mass casualties or more than $500 million in damages.
Silicon Valley leaders are deeply  on their positions regarding the bill: xAI and Tesla founderElon 
MuskandAnthropicCEO Dario Amodei have come out in support of the bill, while leaders fromOpenAI, Meta and 
Google have voiced concerns that the bill would stifle innovation.
TALENT RESHUFFLE 
Three of the five cofounders of French AI startup H have left the company after operational and business 
disagreements, according to. The departure comes just a few months after the startup raised awhopping  seed 
roundfrom billionaires like Eric Schmidt and Bernard Arnault to build AI agents for multi-step tasks.
AI DEAL OF THE WEEK
Coding automation startup Cursor AI raised$60 million in Series A funding at a $400 million valuation, CEO 
Michael Truell told. The company s AI tools are popular among developers at leading AI startups like OpenAI and 
Midjourney, where they areused to write, edit and predict parts of code.But Cursor isn t short on competition  the 
market is flooded with similar AI coding assistants likeCodeium, which launched an engine capable of digesting 100 
million lines of code, and Cognition Labs, which is valued at $2 billion and created an AI software engineer called 
Devin. Tech giants are also developing their own AI programming tools in-house;Amazon CEO Andy Jassysaid 
that its AI assistant, called Q has helped save the company$260 million and  yearsworth of time in terms of 
software development.
DEEP DIVE
The idea of America is big business on Facebook. The social network has hosted more than a hundred pages that 
have adopted American patriotism as a theme, boasting names like Proud American, Proud To Be An American, 
American Story, and We Are America.
But a large swath of those pages   despite their names  aren t American at all.Instead, they re run by foreign click 
farmers, many of whom are based in Macedonia, who useAI to pump out a near-endless ocean of clickbaity 
soup. Posts sharing prayers for American soldiers, rewritten tweets, memes and pictures of old Hollywood pin-up 
girls link out toAI-generated articles, against which the click farmers can sell advertising.
Headlines like  A Father s Heroism: The Tragic Story of Phil Dellegrazie And His Son Anthony  tease short, 
uninformative articles on websites plastered with often sexual advertisements. The pages promoting them fake 
Americanness because they get paid every time someone clicks on one of their links, and in the advertising world, 
American clicks are some of the most valuable.
AForbesreview identified 67 Facebook pages   now taken down   that identified themselves as champions of 
American news, culture or identity, but were actually based overseas. As of August 20, they hadmore than 9 
million followers combined  more than the Facebook pages of the Wall Street Journal or the Washington Post. 
Thirty-three of them were run fromMacedonia,with others spread out across 23 different countries, including 
Canada, France, Morocco, Venezuela and Vietnam.
Click farmers, especially those from Macedonia, have a long history on Facebook. During the 2016 presidential 
election, teenagers in the small Eastern European countrypushedfake news to millions of Americans on Facebook, 
makingtens of thousandsof dollars in ad revenue. In 2019, similar Eastern European pagesran the same playbook  
this time, reaching nearly half of all Americans on the platform.
Now, AI has given those same operations the capacity to producenear-infinite volumes of low-quality (or 
outright fake) news  and in at least some cases, this AI-produced slop is breaking through. The pages have 
begun using generic AI-generated imagery (bald eagles, stars and stripes, camo soldiers and the occasional 
Page 3 of 3
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
Statue of Liberty) to appeal to American Facebook users   and in at least some cases, it s working. Onepostmade 
last week by the Canada-based page American Patriots featured an AI-generated photo of an American soldier 
and his children,and received more than 100,000 likes and 35,000 comments. The American Patriots page, like 
most of the others, directed people from Facebook to click farms featuring low-quality articles.
Read the full story onForbes.
WEEKLY DEMO 
Do you want to practice a tough workplace conversation or get tips on how to negotiate a raise? Companies are 
increasingly deploying AI-powered career coaches as an alternative toexpensive human counselorsthat can 
cost up to $240 an hour,reported. But people who have interacted with these AI-based career counselors note that 
these chatbotsoften lack nuance and can sometimes offer confusing advice.  I m already confused about my 
career. AI [only] throws me in a bigger loop,  one third-year law student said.
AI INDEX
Two years ago, the Biden administration passed the CHIPS Act to incentivize the development of semiconductors 
and chips within the United States, as the country battled with China on developing AI models. Butred tape and a 
grueling application process has largely kept funds out of reach from smaller firms that need it most,reported.
Less than 7% 
Applicants that received funding from the 380 firms that submitted applications.
9 out of 23 
Semiconductor manufacturers who were approved for the funding were smaller companies.
$4 billion out of $134 billion 
Amount of grants and loans awarded to smaller companies; the rest went to chip giants like Intel, TSMC and 
Samsung.
MODEL BEHAVIOR
American rapper and singer Will.i.am is launching anAI-powered radio station called Raidio.FYI, which will allow 
listeners to listen to songs and news and ask questions to the host through a chatbot app built on OpenAI s large 
language models, according toThe Sunday Times. The rapper is reportedly an investor in OpenAI and Anthropic.
Load-Date: August 28, 2024
End of Document
Page 1 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
The Foreign Pro-Trump Fake News Industry Has Pivoted To American 
Patriotism
Forbes.com
August 26, 2024 Monday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1905 words
Byline: Emily Baker-White, Forbes Staff
Highlight: It s been more than eight years since content farms overseas started  American  fake news pages on 
Facebook. Their business, now fueled by AI, is still going strong.
Body
It s been more than eight years since content farms overseas started  American  fake news pages on 
Facebook. Their business, now fueled by AI, is still going strong.
By Emily Baker-White, Forbes Staff
The idea of America is big business on Facebook. The social network has hosted more than a hundred pages that 
have adopted American patriotism as a theme, boasting names like Proud American, Proud To Be An American, 
American Story, and We Are America.
But a large swath of those pages   despite their names   aren t American at all. Instead, they re run by foreign click 
farmers, many of whom are based in Macedonia, who use AI to pump out a near-endless ocean of clickbaity soup. 
Posts sharing prayers for American soldiers, rewritten tweets, memes and pictures of old Hollywood pin-up girls link 
out to AI-generated articles, against which the click farmers can sell advertising. Headlines like  Dedicated 
Firefighters Risk Their Lives To Save Others  and  A Father s Heroism: The Tragic Story of Phil Dellegrazie And His 
Son Anthony  tease short, uninformative articles on websites plastered with often sexual advertisements. The 
pages promoting them fake Americanness because they get paid every time someone clicks on one of their links, 
and in the advertising world, American clicks are some of the most valuable.
AForbesreview identified 67 Facebook pages   now taken down   that identified themselves as champions of 
American news, culture or identity, but were actually based overseas. As of August 20, they had more than 9 million 
followers combined   more than the Facebook pages of the Wall Street Journal or the Washington Post. Thirty-three 
of them were run from Macedonia, with others spread out across 23 different countries, including Canada, France, 
Morocco, Venezuela and Vietnam.
Click farmers, especially those from Macedonia, have a long history on Facebook. During the 2016 presidential 
election, teenagers in the small Eastern European countrypushedfake news to millions of Americans on Facebook, 
makingtens of thousandsof dollars in ad revenue. In 2019, similar Eastern European pagesran the same playbook  
this time, reaching nearly half of all Americans on the platform.

Page 2 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
Now, AI has given those same operations the capacity to produce near-infinite volumes of low-quality (or outright 
fake) news   and in at least some cases, this AI-produced slop is breaking through. The pages have begun using 
generic AI-generated imagery (bald eagles, stars and stripes, camo soldiers and the occasional Statue of Liberty) to 
appeal to American Facebook users   and in at least some cases, it s working. Onepostmade last week by the 
Canada-based page American Patriots featured an AI-generated photo of an American soldier and his children, and 
received more than 100,000 likes and 35,000 comments. The American Patriots page, like most of the others, 
directed people from Facebook to click farms featuring low-quality articles.
<figure>
<figcaption>
Pages like We Are America, American Patriots and USA Army Is Love post a mix of real and AI-generated 
photography and memes.
Facebook
</figcaption></figure>
Forbesfed three of the American Patriots articles through an AI text detector called GPT-Zero, which found that 
they were 79%, 85%, and 100% likely to have been generated by AI. The detector also found that stories linked 
from We Love America, a page from Spain, and American Story, a Macedonian page, had a 100% likelihood of 
being generated by AI.(Disclosure: In a previous life, I held content policy positions at Facebook and 
Spotify.)
 Every platform has incentives   and they provide a window into what is at the heart of Facebook, what makes it 
tick," said Jeff Allen, co-founder of the Integrity Institute and a former Facebook data scientist who tracked networks 
of spammy page administrators from the inside. To him, click farmers are a  great magnifying glass   into the more 
reptilian parts of our brain. 
Meta spokesperson Margarita Franklin toldForbesthat all 67 pages violated Meta s rules on inauthentic behavior, 
because they misrepresented where they were based; all were taken down. It s not necessarily a violation of Meta s 
rules to make a page about one country while based in another, but the pages cross a line when they deceive 
people about where they re from. Franklin said the pages had only been active for a little more than a week 
whenForbesflagged them.
Franklin also said that while AI does make content generation easier for spammers and scammers, their primary 
challenge has always been getting eyeballs on their pages, whether they re made with AI or not. A recent Meta 
Threat Report found that generative AI has  provide[d] only incremental productivity and content-generation gains  
to  threat actors,  because the cost of creating low-quality clickbait articles has always been pretty low.
When Macedonian content farms first became big on Facebook in 2016, they leaned hard into hyper-partisan rage 
bait focused on divisive issues like immigration, trans rights, race and policing. The theory was simple   write about 
what people were most likely to engage with. And at the time, posts about those issuesoften topped the chartsof 
Facebook engagement.
But Facebook s algorithm has shifted away from politics in the eight years since then. The company began 
aggressively demoting political posts after the January 6, 2021 capitol riots, which wereorganized in parton Meta 
platforms.
Some of the American patriotic pages still featured political topics, with recent posts on topics including critical race 
theory and trans rights. In the aggregate, though, the pages didn t focus on politics. More often, they featured 
formulaic tabloid stories, like tales of cheating spouses ( You won t believe what he did next! ) or disrespected blue 
collar workers who get revenge on the elitists who snubbed them. Oddly, ever-present across the pages were 
memes featuring the television personality and America s Got Talent judge Simon Cowell. Along with changing their 
content to echo the Facebook algorithm s shift away from politics, the pages also showed other telltale signs of 
Page 3 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
adapting to the platform s ever-changing rules and incentives. For instance, Facebook has reduced the reach of  
spammy  links but prioritizes a page admin s comments on their own posts; as a result, these pages often posted a 
meme or other image that summarizes the gist of an article, and then posted the link as a comment.
<figure>
<figcaption>
Patriotic Warriors, a Facebook page that had 141,000 followers before it was taken down, is run out of Macedonia.
Facebook
</figcaption></figure>
Some of the pages also used other engagement-juicing tricks that have long been popular. One page based in 
Kosovo, called Animals News America, featured clickbait posts similar (and in some cases, identical) to those on 
other, non-animal themed pages. But it also posted a regular stream of kittens and puppies, using a strategy 
previouslyemployedby notorious misinformation spreaders like the COVID- denying doctor Joseph Mercola and 
NTD News, a Falun Gong-affiliated sister brand of the Epoch Times.
AfterForbesreached out for comment, Meta removed every page.
Even if these pages weren t intentionally being used to shape people s political views, click-farmers will sometimes 
shift their pages into deliberate geopolitical influence operations, Allen said. While still at Facebook, he observed 
one Thailand-based operation that targeted pages about politics to audiences in Myanmar. They would "pop in and 
out of being guns for hire for political campaigns," he said. "But when it wasn't political campaign season, they'd run 
the exact same operations, just making the money themselves."
That makes these pages less innocuous than they might seem.  I bet there are plenty of foreign influence 
operations that would like to buy these Pages when the time is right. So, there are times when  click farms  can 
become much more nefarious," Allen said. After the original Macedonian click farmers were exposed, 
Facebooklaunched a featureto enable users to find out which country a page is run from, if it has at least 5,000 
followers or has run political ads. But the country of a page administrator s origins is often hidden in an obscure 
panel called Page Transparency, and comments on the foreign America-themed pages  posts suggest that many 
people engaging with those posts did not know that the pages are run by foreigners.
The America-themed pages themselves were also deliberately misleading.One postmade last week by a page 
called America Today reads:  Not another cent to nations that disrespect our flag and values!     The page was 
managed from Macedonia.
Franklin noted that in certain cases, Meta now displays the location of certain pages  page managers directly in the 
Facebook News Feed.
Accounts that pretend to be American when they re not may be a widespread issue on social media. Facebook, to 
its credit, is the only major social media platform reveals the country from which its large pages are managed. Other 
platforms, including YouTube and TikTok, allow users to self-declare a location if they want to, making it harder to 
detect accounts that are pretending to be American when they re not. The incentives, however, are the same. 
Parveen Kumar Shah, who makes his living advising people about how to build audiences on YouTube and 
Instagram through his channelTubeSensei,recently suggested other page creators seeking to build an audience 
should pretend to be American. Why? You ll make more money that way, he advised.
AI makes that even easier. In an interview, he toldForbesthat now,  if you don t want to show your face, everything 
can be done through AI.  On YouTube, Shahshowed his followershow to make masculinity-themed pages for 
American teens with titles like Far From Weak and Sigma Male. He toldForbes:  Targeting that type of audience is 
very easy because a teenager s brain is very easy to mold. 
Page 4 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
There aremany videoson YouTube that explain how to hide or spoof your country of residence on the platform, to 
make it look like your channel is based in another part of the world. For Shah, this is a simple economic calculus: 
YouTube pays channel managers based on the ads that run on their channel, and advertisers spend far more in 
Western markets than they do in India. On the TubeSensei channel, he explained:  Our channel is going to be for a 
U.S. audience, and as soon as they come to know that this is an Indian channel, or there is an Indian creator 
behind it, they stop watching the channel. 
YouTube did not respond to a request for comment.
Allen, the former Facebook data scientist, characterized engagement farming as a problem for platforms to fix   one 
that if they don t address, regulators might eventually penalize them for. He compared the prevalence of inauthentic 
pages to defective tires on a car: "Your tires have been popping on the highways for the past ten years. At a certain 
point, there's going to be some regulatory teeth."
As long as the click farmers  crimes don t go beyond the proliferation of stale, low-quality memes, though, Allen 
doesn't think removing pages is the solution. Instead, he said, Facebook should move away from an algorithm that 
incentivizes people to post sensationalist slop in the first place.
"If a click farmer tries to farm on your platform, but doesn't get any clicks   does he do any farming?"
Rashi Shrivastava contributed reporting.
MORE FROM FORBES
Load-Date: August 27, 2024
=======
Bigger picture of Trump's weird AI images obsession The Republican party and its presidential nominee now 
have a tool that allows them to visualise the hypothet....
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 3
How did Donald Trump end up posting Taylor Swift deepfakes?
How did Donald Trump end up posting Taylor Swift deepfakes?
The Guardian (London)
August 24, 2024 Saturday 5:00 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:3
Length: 1114 words
Byline: Nick Robins-Early
Highlight: AI images posted to Truth Social bore the watermark of a tiny Texas non-profit looking to bankroll X 
users
Body
When Donald Trump  shared a slew of AI-generated images  this week that falsely depicted Taylor Swift  and her 
fans endorsing his campaign for president, the former US president was amplifying the work of a murky non-profit 
with aspirations to bankroll rightwing media influencers and a history of spreading misinformation.
Several of the images Trump posted on his Truth Social platform, which showed digitally rendered young women in 
“Swifties for Trump” T-shirts, were the products of the John Milton Freedom Foundation. Launched last year, the 
Texas-based non-profit organization frames itself as a press freedom group with the goal of “empowering 
independent journalists” and “fortifying the bedrock of democracy”.
The group’s day-to-day operations appear to revolve around sharing engagement bait on X and seeking millions 
from donors for a “fellowship program” chaired by a high school sophomore that would award $100,000 to Twitter 
personalities such as Glenn Greenwald, Andy Ngo and Lara Logan, according to a review of the group’s tax 
records, investor documents and social media output. The John Milton Freedom Foundation did not respond to a 
request for comment to a set of questions about its operations and fellowship program.
After months of retweeting conservative media influencers and echoing Elon Musk  ’s claims that freedom of 
speech is under attack from leftwing forces, one of the organization’s messages found its way to Trump and then 
his millions of supporters.
Trump distanced himself from the images in an interview with Fox Business on Wednesday, saying: “I don’t know 
anything about them other than someone else generated them. I didn’t generate them.”
Disinformation researchers have long warned that generative AI  has the ability to lower the bar for creating 
misleading content and threaten information around elections. After Musk’s xAI company released its largely 

Page 2 of 3
How did Donald Trump end up posting Taylor Swift deepfakes?
unregulated Grok image generator last week, there has been a surge of AI content that has included depictions of 
Trump, Kamala Harris and other political figures. The Milton Freedom Foundation is one of many small groups 
flooding social media with so-called AI slop. 
                   A niche non-profit’s AI slop makes its way to Trump                   
During the spike in AI images on X, the conservative @amuse account posted the images  of AI-generated Swift 
fans to more than 300,000 followers. On the text of the post, which was labeled “satire”, was a watermark that 
stated it was “sponsored by the John Milton Freedom Foundation”. Trump posted a screenshot of @amuse’s tweet 
on Truth Social.
The @amuse account has considerable reach itself, with about 390,000 followers on X and dozens of daily posts. 
Running @amuse appears to be Alexander Muse, listed as a consultant in the investor prospectus of the Milton 
Foundation, who also writes a rightwing commentary Substack that includes posts exploring election conspiracy 
theories. The @amuse account has numerous connections with Muse. The X account is connected to a Substack 
posting the same articles that Muse publishes on his LinkedIn page, which also has the username “amuse”, 
reflecting his first initial and last name. Muse’s book on how to secure startup funding, which includes examples of 
him asking ChatGPT  to pretend it’s Musk and offer business advice, lists that same Substack account as its 
publisher.
Prominent accounts including Musk have shared and replied to @amuse’s posts, which recently have included AI 
depictions of Trump fighting Darth Vader and sexualized imagery of Harris. Its banner picture is currently an AI-
generated photo of Trump surrounded by women in “Swifties” shirts. The account posts misleading, pro-Trump 
headlines such as claiming Harris turned hundreds of thousands of children over to human traffickers as “border 
czar”. The headlines, like the AI-generated Swifties for Trump images, come with the watermark “sponsored by the 
John Milton Freedom Foundation”.
The John Milton Freedom Foundation, named after the 17th-century British poet and essayist, has a small online 
footprint: a website, an investor prospectus and an X account with fewer than 500 followers. The team behind it, 
according to its own documents, consists of five people based in the Dallas-Fort Worth area with varying degrees of 
experience in Republican politics. Muse’s daughter, described as a 10th grade honor student on the non-profit’s 
site, serves as the Milton Foundation’s “fellowship chair”.
The foundation’s stated goal is to raise $2m from major donors to award $100,000 grants to a list of “fellows” made 
up of rightwing media influencers. These include people like the former CBS journalist turned far-right star Lara 
Logan, who was cut from Newsmax  in recent years for going on a QAnon-inspired rant that claimed world leaders 
drink children’s blood, as well as the author of an anti-trans children’s book. The organization believes that this 
money would allow these already established influencers to “increase their reach by more than 10x in less than a 
year”, according to its investor prospectus.
While only one of the fellows listed on the foundation’s site mentions the organization on their X profiles and none 
follow its account, the @amuse account has a prominent link to the group’s community page and the foundation 
often engages with its posts.
It is not clear that the foundation has any money to give and if all the media influencers listed as its 2024 fellowship 
class know about the organization. One Texas-based account that posts anti-vaccine content lists itself as a “JMFF” 
fellow in their bio, but none of the others advertise any connection. The most recent tax records for the Freedom 
Foundation place it in the category of non-profits whose gross receipts, or total funds received from all sources, 
range from $0 to $50,000 – far below the millions it is seeking.
The organization’s board includes its chair, Brad Merritt, who is touted as an experienced Republican organizer with 
claims to have raised $300m for various non-profits; its director, Shiree Sanchez, who served as assistant director 
of the Republican party of Texas between 1985 and 1986; and Mark Karaffa, a retired healthcare industry 
executive.
Page 3 of 3
How did Donald Trump end up posting Taylor Swift deepfakes?
Muse’s experience in digital media appears to be far more extensive than the non-profit’s other members. In 
addition to his blog, he claims to have worked with James O’Keefe, the former CEO of the rightwing organization 
Project Veritas , who was known for hidden camera stings until he was ousted last year  over allegations of 
misplaced funds. Muse, who is described in the prospectus as a “serial entrepreneur”, also blogs about how to 
make money from generative AI.
Load-Date: August 26, 2024
End of Document
Page 1 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the 
internet is ‘flooded with garbage’
The Guardian (London)
August 24, 2024 Saturday 9:00 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: AUSTRALIA NEWS; Version:2
Length: 1582 words
Byline: Ariel Bogle
Highlight: Australian Barbara O’Neill’s ‘natural self-healing’ remedies found a certain audience through her own 
efforts. But her image has run wild thanks to unaffiliated groups exploiting her name on social mediaFollow our 
Australia news live blog for latest updatesGet our morning and afternoon news emails, free app or daily news 
podcast
Body
Five years ago, Barbara O’Neill was permanently banned from providing any health services in New South Wales 
or other Australian states. 
O’Neill, whose website describes her as “an international speaker on natural healing”, was found by the NSW 
Health Care Complaints Commission (HCCC)  in 2019 to have given highly risky health advice to vulnerable 
people, including the use of bicarbonate soda as a cancer treatment.
Since then her views have found a much larger audience overseas and online, supported by elements of the 
Seventh-day Adventist (SDA) church and media networks in the US. So far this year O’Neill has spoken in the US, 
the UK and Ireland and advertised retreats in Thailand for thousands of dollars. A Facebook page managed in her 
name is promoting plans for O’Neill to tour Australia later this year, despite the commission’s ruling.
Sign up for Guardian Australia’s free morning and afternoon email newsletters for your daily news roundup
But O’Neill’s story reveals not only the limits of a state health regulator. Beyond her own promotional efforts, a vast 
scam economy has grown up that profits from her notoriety without her authorisation.
Clips of O’Neill’s health teachings, often dating as far back as 2012, now feed a voracious economy of unaffiliated 
Facebook pages and groups – more than 180 at one point – that are branded with her name and share lecture clips 
and recipes but are outside the control of O’Neill. Many are controlled by accounts based in Morocco, but attempts 
to contact administrators went unanswered.

Page 2 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
Old clips of O’Neill are being used to sell herbal teas, Celtic salt and castor oil on TikTok, as Vox found.  AI-
generated content of O’Neill on the app now goes even further, making up entirely new claims about her and her 
health advice.
Accounts on the app share generative AI images that falsely claim she “disappeared” after revealing that a certain 
mineral that will help people live for 100 years, or that show O’Neill being “arrested” for sharing apparent methods 
of natural healing such as black seed oil. The videos typically link to online stores or even Amazon where, naturally, 
the product referred to is for sale. Questions to account owners went unanswered.
It’s part of an emerging online ecosystem in which would-be digital creators in search of easy money follow trending 
topics such as O’Neill’s health claims, and use generative AI to create eye-catching and often bizarre images on 
social media – often sending viewers to online stores.
Jason Koebler, cofounder of 404 Media, has explored the “AI slop” economy  on Facebook. He suggests creators 
around the world are essentially “penetration testing” social media platforms to circumvent moderation policies and 
make money in new ways, building off content they know will capture attention. So-called “wellness secrets” fit the 
bill.
“That’s been the biggest effect of the generative AI boom,” he says. “The entire internet and social media platforms 
have been flooded with garbage.”
                   ‘Genuine’ O’Neill content finds an audience                   
For years, O’Neill and her husband, Michael O’Neill – the founder of the Informed Medical Options party (now the 
Heart party), which opposes water fluoridation and “No jab, no pay” immunisation requirements  – worked at the 
Misty Mountain health retreat in northern New South Wales.
She crisscrossed Australia giving health lectures, often in regional cities and outer suburbs such as Dandenong, 
SDA publications from the 2010s show. “Do you want better health?”, one ad from 2012 asked, indicating O’Neill 
would discuss high blood pressure and “overcoming depression”.
After a series of complaints in 2018 and 2019, the HCCC investigated some of her claims. The commission found  
that among her many claims was that cancer was caused by fungus and that it could be treated by “sodium 
bicarbonate wraps”.
Her comments about infant nutrition, antibiotics for pregnant women and vaccinations were also not based on 
evidence, the HCCC found, and she had “limited qualifications in the area of nutrition and dietetics”.
“Mrs O’Neill does not recognise that she is misleading vulnerable people (including mothers and cancer sufferers) 
by providing very selective information,” it concluded, and banned her permanently from providing any health 
services. The ban is enforceable in New South Wales, the ACT, Queensland and Victoria.
Misty Mountain lost its charity status  in 2021. Yet despite the restrictions she faces in Australia, O’Neill maintains a 
rigorous international touring schedule. In May, she hosted an eight-day retreat in Phuket, Thailand that was 
advertised as costing between US$2,979.80 (about A$4,500) and US$7,070.90.
A June event about childhood vaccinations run by an Australian anti-vaccine group advertised a “bonus zoom live 
with Barbara O’Neill” for about $180.
“I believe it is our role to get this message out to as many as possible,” O’Neill said in a recent online interview. 
“The ban has actually freed me. It freed me to go places I don’t think I ever would have gone.”
Seventh-day Adventist networks have helped O’Neill continue to share her message. She has spoken at retreats 
and conferences organised by SDA institutes and colleges, though not all are affiliated with official church 
leadership.
Page 3 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
A flyer for a multi-day event in September 2023 organised by the Mountaintop SDA church in Maryland, seen by 
Guardian Australia, said O’Neill would lecture on topics including “Cancer: Causes and Treatments” and 
“Safeguarding Against Depression”.
She has featured prominently  on media published by Amazing Discoveries, a channel that broadcasts messages 
on “health, creation-evolution, media, current events, Bible prophecy, history, and Christian living”.
“I do believe that Amazing Discoveries has certainly contributed to Barbara’s fame but we are definitely not solely 
responsible,” the executive director at Amazing Discoveries, Wendy Goubej, says. “The recent TikTok videos are I 
think what really catapulted her to prominence. It’s sad to see that there are people who are misquoting her and 
misusing her information for personal gain.”
The US General Conference of Seventh-day Adventists did not respond to a request for comment. A spokesperson 
for the church in Australia said O’Neill was not an employee and that the church had no involvement in her 
speaking engagements.
“In matters concerning health, the Seventh-day Adventist Church advises people to seek information and guidance 
from qualified and accredited healthcare professionals,” they said.
                   Fake posts take up the message                   
But publicity genuinely affiliated with O’Neill is dwarfed by the avalanche of scam posts on almost every major 
social media platform. Even as videos are taken down, new accounts and claims emerge.
In July, a Facebook ad used faked Channel Nine news footage to claim that O’Neill, an “Australian health coach”, 
had revealed a medicine that would heal “joint diseases” in three weeks. The page’s operator, with a Democratic 
Republic of Congo phone number, said over WhatsApp they had no idea where the video came from and they 
believed their page had been hacked. 
Other Facebook ads claim she has recommended everything from particular herbal salves to supplements that help 
men with impotence. An ad linked to a Dubai pharmacy claims she is “considered one of the best urologists in the 
world”.
One particularly unconvincing video merges faked video and audio of the former Fox News personality Tucker 
Carlson and O’Neill to promote eyedrops.
In late 2023, O’Neill’s team shared a video on her verified Instagram account addressing the deluge of fakes online. 
The post said that while she was grateful for fan pages that “faithfully share” her teachings, “it is important to clear 
up some misconceptions as people have been impersonating Barbara on social media and selling consultations 
and ‘cures’.” 
In August, her Facebook page again posted about the scams. “So many people still being tricked,” it read. “We are 
tagged in stories of people excited about purchasing fake items or products sold off fake AI videos.”
Tara Kirk Sell, a senior scholar at the Johns Hopkins Center for Health Security, says the phenomenon around 
O’Neill “shows the limit of regulatory powers”.
“I think that a lot of people are looking for easy solutions in this space: ‘if only we could take all this content off 
social media … the problem would be solved’.
“Well, it’s not that easy, right?”
A Meta spokesperson said the company was reviewing the Facebook ads flagged by Guardian Australia. “Meta 
adopts a multi-faceted approach to tackle scams,” he said. “We use both technology, such as new machine learning 
techniques, and specially trained reviewers to identify and action content and accounts that violate our policies.”
Page 4 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
A TikTok spokesperson said the platform did not allow impersonation accounts “or attempts to defraud or scam 
members”, and removed an account sharing generative AI images of O’Neill identified by the Guardian. “In 
Australia, between January and March 2024, we removed over 73,000 videos for violating our Frauds and Scams 
Policy, with 98% of these taken down proactively before anyone reported them,” they said.
An HCCC spokesperson said it could not comment on specific cases or speculate on potential complaints. “The 
global spread of health misinformation through social media is an ongoing concern for the commission,” he said.
O’Neill did not respond to requests for comment.
Load-Date: August 25, 2024
End of Document
Page 1 of 2
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Donald Trump, AI Artist
Donald Trump, AI Artist
Atlantic Online
August 23, 2024 Friday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 622 words
Byline: Damon Beres
Body
This is Atlantic Intelligence, a newsletter in which our writers help you wrap your mind around artificial intelligence 
and a new machine age. Sign up here.
The era of generative-AI propaganda is upon us. In the past week, Donald Trump has published fabricated images 
on his social-media accounts showing Kamala Harris speaking to a crowd of uniformed communists under the 
hammer and sickle, Taylor Swift in an Uncle Sam outfit, and young women in "Swifties for Trump" T-shirts. Other 
far-right influencers have published their own AI slop depicting Harris in degrading sexual contexts or glorifying 
Trump.
As my colleague Charlie Warzel writes for The Atlantic, "Although no one ideology has a monopoly on AI art, the 
high-resolution, low-budget look of generative-AI images appears to be fusing with the meme-loving aesthetic of the 
MAGA movement. At least in the fever swamps of social media, AI art is becoming MAGA-coded."
Such images are, in effect, an evolution of the memes that have long fueled the far right. But now even elementary 
Photoshop skills are no longer required: Simply plug a prompt into an image generator and within seconds, you'll 
have a reasonably lifelike JPEG for your posting pleasure.
"That these tools should end up as the medium of choice for Trump's political movement makes sense," Charlie 
writes. "It stands to reason that a politician who, for many years, has spun an unending series of lies into a 
patchwork alternate reality would gravitate toward a technology that allows one to, with a brief prompt, rewrite 
history so that it flatters him."
The MAGA Aesthetic Is AI Slop
By Charlie Warzel
Taylor Swift fans are not endorsing Donald Trump en masse. Kamala Harris did not give a speech at the 
Democratic National Convention to a sea of communists while standing in front of the hammer and sickle. Hillary 
Clinton was not recently seen walking around Chicago in a MAGA hat. But images of all these things exist.

Page 2 of 2
Donald Trump, AI Artist
In recent weeks, far-right corners of social media have been clogged with such depictions, created with generative-
AI tools 
This AI slop doesn't just exist in a vacuum of a particular social network: It leaves an ecological footprint of sorts on 
the web. The images are created, copied, shared, and embedded into websites; they are indexed into search 
engines. It's possible that, later on, AI-art tools will train on these distorted depictions, creating warped, digitally 
inbred representations of historical figures. The very existence of so much quickly produced fake imagery adds a 
layer of unreality to the internet.
Read the full article.
What to Read Next
  
• Silicon Valley is coming out in force against an AI-safety bill: This week, my colleague Caroline Mimbs 
Nyce spoke with California State Senator Scott Wiener, whose attempts to impose regulations on 
advanced AI models have been met with severe pushback-not just from tech companies, but from other 
Democrats, including Nancy Pelosi. "The opposition claims that the bill is focused on ~science-fiction 
risks,'" Wiener said. "They're trying to say that anyone who supports this bill is a doomer and is crazy. This 
bill is not about the Terminator risk. This bill is about huge harms that are quite tangible."
P.S.
Speaking of science fiction, I'm off to see Alien: Romulus tonight. Writing for The Atlantic about this film and the 
greater franchise to which it belongs, the journalist Fran Hoepfner noted, "The Alien films have always touched on 
heady, pessimistic visions of a future overrun by capitalism and genetic experimentation, but they're also movies 
about a human beating a monster-shooting it, setting it on fire, throwing it out of an air-locked door into the void of 
space." Sounds like a good Friday night to me.
- Damon
Load-Date: August 24, 2024
End of Document
Page 1 of 3
The MAGA Aesthetic Is AI Slop
The MAGA Aesthetic Is AI Slop
Atlantic Online
August 21, 2024 Wednesday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1298 words
Byline: Charlie Warzel
Body
Taylor Swift fans are not endorsing Donald Trump en masse. Kamala Harris did not give a speech at the 
Democratic National Convention to a sea of communists while standing in front of the hammer and sickle. Hillary 
Clinton was not recently seen walking around Chicago in a MAGA hat. But images of all these things exist.
In recent weeks, far-right corners of social media have been clogged with such depictions, created with generative-
AI tools. You can spot them right away, as they bear the technology's distinct image style: not-quite-but-almost 
photorealistic, frequently outrageous, not so dissimilar from a tabloid illustration. Donald Trump-or at least whoever 
controls his social-media accounts-posted the AI-generated photo of Harris with the hammer and sickle, as well as 
a series of fake images depicting Taylor Swift dressed as Uncle Sam and young women marching in Swifties for 
Trump shirts. (This after he falsely claimed that Harris had posted an image that had been "A.I.'d"-a tidy bit of 
projection.)
[Read: Why does AI art look like that?]
Trump himself has been the subject of generative-AI art and has shared depictions of himself going back to March 
2023. He's often dressed up as a gun-toting cowboy or in World War II fatigues, storming a beach. Yet these are 
anodyne compared with much of the material created and shared by far-right influencers and shitposters. There are 
plenty of mocking or degrading images of Harris and other female Democratic politicians, such as Alexandria 
Ocasio-Cortez. On X, one post that included a fake image in which Harris is implied to be a sex worker has been 
viewed more than 3.5 million times; on Facebook, that same post has been shared more than 87,000 times. One 
pro-Trump, Elon-Musk-fanboy account recently shared a suggestive image depicting a scantily clad Harris 
surrounded by multiple clones of Donald Trump; it's been viewed 1.6 million times. There are images and videos of 
Harris and Trump holding hands on a beach and Harris wearing a crown that reads Inflation Queen. On the first 
night of the DNC, MAGA influencers such as Catturd2 and Jack Posobiec supplemented their rage tweets about 
Democrats with stylized AI images of Tim Walz and Joe Biden looking enraged.

Page 2 of 3
The MAGA Aesthetic Is AI Slop
Although no one ideology has a monopoly on AI art, the high-resolution, low-budget look of generative-AI images 
appears to be fusing with the meme-loving aesthetic of the MAGA movement. At least in the fever swamps of social 
media, AI art is becoming MAGA-coded. The GOP is becoming the party of AI slop.
AI slop isn't, by nature, political. It is most prevalent on platforms such as Facebook, where click farmers and 
spammers create elaborate networks to flood pages and groups with cheap, fake images of starving children and 
Shrimp Jesus in the hopes of going viral, getting likes, and picking up "creator bonuses" for online engagement. 
Jason Koebler, a technology reporter who has spent the past year investigating Facebook's AI-slop economy, has 
described the deluge of artificial imagery as part of a "zombie internet" and "the end of a shared reality," where "a 
mix of bots, humans, and accounts that were once humans but aren't anymore interact to form a disastrous website 
where there is little social connection at all."
What's going on across the MAGA internet isn't exactly the same as Facebook's spam situation, although the vibe 
is similar. MAGA influencers may be shitposting AI photos for fun, but they're also engagement farming, especially 
on X, where premium subscribers can opt in to the platform's revenue-sharing program. Right-wing influencers 
have been vocal about these bonuses, which are handed out based on how many times a creator's content is seen 
in a given month. "Payout was huge. They've been getting bigger," Catturd2 posted this March, while praising 
Musk.
Although many of these influencers already have sizable followings, AI-image generators offer an inveterate poster 
the thing they need most: cheap, fast, on-demand fodder for content. Rather than peck out a few sentences 
complaining about Biden's age or ridiculing Harris's economic policies, far-right posters can illustrate their attacks 
and garner more attention. And it's only getting easier to do this: Last week, X incorporated the newest iteration of 
the generative-AI engine Grok, which operates with fewer guardrails than some competing models and has already 
conjured up untold illustrations of celebrities and politicians in compromising situations.  
[Read: Hot AI Jesus is huge on Facebook]
It's helpful to think of these photos and illustrations not as nefarious deepfakes or even hyper-persuasive 
propaganda, but as digital chum-Shrimp Jesus on the campaign trail. For now, little (if any) of what's being 
generated is convincing enough to fool voters, and most of it is being used to confirm the priors of true believers. 
Still, the glut of AI-created political imagery is a pollutant in a broader online information ecosystem. This AI slop 
doesn't just exist in a vacuum of a particular social network: It leaves an ecological footprint of sorts on the web. 
The images are created, copied, shared, and embedded into websites; they are indexed into search engines. It's 
possible that, later on, AI-art tools will train on these distorted depictions, creating warped, digitally inbred 
representations of historical figures. The very existence of so much quickly produced fake imagery adds a layer of 
unreality to the internet. You and I, like voters everywhere, must wade through this layer of junk, wearily separating 
out what's patently fake, what's real, and what exists in the murky middle.
In many ways, political slop is a logical end point for these image generators, which seem most useful for people 
trying to make a quick buck. Photography, illustration, and graphic design previously required skill or, at the very 
least, time to create something interesting enough to attract attention, which, online, can be converted into real 
money. Now free or easily affordable tools have flooded the market. What once took expert labor is now spam, 
powered by tools trained on the output of real artists and photographers. Spam is annoying, but ultimately easy to 
ignore-that is, until it collides with the negative incentives of social-media platforms, where it's used by political 
shitposters and hucksters. Then the images become something else. In the hands of Trump, they create small 
news cycles and narratives to be debunked. In the hands of influencers, they are fired at our timelines in a 
scattershot approach to attract a morsel of attention. As with the Facebook AI-slop farms, social media shock jocks 
churning out obviously fake, low-quality images don't care whether they're riling up real people, boring them, or 
creating fodder for bots and other spammers. It is engagement for engagement's sake. Mindlessly generated 
information chokes our information pathways, forcing consumers to do the work of discarding it.
That these tools should end up as the medium of choice for Trump's political movement makes sense, too. It stands 
to reason that a politician who, for many years, has spun an unending series of lies into a patchwork alternate 
Page 3 of 3
The MAGA Aesthetic Is AI Slop
reality would gravitate toward a technology that allows one to, with a brief prompt, rewrite history so that it flatters 
him. Just as it seems obvious that Trump's devoted followers-an extremely online group that has so fully embraced 
conspiracy theorizing and election denial that some of its members stormed the Capitol building-would delight in the 
bespoke memes and crude depictions of AI art. The MAGA movement has spent nine years building a coalition of 
conspiratorial hyper-partisans dedicated to creating a fictional information universe to cocoon themselves in. Now 
they can illustrate it.
Load-Date: August 22, 2024
End of Document
Page 1 of 2
Why the Popular Software Company Procreate Is Swearing Off Generative AI
Why the Popular Software Company Procreate Is Swearing Off Generative AI
Inc.com
August 19, 2024 Monday 15:57 PM EST
Copyright 2024 Mansueto Ventures, LLC All Rights Reserved
Length: 381 words
Byline: Ben Sherry
Body
Art and design company Procreate said artificial intelligence is 'ripping the humanity out of things.'
While technology firms scramble to take advantage of generative AI, one artist-friendly company is pushing in a 
decidedly different direction. Procreate, the company behind the popular art and design iPad app of the same 
name, has vowed to never introduce generative AI-powered features to its platform, writing in a statement that the 
technology is "ripping the humanity out of things."
In a video titled "we're never going there," posted to the Australia-based company's social channels, Procreate co-
founder and CEO James Cuda responded to questions about potential plans to implement generative AI features or 
use customers' work to train AI models. Adobe, one of Procreate's main competitors, recently announced plans to 
do both. Cuda, who started the company in 2011 with wife Alanna, said "I really f*cking hate generative AI," and 
announced that Procreate will not use the tech at all. 
"I don't like what's happening in the industry and I don't like what it's doing to artists," said Cuda, adding that "our 
products are always designed and developed with the idea that a human will be creating something."
In a statement shared to Procreate's website, the company wrote that generative AI is built on a foundation of theft. 
The company specified that it sees machine learning as a "compelling technology with a lot of merit, but the path 
generative AI is on is wrong for us." 
The company acknowledged that the decision "might make us an exception or seem at risk of being left behind," 
but affirmed their chosen path as being "the more exciting and fruitful one for our community." Procreate, which 
costs $13, has been one of the most popular digital art platforms on the iPad for over a decade, and has 
consistently been the top paid app on the iPad app store for more than seven years. 
On X, Ed Newton-Rex, CEO of genAI certification company Fairly Trained, wrote that he suspects more companies 
will come out against generative AI, "not just for legal/ethical reasons (though those are big)," he said, "but also 
because rejecting gen AI will be a signal of premium quality. In a world of AI-generated slop, platforms that keep 
themselves slop-free will stand out."
Link to Image

Page 2 of 2
Why the Popular Software Company Procreate Is Swearing Off Generative AI
Graphic
 
Photo: Getty Images
Load-Date: August 19, 2024
End of Document
Page 1 of 2
Ripple CTO highlights AI controversy over dangerous Mushroom identification book
Ripple CTO highlights AI controversy over dangerous Mushroom 
identification book
Newstex Blogs 
Cryptopolitan
August 18, 2024 Sunday 8:30 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 Cryptopolitan
Length: 431 words
Body
August 18th, 2024 (Cryptopolitan — Delivered by Newstex)
David Schwartz, Ripple's Chief Technology Officer, recently posted a viral Reddit post on his social media account, 
which tells the story of a family who was admitted to the hospital after consuming poisonous mushrooms, which 
they identified using an AI-generated book.
If this report is true, it's history repeating itself.https://t.co/UEVENXO72E  https://t.co/sjQgkATFqz— David 
"JoelKatz" Schwartz (@JoelKatz) 
August 17, 2024
According to the Reddit post, the family used a mushroom identification book they bought from a popular store. The 
post stated that the book provided images and text created by AI to identify the mushrooms, but all of them were 
poisonous. The family consumed the mushrooms with the help of the book written by the AI, and all of them were 
admitted to the hospital, which is a big question mark on the AI content. 
Ripple CTO draws parallels to historical lawsuit
The post also stated that not only there are AI pictures in the book but also Chatbot replies in the text of the book 
suggesting that no human had a hand in it. Even though the retailer has apparently provided a refund for the book, 
the issue has made people question whether there could be more low-quality books written by AI for sale. 
In his social media post, Schwartz compared this event to a well-known lawsuit that occurred at the beginning of the 
1990s. The Ripple executive cited Winter v. G.P. Putnam's Sons, a 1991 Court of Appeals case. The case points to 
two young adults who decided to purchase a book they named 'The Encyclopedia of Mushrooms' to act as a 
reference.
The couple was forced to seek legal intervention against P. Putnam's Sons for product liability, negligence, and 
false representation. Although the two mushroom hunters almost lost their lives because of the wrong information 
provided by the book, the court ruled in favor of the publisher. 

Page 2 of 2
Ripple CTO highlights AI controversy over dangerous Mushroom identification book
Identification guides face scrutiny over AI use
Schwartz's use of this case demonstrates how the use of AI in content creation is not a positive thing and has legal 
ramifications. Whether books generated by AI can be subjected to similar legal procedures as more and more 
content is being produced with the help of AI is still up for debate. 
Schwartz wrote an X post concerning Quora, a popular question-and-answer website. This is not the first time that 
the Ripple CTO has criticized this website and how AI is being used on it. In his post, Schwartz highlighted some of 
the issues with the questions that Quora's AI-generated, which he referred to as 'AI-generated slop.' 
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: August 18, 2024
End of Document
Page 1 of 2
In a word: This week's column: 'the ick' or a 'boop'?
In a word: This week's column: 'the ick' or a 'boop'?
Sunjournal.com 
August 18, 2024 Sunday
Copyright 2024 Lewiston Sun Journal  All Rights Reserved
Length: 625 words
Byline: By Jim Witherell Special to the Sun Journal
Body
Recently the lexicographers at the Cambridge Dictionary added 3,236 new words and phrases to their list of 
searchable words (as well as myriad new meanings of existing words). This news should be enough to excite word 
lovers everywhere or at least be enough to keep them interested in reading the next few hundred words, I hope - so 
let's jump right in.
Let's start by looking at how new words are selected for inclusion in the tome. According to Cambridge Dictionary 
Publishing Manager Wendalyn Nichols, "Some new terms are added very quickly and others can take some time. 
We try to identify words and uses that have proven staying power, rather than adding ones that might be short-
lived."
Here are a few of the words that made the cut this time, beginning with "the ick," which is defined as "a sudden 
feeling that you dislike someone or something or are no longer attracted to someone because of something they 
do."
On the other hand, a "boop" is one way of showing someone that you like them, and is accomplished by simply 
touching that person - or thing - gently on the head with your finger.
Another way of showing affection is by "pebbling," which is the act of showing appreciation for someone by sending 
them small gifts, such as memes, videos, or links, that they think the other person would enjoy. The term, it's said, 
comes from gentoo penguins, which give pebbles to potential mates as part of their courtship rituals.
One way to tell if your pebbles were well received is to wait for the recipient to give you a "chef's kiss," which is a 
movement in which they put their fingers and thumb together, kiss them, then pull their hand away from their lips.

Page 2 of 2
In a word: This week's column: 'the ick' or a 'boop'?
If no chef's kiss is forthcoming, you might want to study their "face journey," defined as "a series of expressions that 
appear on someone's face showing different emotions that they are experiencing as a reaction to something."
"We also collect evidence of new words that have only appeared in English very recently," said Nichols. But exactly 
how do the Cambridge editors know which newer words are worthy of being included in the dictionary? It turns out 
that they make use of a blog called "About words" that helps them decide.
On the blog, visitors are asked for their opinions on whether or not certain words and phrases are worthy of being 
included in the Cambridge Dictionary. The three choices people have are: "Yes! I've heard/read this a lot," 
"Definitely not!" and "Let's wait and see. Maybe people will start using it."
One candidate for inclusion is the phrase "Generation T," which is a way of referring to "a group of people who were 
born in the early 2000s and who spend a lot of their free time traveling." Another hopeful is a new definition of 
"slop" -  "AI-generated content that is unwanted and is of poor quality."
If you work in an office, have you ever been guilty of "mouse jiggling," which is another candidate. It's "the activity of 
making one's computer mouse move at regular intervals . . . in order to make your employer think you are working."
And if there's a good reason for that mouse jiggling that you're doing, it might be because your boss has burdened 
you with too many "vampire tasks," which are all those "routine but necessary administrative tasks" that take time 
away from doing the important stuff.
"Lexicographers," explained Nichols, "use the Cambridge English Corpus, a collection of more than 2 billion written 
and spoken English words, to gather evidence for how a new word is used by different people and in a variety of 
situations." That's a lot of words!
Jim Witherell of Lewiston is a writer and lover of words whose work includes "L.L. Bean: The Man and His 
Company" and "Ed Muskie: Made in Maine." He can be reached at jlwitherell19@gmail.com
Load-Date: October 8, 2024
End of Document
Page 1 of 3
Why Does AI Art Look Like That?
Why Does AI Art Look Like That?
Atlantic Online
August 16, 2024 Friday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1530 words
Byline: Caroline Mimbs Nyce
Body
This week, X launched an AI-image generator, allowing paying subscribers of Elon Musk's social platform to make 
their own art. So-naturally-some users appear to have immediately made images of Donald Trump flying a plane 
toward the World Trade Center; Mickey Mouse wielding an assault rifle, and another of him enjoying a cigarette and 
some beer on the beach; and so on. Some of the images that people have created using the tool are deeply 
unsettling; others are just strange, or even kind of funny. They depict wildly different scenarios and characters. But 
somehow they all kind of look alike, bearing unmistakable hallmarks of AI art that have cropped up in recent years 
thanks to products such as Midjourney and DALL-E.  
Two years into the generative-AI boom, these programs' creations seem more technically advanced-the Trump 
image looks better than, say, a similarly distasteful one of SpongeBob SquarePants that Microsoft's Bing Image 
Creator generated last October-but they are stuck with a distinct aesthetic. The colors are bright and saturated, the 
people are beautiful, and the lighting is dramatic. Much of the imagery appears blurred or airbrushed, carefully 
smoothed like frosting on a wedding cake. At times, the visuals look exaggerated. (And yes, there are frequently 
errors, such as extra fingers.) A user can get around this algorithmic monotony by using more specific prompts-for 
example, by typing a picture of a dog riding a horse in the style of Andy Warhol rather than just a picture of a dog 
riding a horse. But when a person fails to specify, these tools seem to default to an odd blend of cartoon and 
dreamscape.
These programs are becoming more common. Google just announced a new AI-image-making app called Pixel 
Studio that will allow people to make such art on their Pixel phone. The app will come preinstalled on all of the 
company's latest devices. Apple will launch Image Playground as part of its Apple Intelligence suite of AI tools later 
this year. OpenAI now allows ChatGPT users to generate two free images a day from DALL-E 3, its newest text-to-
image model. (Previously, a user needed a paid premium plan to access the tool.) And so I wanted to understand: 
Why does so much AI art look the same?
[Read: AI has a hotness problem]

Page 2 of 3
Why Does AI Art Look Like That?
The AI companies themselves aren't particularly forthcoming. X sent back a form email in response to a request for 
comment about its new product and the images its users are creating. Four firms behind popular image generators-
OpenAI, Google, Stability AI, and Midjourney-either did not respond or did not provide comment. A Microsoft 
spokesperson directed me toward some of its prompting guides and referred any technical questions to OpenAI, 
because Microsoft uses a version of DALL-E in products such as Bing Image Creator.
So I turned to outside experts, who gave me four possible explanations. The first focuses on the data that models 
are trained on. Text-to-image generators rely on extensive libraries of photos paired with text descriptions, which 
they then use to create their own original imagery. The tools may inadvertently pick up on any biases in their data 
sets-whether that's racial or gender bias, or something as simple as bright colors and good lighting. The internet is 
filled with decades of filtered and artificially brightened photos, as well as a ton of ethereal illustrations. "We see a 
lot of fantasy-style art and stock photography, which then trickles into the models themselves," Zivvy Epstein, a 
scientist at the Stanford Institute for Human-Centered AI, told me. There are also only so many good data sets 
available for people to use to build image models, Phillip Isola, a professor at the MIT Computer Science &amp; 
Artificial Intelligence Laboratory, told me, meaning the models might overlap in what they're trained on. (One 
popular one, CelebA, features 200,000 labeled photos of celebrities. Another, LAION 5B, is an open-source option 
featuring 5.8 billion pairs of photos and text.)
The second explanation has to do with the technology itself. Most modern models use a technique called diffusion: 
During training, models are taught to add "noise" to existing images, which are paired with text descriptions. "Think 
of it as TV static," Apolin¡rio Passos, a machine-learning art engineer at Hugging Face, a company that makes its 
own open-source models, told me. The model then is trained to remove this noise, over and over, for tens of 
thousands, if not millions, of images. The process repeats itself, and the model learns how to de-noise an image. 
Eventually, it's able to take this static and create an original image from it. All it needs is a text prompt.
[Read: Generative art is stupid]
Many companies use this technique. "These models are, I think, all technically quite alike," Isola said, noting that 
recent tools are based on the transformer model. Perhaps this technology is biased toward a specific look. Take an 
example from the not-so-distant past: Five years ago, he explained, image generators tended to create really blurry 
outputs. Researchers realized that it was the result of a mathematical fluke; the models were essentially averaging 
all the images they were trained on. Averaging, it turns out, "looks like blur." It's possible that, today, something 
similarly technical is happening with this generation of image models that leads them to plop out the same kind of 
dramatic, highly stylized imagery-but researchers haven't quite figured it out yet. Additionally, "most models have an 
~aesthetic' filter on both the input and output that reject images that don't meet a certain aesthetic criteria," Hany 
Farid,  a professor at the UC Berkeley School of Information, told me over email. "This type of filtering on the input 
and output is almost certainly a big part of why AI-generated images all have a certain ethereal quality."
The third theory revolves around the humans who use these tools. Some of these sophisticated models incorporate 
human feedback; they learn as they go. This could be by taking in a signal, such as which photos are downloaded. 
Others, Isola explained, have trainers manually rate which photos they like and which ones they don't. Perhaps this 
feedback is making its way into the model. If people are downloading art that tends to have really dramatic sunsets 
and absurdly beautiful oceanscapes, then the tools might be learning that that's what humans want, and then giving 
them more of that. Alexandru Costin, a vice president of generative AI at Adobe, and Zeke Koch, a vice president of 
product management for Adobe Firefly (the company's AI-image tool) told me in an email that user feedback can 
indeed be a factor for some AI models-a process called "reinforcement learning from human feedback," or RLHF. 
They also pointed to training data as well as assessments performed by human evaluators as influencing factors. 
"Art generated by AI models sometimes have a distinct look (especially when created using simple prompts)," they 
said in a statement. "That's generally caused by a combination of the images used to train the image output and the 
tastes of those who train or evaluate the images."
The fourth theory has to do with the creators of these tools. Although representatives for Adobe told me that their 
company does not do anything to encourage a specific aesthetic, it is possible that other AI makers have picked up 
on human preference and coded that in-essentially putting their thumb on the scale, telling the models to make 
Page 3 of 3
Why Does AI Art Look Like That?
more dreamy beach scenes and fairylike women. This could be intentional: If such imagery has a market, maybe 
companies would begin to converge around it. Or it could be unintentional; companies do lots of manual work in 
their models to combat bias, for example, and various tweaks favoring one kind of imagery over another could 
inadvertently result in a particular look.
More than one of these explanations could be true. In fact, that's probably what's happening: Experts told me that, 
most likely, the style we see is caused by multiple factors at once. Ironically, all of these explanations suggest that 
the uncanny scenes we associate with AI-generated imagery are actually a reflection of our own human 
preferences, taken to an extreme. No surprise, then, that Facebook is filled with AI-generated slop imagery that 
earns creators money, that Etsy recently asked users to label products made with AI following a surge of junk 
listings, and that the arts-and-craft store Michaels recently got caught selling a canvas featuring an image that was 
partially generated by AI (the company pulled the product, calling this an "unacceptable error.").
[Read: AI-generated junk is flooding Etsy]
AI imagery is poised to seep even further into everyday life. For now, such art is usually visually distinct enough that 
people can tell it was made by a machine. But that may change. The technology could get better. Passos told me 
he sees "an attempt to diverge from" the current aesthetic "on newer models." Indeed, someday computer-
generated art may shed its weird, cartoonish look, and start to slip past us unnoticed. Perhaps then we'll miss the 
corny style that was once a dead giveaway.
Load-Date: August 17, 2024
End of Document
Page 1 of 2
=======
>>>>>>> c98f417 (update data file):extract_text.txt
Twitter page gains thousands of followers for making fun of Facebook posts
Twitter page gains thousands of followers for making fun of Facebook posts
CE Noticias Financieras English
August 14, 2024 Wednesday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 CE Noticias Financieras All Rights Reserved
Length: 372 words
Body
Anyone who has an account on a social network knows that each platform has its own particularities, which means 
that its audience is also unique. In a "crossover", a profile on X (old) has been successful for making fun of bizarre 
posts made using images generated by artificial intelligence.
Théodore Cazals, 19, is a French student living in Paris and the creator of the profile "Insane Facebook AI slop" 
(low-quality madness made by artificial intelligence on Facebook, in free translation), which already has more than 
100,000 followers since its creation in April.
The images published on Mark Zuckerberg's network are generally appealing and stir users' empathy and 
superstition because they portray sad situations, despite being unrealistic. They are also accompanied by phrases 
that encourage user engagement. Prints of these posts ended up on X as a joke.
The page came about when Théodore Cazals realized that this type of post generated a lot of engagement on X. 
Although he is the only one behind the profile, there is collaboration from followers, who send suggestions by 
private message.
According to Cazals, the aim of the page is to show a side of Facebook that many X users don't know about. In 
addition, the young Frenchman suggests that the content helps his followers to know what less tech-savvy relatives 
are consuming - and believing - on the social network.
The Frenchman says that the page didn't gain many followers in its first month, but has grown a lot recently. "The 
ridiculous aspect of the images and the fact that they mock less technologically literate people is what makes it so 
successful," he says.
Cazals has come to see the page as a product that could be worth something in the future. He explains that if this 
type of content no longer engages, he intends to change the name and subject matter in order to make the most of 
the space with the followers he has already gained.
Here are the main posts from X's @FacebookAIslop page, formerly Twitter:
"I'm poor. Who loves me?"
"The biggest fish in the whole world"
"Incredible photo of a truck full of babies"
"Why do images like this never go viral?"
"When Peter Griffin visited Africa to donate food"
"Today is my birthday"
"Nobody loves me because I'm poor"

Page 2 of 2
Twitter page gains thousands of followers for making fun of Facebook posts
Load-Date: August 15, 2024
End of Document
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Page 1 of 2
Generative AI's Slop Era
Generative AI's Slop Era
Atlantic Online
August 9, 2024 Friday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 563 words
Byline: Damon Beres
Body
This is Atlantic Intelligence, a newsletter in which our writers help you wrap your mind around artificial intelligence 
and a new machine age. Sign up here.
Tech companies believe that generative AI can transform how we find information online, replacing traditional 
search engines with bots that synthesize knowledge into a more interactive format. Rather than clicking a series of 
links, reading a variety of sources, and then determining an answer for yourself, you might instead have a 
conversation with a search bot that has effectively done the reading for you. Companies such as OpenAI, 
Perplexity, and Google are bringing such tools to market: As my colleague Matteo Wong wrote in a recent story for 
The Atlantic, "The generative-AI search wars are in full swing."
As part of his reporting, Matteo spoke with Dmitry Shevelenko, Perplexity's chief business officer. In particular, the 
two discussed the media partnerships that have been signed by Perplexity and other AI firms to support their 
search projects. These deals give media companies compensation for allowing their material to be used by 
generative-AI tools; The Atlantic, for example, has signed a contract with OpenAI that may, among other things, 
show our articles to users of the new SearchGPT tool. (The editorial division of The Atlantic operates independently 
from the business division, which announced its corporate partnership with OpenAI in May.)
I found two of Shevelenko's quotes especially striking. First: "One of the key ingredients for our long-term success 
is that we need web publishers to keep creating great journalism that is loaded up with facts, because you can't 
answer questions well if you don't have accurate source material." And second: "Journalists' content is rich in facts, 
verified knowledge, and that is the utility function it plays to an AI answer engine." Each statement seemed to 
betray an attitude that the creative output of humanity amounts to little more than fodder-which seems particularly 
grim in light of what we know about how AI is trained on tremendous amounts of copyrighted material without 
consent, and how these tools have a tendency to present users with false information. Or as I put it last year: "At its 
core, generative AI cannot distinguish original journalism from any other bit of writing; to the machine, it's all slop 
pushed through the pipes and splattered out the other end."
The AI Search War Has Begun

Page 2 of 2
Generative AI's Slop Era
By Matteo Wong
Every second of every day, people across the world type tens of thousands of queries into Google, adding up to 
trillions of searches a year. Google and a few other search engines are the portal through which several billion 
people navigate the internet. Many of the world's most powerful tech companies, including Google, Microsoft, and 
OpenAI, have recently spotted an opportunity to remake that gateway with generative AI, and they are racing to 
seize it. And as of this week, the generative-AI search wars are in full swing.
Read the full article.
What to Read Next
  
• Bing is a trap: "Tech companies say AI will expand the possibilities of searching the internet. So far, the 
opposite seems to be true," I wrote last year.
P.S.
The future of search bots may depend on recent copyright lawsuits against generative-AI companies. Earlier this 
year, Alex Reisner wrote a great article for The Atlantic exploring what's at stake.
- Damon
Load-Date: August 10, 2024
End of Document
Page 1 of 2
FTAV’s further reading
FTAV’s further reading
 
FT.com
August 8, 2024 Thursday
Copyright 2024 The Financial Times Ltd. All Rights Reserved Please do not cut and paste FT articles and redistribute by email or post to the 
web.
Length: 90 words
Byline: Bryce Elder
Body
Elsewhere on Thursday . . . 
—  The banker has no clothes, part three (Rupak Ghose)
— Sahm: My recession rule was meant to be broken (Bloomberg  $)
—  Intel, the weak link in the chip strategy of Bidenomics (Chartbook) 
—  America’s deficit attention disorder (Project Syndicate)
—  Where Facebook’s AI slop comes from (404 Media)
—  The empathy punishment (Grub Street, New York  $)
—  Artists and Activists Both Have a Role. But Not the Same One (New York Times  $)
—  The bizarre secrets I found investigating corrupt Winamp skins (Jordan Eldredge)
Load-Date: August 8, 2024

Page 2 of 2
FTAV’s further reading
End of Document
Page 1 of 1
FTAV’s further reading
FTAV’s further reading
FT.com Headlines
FT.com Headlines
https://www.ft.com/content/267e8469-bb77-45c6-8dab-b62c6600b4e6
August 8, 2024 Thursday
Length: 99 words
Body
Elsewhere on Thursday . . . — The banker has no cloth...
End of Document

Page 1 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
‘Hold on to your seats’: how much will AI affect the art of film-making?
The Guardian (London)
July 27, 2024 Saturday 10:07 AM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: FILM; Version:1
Length: 2214 words
Byline: Adrian Horton
Highlight: The future is here, whether some like it or not, and artificial intelligence is already impacting the film 
industry. But just how far can, and should, it go?
Body
Last year, Rachel Antell, an archival producer for documentary films, started noticing AI-generated images mixed in 
with authentic photos. There are always holes or limitations in an archive; in one case, film-makers got around a 
shortage of images for a barely photographed 19th-century woman by using AI to generate what looked like old 
photos. Which brought up the question: should they? And if they did, what sort of transparency is required? The 
capability and availability of generative AI – the type that can produce text, images and video – have changed so 
rapidly, and the conversations around it have been so fraught, that film-makers’ ability to use it far outpaces any 
consensus on how.
“We realized it was kind of the wild west, and film-makers without any mal-intent were getting themselves into 
situations where they could be misleading to an audience,” said Antell. “And we thought, what’s needed here is 
some real guidance.”
So Antell and several colleagues formed the Archival Producers Alliance (APA), a volunteer group of about 300 
documentary producers and researchers dedicated to, in part, developing best practices for use of generative AI in 
factual storytelling. “Instead of being, ‘the house is burning, we’ll never have jobs,’ it’s much more based around an 
affirmation of why we got into this in the first place,” said Stephanie Jenkins, a founding APA member. Experienced 
documentary film-makers have “really been wrestling with this”, in part because “there is so much out there about 
AI that is so confusing and so devastating or, alternatively, a lot of snake oil.”
The group, which published an open letter  warning against “forever muddying the historical record” through 
generative AI and released a draft set of guidelines  this spring, is one of the more organized efforts in Hollywood to 
grapple with the ethics of a technology that, for all the bullish or doomsday prophesying, is already here and 
shaping the industry. Short of regulation or relevant union agreements, it has come down to film-makers – directors, 
producers, writers, visual effects and VFX artists and more – to figure out how to use it, where to draw the line and 

Page 2 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
how to adapt. “It’s a project by project basis” for “use cases and the ethical implications of AI”, said Jim Geduldick, a 
VFX supervisor and cinematographer who has worked on Masters of the Air, Disney’s live-action Pinocchio and the 
upcoming Robert Zemeckis film Here , which uses AI to de-age  its stars Tom Hanks and Robin Wright. 
“Everybody’s using it. Everybody’s playing with it.”
Some of the industry’s adoption of AI has been quiet – for years, studios and tech companies with entertainment 
arms have already engaged in a tacit machine learning arms race.  Others have embraced the technology 
enthusiastically and optimistically; Runway, an AI research company , hosted its second annual AI Film Festival  in 
New York and Los Angeles this spring, with presenting partners in the Television Academy and the Tribeca 
Festival. The latter featured five short films made by OpenAI’s Sora , the text-to-video model yet to be released to 
the public that prompted the film mogul Tyler Perry to halt an $800m expansion of his studios  in Atlanta because 
“jobs are going to be lost”.
The industry’s embrace has engendered plenty of pushback. Last month, in response to Tribeca and other nascent 
AI film festivals, the director of Violet, Justine Bateman, announced  a “raw and real”, no-AI-allowed film festival for 
spring 2025, which “creates a tunnel for human artists through the theft-based, job-replacing AI destruction”. And in 
the year since the dual actors and writers’ strikes secured landmark protections against the use of generative AI to 
replace jobs or steal likenesses, numerous non-protected instances of AI have drawn attention and scorn online. 
Concerns about job and quality loss surrounded AI-generated images in A24 promotional posters for the film Civil 
War , interstitials in the horror film Late Night with the Devil  and a fake band poster in True Detective: Night 
Country.  The alleged use of AI-generated archival photos in the Netflix documentary What Jennifer Did  reignited 
discussions about documentary ethics first sparked by similar outcry  over three lines of AI-generated narration  to 
mimic Anthony Bourdain in the 2021 film Roadrunner. And that’s not to mention all of the bemoaning of disposable 
AI filler content  – or “ slop  ”, as the parlance goes – clogging up our social media feeds.
Taken together, the burgeoning use of generative AI in media can feel overwhelming – before the ink is dry on any 
new proclamation about it, the ground has shifted again. On an individual level, film artists are figuring out whether 
to embrace the technology now, how to use it and where their craft is headed. It has already rendered dubbing and 
translation work nearly obsolete.  Visual effects artists, perennially on the bleeding edge of new technology for 
Hollywood, are already working with machine learning and some generative AI, particularly for pre-production 
visualizations and workflows. “From an artist’s perspective, we’re all trying to get ahead of the game and play with 
open source tools that are available,” said Kathryn Brillhart, a cinematographer and director whose credits include 
The Mandalorian, Black Adam and Fallout.
Both Geduldick and Brillhart noted numerous limitations on the use of generative AI in film projects at this point – 
for one, the security of these platforms, especially for big studios worried about leaks or hacks. There’s the legal 
liability and ethics of the current generative AI models, which to date have trained on scraped data. “Some studios 
are like, ‘We don’t even feel comfortable using gen AI in storyboards and concept art, because we don’t want a hint 
of any theft or licensing issues to come through in the final,’” said Brillhart. Studio films that do employ AI have 
limited uses and a clear data trail – in the case of Zemeckis’s Here, the new de-aging and face replacement tech, 
designed by the AI firm Metaphysic and the Hollywood agency CAA, uses the faces of Hanks and Wright, famous 
actors who have signed on to the roles, to play characters over the course of 50 years.  “I’ve always been attracted 
to technology that helps me to tell a story,” Zemeckis said  in 2023 of his decision to use Metaphysic. “With Here, 
the film simply wouldn’t work without our actors seamlessly transforming into younger versions of themselves. 
Metaphysic’s AI tools do exactly that, in ways that were previously impossible!”
And then there’s the output of generative AI, which often plunges deep into the uncanny valley and leaves much to 
be desired. (Or, in the words  of the AI skeptic David Fincher, “it always looks like sort of a low-rent version of 
Roger Deakins”). Geduldick, who has integrated AI into his workflow, sees current generative AI models as more 
“assistive” than truly imitative of human art. “Are they implementing generative models that are going to speed up 
both the business and the creative side of what we’re doing? Yes,” he said. “But I think that there is no generative 
model out there today that doesn’t get touched by artistic hands to get it to the next level. That is for the foreseeable 
future.”
Page 3 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
Still, like the digital revolution before it, the one certainty about generative AI is that it will change the field of visual 
effects – making pre-visualization cheaper and more efficient, streamlining tedious processes, shaping storyboard 
design. As the work shifts, “I think everybody needs to pivot,” said Geduldick.
“The craft has gone from hand-making models to using a mouse to now using text and using your brain in different 
ways,” said Brillhart. “What’s going to happen is more of a forced learning curve,” she added. “I think there’s going 
to be growing pains, for sure.”
On the documentary side, generative AI opens new opportunities for nonfiction storytelling, though also threatens 
trust. “All technology has a kind of a dual moral purpose. And it’s up to us to interrogate the technology to find the 
way to use it for good,” said David France, an investigative journalist and film-maker whose 2020 documentary 
Welcome to Chechnya  is one of a handful in recent years to employ generative AI as an anonymization device. 
The film, which follows the state-sanctioned persecution of LGBTQ+ people in the Russian republic, used AI to map 
actors’ faces over real subjects who faced harrowing violence. France and his team tried several different methods 
to get around risking exposure; nothing worked cinematically, until trying the equivalent of deepfake technology, 
though with multi-step processes of consent and clear limitations. “We realized that we had an opportunity to really 
empower the people whose stories we were telling, to tell their stories directly to the audience and be faithful in their 
kind of emotional presentation,” said France.
The film-makers Reuben Hamlyn and Sophie Compton employed a similar technique for the subjects of their film 
Another Body , who were the victims of nonconsensual, deepfake pornography. Their main subject, “Taylor”, 
communicates through a digital veil – like deepfakes, an AI-generated face that interprets her real expressions 
through different features.
Along with demonstrating the convincing, uncanny power of the technology that someone used to target Taylor, the 
AI translated “every minute facial gesture”, said Hamlyn. “That emotional truth is retained in a way that is impossible 
even with silhouetting.”
“It’s such an important tool in empowering people to share their story,” he added.
Crucially, both Welcome to Chechnya and Another Body clue their audiences to the technology through implicit or 
explicit tells. That’s in line with the best practices put forth by the Archival Producers Alliance, to avoid what has 
landed other films in hot water – namely Roadrunner , whose use of AI was revealed in the New Yorker  after the 
film’s release. The group also encourages documentary film-makers to rely on primary sources whenever possible; 
to think through algorithmic biases produced by the model’s training data; to be as intentional with generative AI as 
they would with re-enactments; and consider how synthetic material, released in the world, could cloud the 
historical record.
“We never say don’t do it,” said Jenkins, the APA member, but instead “think about what you’re saying when you 
use this new material and how it will come across to your audience. There is something really special about the 
human voice and the human face, and you want to engage with [generative AI] in a way that is intentional and 
doesn’t fall into some sort of manipulation.”
That line between human and machine is perhaps the most fraught one in Hollywood at the moment, in flux and 
uncertain. Compton, the co-director of Another Body, sees the emotionally loaded debates around AI as a series of 
smaller, more manageable questions involving pre-existing industry issues. “There are genuinely existential aspects 
of this discussion, but in terms of film and AI, we’re not really talking about those things,” she said. “We’re not 
talking about killer robots. What we are talking about is consent, and what is the dataset that’s being used, and 
whose jobs are on the line if this is adopted massively.”
Geduldick, an optimist on the assistive uses of generative AI, nevertheless sees a gap between its day-to-day 
applications, tech companies’ lofty rhetoric, and “soulless” AI content produced for content’s sake. Companies such 
as OpenAI – whose chief technology officer recently said  generative AI might eliminate some creative jobs, “but 
maybe they shouldn’t have been there in the first place” – have “repeatedly shown in their public-facing interviews 
or marketing that there’s a disconnect [in] understanding what creatives actually do,” he said. “Film-making is a 
Page 4 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
collaborative thing. You are hiring loads of talented artists, technicians, craftspeople to come together and create 
this vision that the writers, director, showrunners and producers have thought up.”
For now, according to Geduldick, the “hype outweighs the practical applications” of generative AI, but that does not 
obviate the need for regulation from the top, or for guidelines for those already using it. “The potential for it to be 
cinematic is really great,” said France. “I don’t know yet that we’ve seen anybody solve the ethical problem of how 
to use it.”
In the meantime, film-making, both feature and nonfiction, is at a fluid, amorphous crossroads. Generative AI is 
here – part potential, part application, part daunting, part exciting and, to many, a tool. There will likely be more AI 
film festivals, more backlash, more and more AI content creation – for better or for worse. There are already whole 
AI-generated streaming services , should you choose to generate your own content. How the human element will 
fare remains an open question – according to a recent Deloitte study , a surprising 22% of Americans thought 
generative AI could write more interesting TV shows or movies than people.
The only certainty, at this point, is that AI will be used, and the industry will change as a result. “This will be in films 
that are coming out,” said Jenkins. “So hold on to your seats.”
Load-Date: July 27, 2024
End of Document
Page 1 of 3
AI's Real Hallucination Problem
AI's Real Hallucination Problem
Atlantic Online
July 24, 2024 Wednesday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1703 words
Byline: Charlie Warzel
Body
Two years ago, OpenAI released the public beta of DALL-E 2, an image-generation tool that immediately signified 
that we'd entered a new technological era. Trained off a huge body of data, DALL-E 2 produced unsettlingly good, 
delightful, and frequently unexpected outputs; my Twitter feed filled up with images derived from prompts such as 
close-up photo of brushing teeth with toothbrush covered with nacho cheese. Suddenly, it seemed as though 
machines could create just about anything in response to simple prompts.
You likely know the story from there: A few months later, ChatGPT arrived, millions of people started using it, the 
student essay was pronounced dead, Web3 entrepreneurs nearly broke their ankles scrambling to pivot their 
companies to AI, and the technology industry was consumed by hype. The generative-AI revolution began in 
earnest.
Where has it gotten us? Although enthusiasts eagerly use the technology to boost productivity and automate 
busywork, the drawbacks are also impossible to ignore. Social networks such as Facebook have been flooded with 
bizarre AI-generated slop images; search engines are floundering, trying to index an internet awash in hastily 
assembled, chatbot-written articles. Generative AI, we know for sure now, has been trained without permission on 
copyrighted media, which makes it all the more galling that the technology is competing against creative people for 
jobs and online attention; a backlash against AI companies scraping the internet for training data is in full swing.
Yet these companies, emboldened by the success of their products and the war chests of investor capital, have 
brushed these problems aside and unapologetically embraced a manifest-destiny attitude toward their technologies. 
Some of these firms are, in no uncertain terms, trying to rewrite the rules of society by doing whatever they can to 
create a godlike superintelligence (also known as artificial general intelligence, or AGI). Others seem more 
interested in using generative AI to build tools that repurpose others' creative work with little to no citation. In recent 
months, leaders within the AI industry are more brazenly expressing a paternalistic attitude about how the future will 
look-including who will win (those who embrace their technology) and who will be left behind (those who do not). 

Page 2 of 3
AI's Real Hallucination Problem
They're not asking us; they're telling us. As the journalist Joss Fong commented recently, "There's an audacity 
crisis happening in California."
There are material concerns to contend with here. It is audacious to massively jeopardize your net-zero climate 
commitment in favor of advancing a technology that has told people to eat rocks, yet Google appears to have done 
just that, according to its latest environmental report. (In an emailed statement, a Google spokesperson, Corina 
Standiford, said that the company remains "dedicated to the sustainability goals we've set," including reaching net-
zero emissions by 2030. According to the report, its emissions grew 13 percent in 2023, in large part because of the 
energy demands of generative AI.) And it is certainly audacious for companies such as Perplexity to use third-party 
tools to harvest information while ignoring long-standing online protocols that prevent websites from being scraped 
and having their content stolen.
But I've found the rhetoric from AI leaders to be especially exasperating. This month, I spoke with OpenAI CEO 
Sam Altman and Thrive Global CEO Arianna Huffington after they announced their intention to build an AI health 
coach. The pair explicitly compared their nonexistent product to the New Deal. (They suggested that their product-
so theoretical, they could not tell me whether it would be an app or not-could quickly become part of the health-care 
system's critical infrastructure.) But this audacity is about more than just grandiose press releases. In an interview 
at Dartmouth College last month, OpenAI's chief technology officer, Mira Murati, discussed AI's effects on labor, 
saying that, as a result of generative AI, "some creative jobs maybe will go away, but maybe they shouldn't have 
been there in the first place." She added later that "strictly repetitive" jobs are also likely on the chopping block. Her 
candor appears emblematic of OpenAI's very mission, which straightforwardly seeks to develop an intelligence 
capable of "turbocharging the global economy." Jobs that can be replaced, her words suggested, aren't just 
unworthy: They should never have existed. In the long arc of technological change, this may be true-human 
operators of elevators, traffic signals, and telephones eventually gave way to automation-but that doesn't mean that 
catastrophic job loss across several industries simultaneously is economically or morally acceptable.
[Read: AI has become a technology of faith]
Along these lines, Altman has said that generative AI will "create entirely new jobs." Other tech boosters have said 
the same. But if you listen closely, their language is cold and unsettling, offering insight into the kinds of labor that 
these people value-and, by extension, the kinds that they don't. Altman has spoken of AGI possibly replacing the 
"the median human" worker's labor-giving the impression that the least exceptional among us might be sacrificed in 
the name of progress.
Even some inside the industry have expressed alarm at those in charge of this technology's future. Last month, 
Leopold Aschenbrenner, a former OpenAI employee, wrote a 165-page essay series warning readers about what's 
being built in San Francisco. "Few have the faintest glimmer of what is about to hit them," Aschenbrenner, who was 
reportedly fired this year for leaking company information, wrote. In Aschenbrenner's reckoning, he and "perhaps a 
few hundred people, most of them in San Francisco and the AI labs," have the "situational awareness" to anticipate 
the future, which will be marked by the arrival of AGI, geopolitical struggle, and radical cultural and economic 
change.
Aschenbrenner's manifesto is a useful document in that it articulates how the architects of this technology see 
themselves: a small group of people bound together by their intellect, skill sets, and fate to help decide the shape of 
the future. Yet to read his treatise is to feel not FOMO, but alienation. The civilizational struggle he depicts bears 
little resemblance to the AI that the rest of us can see. "The fate of the world rests on these people," he writes of the 
Silicon Valley cohort building AI systems. This is not a call to action or a proposal for input; it's a statement of who 
is in charge.
Unlike me, Aschenbrenner believes that a superintelligence is coming, and coming soon. His treatise contains quite 
a bit of grand speculation about the potential for AI models to drastically improve from here. (Skeptics have strongly 
pushed back on this assessment.) But his primary concern is that too few people wield too much power. "I don't 
think it can just be a small clique building this technology," he told me recently when I asked why he wrote the 
treatise.
Page 3 of 3
AI's Real Hallucination Problem
"I felt a sense of responsibility, by having ended up a part of this group, to tell people what they're thinking," he said, 
referring to the leaders at AI companies who believe they're on the cusp of achieving AGI. "And again, they might 
be right or they might be wrong, but people deserve to hear it." In our conversation, I found an unexpected overlap 
between us: Whether you believe that AI executives are delusional or genuinely on the verge of constructing a 
superintelligence, you should be concerned about how much power they've amassed.
Having a class of builders with deep ambitions is part of a healthy, progressive society. Great technologists are, by 
nature, imbued with an audacious spirit to push the bounds of what is possible-and that can be a very good thing for 
humanity indeed. None of this is to say that the technology is useless: AI undoubtedly has transformative potential 
(predicting how proteins foldis a genuine revelation, for example). But audacity can quickly turn into a liability when 
builders become untethered from reality, or when their hubris leads them to believe that it is their right to impose 
their values on the rest of us, in return for building God.
[Read: This is what it looks like when AI eats the world]
An industry is what it produces, and in 2024, these executive pronouncements and brazen actions, taken together, 
are the actual state of the artificial-intelligence industry two years into its latest revolution. The apocalyptic visions, 
the looming nature of superintelligence, and the struggle for the future of humanity-all of these narratives are not 
facts but hypotheticals, however exciting, scary, or plausible.
When you strip all of that away and focus on what's really there and what's really being said, the message is clear: 
These companies wish to be left alone to "scale in peace," a phrase that SSI, a new AI company co-founded by Ilya 
Sutskever, formerly OpenAI's chief scientist, used with no trace of self-awareness in announcing his company's 
mission. ("SSI" stands for "safe superintelligence," of course.) To do that, they'll need to commandeer all creative 
resources-to eminent-domain the entire internet. The stakes demand it. We're to trust that they will build these tools 
safely, implement them responsibly, and share the wealth of their creations. We're to trust their values-about the 
labor that's valuable and the creative pursuits that ought to exist-as they remake the world in their image. We're to 
trust them because they are smart. We're to trust them as they achieve global scale with a technology that they say 
will be among the most disruptive in all of human history. Because they have seen the future, and because history 
has delivered them to this societal hinge point, marrying ambition and talent with just enough raw computing power 
to create God. To deny them this right is reckless, but also futile.
It's possible, then, that generative AI's chief export is not image slop, voice clones, or lorem ipsum chatbot bullshit 
but instead unearned, entitled audacity. Yet another example of AI producing hallucinations-not in the machines, 
but in the people who build them.
Load-Date: July 25, 2024
End of Document
Page 1 of 2
No One Can Believe What Comes Up When You Google Beethoven: 'I'm So Done'
No One Can Believe What Comes Up When You Google Beethoven: 'I'm So 
Done'
Newsweek.com
July 18, 2024 Thursday 11:53 AM EST
Copyright © 2024 Newsweek Inc. All Rights Reserved
Length: 584 words
Byline: Rachael O'Connor
Highlight: One user labeled it "disgusting".
Body
The discovery of what comes up when you Google the composer Ludwig van Beethoven has sparked a huge 
discussion online as people debate the rise of artificial intelligence.
German composer Beethoven died in 1827, but his works, which include Moonlight Sonata, The Emperor Piano 
Concerto, and Für Elise, means he remains one of the most recognizable names in history.
This legendary status is likely contributing to anger around what comes up when you Google his name: rather than 
the famous Joseph Karl Stieler portrait, or any other recognizable portrait of the composer, the image 
accompanying his name is made by artificial intelligence (AI).
The Google discovery was pointed out in a viral post on Reddit by user u/PeopleAreBozos, with the image bearing 
the tell-tale smoothness of AI art, and it racked up 35,000 upvotes as commenters let their frustration be known.
Newsweek ran the image through multiple AI checkers, all of which gave a probability of between 93 to 98 percent 
chance of having been generated by AI.
One user shared the iconic Stieler portrait in the comments of the r/mildlyinfuriating post, asking: "Why on earth 
would anyone need that picture to exist when you have this in public domain?"
"I'm so done with finding AI images when I just want an actual, real image. Especially when having it in AI brings 
absolutely nothing, it's justa slightly worse version of the portrait we already have," another complained.
One simply labeled it "disgusting", and another said "I hate it so much how AI ruined Google images. I can't even 
look at it anymore."

Page 2 of 2
No One Can Believe What Comes Up When You Google Beethoven: 'I'm So Done'
The image also made it to the popular X account Insane Facebook AI Slop, racking up close to 7,000 likes of its 
own, where one commenter despaired, "the internet is actually dying".
It appears the image was originally posted on the website LVBeethoven.com, which describes itself as a "resource 
for everything Beethoven" and features multiple AI-generated images.
It is not an official site for the composer: Beethoven.de is the official site for the Beethoven-Haus museum and 
cultural institution based in Bonn, Germany, where he was born.
Newsweek reached out to LVBeethoven.com for comment.
The controversy of AI-generated art is well-publicized: Shawn Simpson, visiting lecturer in the Department of 
Philosophy at the University of Pittsburgh, wrote in a recent opinion piece forNewsweekthat "AI art is a real 
problem, and we need to make an effort to address it."
He shared the story of a visual artist who had lost a commission after the company generated images themselves 
through the AI program Dall-E, and told the artist they no longer needed their services.
"If we care about keeping human artists employed and producing great works of art, something must be done," he 
wrote, suggesting a ban on at least some AI art or supporting artists through public grants could be an option to 
protect creatives in the future.
Media artist Boris Eldagsen also wrote in an opinion piece for Newsweek where he described how he won a prize in 
a photography competition, using Dall-Eto generate an image.
He stated he came clean to the organizers but was told he could keep the prize. Eldagsen refused to accept the 
award, stating photography and AI should not compete with one another as they are separate entities.
Newsweek has contacted u/PeopleAreBozos on Reddit for comment.
Do you have funny and adorable videos or pictures you want to share? Send them to life@newsweek.com 
with some extra details, and they could appear on our website.
Link to Image
Graphic
 
Beethoven
Getty/ brandstaetter images
The iconic portrait of Ludwig van Beethoven, created in 1820 by German artist Joseph Karl Stieler. It is on display 
at the Beethoven-Haus museum in Bonn, Germany.
Load-Date: July 18, 2024
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 24, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: August 1, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 31, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 876 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his shed more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 18, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 876 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his shed more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 19, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: August 2, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 25, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 22, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 29, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 26, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 30, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 23, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
Newstex Blogs 
JD Supra
July 12, 2024 Friday 10:27 AM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 JD Supra 
Length: 2155 words
Byline: EDRM - Electronic Discovery Reference ModelSheila Grela
Body
July 12th, 2024 ( JD Supra  - Delivered by  Newstex )
Image: Sheila Grela with AI.
Introduction
As the granddaughter of two Alabama farmers, the word 'slop' evokes images of something with little value. In 
today's digital landscape, avoiding AI-generated content is nearly impossible, akin to dodging spoilers online. From 
AI-enhanced Google searches to AI-written articles and AI-composed music, artificial intelligence permeates every 
corner of the internet. This surge in AI content echoes the Dead Internet Theory, which posits that a significant 
portion of online activity is generated by bots rather than humans. The concern is that the internet may become a 
digital trough filled with 'slop,' where valuable content is lost amid low-quality AI-generated material.
Meet 'Slop'
'Slop' is the term for AI-generated content created primarily for profit. Similar to spam, slop is low-quality material 
that floods the web to generate ad revenue. Like spam and trolls, slop is another time-waster clogging digital feeds 
with irrelevant, unhelpful content. Examples include clickbait articles with misleading titles leading to shallow 
content filled with ads or poorly written blog posts stuffed with keywords to manipulate search engine rankings. 
These are classic examples of 'slop.'
'Slop' is the term for AI-generated content created primarily for profit. Similar to spam, slop is low-quality material 
that floods the web to generate ad revenue. Like spam and trolls, slop is another time-waster clogging digital feeds 
with irrelevant, unhelpful content.
Sheila Grela.
What is AI-Generated Slop?

Page 2 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
'Slop' encompasses various AI-generated content-text and images-designed to flood the internet with low-quality 
material. This content aims to pull in ad revenue and manipulate search engine rankings. Unlike the interactive 
nature of chatbots, slop is static, often misleading, and essentially digital clutter. It is cheap to produce, and even 
minimal clicks can make it profitable. However, not all promotional content is spam, and not all AI-generated 
content is slop. Thoughtlessly produced content imposed on unsuspecting users can be aptly described as 'slop.' 
For instance, automated news articles that repeat the same information with little context or analysis fall into this 
category.
How to Discern High-Quality Content from 'Slop'
Navigating the vast ocean of online content can be challenging, especially with the rise of AI-generated 'slop.' Here 
are some tips to help you distinguish high-quality content from digital clutter:
Check the Source
Reputable Publishers: Look for content from well-known, reputable sources such as established news outlets, 
academic journals, and official organizational websites. For example, articles from The New York Times or studies 
published in The Lancet are more likely to be reliable.
Author Credentials: Verify the credentials of the author. Are they an expert in the field? Do they have a history of 
reliable publications? Checking the author's LinkedIn profile or previous work can provide insights into their 
expertise.
Look for Detailed References and Citations
Citations: High-quality content typically includes references and citations to support its claims. Check if the article 
links to credible sources or provides a bibliography.
External Links: Follow the links to see if they lead to reputable websites or primary sources. For instance, an article 
on health should link to studies from medical journals or government health websites, not random blogs.
Evaluate the Writing Quality
Grammar and Style: Poor grammar, awkward phrasing, and inconsistent style can indicate low-quality, hastily 
generated content. High-quality articles are typically well-edited and free of such errors.
Depth of Analysis: Good content provides in-depth analysis, context, and multiple perspectives rather than 
superficial information. Look for detailed explanations and balanced viewpoints.
Analyze the Purpose and Tone
Objective vs. Promotional: Determine whether the content aims to inform or has a hidden agenda, such as selling a 
product or service. For example, an objective article will present facts and research, while a promotional piece 
might overly praise a product without much evidence.
Neutral Tone: High-quality content maintains a neutral, objective tone and avoids sensationalism. Watch out for 
exaggerated claims or emotional language that can indicate bias.
Cross-Check Information
Multiple Sources: Verify the information by checking multiple sources. Consistency across reputable sources can 
indicate reliability. If several trustworthy websites report the same facts, the information is likely accurate.
Fact-Checking Websites: Use fact-checking websites like Snopes, FactCheck.org, or PolitiFact to verify 
controversial claims. These sites often debunk false information and provide reliable facts.
Check for AI Hallmarks
Page 3 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
Repetition and Redundancy: AI-generated content often contains repetitive phrases and redundant information. If 
an article keeps repeating the same points, it might be AI-generated.
Lack of Depth: AI content may provide general information but lack the depth and nuance found in expert human 
writing. Look for detailed analysis and insights.
Static Content: Unlike interactive and responsive human-written content, AI-generated 'slop' tends to be static and 
non-engaging. High-quality articles often invite reader interaction through comments or discussion.
Look for Visual and Structural Clues
Layout and Design: Professionally designed content usually features a good layout; and proper use of headings, 
images, and other multimedia elements. Slop often lacks these features and may appear cluttered or poorly 
formatted.
Advertisements: Excessive ads and pop-ups can indicate that the primary goal of the content is monetization rather 
than providing valuable information. High-quality sites typically have fewer ads and more focus on content.
Test for Engagement and Interactivity
Comments and Discussions: High-quality content often sparks discussions and thoughtful comments from readers. 
Look for active engagement and meaningful exchanges. A lively comment section can indicate that the content is 
resonating with readers.
Updates: Reliable sources frequently update their content to reflect new information and developments. Check if the 
article has been updated recently to include the latest data.
By being vigilant and applying these strategies, you can better navigate the digital landscape and avoid falling for 
AI-generated 'slop.' Always prioritize confirmed human information and critical thinking to ensure your digital 
interactions are based on accurate, reliable, and valuable content.
Why Confirmed Human Information Needs to Take Precedence
As a paralegal, I can attest that confirmed human information must take precedence. Douglas Adams aptly said, 
'We are stuck with technology when what we really want is just stuff that works.' While AI can generate content 
quickly, it lacks the nuance, empathy, and critical thinking that only humans can provide. Human input ensures that 
information is accurate, reliable, and meaningful.
AI-generated content, with its potential for errors and lack of accountability, can mislead us. This is particularly 
dangerous in critical areas like legal advice, medical information, and financial guidance. Human expertise comes 
with a responsibility and a level of scrutiny that AI cannot match.
As a paralegal, I can attest that confirmed human information must take precedence. Douglas Adams aptly said, 
'We are stuck with technology when what we really want is just stuff that works.' While AI can generate content 
quickly, it lacks the nuance, empathy, and critical thinking that only humans can provide. Human input ensures that 
information is accurate, reliable, and meaningful.
Sheila Grela.
Real-World Examples and Potential Risks
Misleading Legal Advice
Legal advice and strategy are inherently complex and require the expertise of a competent attorney. AI-generated 
legal advice websites can provide misleading or incorrect guidance on critical legal matters, such as filing deadlines 
and legal procedures. This misinformation can lead to missed court dates and adverse legal outcomes, potentially 
Page 4 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
causing significant harm. For example, an AI tool might incorrectly calculate a filing deadline, leading to missed 
opportunities for legal action. Consulting a qualified human attorney for legal matters is essential.
Health Risks from AI Content
AI-powered apps offering lifestyle and health recommendations can sometimes provide dangerous advice. For 
instance, an AI might suggest unsafe exercise routines or dietary changes without considering individual health 
conditions, leading to potential injuries or health issues. This lack of personalized context and understanding poses 
serious risks to users.
Financial Misinformation
AI-generated articles and financial reports can cause significant monetary losses. For example, an AI-authored 
article might provide inaccurate stock information, recommending investments in companies with poor financial 
health. Investors following this advice could suffer substantial financial losses, underscoring the dangers of relying 
on AI for critical financial decisions. In one notable case, AI-generated stock analysis led to a surge in investments 
in a failing company, causing widespread financial losses.
Statistics Highlighting the Issue
Content Volume: According to a 2023 study by the University of California, 40% of web content is now generated by 
AI. This influx of AI-generated material contributes to the digital clutter we experience today.
User Trust: A 2022 survey by Pew Research found that 60% of internet users have encountered misleading or false 
information online. Of these, 45% reported that the misleading information was AI-generated.
Economic Impact: The economic model behind AI-generated slop is straightforward: a study by the Digital 
Marketing Institute found that producing AI content costs up to 80% less than human-generated content, making it 
an attractive option for content farms and low-budget operations.
Why Human-Confirmed Information Matters
When we need genuine insights, thoughtful analysis, or reliable data, turning to humans is essential. Confirmed 
human information brings wisdom, context, and integrity-qualities that are crucial for making informed decisions and 
maintaining trust in the digital age. No AI can replace the accuracy and depth that comes from human experience 
and knowledge. The lack of wit, humor, and empathy can make facts boring and forgettable.
As William Pollard wisely noted, 'Information is a source of learning. But unless it is organized, processed, and 
available to the right people in a format for decision making, it is a burden, not a benefit.'
This emphasizes the importance of confirmed, reliable information over sheer volume.
Similarly, Atul Gawande pointed out, 'Better is possible. It does not take genius. It takes diligence. It takes moral 
clarity. It takes ingenuity. And above all, it takes a willingness to try.'
This rings true when considering the need for high-quality, human-verified information.
Garry Kasparov observed, 'AI may be able to process vast amounts of data, but it lacks the ability to make 
judgments and decisions with the same depth and ethical considerations as humans.'
This highlights the critical need for human oversight in evaluating and using information.
Neil Gaiman hit the nail on the head: 'Google can bring you back 100,000 answers. A librarian can bring you back 
the right one.'
Prioritizing confirmed human information is more important than ever. It is the key to ensuring that our digital 
interactions remain trustworthy, insightful, and truly beneficial.
Page 5 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
Conclusion
While AI-generated slop might flood the digital landscape, the value of human input remains irreplaceable. As we 
navigate through this AI-driven world, let us remember to prioritize the wisdom and reliability that only human minds 
can offer. By doing so, we can ensure that our digital interactions are based on accurate, reliable, and valuable 
content, keeping the essence of human touch alive in the age of artificial intelligence.
Searching through the vast sea of data on the internet can feel like trying to find a needle in a haystack-while 
blindfolded. Even with the advent of generative AI, distinguishing valuable information from the irrelevant noise 
remains a significant challenge. In this sprawling digital landscape, we need strategies that make navigating the 
vast ocean of information more manageable and insightful. Moreover, there is a pressing need for innovative 
solutions to filter out low-quality content, akin to how we handle spam.
Can generative AI offer any bright ideas on how to clean up the digital clutter it helps generate? From advanced 
algorithms to smarter filters, exploring these possibilities could revolutionize how we access and utilize online 
information.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: July 12, 2024
End of Document
Page 1 of 2
Spam evolves with AI: What is "Slop"?
Spam evolves with AI: What is "Slop"?
CE Noticias Financieras English
July 11, 2024 Thursday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 CE Noticias Financieras All Rights Reserved
Length: 601 words
Body
Headless articles that only create disinformation, memes and meaningless images that flood social networks, eye-
catching headlines, but without reliable content that fill the "timelines" of cybernauts. Artificial intelligence has 
opened the door to a new era of creativity and automation, but also to a new type of digital garbage, the "Slop", the 
evolution of "Spam", one of the evils that appeared with the rise of the Internet.
The "Slop" can be translated as garbage or 'slop' and refers to the content created automatically by generative AI 
tools in an automated way, without human labor or supervision, which only aims to monetize in some way.
As with Spam , these undesirable contents are programmed and created for the simple purpose of generating traffic 
or being monetized, which encourages their mass production with the help of generative AI, which facilitates the 
task of generating texts or images on an industrial scale, although their quality and usefulness are null.
Specialized technology media cite some examples, such as tourist articles that recommend visiting slums or 
unimportant sites in cities, books published in Amazon of zero quality or meaningless viral memes on Facebook or 
X.
These contents are often ridiculous and harmless, although annoying because of their persistence, generating 
waste of time and frustration among cybernauts, since they force them to navigate among dozens of useless pages 
and reduce trust in legitimate contents.
Simon Willison, a developer credited with being one of the first to use the word "slop" indicates that it is crucial to 
recognize and label this threat. "The term spam helped to understand and combat spam. Defining slop can raise 
awareness of the dangers of unsupervised AI," he warns.
The expert warns that, today, there are not too many tools to detect this type of articles. However, he believes that, 
over time, it will be possible to put a stop to it in the same way as spam.
However, while AI has the potential to change the lives of mankind, there are also those who seek to exploit it for 
illicit purposes. In fact, it is becoming increasingly common to find news of deepfakes circulating on the networks. It 
is even used to perfect the wording of phishing emails and to spread hoaxes.
Marcelo Pacheco, director of the Systems Engineering program at the Franz Tamayo University, Unifranz, says 
that, as with any technological tool, AI can be used for both good and evil, i.e. its uses can be beneficial for 
humanity, but also harmful.

Page 2 of 2
Spam evolves with AI: What is "Slop"?
 Unifranz 
"It is possible to use artificial intelligence for a multitude of things, from making our lives easier to extortion, because 
AI is not inherently good or bad, it is what we do with it," he says.
For his part, systems engineer Sergio Valenzuela, professor of systems engineering at Unifranz, says it is important 
to understand the duality of the human being, who can be capable of great good as well as great evil, so ethics 
must always go hand in hand with advances, as this way risks can be reduced.
"AI is not inherently good or bad, however, it is important that its development is guided by ethical principles and 
that it avoids harming society through its use," he notes.
Given this reality, experts invite cybernauts to contrast the information they are reading if there is the slightest 
suspicion that it has been generated with AI. They also point out that the only viable solution is to force the labeling 
of content produced by this technology so that users know the truth. A system that Meta is trying to implement on 
Facebook and Instagram, although without the expected success.
?       
Load-Date: July 12, 2024
End of Document
Page 1 of 2
Dead tech blog now publishing using AI with old bylines
Dead tech blog now publishing using AI with old bylines
Newstex Blogs 
Talking Biz News
July 11, 2024 Thursday 8:51 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 Talking Biz News
Length: 248 words
Body
July 11th, 2024 (Talking Biz News — Delivered by Newstex)
The Unofficial Apple Weblog, a legendary and long-dead Apple-centric tech news blog, is publishing new content 
using artificial intelligence and the bylines of former journalists, reports Jason Koebler of 404 Media.
Koebler reports, 'This month, 'Christina Warren' started blogging again for The Unofficial Apple Weblog (TUAW), a 
legendary and long-dead Apple-centric tech news blog that she worked at more than a decade ago. Warren was for 
years a well-known and very good tech journalist, before she went on to work for Microsoft and GitHub. The real 
Christina Warren hasn't been writing these new posts on the zombie TUAW, however. The site's new owners have 
stolen her identity, replaced her photo with an AI-generated one, and have been publishing what appear to be AI-
generated articles under her byline.
'Worse, the new version of TUAW has 'recreated' the archives of the site by running old, real articles through a 
summarization tool and then republishing new, 'bastardized versions' of the old articles under the bylines of real 
writers who didn't actually write them, Warren said. The names and bios of dozens of real journalists who actually 
worked for TUAW a decade ago are listed on the website, and all of them have had their real images replaced with 
AI-generated ones, and their old work misattributed to other people and turned into AI slop by a summarization tool 
that has destroyed their original work.'
Read more here.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 

Page 2 of 2
Dead tech blog now publishing using AI with old bylines
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: July 12, 2024
End of Document
Page 1 of 2
TUAW makes a sad return as an AI-powered stolen content farm
TUAW makes a sad return as an AI-powered stolen content farm
Newstex Blogs 
9to5Mac
July 10, 2024 Wednesday 12:04 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 9to5Mac
Length: 377 words
Body
July 10th, 2024 (9to5Mac — Delivered by Newstex)
The Unofficial Apple Weblog, more commonly referred to as TUAW, has made a return from the dead, almost a 
decade after it was closed down. Unfortunately, that's not a good thing 
TUAW launched in 2004, and was once a popular source of Apple content. It was owned by AOL, and closed down 
in 2015 when the corporation decided to pull resources from its smaller web publications to focus on the bigger 
ones. The  archives were  folded into Engadget.
The domain was acquired by Yahoo, which recently sold it - without any rights to the content - to a company called 
Web Orange Limited (WOL). This is when things get messy.
Former contributor Christina Warren found that the company had seemingly come up with a cheap plan to 
repopulate it with content: just get an AI to rewrite some junk, and steal the identities of the original writers.
So someone bought the TUAW domain, populated it with AI-generated slop, and then reused my name from a job I 
had when I was 21 years old to try to pull some SEO scam that won't even work in 2024 because Google changed 
its algo. Assholes! H/t @gruber  pic.twitter.com/1JQeNljarT— Christina Warren (@film_girl) 
July 9, 2024
Some of the content was stolen from the TUAW archives, and some from current Apple sites.
Having been called out by Warren, the company simply changed her name.
Engadget reports that WOL seems to think all this is just fine.
'With a commitment to revitalize its legacy, the new team at Web Orange Limited meticulously rewrote the content 
from archived versions available on archive.org, ensuring the preservation of TUAW's rich history while updating it 
to meet modern standards and relevance,' the site's about page states.

Page 2 of 2
TUAW makes a sad return as an AI-powered stolen content farm
TUAW doesn't say if AI was used in those 'rewrites,' but a comparison between the original archive on Engadget 
and the 'rewritten' content on TUAW suggests that Web Orange Limited put little effort into the task. 'The article 
'rewrites' aren't even assigned to the correct names,' Warren tells Engadget, 'It has stuff for me going back to 2004. 
I didn't start writing for the site until 2007.'
The company didn't respond to a request for a comment.
Photo by Andrea De Santis on  Unsplash 
FTC: We use income earning auto affiliate links. More.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: July 10, 2024
End of Document
Page 1 of 2
Google Searches Prefer AI Spam to Real Content
Google Searches Prefer AI Spam to Real Content
Inc.com
July 3, 2024 Wednesday 12:38 PM EST
Copyright 2024 Mansueto Ventures, LLC All Rights Reserved
Length: 709 words
Byline: Kit Eaton
Body
Search engine optimization is the holy grail to boost traffic to websites--but in the AI era, even Google's much-
scrutinized search algorithm shows a preference for ripped-off, AI-generated material over original content.
The rise of AI-generated spam articles, now dubbed "AI slop," prompted Google to take steps to contain the 
influence of this junk material influencing its search results. But a recent report in Wiredshows that either 
Google's policy changes made earlier this year didn't go far enough--or AI-generated content producers have 
already found workarounds--because some AI-tweaked spam news stories ripped off from the original publishers 
were found to be ranking above the genuine news articles.
Wired's investigation into the phenomenon involved its own content, and its report first looked into where these AI-
faked articles were being published. It found that plagiarized Wired articles were being republished on some 
spammy AI-generated websites, and showing up higher in Google's search results than the originals. The AI slop 
pieces used whole quotes from the original articles and some included AI-generated artwork. However the 
unauthorized content was generated, the spammer was thorough--the plagiarized content also included Wired 
articles that the magazine had published in 10 languages other than English. News articles ripped from other sites, 
like Reuters and TechCrunch, were also published, with similar AI-generated imagery on top.
Explaining its campaign against AI-made spam in March, Google's blog post said the search engine was 
"enhancing Search so you see more useful information, and fewer results that feel made for search engines." It said 
it expected to reduce the appearance of "low-quality, unoriginal content" in search results by 40 percent. A late April 
update to the post said Google had actually seen a drop of 45 percent instead. The post also directly mentioned 
spam, noting Google was making "several updates" to spam policies to "better address new and evolving abusive 
practices that lead to unoriginal, low-quality content."
The problem is that rising AI technology is making it really easy for ill-intentioned people to easily "scrape" content 
that is someone else's legal intellectual property, tweak it and republish it. And somehow, this low-quality, AI-
generated material still seems to be getting past Google's filters and affecting the ranking of genuine news articles 
on the site. It's a game of whack-a-mole, of course, just like hacking: when bad actors are prevented from doing 
one activity, they try something new, which then gets blocked by an algorithm change or other tweak, but the 
process just repeats itself without a permanent fix.

Page 2 of 2
Google Searches Prefer AI Spam to Real Content
When Google adjusts its algorithms, it often changes search results that affect businesses that rely on traffic from 
Google to attract customers and help generate online revenue. While Wired is obviously concerned about how its 
published news pieces are affected, AI-made spam could easily impact other industries. 
News that AI slop is displacing genuine human-generated content is especially concerning in light of Google's 
recent decision to retire the infinite scroll it has long used to display search results. The world's dominant search 
engine is instead returning to an earlier system that displays search results on a number of separate numbered 
webpages. This change already concerns some web-centered businesses, since opening a search result would 
require extra clicks, which could be a barrier to traffic in the short attention span habits of many web users. And if 
your business appears in search results that are listed "below the fold," on pages beyond the first set of results, it's 
a genuine source of worry: the search preference for AI spam may be pushing legitimate results off the page.
How this affects your company depends on exactly how you generate income, how much reliant your business is on 
search traffic, and how good your current search engine optimization skills are. But it's an excellent reminder to 
double check with your web team to ensure they're on top of all the latest SEO trends, and that they're looking for 
possible AI-generated slop that might even have been grabbed from your own company content.
Link to Image
Graphic
 
Photos: Getty Images
Load-Date: July 3, 2024
End of Document
Page 1 of 2
Thousands of Raptive creators push to hold AI companies accountable
Thousands of Raptive creators push to hold AI companies accountable
Newstex Blogs 
Android Headlines
June 27, 2024 Thursday 4:18 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 Android Headlines 
Length: 586 words
Byline: Arthur Brown
Body
June 27th, 2024 ( Android Headlines  - Delivered by  Newstex )
We're at a point where we're starting to see the negative effects of  AI technology despite what CEOs of AI 
companies tell us in keynotes. Creators stand to lose significantly thanks to AI, and this is why they're banding 
together. Thousands of Raptive creators band together to urge Congress to hold AI companies accountable.
It doesn't take a rocket scientist to know what sort of effects AI technology will have on the creator economy. We're 
already seeing creators being let go from their jobs because their employers chose to replace them with an AI 
model. As these AI tools get better, more people are going to lose their jobs. Writers, artists, musicians, filmmakers, 
actors, voice actors, etc. will all need to either abandon their lifelong passions or sell out and mass-produce soul-
less AI slop to please money-hungry corporations. There are very few other avenues to take.
Thousands of Raptive creators want AI companies to be held accountable
The American has been hard at work trying to pull some AI regulations out of the ether, but not much has 
materialized. However, other entities are out fighting the good fight while the government waits for the ink to dry.
For example, several major record labels are suing the companies behind two AI music generators for copyright 
infringement. This is one of the many lawsuits going on right now.
Raptive is a company representing thousands of independent creators. It's paid out more than $2 billion to creators, 
and that number is going up. Raptive also acknowledges the threat of AI technology.
The company,  backed by more than 13,000 creators from across the U.S. has urged Congress to hold major AI 
companies accountable for their actions. According to PR Newswire, the creator economy is valued at $100 billion, 
and it could nearly double in the next three years. However, with AI companies shoving AI tools down our throats, 
we fear that the creator economy could crumble.
Requests

Page 2 of 2
Thousands of Raptive creators push to hold AI companies accountable
Raptive and the creators  have a handful of requests. Firstly, they want to enforce copyright law to protect original 
content from being scraped without consent. Secondly, they want a form of revenue-sharing structure in place so 
that creators are properly compensated for their work.Thirdly, AI tools shouldn't reduce the traffic going to creators' 
websites. Tools like these (a good example is Google's AI Overviews) can cut a company's ad revenue 
significantly.
Fourthly, future AI products shouldn't be able to unfairly compete against creators. This is pretty tricky, as this is 
what they're doing now. 'Why hire an artist to spend three hours on a painting when MidJourney can whip it up in 30 
seconds?' These are the questions that companies are asking. So, we're going to have to see what the government 
makes of that request. Lastly, the government needs to ensure that these AI companies are being held accountable 
for their behavior.
We're talking about major corporations here; they're about as ethical as a desert is wet. There need to be some 
rules, guidelines, and the threat of MAJOR FINES to keep companies in line. OpenAI, Alphabet, and Meta 
contacted Hollywood studios about their AI products. HOLLYWOOD STUDIOS! So, not even industry-level jobs are 
safe from AI. We need something to keep these companies from completely ruining the entire creator economy.
The post  Thousands of Raptive creators push to hold AI companies accountable appeared first on Android 
Headlines.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: June 27, 2024
End of Document
Page 1 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy 
AI Blog Posts
Forbes.com
June 26, 2024 Wednesday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1919 words
Byline: Rashi Shrivastava, Forbes Staff
Highlight: As Perplexity faces criticism for allegedly plagiarizing journalistic work and distributing it like a media 
company, it is increasingly citing AI-generated blogs and LinkedIn posts riddled with inaccurate and out of date 
information.
Body
<figure>
<figcaption>
In April, Aravind Srinivas, CEO of AI search startup Perplexity told Forbes, "Citations are our currency." Now, it's 
increasingly citing AI-generated blog posts on a wide variety of topics.
Christie Hemm Klok for Forbes
</figcaption></figure>
AI search engine Perplexity claims to be different from other generative AI tools like ChatGPT. Instead of 
regurgitating data without including any sources, it marks up its short summaries on any topic you want with 
footnotes that are supposed to link to recent and reliable sources of real-time information drawn from the internet.  
Citations are our currency,  CEO Aravind Srinivas toldForbes in April.
But even as the startup has comeunder firefor republishing the work of journalists without proper 
attribution,Forbeshas learned that Perplexity is also citing as authoritative sources AI-generated blogs that contain 
inaccurate, out of date and sometimes contradictory information.
According to astudyconducted by AI content detection platform GPTZero, Perplexity s search engine is drawing 
information from and citing AI-generated posts on a wide variety of topics including travel, sports, food, technology 
and politics. The study determined if a source was AI-generated by running it through GPTZero s AI detection 
software, which provides an estimation of how likely a piece of writing was written with AI with a 97% accuracy rate; 
for the study, sources were only considered AI-generated if GPTZero determined with at least 95% certainty that 
they were written with AI (Forbesran them through an additional AI detection tool called DetectGPT which has a 
99% accuracy rate to confirm GPTZero s assessment).

Page 2 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
On average, Perplexity users only need to enter three prompts before they encounter an AI-generated source, 
according to the study, in which over 100 prompts were tested.
 Perplexity is only as good as its sources,  GPTZero CEO Edward Tian said.  If the sources are AI hallucinations, 
then the output is too. 
Searches like  cultural festivals in Kyoto, Japan,  "impact of AI on the healthcare industry,"  street food must-tries in 
Bangkok Thailand,  and  promising young tennis players to watch,  returned answers that cited AI-generated 
materials. In one example, a search for  cultural festival in Kyoto, Japan  on Perplexity yielded a summary in which 
the only reference was for anAI-generated LinkedIn post. In another travel-related search for Vietnam s floating 
markets, Perplexity s response, which cited an AI-generated blog, included out-of-date information, the study found.
  Perplexity is only as good as its sources. If the sources are AI hallucinations, then the output is too.   
<footer>GPTZero cofounder and CEO Edward Tian</footer>
Perplexity Chief Business Office Dmitri Shevelenko said in an email statement toForbesthat its system is  not 
flawless  and that it continuously improves its search engine by refining the processes that identify relevant and 
high quality sources. Perplexity classifies sources as authoritative by assigning  trust scores  to different domains 
and their content. Its algorithms downrank and exclude websites that contain large amounts of spam, he said. For 
instance, posts by Microsoft and Databricks are prioritized in search results over others, Shevelenko said.
 As part of this process, we've developed our own internal algorithms to detect if content is AI-generated. As with 
other detectors, these systems are not perfect and need to be continually refined, especially as AI-generated 
content becomes more sophisticated,  he said.
As AI-generated slop gluts the internet, it becomes more challenging to distinguish between authentic and fake 
content. And increasingly these synthetic posts are trickling into the products that rely on web sources, bringing with 
them the inconsistencies or inaccuracies they contain, resulting in  second-hand hallucinations,  Tian said.
 It doesn't take 50% of the internet being AI to start creating this AI echo chamber,  he toldForbes. 
In multiple scenarios, Perplexity relied on AI-generated blog posts, among other seemingly authentic sources, to 
provide health information. For instance, when Perplexity was prompted to provide  some alternatives to penicillin 
for treating bacterial infections,  it directly cited an AI-generated blog by a medical clinic that calls itself Penn 
Medicine Becker ENT & Allergy. (According toGPTZero, it s 100% likely that the blog is AI-generated. DetectGPT 
said there is a 94% chance it is fake.)
Such data sources are far from trustworthy because they sometimes offer conflicting information. The AI-generated 
blog mentions that antibiotics like cephalosporins can be used as an alternative to penicillin for those who are 
allergic to it, but a few sentences later the post contradicts itself by saying  those with a penicillin allergy should 
avoid cephalosporins.  Such contradictions were also reflected in answers generated by Perplexity s AI system, 
Tian said. The chatbot did, however, suggest consulting a specialist for the safest alternative antibiotic.
Got a tip for us? Reach out securely to Rashi Shrivastava at rshrivastava@forbes.com or rashis.17 on Signal.
Penn Medicine Becker ENT & Allergy customer service representatives redirectedForbesto Penn Medicine. But in 
response toForbes  questions about why the clinic was using AI to generate blogs that gave medical advice, Penn 
Medicine spokesperson Holly Auer said the specialty physician s website was not managed by Penn Medicine and 
that  accuracy and editorial integrity are key standards for all web content associated with our brand, and we will 
investigate this content and take action as needed.  It s unclear who manages the website.
Shevelenko said that the study s examples do not provide  a comprehensive evaluation  of the sources cited by 
Perplexity but he declined to share data about the types of sources that are cited by the system.
Page 3 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
 The reality is that it depends heavily on the types of queries users are asking and their location,  he said.  
Someone in Japan asking about the best TV to purchase will yield a very different source set from someone in the 
U.S. asking about which running shoes to buy. 
Perplexity has also stumbled in its handling of authoritative sources of information. The billion dollar startup recently 
came under scrutiny for allegations of plagiarizing journalistic work from multiple news outlets includingForbes, 
CNBC and Bloomberg. Earlier this month,found Perplexity had lifted sentences, crucial details and custom art from 
an exclusiveForbesstory aboutEric Schmidt s secretive AI drone projectwithout proper attribution. The company 
recreated theForbesstory across multiple media, in an article, podcast and YouTube video, and pushed it out 
aggressively to its users with a direct push notification.
 Perplexity represents the inflection point that our AI progress now faces  in the hands of the likes of Srinivas   who 
has the reputation as being great at the PhD tech stuff and less-than-great at the basic human stuff   amorality 
poses existential risk,  Forbes Chief Content Officer Randall Lanewrote. Forbes sent a cease and desist letter to 
Perplexity, accusing the startup of copyright infringement. In response, Perplexity s CEO Srinivas denied the 
allegations, arguing that facts cannot be plagiarized, and said that the company has not   rewritten,   redistributed,   
republished,  or otherwise inappropriately usedForbescontent. 
The GPTZero study noted that a Perplexity search for  Eric Schmidt s AI combat drones,  one of the  pre-
recommended  search topics that sits on Perplexity s landing page, also used ablog post that was written with AI as 
one of its sources. (GPTZero found that there was a 98% chance the blog was AI-generated while DetectGPT said 
it was 99% confident.)
  When you use such references, it's much easier to promote disinformation even if there is no intention to do 
so.     <footer>Zak Shumaylov, machine learning researcher at the University of Cambridge.</footer>
Ainvestigation found that through a secret IP address, the startup had also accessed and scraped work fromWired 
and other publications owned by media companyCondé Nast,even though its engineers had attempted to block 
Perplexity s web crawler from stealing content. Even then, the search engine tends to make up inaccurate 
information and attribute fake quotesto real people. Srinivas did not respond to theWired story s claims but said,  
The questions from Wired reflect a deep and fundamental misunderstanding of how Perplexity and the Internet 
work. 
Shevelenko said the company realizes the crucial role that publishers have in creating a healthy information 
ecosystem that its product depends on. To that end, Perplexity has created what it claims is a  first-of-its-kind  
revenue sharing program that will compensate publishers in a limited capacity. It plans to add an advertising layer 
on its platform that will allow brands to sponsor follow-up or  related  questions in its search and Pages products. 
For specific responses generated by its AI where Perplexity earns revenue, the publishers that are cited as a 
source in that answer will receive a cut. The company did not share what percentage of revenue it plans to share. It 
has been in talks withThe Atlanticamong other publishers about potential partnerships.
Srinivas, who was a researcher at OpenAI before startingPerplexityin 2022, has raised over $170 million in venture 
funding (per Pitchbook). The company s backers include some of the most high-profile names in tech, including 
Amazon founder Jeff Bezos, Google Chief Scientist Jeff Dean, former YouTube CEO Susan Wojcicki, Open AI 
cofounder Andrej Karpathy and Meta Chief Scientist Yann LeCun. In recent months, its conversational search 
chatbot has exploded in popularity, with 15 million users that include billionaires like Nvidia CEO Jensen Huang and 
Dell founder and CEO Michael Dell.
Perplexity uses a process called  RAG  or retrieval-augmented generation, which allows an AI system to retrieve 
real time information from external data sources to improve its chatbot s responses. But a degradation in the quality 
of these sources could have a direct impact on the responses its AI produces, experts say.
Zak Shumaylov, a machine learning researcher at the University of Cambridge, said if real time sources themselves 
contain biases or inaccuracies, any application built on top of such data could eventually experience a phenomenon 
Page 4 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
calledmodel collapse, where an AI model that is trained on AI-generated data starts  spewing nonsense because 
there is no longer information, there is only bias. 
 When you use such references, it's much easier to promote disinformation even if there is no intention to do so,  he 
said.
Relying on low-quality web sources is a widespread challenge for AI companies, many of which don t cite sources 
at all. In May, Google s  AI overviews,  a feature that uses AI to generate previews on a topic, produced an array of 
misleading responses like suggesting adding glue to stick cheese on pizza and claiming that eating rocks can be 
good for your health. Part of the problem was that the system appeared to be pulling from unvetted sources like 
discussion forums on Reddit and satirical sites likeLiz Reid, head of Google Search, admitted in ablogthat some 
erroneous results appeared on Google in part because of a lack of quality information on certain topics.
 Perplexity is only one case,  Tian said.  It's a symptom, not the entire problem. 
MORE FROM FORBES
Load-Date: April 2, 2025
End of Document
=======
>>>>>>> c98f417 (update data file):extract_text.txt
Page 1 of 1
Letter writer declares ' Durango Decline' citing online classes, branding and merch
Letter writer declares 'Durango Decline' citing online classes, branding and 
merch
The Gateway: University of Nebraska at Omaha
June 24, 2024 Monday
University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved
Section: NEWS; Pg. 1
Length: 276 words
Body
It's hard not to notice as you walk about our campus that the higher-ups are hard at work rebranding each and 
every aspect of our fine institution with the "Maverick"or "Durango" moniker. We have a Maverick Store, Advising 
Center, Productions, the list goes on. While I can appreciate the sentiment of building community in a low-prestige 
commuter school, we've officially entered the era of "Durango Decline".
Somewhere along the line, the higher-ups decided that shifting to prioritizing totally online, self-paced course 
sections would help improve accessibility and fit more people into classes, so why not do it? Plus, it's another thing 
to charge fees for.
Well, students went all in for this. And why is that? Because, in most online sections, one can get away with pasting 
AI slop three times a week into a discussion board. Because, in most cases, professors or grad instructors are too 
busy to bother enforcing any kind of academic rigor in their online sections. Because, you don't need to really be 
present or part of the community to get your rubber-stamp credits.
Don't get me wrong - we need to include students who work full-time, and can't attend regularly scheduled classes. 
There's other options, though, like night and weekend classes, as well as synchronous online classes. All of those, 
of course, would take money and effort, which UNO would rather spend on flimsy Maverick merch.
Congrats to UNO for improving the accessibility of an education, by making sure nobody gets one at all.
Editor's Note
The Gateway welcomes letters to the editor as a part of our duty to provide a public forum for the university. Please 
submit any letters here.
Load-Date: June 24, 2024
End of Document

Page 1 of 2
Comment: 'We deserve more than reheated housing ideas and AI slop'
Comment: 'We deserve more than reheated housing ideas and AI slop'
standard.co.uk
June 12, 2024 Wednesday 11:54 AM EST
Copyright 2024 Evening Standard Limited  All Rights Reserved
Length: 435 words
Byline: India Block
Body
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
You may not know exactly what "slop" means in the context of artificial intelligence. But on some level, you 
probably know what I'm talking about.
Slop is a broad term that has gained traction when referring to bad or unwanted AI content on social media, art, 
books and, increasingly, in internet search results.
Google suggesting that you could add glue to make cheese stick to pizza? That's slop. As is a cheap ebook that 
seems to be what you were looking for, but not quite. What about those posts on your Facebook feed that 
seemingly came out of nowhere? That's slop too.
The term became more prevalent last month when Google incorporated its Gemini AI model into its search results 
in the US.
Instead of pointing users to links, the service tries to solve a query directly with an "AI Overview" - a piece of text at 
the top of a page that uses Gemini to form its best guess as to what the user is looking for.
The move was a reaction to Microsoft incorporating AI into its Bing search results, and had some immediate 
stumbles, leading Google to declare that it would roll back some of its AI features until the problems were resolved.
But with the major search engines having made AI a priority, it seems that vast amounts of machine-generated 
information, rather than being largely selected by humans, will be served up daily as part of life on the internet for 
the foreseeable future.
Hence the term slop, which conjures up images of piles of unappetizing food being poured into cattle troughs. Like 
this kind of slop, search with AI forms quickly, but not necessarily in a way that the most critical can accept.
Kristian Hammond, director of Northwestern University's Center for Advancing Safety of Machine Intelligence, 
pointed out a problem with the current model: the information in the AI Overview is being presented as a definitive 
answer, rather than as a starting point for an internet user's research into a particular subject.
"You search for something and you get what you need to think about it - and it really encourages you to think," said 
Hammond. "What's happening, in this integration with language models, is something that doesn't encourage the 
user to think. It encourages them to accept. And I think that's dangerous."

Page 2 of 2
After spam, meet slop, poor quality content generated by AI
Giving a name can be useful for identifying a problem. And while slop is an option, it's still an open question 
whether it will be adopted by a wider audience or end up in the slang garbage can with cheugy, bae and skibidi.
Adam Aleksic, a linguist and content creator who goes by the name Etymologynerd on social media, believes that 
slop - which he said has not yet become popular - is promising.
"I think this is a great example of an understated word at the moment, because it's a word we're all familiar with," 
said Aleksic. "It's a word that seems naturally applicable to this situation. So it's less invasive."
The use of slop to describe low-quality AI material apparently came about in reaction to the launch of AI art 
generators in 2022.
Some have identified programmer Simon Willison as an early adopter of the term - but Willison, who defended the 
adoption of the phrase, said it had been in use long before he encountered it.
"I think I may actually have been quite late to the party!" he said in an email.
The term has appeared on 4chan, Hacker News and YouTube comments, where anonymous commenters 
sometimes project their proficiency in complex subjects using niche language.
"What we always see with any slang is that it starts in a niche community and then spreads," said Aleksic.
"Usually, whether the slang is interesting or not is a factor that helps it spread, but not necessarily. Just as we've 
had a lot of words spreading from a bunch of programming geeks. Look at the word 'spam'. Usually, the word is 
created because there is a specific group with shared interests, with a shared need to invent words."
In the short term, the effect of AI on search engines and the internet in general may be less extreme than some 
fear.
News organizations have worried about a shrinking online audience as people rely more on AI-generated answers, 
and data from Chartbeat, a company that researches internet traffic, indicates that there was an immediate drop in 
Google Discover referrals to websites in the early days of AI Overviews.
But that drop has since recovered, and in the first three weeks of the Overviews, overall search traffic to more than 
2,000 websites in the US increased, according to Chartbeat.
But as people get used to the growing role of AI in the functioning of the internet, Willison, who identified himself as 
an optimist about AI when used correctly, thought that slop could become the standard term for the less important 
forms of machine-generated content.
"Society needs concise ways to talk about modern AI - both the positive and negative aspects. 'Ignore that email; 
it's spam' and 'ignore that article; it's slop' are useful examples," he said.
Load-Date: June 19, 2024
End of Document
Page 1 of 3
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
The Irish Times
June 18, 2024 Tuesday
Copyright 2024 The Irish Times All Rights Reserved
Section: FINANCE; Pg. 14
Length: 930 words
Body
I missed the RTÉ One O Clock News last Thursday, and I was raging. They say it s important for your sense of 
inner order and productivity to build an anchor habit into your daily routine, and for me that anchor is Eileen Whelan.
On this occasion, the miss meant not getting to see a spot of comedy gold as it unfolded live in the wilds of linear 
television. I had to catch up with a clipped-up version of it later in the day along with the rest of the extremely online 
masses.
The moment came courtesy of RTÉ News southern editor, Paschal Sheehy, who brought some much-needed 
colour to the fifth day of the European Parliament count from Nemo Rangers GAA club in Cork.
 [Fianna Fáil candidate] Billy Kelleher s team has just arrived here with a tray of sandwiches,  he informed Whelan 
near the end of a live link.
With some time to go before the result of the next count, there was  probably more interest in the distribution of 
those sandwiches at this stage  than there was in the distribution of an eliminated candidate s votes, he suggested 
to absolutely no dissent whatsoever.
 My presence on this plinth is a source of some mirth for some people here because I am being kept away from 
these sandwiches,  explained Sheehy then, conveying the perils of live broadcasting via some real-time smirking.
He didn t seem too hopeful when Whelan ventured that someone might save one for him. But after dropping into 
the Midlands-North-West count centre for an update from the suddenly  peckish  western correspondent Pat 
McGrath, there was time for a quick goodbye from a newly sandwich-laden Sheehy.
 I have scored, Eileen,  he declared with the sort of glee that can only be elicited by the arrival of food.
A replay of the full bulletin confirms that Whelan, because she s a pro, smoothly segued from congratulating her 
freshly carb-equipped colleague to the straightest of faces and most serious of voices as she proceeded to the next 
item, which happened to be news of Enoch Burke losing his defamation case against the publisher of the Sunday 
Independent.

Page 2 of 3
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
I was reminded of Sheehy, his single transferable sandwich triumph and the clip that RTÉ packaged up for online 
consumption when I was sent an embargoed copy of this year s Reuters Institute for the Study of Journalism global 
digital news report.
One of its significant Irish findings is that the level of trust in RTÉ News has risen. Based on a survey of more than 
2,000 people, conducted this year, some 72.4 per cent of news consumers in Ireland trust RTÉ, up 1 percentage 
point compared with last year.
RTÉ s performance, DCU s Institute of Future Media, Democracy and Society (FuJo) said in its analysis, was  
particularly notable  in light of the corporate governance scandal at the broadcaster over the past year.
Trusted news 
So, there has been no reputational contagion, this appears to confirm. RTÉ is the most trusted news organisation in 
Ireland, though I m contractually obliged to mention that The Irish Times is right there with it, trusted by 71.7 per 
cent, while local and regional radio is next on 71 per cent.
This is worth remembering amid all the online noise. In communities across Ireland, reporters for long-established 
news outlets   who face consequences when they don t live up to editorial standards   tend to be respected, well-
liked figures who may, sometimes, be hungry.
Interestingly, the survey found that online news has now nudged ahead of television as the most likely answer when 
people are asked to give their  main  source of news. This wasn t by much   33 per cent compared with 31 per cent   
and the survey itself is conducted online, meaning it tends to underrepresent traditional offline news consumption. 
But it does underline the benefit to RTÉ if its news clips go viral every so often.
Up to date 
When asked about the role of news in their lives, a relatively low percentage   43 per cent   say it is  very  or  
somewhat  important for news to be entertaining. This is less than the 75 per cent who say it is the role of news to 
keep them  up to date with what s going on  or even the 52 per cent who say it is important for news to make them  
feel connected to others in society .
This seems about right. I don t think it is the role of news to be entertaining, necessarily. I just appreciate it when 
somehow, against all the odds, its manages this feat. Indeed, it s the unexpectedness of any injection of humanity 
into the formal, historically stiff genre of television news   and the relief of fleeting lightness in a world of misery and 
gloom   that makes such moments stand out.
The global Reuters Institute report expands on the theme, examining  user needs  when it comes to news.  Update 
me  is the biggest one, important for 72 per cent, and  divert me  is bottom of the pile on 47 per cent. The authors 
caution that diversions may be more important overall to people s lives, but are just not something they always  
expect the news media to provide.
Again, this is fair enough. But what we think of as  news  does not exist in a silo. It is part of a much wider attention 
economy in which failure to engage is punished. It would actually be odd if a  bundle  of news, such as a television 
bulletin or a newspaper, was rigidly monotonal and robotic. 
And with the age of AI- generated slop now seemingly imminent, it would be counterproductive, too.
For sure, the banter-as- default mode of some US television news networks would be unbearable. Constant, 
contrived jokes would be inappropriate and weird. But, like the seasoning in a sandwich, a little bit of personality 
goes a long way.
Load-Date: June 17, 2024
Page 3 of 3
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
End of Document
Page 1 of 2
How technology has changed our daily lives
How technology has changed our daily lives
 
B-Metro
June 17, 2024 Monday
Copyright 2024 B-Metro All Rights Reserved
Length: 517 words
Body
 Remember the days when a trip to the library was your only option for research, or a landline phone tethered you 
to one spot for communication?
The relentless march of technology has transformed our lives in ways unimaginable just a few decades ago, 
offering unparalleled opportunities but also presenting new challenges. Below, we explore some of the key areas 
where it's had the most significant impact.
Communication
Instant messaging platforms like WhatsApp and Facebook Messenger allow us to connect with anyone in the world 
in real-time, fostering closer relationships and global collaboration. Video conferencing platforms like Zoom have 
also become ubiquitous after seeing massive growth during the pandemic, facilitating business meetings and even 
personal interactions between friends and family members.
Information
The internet has democratised access to information like never before. Search engines like Google put a vast 
library of knowledge at our fingertips, allowing us to research any topic imaginable within seconds. The recently 
announced Artificial Intelligence (AI)-powered overviews promise to further empower individuals to understand any 
subject that interests them.
However, the sheer volume of information available can be overwhelming, and the ability to discern credible 
sources from misinformation remains a critical challenge, only exacerbated by AI-generated 'slop' content.
Entertainment
In place of the video rental stores like Blockbuster we enjoyed at the start of the 21st century, modern streaming 
services like Netflix and Disney offer on-demand access to a vast library of movies and TV shows, while platforms 
like YouTube provide a constant stream of user-generated content.

Page 2 of 2
How technology has changed our daily lives
Online gaming has also become a major form of leisure, with gaming platforms offering everything from first-person 
shooters to complex strategy titles. Even classic games have been given a digital makeover, with online bingo 
platforms letting players connect and enjoy a familiar game from the comfort of their homes.
Work-life balance
With smartphones and laptops allowing us to be constantly connected, modern technology has undeniably blurred 
the lines between work and personal life, making it difficult to ever truly switch off. This can lead to stress, burnout, 
and difficulty maintaining a healthy work-life balance.
However, there are many ways in which technology has also enhanced the workplace. There are countless tools for 
productivity, project management and much more that can streamline workflows, potentially freeing up time for 
personal pursuits. Ultimately, it's up to individuals to maintain healthy habits and ensure technology enhances, 
rather than hinders, our relationship with work.
Harnessing technology for the future
Technology has become a double-edged sword in our time. It offers unparalleled connection, information, and 
entertainment, but also challenges us with information overload, work-life blur, and the need for constant vigilance 
in a world of digital noise. Striking the right balance is key to harnessing technology's power for a fulfilling and 
connected life.
Load-Date: June 17, 2024
End of Document
Page 1 of 2
The rise and risk of AI-generated slop
The rise and risk of AI-generated slop
Devx.com
June 14, 2024 Friday 6:42 PM EST
Copyright 2024 DevX  All Rights Reserved
Length: 452 words
Byline: Cameron Wiggins
Body
The "dead internet theory" suggests that a significant portion of online content and activity is generated by artificial 
intelligence (AI) agents rather than humans. These AI agents rapidly create posts and images designed to farm 
engagement on social media platforms. While some of this AI-generated content may seem harmless, like the viral 
"shrimp Jesus" images, there are concerns about more sophisticated and potentially deceptive uses.
Studies have found that bot accounts on social media can spread misinformation and disinformation, amplifying 
unreliable sources and swaying public opinion. Social media companies are taking steps to address the misuse of 
their platforms. They are exploring ways to identify and remove bot activity, as well as considering measures like 
requiring users to pay for membership to deter bot farms.
The concept of "slop" has emerged to describe carelessly automated AI webpages and images that clutter the 
internet. Unlike interactive chatbots, slop is not intended to serve users' needs but rather to generate ad revenue 
and manipulate search engine results. Slop can be harmful when it contains incorrect or misleading information.
Examples include an AI-generated article listing a food bank as a tourist attraction and AI-written books with 
dangerous advice.
The spread of AI-generated slop
Image-generated slop, like bizarre reworkings of religious iconography, has also proliferated on social media.

Page 2 of 2
The rise and risk of AI-generated slop
Advertising agencies, the main revenue source for social media, are becoming concerned about the rise of slop. 
They worry that consumers may start to feel they are being served low-quality content and mistakenly flag 
legitimate ads as AI-generated. Tackling the problem of slop will be challenging, as major tech companies 
themselves are now using AI to generate content like search result overviews.
While they claim to have strong safety guardrails, slop continues to spread across the web. The story of "Shrimp 
Jesus" illustrates how an innocent joke can be co-opted by AI and used by scammers to lure unsuspecting users. 
As AI-generated content becomes more sophisticated, it will be increasingly difficult to discern the intentions behind 
it.
Experts call for greater transparency from social media companies, including labeling AI-generated content. While 
AI can create impressive images, many people still value the authenticity and "soul" of human-made art. The rise of 
AI-generated content on the internet is a cautionary tale, reminding us to be skeptical and navigate social media 
with a critical mind.
As one researcher noted, "Sometimes people use AI for creation, but there's always a dark side."
The post The rise and risk of AI-generated slop appeared first on DevX.
Load-Date: June 14, 2024
End of Document
Page 1 of 2
Comment: 'We deserve more than reheated housing ideas and AI slop'
Comment: 'We deserve more than reheated housing ideas and AI slop'
standard.co.uk
June 12, 2024 Wednesday 11:54 AM EST
Copyright 2024 Evening Standard Limited  All Rights Reserved
Length: 435 words
Byline: India Block
Body
The manifestos and housing pledges are dropping, and with it any hope for serious ideas to help London's 
struggling renters and homeowners.
Nothing even vaguely fresh or original has made it onto the menu. 
Labour suggested it would extend the Conservative's 95 per cent mortgage scheme to help first-time buyers 
(FTBS). In reality, anyone who can't save for a deposit will struggle to pass the mortgage checks, especially in 
pricey London.
The Conservatives are still insisting they'd totally be able to pass the Renters Reform Bill in ban section 21, a 
broken promise from the last election. 
They also want to bring back Help To Buy, which begs the question why they stopped it it in the first place - seeing 
as London new build prices are now permanently inflated.
Lib Dems want to bring in Rent to Own for social housing, a rebranded Right to Buy that would require a lot more 
social housing to replace the stock moving into private ownership. They'd also build 10 garden cities, location 
undetermined. 
"Quality housing should be our shared future, not a reanimated zombie of the past."
Labour is beating the drum for new towns too, getting into bed with Conservative think tank Create Streets with a 
New Town's Code that promises new urban hubs with old world charm. 
Create Streets' AI-created images of leafy streets and faux-Edwardian mansion blocks should give us all pause. 

Page 2 of 2
=======
The manifestos and housing pledges are dropping, and with it any hope for serious ideas to help London's 
struggling renters and homeowners.
Nothing even vaguely fresh or original has made it onto the menu. 
Labour suggested it would extend the Conservative's 95 per cent mortgage scheme to help first-time buyers 
(FTBS). In reality, anyone who can't save for a deposit will struggle to pass the mortgage checks, especially in 
pricey London.
The Conservatives are still insisting they'd totally be able to pass the Renters Reform Bill in ban section 21, a 
broken promise from the last election. 
They also want to bring back Help To Buy, which begs the question why they stopped it it in the first place - seeing 
as London new build prices are now permanently inflated.
Lib Dems want to bring in Rent to Own for social housing, a rebranded Right to Buy that would require a lot more 
social housing to replace the stock moving into private ownership. They'd also build 10 garden cities, location 
undetermined. 
"Quality housing should be our shared future, not a reanimated zombie of the past."
Labour is beating the drum for new towns too, getting into bed with Conservative think tank Create Streets with a 
New Town's Code that promises new urban hubs with old world charm. 
Create Streets' AI-created images of leafy streets and faux-Edwardian mansion blocks should give us all pause. 

Page 2 of 2
>>>>>>> c98f417 (update data file):extract_text.txt
Comment: 'We deserve more than reheated housing ideas and AI slop'
Looking to RETVRN to a non-existent halcyon past of housing is an alt-right dog whistle, one that won't fly in 
multicultural London. 
The appeal of building an entirely new place is you don't have to risk upsetting existing residents by bolting on 
hundreds of new homes. 
But much of this NIMBYism is underpinned by the real fear over having to share already over-stretched public 
services, not fussing over the visual familiarity. 
New homes need sufficient GP appointments and school places - they don't need to smuggle in weird nationalist 
ideas.
That Create Streets has to resort to image generators likely trained on stolen art speaks to a lack of commitment to 
serious design that values human labour.
We have plenty of smart architects and urban planners working on contemporary housing ideas for our city. Just 
look at the winners of the recent RIBA London awards. 
Quality housing should be our shared future, not a reanimated zombie of the past.
Read More
General election: Labour pledges 'Freedom to Buy' mortgage guarantee scheme - but will it work in London?
Tory manifesto: pledge to revive Help to Buy scheme 'devoid of imagination' say property experts
Comment: Can the general election rescue a bedraggled London housing market?
Load-Date: June 28, 2024
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
End of Document
Page 1 of 3
Apple is finally letting you have it your way-kinda
Apple is finally letting you have it your way-kinda
Macworld (US)
June 12, 2024 Wednesday 10:30 AM EST
Copyright 2024 IDG Communications, Inc. All Rights Reserved
Length: 900 words
Body
Macworld
Apple, as a company, has always extolled the value of putting the personal in personal computer. From its earliest 
days pushing back at the monolith of IBM and beige boxes that all looked like one another, to its more recent 
extremely personal devices like the iPhone, Apple Watch, and AirPods.
But that ethos of personal technology has always been in fundamental tension with the companys other overriding 
principle: Apple knows best. Whether its the design of its apps or how to use its features, the company has a strong 
streak of imposing on its users what it believes is the best approach.
In the companys latest platform updates, this tension is more apparent than ever. Apple announced several new 
features that allow users to bring their own touches to their devicesbut it did so in a typically Apple fashion that still 
kept everything within bounds.
Custom-ish-ation
One of the most anticipated announcements ahead of this years Worldwide Developers Conference was that Apple 
would finally relax the strictures around your iOS devices home screen. The grid of icons has remained largely 
unchanged since its appearance in the very first iPhone back in 2007. There have been a few additions of course: 
folders, the App Library, and at long last the addition of widgets in iOS 14. But even all of those enhancements fit 
within the structure provided by the grid.
Apple
    Apple
  Apple
The rumor that this year would let you put icons anywhere on your screen no doubt conjured the freedom of macOS 
in some minds eyes. Unsurprisingly, perhaps, it wasnt to be: when the company did announce the feature, it 
became clear that while you could move your icons around and leave open spaces so your wallpaper showed 
through, the icons would still ultimately reside within the grid.

Page 2 of 3
Apple is finally letting you have it your way-kinda
Likewise, the news that you would at long last be able to reassign the iPhones lock screen shortcut buttons for the 
flashlight and the camera was greeted enthusiasticallybut there remain just the two icons. Apple specifically 
acknowledged this push and pull to me, saying that they wanted to give users the freedom to customize their 
experiences while still trying to maintain the iconic look and feel of the iPhone.
There is, however, one place on the home screen where Apple has put peoples customizations front and center: 
the new app icon features, which let you not only choose a light or dark option but also tint all your apps the same 
color. When you select a tint, it changes all of your app iconsregardless of whether or not the developer has 
designed their icon appropriately.
Picture window
Theres a big Photos redesign happening this year, and its largely about customization as well. Users can choose 
what they want to show up in the carousel at the top, whether its the traditional grid of photos or a specific set of 
curated pictures, or even photos the system has chosen to feature. Below that main section is a set of collections, 
which you can select and order as you like.
The push-and-pull of the customization is almost more internalized to the app here. Its a question of Apple trying to 
make your Photos app look as good as possible by suggesting the content that might take center stage, even if you 
do have the option to override it. Given that this is a feature centered around your own pictures, it does seem smart 
for Apple to try and go a little more hands-off here, making sure that its your content that remains the star.
Apple
    Apple
  Apple
Intelligence agency
By far the most personal-oriented development from this years WWDC is, of course, the companys rollout of its AI-
powered features, under the aegis of Apple Intelligence. This suite of improvements to features across the 
companys platforms may unlock some very powerful behaviors that help you do the things you need to do, but it 
remains to be seen just how personal it will be.
The problem is, to a degree, inherent in the very technology that underpins it. Much as AI is intended to help people 
accomplish things in a faster and more efficient manner, the way it achieves this is via a technology that is often 
trained on a huge corpus of material. One risk of technology like that is that it can feel depersonalizedalmost 
generic. For example, if you use Apples new Writing Tools feature to make an email sound more professional, 
might it do so in a way that sounds lesslike you? Will everybodys use of the Friendly rewrite tone end up sounding 
like the same person? Again, its not a concern thats unique to Applemuch of the text generated by other systems 
like ChatGPT has a way of sounding sameybut its something that the company may have to contend with when 
convincing people to take advantage of its feature.
Likewise, Apples new image generation technologies might unlock the ability to create pictures even for those who, 
like me, are artistically challenged, but their reliance on a handful of specific styles can end up feeling generic. Or, 
as developer Sebastiaan de With pointed out a feature that can turn whimsical sketches into AI slop.
All of this is something that Apple needs to contend with as it attempts to make its own foray into artificial 
intelligence. A personalized intelligent agent needs to feel personal, and the companys demonstration of a system 
that knows about your data and information is a good step in that directioneven if the generative features 
sometimes feel like a step back.
iOS, iPad, iPhone
Page 3 of 3
Apple is finally letting you have it your way-kinda
Load-Date: June 13, 2024
End of Document
Page 1 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
Newstex Blogs 
VentureBeat
June 10, 2024 Monday 11:02 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 VentureBeat 
Length: 1471 words
Byline: Carl Franzen
Body
June 10th, 2024 ( VentureBeat  - Delivered by  Newstex )
Apple had been among the tech giants most conspicuously absent from - or at least, low-key about - the generative 
AI craze, at least until today.
At its annual Worldwide Developer Conference (WWDC 2024) in Cupertino, California, the company unveiled its 
biggest push into generative AI so far: a new service called Apple Intelligence , which will offer a variety of features 
across Apple devices including Mac computers, iPhones, and iPads.
The service is not an app per se, rather, it is a set of features embedded within other popular apps, from web 
browser Safari (where you can summarize articles) to Mail (where it can rewrite and suggest grammar 
improvements) to Photos (auto generate photo albums on specific subjects and topics set to music based on a text 
prompt) to Messages (where it can create custom AI generated emoji and photos of your contacts, as well as event 
and group photos).
As with nearly all new Apple announcements of the company's storied history, the Apple Intelligence announcement 
was watched by a large audience of tech workers and journalists, as well as creatives, and some notable 
entrepreneurs and executives from rival firms.
It also inspired a wide range of responses, from some interpreting the announcement as underwhelming or 
undermining of Apple's reputation as a company where minimalistic and clean designs are prioritized, while others 
viewed it as one of, if not the best examples of generative AI done right. Here are some of the most interesting 
reactions I saw:
High praise from former rivals
Steven Sinofsky, the former president of the Windows Division at Microsoft and current board partner at 
Andreessen Horowitz, called Apple Intelligence 'really excellent work.'

Page 2 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
This is really excellent work. There is a ton that won't show up for a long time, but that is precisely what Apple does 
so well.
- Steven Sinofsky (@stevesi) June 10, 2024
He also said he thought the idea of weaving Apple Intelligence through its various Apple-branded apps was 'exactly 
right and even more so when combined with privacy/on device.'
Excellent. Today was super high on 'vision' for Apple with tons of future tense. At the same time their strong point of 
view is abundantly clear. This is not just privacy and on device, but how they see integration at the platform level. 
The idea for example of building on top of
- Steven Sinofsky (@stevesi) June 10, 2024
And, as if that wasn't enough of a favorable review, Sinofsky also took the opportunity to ding Google and his own 
former employer Microsoft in comparison to Apple's approach:
The contrast between what Apple is showing and what Google and Microsoft have shown is a stark as ever. This is 
really important. Apple brings their point of view to the newest technologies, again.
- Steven Sinofsky (@stevesi) June 10, 2024
Similarly, Andrej Karpathy, an esteemed researcher who was previously director of artificial intelligence and 
Autopilot Vision at Tesla (where he competed with Apple's abandoned self-driving car project) and a co-founder of 
OpenAI, said in a post on X that he found Apple Intelligence 'super exciting.'
Actually, really liked the Apple Intelligence announcement. It must be a very exciting time at Apple as they layer AI 
on top of the entire OS. A few of the major themes.
Step 1 Multimodal I/O. Enable text/audio/image/video capability, both read and write. These are the native
- Andrej Karpathy (@karpathy) June 10, 2024
Double standard?
Bilawal Sidhu, host of the TED Talks AI Show and a former Google Maps AR/VR engineer, wrote a lengthy post on 
X comparing how Apple Intelligence leverages personal data on the device in which it operates, as well as virtual 
private clouds, to serve up AI responses - a tack that he saw as similar to Microsoft's new Recall feature for 
Windows Copilot + PCs that faced intense backlash from some users and researchers for possible data security 
risks . Microsoft Recall was, as of last week, disabled by default and now must be turned on by the user during 
setup.
Apple's reality distortion field is strong. It's kinda wild that with "semantic index," Apple is basically doing what 
Microsoft wants to do with AI recall + Copilot, and without any of the big brother backlash.
Semantic index means all your private content (messages, emails, https://t.co/dFNy7yTotv
- Bilawal Sidhu (@bilawalsidhu) June 10, 2024
AI images and Genmoji: love/hate?
One of the most immediately obvious use cases for Apple Intelligence for regular users is in its ability to create 
custom imagery and emoji based on their text prompts within Messages and other apps.
Open source software developer and AI influencer Simon Willison took to his blog  to commend Apple's approach 
toward AI image generation, writing:
Page 3 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
This feels like a clever way to address some of the ethical objections people have to this specific category of AI 
tool:
If you can't create photorealistic images, you can't generate deepfakes or offensive photos of people
By having obvious visual styles you ensure that AI generated images are instantly recognizable as such, without 
watermarks or similar
Avoiding the ability to clone specific artist's styles further helps sidestep ethical issues about plagiarism and 
copyright infringement
The social implications of this are interesting too. Will people be more likely to share AI-generated images if there 
are no awkward questions or doubts about how they were created, and will that help it more become socially 
acceptable to use them?
Others criticized the look and feel of the cartoonish AI generated images in Messages:
As someone who spends 24 hours a day optimizing the fine-tuning of image models for everyday cases (such as 
this one), this was hard to watch. pic.twitter.com/W4oe46NXbZ
- Pietro Schirano (@skirano) June 10, 2024
some of the apple/AI integrations look potentially useful, but the image playground feature is pure AI slop. the 
"animation" style apple kept on showcasing looks horribly dated already. i imagine this will entertain older users but 
be an instant turn off for gen z pic.twitter.com/GhmuBOT2Jv
- James Vincent (@jjvincent) June 10, 2024
A third-party app killer
Various users pointed out that be integrating a number of AI features across its native apps, Apple was essentially 
killing third-party AI-powered apps and services that sought to offer similar functionality prior to the news today and 
the absence of Apple Intelligence.
Apps Apple sherlocked this WWDC
AllTrails
Soulver
1Password
Grammarly
Bitmoji
Bezel
Making mac apps, just mirror your phone lol
Rabbit R1
ChatGPT signups
did I miss any?
- Nick Dobos (@NickADobos) June 10, 2024
Page 4 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
Questions about training data
Other users on X, including some visual artists and tech workers opposed to the practices of generative AI model 
providers training without express consent on vast swaths of artwork and creative work posted to the web, 
questioned exactly how Apple had trained its underlying Apple Intelligence AI models - the company mentioned 
both language and diffusion models in its keynote announcement - and on what specific data.
1/ Apple 'Intelligence' is here and 0 questions of 'where does the data come from?' to be seen in press.
APPLE is trying to shove a huge privacy risk and tech that screams scraped off the internet without consent to the 
public. So here's a list of potential data sources ? pic.twitter.com/2WBzRSjsh3
- Karla Ortiz (@kortizart) June 10, 2024
Obviously impossible to know, but I suspect Steve Jobs would have been one of the few big tech CEOs to refuse to 
train generative AI on creators' work without their permission. Disappointing to see Apple drop hints they've done 
just that ('public web', 'can opt out' etc.) https://t.co/v3AjXQvzXE
- Ed Newton-Rex (@ednewtonrex) June 10, 2024
One Apple executive present at WWDC told Axios's Ina Fried that the models were trained on 'data from the public 
web' combined with licensed, or paid, data.
Giannandrea says Apple's llm was built in part using data from the public web and that publishers can opt out of, 
along with a wide range of licensed data. He doesn't get more specific, though.
- Ina Fried (@inafried) June 10, 2024
AI is a feature not a product?
Apple's choice to weave the Apple Intelligence service throughout its apps also had The Information founder and 
CEO Jessica Lessin musing that the approach was likely to be seen as influential.
The legacy of today's Apple news will be that AI is a feature not a product.
- Jessica Lessin (@Jessicalessin) June 10, 2024
Clearly, a wide range of reactions and they're still rolling in. What do you think about Apple Intelligence so far?
VB Daily
Stay in the know! Get the latest news in your inbox daily
By subscribing, you agree to VentureBeat's Terms of Service.
Thanks for subscribing. Check out more VB newsletters here .
An error occured.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
Page 5 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: June 10, 2024
=======
>>>>>>> c98f417 (update data file):extract_text.txt
End of Document
Page 1 of 3
The Artificial is Rarely Intelligent
The Artificial is Rarely Intelligent
Free The People
June 5, 2024 Wednesday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 Free the People, USA All Rights Reserved
Length: 1196 words
Byline: Taylor Lewis
Body
Jerry Seinfeld's commencement speech at Duke garnered national attention for the wrong reason. The handful of 
kids who petulantly stomped out in protest of Seinfeld's "Zionism," which I guess means being Jewish and believing 
your race deserves a homeland free of wanton pogroms, earned a few headlines, while also kicking in the Streisand 
Effect, awarding the sitcom star even more media regard. Score one for the children being carpet-bombed in Rafah, 
right?
What Seinfeld told graduates, which in typical comedic fashion cut against the grain of public sentiment, was 
approbatory. So of course it wasn't sensationalized. He issued no angry adjurations to feel guilty about earning a 
college degree because someone, somewhere, probably in a Botswanan bidonville, will never achieve the same 
credential. No preening "land acknowledgement." No "remember your fellow man" Dickensian platitudes meant to 
humble with humiliation. No cringey "change the world" injunction that inevitably leads to an overly idealistic student 
throwing him or herself into traffic to save the whooping crane.
Instead, Seinfeld ripped every page out of the DEI handbook, urging the audience to embrace their privilege and-
get this-be proud of their accomplishments. Who knew it was still legal to toot your own horn in America? (Lest 
you're a racial/sexual minority with a grievance pathology, obviously.)
That's all grand contrarian messages go, and Seinfeld's pro-privilege postulation would fit nicely in a Daily Wire 
infomercial. (Picture Ben Shapiro hyper-verbally sputtering, "Facts don't care about your feelings and privilege is 
good. You hear that, libs? PRIVILEGE IS GOOD. Ha! Triggered!) It's also uniquely American-that is, it was 
American up to about, by my estimate, seven years, fifty days, and thirty-two seconds ago when the Great 
Awokening entered its shame-success phase, when even the slightest flash of self-respect is slagged and 
maligned.
Being in favor of unapologetic excellence gives Seinfeld and edgelord verve. But he went further, needling 
America's most applauded class, after blacks, gays, and illegal migrants: the lazy. In particular, he went after the 
biggest boon to the slothful since the advent of DoorDash: artificial intelligence.
"AI," Seinfeld quipped, "is the most embarrassing thing we've ever invented in mankind's time on earth. Oh, you 
can't do the work. Is that what you're telling me? You can't figure it out?" You could almost hear the iconic bass line 
and laugh track as he delivered the bit. "This seems to be the justification of AI: I couldn't do it."

Page 2 of 3
The Artificial is Rarely Intelligent
That AI is a shortcut for the short-sighted and short-thinking is indisputable. The synthetic brain was coded to ease 
the pressure on organic brain tissue-that's its deontological purpose. Meanwhile, half of comedy's deontological 
purpose is, as Justin Taylor explains, is putting forth a "critique of the world as it is based on a vision of the world as 
it ought to be." The other half is to tickle your diaphragm with discernment.
Seinfeld mocks Silicon Valley's latest plaything as a godsend for hand-sitters, thumb-twiddlers, fiddle-fotters, 
dodderers, and work-shy corner-cutters. Extra points for Jerry: the shiftless need beration, if only to get their sorry 
hides off the couch.
Yet we seem to be increasingly settling for AI-generation in commercial areas that, as recently as a month ago, 
weren't subsumed by computerized composition. And the creations are far from triggering an "uncanny valley" 
feeling. They're downright chintzy.
Take Rudy Giuliani's fall from grace, hitting a new nadir with a panhandling coffee ad. America's mayor-turned-
mendicant is fobbing off drop-ship java beans in cheaply cartoonish bags for $30 a pop. "The will to survive," or pay 
off legal debt, "sweeps away moral imperatives," declared poet Marius Kociejowski. The spot Rudy recorded for his 
latest fleece-MAGA scheme was even jankier. He recorded his please-buy-plea in front of an obvious AI-produced 
background, complete with a Photoshop of his own product, which was supposed to resemble a Manhattan 
penthouse but comes across like a living room out of Sims 2. Just like his challenging the 2020 election results, 
Giuliani could hardly be accused of supererogatory effort.
The fakery involved in Giuliani's light-roast-grift is of a piece of widespread AI usage. There's always something off, 
something askew, something off the mark, something unholistic, something vaguely uneasy about digitized 
simulacrums of real life. The computerized-contoured images aren't all the way there; the .JPEGs can't pass a 
visual Turing test.
For one, there are the human hands, which most AI pic-producer flubs by turning digits and palms into alien 
echinoderms. Then there was the Google chatbot's wokely unhistorical depictions of ethnicities, including Indian-
shaded Vikings and blackified American Founding Fathers. Clearly, Gemini was coded with more Lin-Manuel 
Miranda than Noah Webster. There was also the amorous case where Microsoft's own AI avatar tried seducing a 
journalist-a very artificial affair, if you'll allow. Facebook, which was basically created by a borg passing as a man 
that has a surname curiously close to "sucker," hosts a multiplying ecosystem of bizarre "island of lost AI" slop 
content, including erotic martial Christian memes.
I know the left wants to sexualize everything, but J.C. being spooned by a biracial soldier couplet isn't something 
any human mind dreams up. It could only come from the rigidly binary algorithm of a circuit board that takes man-
made inputs and pushes them to illogical-or maybe too logical-conclusions.
With the U.S. presidential election in high gear, and a long hot summer of hustings events on deck, the use of AI 
campaign tactics are no doubt underway. That also means a concomitant rise in shenanigans, including the use of 
deepfake videos and propagandic imagery. Fake news has long been in America's stock of electoral weapons, but 
AI has the capacity to take the mendacious scheming of trolls to new heights. ChatGPT commandeered Scarlett 
Johansson's sultry voice; how long before a dirty trickster uses a comp-contrived Biden dialect to tell Democratic 
voters the election is really on November 12th? Answer: six months ago.
If artificial intelligence is a workaround for trying, it's going to take actual effort to parse the real from the ersatz. 
Piercing AI's verisimilitude will require, contra Seinfeld, us to do the work. Sometimes it'll be simple to spot the N64 
diorama behind a washed-up pol selling repackaged Folgers. Other times, it will take that extra few seconds to 
realize what you're hearing or seeing isn't an organic creation but a tech-fashioned artifice.
I know it's noisy out there, and too easy to scroll along. But take the extra half-minute to question and consider if 
what you're looking at comports with reality. Remember Kipling and keep your head if you see a grainy video of 
President Biden reading Mein Kampf and his lips aren't matching the words he's supposedly reciting. And do not, 
under any circumstances, take the first Google result for gospel.
The post The Artificial is Rarely Intelligent appeared first on Free the People.
Page 3 of 3
The Artificial is Rarely Intelligent
Load-Date: June 6, 2024
End of Document
Page 1 of 3
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Why Facebook won’t be influential in the UK general election
Why Facebook won’t be influential in the UK general election
The Guardian (London)
June 4, 2024 Tuesday 11:46 AM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:1
Length: 1268 words
Byline: Alex Hern
Highlight: All-powerful ‘microtargeting’ swaying the masses into voting a certain way was always overblown, but 
these days social media has moved on – and so have the parties
Body
You’ve heard the one about the drunk man looking for his keys under the streetlamp? After an age pacing back and 
forth, scouring the floor for them, his friend asks him where he thinks he dropped them. He points across the road, 
to a patch of darkness. “Why aren’t you looking there, then,” he friend asks. He shrugs. “Because this is where the 
light is.” Good joke. Everybody laughs.
Let’s talk about online political adverts.
“Microtargeting” isn’t a thing any more, explains the Guardian’s Jim Waterson  :
                       Don’t expect to see Cambridge Analytica-style microtargeted political adverts driven by personal data 
during this general election: the tactic is now considered by many to be an ineffective “red herring” and is 
increasingly being blocked by social media platforms. The digital strategist Tom Edmonds said Facebook had 
banned political campaigns from using many of the tactics deployed in past contests. “Running a campaign aimed 
at 500 people didn’t earn them much money and just got them loads of shit,” he said.                     
Microtargeting was feared because of the possibility of deleterious effects on democracy: if you could target a 
thousand different messages at a thousand different demographics, then the whole idea of a single national 
conversation begins to break down. Instead, what happened is it just didn’t really work.
Ultimately, the biggest competitor to the likes of Cambridge Analytica was Facebook itself. There’s little point in 
spending vast sums profiling individual voters to microtarget them when the social network’s ad tools let you simply 
hand over all targeting decisions to Facebook itself. The social network lets advertisers set “performance goals” 
[like sales, clicks, or signups], set a spend limit, and sit back and watch as it goes ahead and does whatever it 

Page 2 of 3
Why Facebook won’t be influential in the UK general election
thinks maximises return. The company will even pick the best combination of words and images to boost your 
chances of success.
But Facebook can only help you so much. If you’re creating adverts for specific candidates, for instance, who 
should you focus your time and money on: people who might win, or people who are definitely going to lose? If you 
said the latter, you might just work for the Conservative party. From our story  :
                       The strategy is known within the party as the “80/20” approach, in which it focuses all its spending on 
the 80 seats it came closest to losing in 2019 and the 20 seats it came closest to winning.                       Ad 
spending reports on Facebook show that these constituencies are exactly where the party is funnelling its money. 
More than half of the party’s spending on the social network since January has gone to its 80 tightest seats, or to 
seats it does not hold at all.                     
We started monitoring Meta ad spending to try to work out whether the reported “80/20 strategy” was holding. It is 
one thing to propose two years out from an election; it’s quite another to stick with it when an election is barely a 
month away.
But we also started monitoring Meta ad spending because we could. The company maintains a library of all political 
ads, discloses total spending, and requires verification of residency before people can launch new adverts. That 
library has come under a lot of criticism over the years, but at least it exists. More than that, it has a robust toolset 
that lets us write our own software to query against it, which means we can answer more serious questions than 
“are there any interesting adverts that anyone has paid for recently”.
Yet, like the drunk looking for his keys, it’s unlikely that Facebook is actually where the story is. For huge swathes of 
the country, conversations that once happened on the public social network have shifted to private channels, led by 
Meta’s own WhatsApp. That which remains on Facebook itself is swamped by AI-generated slop, and detached 
from reality after an algorithmic adjustment intended to boost content from “friends and family” – doubly so on 
Threads, Meta’s Twitter clone, which actively and openly downranks political content of all sorts.
There is more conversation on TikTok, but coverage of that platform is hard. The Observer looked at the digital 
campaigns , but for TikTok, was forced to focus on the parties’ own official feeds:
                       TikTok is free – it does not allow paid-for advertising by politicians or parties – but not easy: the 
social media teams need to work harder to persuade the app’s notoriously opaque algorithm to organically float 
their content on to users’ phones, which becomes more likely as more people like, share, comment or re-post 
videos. For smaller, agile parties with low budgets, TikTok will feel like there is everything to win: views, 
engagement and people who finally find out who they are. Creators who know how it’s done believe Labour has had 
a better start.                     
There is an election conversation happening on TikTok. There’s many, in fact, with the platform’s heavily curated 
algorithmic feed letting every demographic have their own exclusive discourse. But it’s nearly impossible to observe 
from the outside, short of brute-force techniques like totting up the view count on videos tagged “Sunak”.
It’s worse still, of course, for the conversation on WhatsApp. With its end-to-end encryption and sparse public 
“channels”, doing data journalism to track the election chats is a dead end.
And then there’s AI. There’s a lingering suspicion that the rise of AI systems will have some sort of effect on this 
election, but again, we’re forced to look where the light is. Deepfaked video going viral on Twitter, the platform 
currently known as X, is very obvious (and hasn’t really been seen so far). Wavering voters having conversations 
with ChatGPT to try to determine where they should put their X is invisible – if it’s even happening.
In the UK, these questions feel largely academic. Outside a few personality-driven local races, the eventual results 
feel more of a foregone conclusion  than they have at any point in my life to date. But as the US goes to the polls in 
five months’ time, the same questions will be asked – and the answers could be key to what side the coin lands on.
Page 3 of 3
Why Facebook won’t be influential in the UK general election
Best get to trying to find them, then.
                   The wider Techscape                                                               Speaking of deepfakes – a fake Tom 
Cruise video  (pictured above) was used to spread disinformation about the Olympics, Microsoft says.                                                                                          
Is the internet bad  ? It certainly seems to have been for the Marubo tribe, whose first nine months online hasn’t 
been all sunshine and roses.                                                                 An internal Google database tracking privacy 
and security breaches was leaked to 404 Media.  One of the biggest threats? YouTube employees sneaking a look 
at big scheduled video uploads to get a heads-up on the information.                                                                 
Voters support raising the minimum age for social media apps in the UK to 16, a Guardian poll reveals.                                                                  
Microsoft’s “ Recall ” feature – a clone of Mac app Rewind, built into the OS – has been labelled a security 
“disaster”.  The AI service keeps a database of everything you’ve ever seen on your computer, for an LLM to use to 
answer questions. It’s the perfect target for hackers, critics say.                                                         
Load-Date: June 4, 2024
End of Document
Page 1 of 5
Links 5/29/2024
Links 5/29/2024
Newstex Blogs 
Naked Capitalism
May 30, 2024 Thursday 10:58 AM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 Naked Capitalism 
Length: 1406 words
Byline: Lambert Strether
Body
May 30th, 2024 ( Naked Capitalism  - Delivered by  Newstex )
Something Strange Happens to Wolves Infected by an Infamous Mind-Altering Parasite  Science Alert
Taking Stock: Dollar Assets, Gold, and Official Foreign Exchange Reserves  Federal Reserve Bank of New York, 
Liberty Street Economics
Would Returning to the Gold Standard Resolve Our Most Pressing Monetary Problems?  Charles Hugh Smith, Or 
Two Minds. No.
CalPERS opposes Elon Musk's $56 billion pay package amid shareholder discontent  WION
The CRE non-crisis rolls on  FT
Climate
US and China must take lead in climate fight despite their competitive relationship, top Beijing envoy  says South 
China Morning Post
In search of a market-driven price on carbon  S&P Global. Let me know how that works out.
Trees in Distress  St Louis Post-Dispatch
Proposed Cooling Policy Would Cause Air Conditioning Usage to Rise, Risking Blackouts  RAND
Water
Accusations flare as Mexico City's water crisis approaches 'day zero'  Bnamericas

Page 2 of 5
Links 5/29/2024
Dozens of Alaskan rivers and streams turn orange, visible from space  Interesting Engineering
Understanding Water Advisories  The Brockovich Report
Syndemics
Officials investigate unusual surge in flu viruses in Northern California  San Francisco Chronicle
The bird flu vaccine is made with eggs. That has scientists worried.  CBS
China?
Beware forecasts of doom for Taiwan under Lai  Brookings Institution
Debt-Trap Diplomacy  J-STOR Daily
Chinese scientists cure diabetes using stem cells in world first  NextShak. But if we cure it, what happens t our rents 
on insulin? Think. people!
Myanmar
Myanmar's ethnic armies consolidate strongholds as junta weakens, reports say  Reuters
Vast concessions threaten Malaysia's forests: Report  Channel News Asia
India
Delhi 'unbearable' as temperatures near 50C  BBC
Power demand peaks in heatwave-hit Delhi, but temperature readings may be 'error' Channel News Asia
Syraqistan
The US-built pier in Gaza broke apart. Here's how we got here and what might be next  Orlando Sentinel
* * *
Israel says it seized key Gaza-Egypt corridor as Rafah ground offensive intensifies  France24
Pushed to the edge, starved and exhausted, Rafah IDPs struggle to survive  The New Arab
* * *
Attacks on ICC Show 'Condemning Hamas' Is Really About Absolving Israel  FAIR
Israel shrugs off UNSC bid to 'stop the killing' to continue Rafah assault  Al Jazeera
European Disunion
Walking France: Avignon to Pont-Saint-Esprit  Chris Arnade, Walking the World
Dear Old Blighty
Favoured Nation  New Left Review
Labour promises to hit 18-week NHS waiting target within five years  BBC. Ambitious!
Page 3 of 5
Links 5/29/2024
New Not-So-Cold War
NATO meets as calls grow to let Ukraine strike targets inside Russia  France24. Mercouris, more recent than any of 
these, says striking targets in Russia is coming off the boil.
US Secretary of State hints they may allow Ukraine to strike Russian territory with US weapons  and Poland allows 
Ukraine to use Polish-supplied weapons to strike targets in Russia  Ukrainska Pravda
NATO Ramps Up Figleaf of Cross-Border Strikes  Simplicius the Thinker(s)
U.S. concerned about Ukraine strikes on Russian nuclear radar  stations WaPo
How to Win in Ukraine: Pour It On, and Don't Worry About Escalation  RAND. But from May 22.
* * *
Ukraine war: influential Russian think tank proposes a 'demonstrative' nuclear explosion  South China Morning Post
* * *
Nato has just 5% of air defences needed to protect eastern  flank FT
Image shows a 7-layer defensive line planned for the border between NATO and Russia  Insider. Awesome. I 
assume a PowerPoint comes with it?
NATO Holds First Meeting Of Critical Undersea Infrastructure Network  Naval News
* * *
Delivery of US weapons to Ukraine helping stabilize frontline, Blinken says  Reuters
Soldiers in Ukraine say US-supplied tanks have made them targets for Russian strikes  CNN. Oopsie.
Increasingly Effective Russian Electronic Warfare Turning the Tide on the Frontlines - Reports  Military Watch
* * *
Georgia's 'foreign agents' law is now a reality. When will it take effect and who will it impact?  JAM News
Hundreds of Georgian NGOs pledge to defy 'foreign influence' law  Al Jazeera
Global Elections
South Africa counts ballots in most competitive election since apartheid  France24
2024
Jury Instructions & Charges  (PDF), People v Donald J. Trump
AIPAC offshoot spending heavily to beat Cori Bush in her primary  Politico. Election interference.
The Supremes
82. The Supreme Court's Four Officers  One First
Spook Country
Page 4 of 5
Links 5/29/2024
The obscure federal intelligence bureau that got Vietnam, Iraq, and Ukraine right  Vox
The Bezzle
Courts rather than arbitrators to decide whether Dogecoin dispute goes to arbitration  SCOTUSblog
Exclusive: The Atlantic, Vox Media ink licensing, product deals with OpenAI  Axios
Publishing AI Slop Is a Choice  Daring Fireball
Digital Watch
Google Researchers Say AI Now Leading Disinformation Vector (and Are Severely Undercounting the Problem)  
404 Media. 'If you didn't want to go to Milwaukee, why did you get on the train?' -Father Emil, A Prairie Home 
Companion (from memory).
Google confirms the leaked Search documents are real  The Verge
US judge makes 'unthinkable' pitch to use AI to interpret legal texts  Reuters
Gavin Newsom warns against perils of over-regulating  AI Politico
Boeing
FAA appears poised to grant Boeing extension on safety report  Leeham News & Analysis
The 420
K-Pop  The Baffler. Ketamine.
Imperial Collapse Watch
Jeffrey Sachs: The Untold History of the Cold War, CIA Coups Around the World, and COVID's Origin  (video) 
Tucker Carlson, YouTube
Can The B-21 Raider Save America's Shrinking Bomber Force?  1945. No.
Class Warfare
How Tens of Thousands of Grad Workers Are Organizing Themselves  Labor Notes
Seattle isn't claiming Tukwila's migrant crisis. But it did start here  Seattle Times
Antidote du jour, via JB:
'A little bird singing in the cold.'
See yesterday's Links and Antidote du Jour here .
This entry was posted in Guest Post , Links  on May 30, 2024  by  Lambert Strether  .
About Lambert Strether
Readers, I have had a correspondent characterize my views as realistic cynical. Let me briefly explain them. I 
believe in universal programs that provide concrete material benefits, especially to the working class. Medicare for 
All is the prime example, but tuition-free college and a Post Office Bank also fall under this heading. So do a Jobs 
Page 5 of 5
Links 5/29/2024
Guarantee and a Debt Jubilee. Clearly, neither liberal Democrats nor conservative Republicans can deliver on such 
programs, because the two are different flavors of neoliberalism ('Because markets'). I don't much care about the 
'ism' that delivers the benefits, although whichever one does have to put common humanity first, as opposed to 
markets. Could be a second FDR saving capitalism, democratic socialism leashing and collaring it, or communism 
razing it. I don't much care, as long as the benefits are delivered.To me, the key issue - and this is why Medicare for 
All is always first with me - is the tens of thousands of excess 'deaths from despair,' as described by the Case-
Deaton study, and other recent studies. That enormous body count makes Medicare for All, at the very least, a 
moral and strategic imperative. And that level of suffering and organic damage makes the concerns of identity 
politics - even the worthy fight to help the refugees Bush, Obama, and Clinton's wars created - bright shiny objects 
by comparison. Hence my frustration with the news flow - currently in my view the swirling intersection of two, 
separate Shock Doctrine campaigns, one by the Administration, and the other by out-of-power liberals and their 
allies in the State and in the press - a news flow that constantly forces me to focus on matters that I regard as of 
secondary importance to the excess deaths. What kind of political economy is it that halts or even reverses the 
increases in life expectancy that civilized societies have achieved? I am also very hopeful that the continuing 
destruction of both party establishments will open the space for voices supporting programs similar to those I have 
listed; let's call such voices 'the left.' Volatility creates opportunity, especially if the Democrat establishment, which 
puts markets first and opposes all such programs, isn't allowed to get back into the saddle. Eyes on the prize! I love 
the tactical level, and secretly love even the horse race, since I've been blogging about it daily for fourteen years, 
but everything I write has this perspective at the back of it.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: May 30, 2024
End of Document
Page 1 of 2
Losing the library
Losing the library
The Week US
May 28, 2024 Tuesday 5:36 PM EST
Copyright 2024 Future US, Inc.  All Rights Reserved
Section: TECH LATEST
Length: 340 words
Byline: Theunis Bates
Body
Around 300 B.C., King Ptolemy I - the new ruler of Egypt and a former general of Alexander the Great - tasked an 
adviser with a modest mission: "to collect, if possible, all the books in the world." Over the next two centuries, the 
great library in the Ptolemaic capital of Alexandria would be filled with hundreds of thousands of papyrus scrolls: 
the full corpus of ancient Greek and Egyptian literature along with Buddhist, Jewish, and Zoroastrian texts. 
Ships would be searched for books when they docked at Alexandria, and royal agents would pay hefty sums for 
almost any written work. A booming market in fakes and forgeries soon emerged. Entrepreneurial scribes dashed 
off scrolls of supposed secret wisdom from famous thinkers - one was titled Everything Thucydides Left Unsaid - 
while others created books that mixed the authentic with the imagined. In Alexandrias merchant quarter, stalls that 
once sold vegetables and baskets were "replaced with those stacking rolls and rolls of books," writes historian Islam 
Issa. 
Eventually, the library had to hire experts to wade through the sea of bogus texts and identify genuine treasures. 
The web, our modern-day library of Alexandria, faces a similar problem. This digital repository of human knowledge 
is being swamped with AI-generated slop - pointless listicles, nonsensical how-to guides, and factually flawed news 
summaries churned out by content factories that want to grab clicks and ad revenue on the cheap. To save users 
the hassle of scrolling through reams of garbage links in its search engine, Google has now started showing users 
AI-generated answers to their queries. But those answers are sometimes wrong - one user who wanted a fix for a 
cars faulty turn signal was advised to "replace the blinker fluid" - and pull traffic and dollars away from useful, 
human-run websites. Maybe the tech giant should hire more humans to curate trustworthy collections of knowledge. 
It could call them "librarians."
This is the editors letter in the current issue of The Week magazine. 
Load-Date: May 28, 2024

Page 2 of 2
Losing the library
End of Document
Page 1 of 2
TechScape: The people charged with making sure AI doesn
TechScape: The people charged with making sure AI doesn
 
Africa Newswire
May 22, 2024 Wednesday
Copyright 2024 Africa Newswire All Rights Reserved
Length: 745 words
Body
 22 May 2024 (TourismAfrica2006) Everything happens so much. I'm in Seoul for the International AI summit, the 
half-year follow-up to last year's Bletchley Park AI safety summit (the full sequel will be in Paris this autumn). While 
you read this, the first day of events will have just wrapped up - though, in keeping with the reduced fuss this time 
round, that was merely a "virtual" leaders' meeting.
When the date was set for this summit - alarmingly late in the day for, say, a journalist with two preschool children 
for whom four days away from home is a juggling act - it was clear that there would be a lot to cover. The hot AI 
summer is upon us:
Then, the weekend before the summit kicked off, everything kicked off at OpenAI as well. Most eye-catchingly, 
perhaps, the company found itself in a row with Scarlett Johansson over one of the voice options available in the 
new iteration of ChatGPT. Having approached the actor to lend her voice to its new assistant, an offer she declined 
twice, OpenAI launched ChatGPT-4o with "Sky" talking through its new capabilities. The similarity to Johansson 
was immediately obvious to all, even before CEO Sam Altman tweeted "her" after the presentation (the name of the 
Spike Jonze film in which Johansson voiced a super-intelligent AI). Despite denying the similarity, the Sky voice 
option has been removed.
More importantly though, the two men leading the company/nonprofit/secret villainous organisation's 
"superalignment" team - which was devoted to ensuring that its efforts to build a superintelligence don't end 
humanity - quit. First to go was Ilya Sutskever, the co-founder of the organisation and leader of the boardroom coup 
which, temporarily and ineffectually, ousted Altman. His exit raised eyebrows, but it was hardly unforeseen. You 
come at the king, you best not miss. Then, on Friday, Jan Leike, Sutskever's co-lead of superalignment also left, 
and had a lot more to say:
Leike's resignation note was a rare insight into dissent at the group, which has previously been portrayed as almost 
single-minded in its pursuit of its - which sometimes means Sam Altman's - goals. When the charismatic chief 
executive was fired, it was reported that almost all staff had accepted offers from Microsoft to follow him to a new AI 
lab set up under the House of Gates, which also has the largest external stake in OpenAI's corporate subsidiary. 

Page 2 of 2
TechScape: The people charged with making sure AI doesn
Even when a number of staff quit to form Anthropic, a rival AI company that distinguishes itself by talking up how 
much it focuses on safety, the amount of shit-talking was kept to a minimum.
It turns out (surprise!) that's not because everyone loves each other and has nothing bad to say. From Kelsey Piper 
at Vox:
Barely a day later, Altman said the clawback provisions "should never have been something we had in any 
documents". He added: "we have never clawed back anyone's vested equity, nor will we do that if people do not 
sign a separation agreement. this is on me and one of the few times I've been genuinely embarrassed running 
openai; i did not know this was happening and i should have." (Capitalisation model's own.)
Altman didn't address the wider allegations, of a strict and broad NDA; and, while he promised to fix the clawback 
provision, nothing was said about the other incentives, carrot and stick, offered to employees to sign the exit 
paperwork.
As set-dressing goes, it's perfect. Altman has been a significant proponent of state and interstate regulation of AI. 
Now we see why it might be necessary. If OpenAI, one of the biggest and best-resourced AI labs in the world, 
which claims that safety is at the root of everything it does, can't even keep its own team together, then what hope 
is there for the rest of the industry?
It's fun to watch a term of art developing in front of your eyes. Post had junk mail; email had spam; the AI world has 
slop:
I'm keen to help popularise the term, for much the same reasons as Simon Willison, the developer who brought its 
emergence to my attention: it's crucial to have easy ways to talk about AI done badly, to preserve the ability to 
acknowledge that AI can be done well.
The existence of spam implies emails that you want to receive; the existence of slop entails AI content that is 
desired. For me, that's content I've generated myself, or at least that I'm expecting to be AI-generated. No one 
cares about the dream you had last night, and no one cares about the response you got from ChatGPT. Keep it to 
yourself.
Load-Date: May 23, 2024
End of Document
Page 1 of 2
Spam, junk
Spam, junk
 
Africa Newswire
May 21, 2024 Tuesday
Copyright 2024 Africa Newswire All Rights Reserved
Length: 926 words
Body
 21 May 2024 (TourismAfrica2006) Your email inbox is full of spam. Your letterbox is full of junk mail. Now, your 
web browser has its own affliction: slop.
"Slop" is what you get when you shove artificial intelligence-generated material up on the web for anyone to view.
Unlike a chatbot, the slop isn't interactive, and is rarely intended to actually answer readers' questions or serve 
their needs.
Instead, it functions mostly to create the appearance of human-made content, benefit from advertising revenue and 
steer search engine attention towards other sites.
Just like spam, almost no one wants to view slop, but the economics of the internet lead to its creation anyway. AI 
models make it trivial to automatically generate vast quantities of text or images, providing an answer to any 
imaginable search query, uploading endless shareable landscapes and inspirational stories, and creating an army 
of supportive comments. If just a handful of users land on the site, reshare the meme or click through the adverts 
hosted, the cost of its creation pays off.
But like spam, its overall effect is negative: the lost time and effort of users who now have to wade through slop to 
find the content they're actually seeking far outweighs the profit to the slop creator.
"I think having a name for this is really important, because it gives people a concise way to talk about the problem," 
says the developer Simon Willison, one of the early proponents of the term "slop".
"Before the term 'spam' entered general use it wasn't necessarily clear to everyone that unwanted marketing 
messages were a bad way to behave. I'm hoping 'slop' has the same impact - it can make it clear to people that 
generating and publishing unreviewed AI-generated content is bad behaviour."
Slop is most obviously harmful when it is just plain wrong. Willison pointed to an AI-generated Microsoft Travel 
article that listed the "Ottawa food bank" as a must-see attraction in the Canadian capital as a perfect example of 

Page 2 of 2
Spam, junk
the problem. Occasionally, a piece of slop is so useless that it goes viral in its own right, like the careers advice 
article that earnestly explains the punchline to a decades-old newspaper comic: "they pay me in woims".
"While the precise meaning of 'They Pay Me in Woims' remains ambiguous, various interpretations have emerged, 
ranging from a playful comment on work-life balance to a deeper exploration of our perceived reality," the slop 
begins.
AI-generated books have become a problem too. A prominent example came when amateur mushroom pickers 
were recently warned to avoid foraging books sold on Amazon that appeared to have been written by chatbots and 
contained dangerous advice for anyone hoping to discern a lethal fungus from an edible one.
Image-generated slop has also blossomed on Facebook, as images of Jesus Christ with prawns for limbs, children 
in plastic bottle-cars, fake dream homes and improbably old women claiming to have baked their 122nd birthday 
cake garner thousands of shares.
Jason Koebler of the tech news site 404 Media believes the trend represents what he calls the "zombie internet". 
The rise of slop, he says, has turned the social network into a space where "a mix of bots, humans and accounts 
that were once humans but aren't any more mix together to form a disastrous website where there is little social 
connection at all."
Nick Clegg, the president of global affairs at Facebook's parent company, Meta, wrote in February that the social 
network is training its systems to identify AI-made content. "As the difference between human and synthetic content 
gets blurred, people want to know where the boundary lies," he wrote.
The problem has begun to worry the social media industry's main revenue source: the advertising agencies who 
pay to place ads next to content. Farhad Divecha, the managing director of UK-based digital marketing agency 
AccuraCast, says he is now encountering cases where users are mistakenly flagging ads as AI-made slop when 
they are not.
"We have seen instances where people have commented that an advert was AI-generated rubbish when it was 
not," he says, adding that it could become a problem for the social media industry if consumers "start to feel they 
are being served rubbish all the time".
Tackling spam in inboxes required an enormous cross-industry effort and led to a fundamental change in the nature 
of email. Big webmail providers like Gmail aggressively monitor their own platforms to crack down on spammers 
and are increasingly suspicious of emails arriving from untrusted email servers. They also apply complex, largely 
undocumented, AI systems to try to detect spam directly, in a constant cat-and-mouse game with the spammers 
themselves.
For slop, the future is less rosy: the world's largest companies have gone from gamekeeper to poacher. Last week, 
Google announced an ambitious plan to add AI-made answers to the top of some search results, with US-based 
users the first to experience a full rollout of the "AI Overviews" feature. It will include links as well, but users who 
want to limit the response to just a selection of links to other websites will be able to find them - by clicking through 
to "web" on the search engine, demoted to sit beside "images" and "maps" on the list of options.
"We've added this after hearing from some that there are times when they'd prefer to just see links to webpages in 
their search results," wrote Danny Sullivan, the company's search liaison.
Google says the AI overviews have strong safety guardrails. Elsewhere on the web though, slop is spreading.
Load-Date: May 22, 2024
End of Document
Page 1 of 3
The people charged with making sure AI doesn’t destroy humanity have left the building
The people charged with making sure AI doesn’t destroy humanity have left 
the building
The Guardian (London)
May 21, 2024 Tuesday 11:38 AM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:1
Length: 1639 words
Byline: Alex Hern
Highlight: If OpenAI can’t keep its own team together, what hope is there for the rest of the industry? Plus, AI-
generated ‘slop’ is taking over the internet Don’t get TechScape delivered to your inbox? Sign up for the full article 
here
Body
Everything happens so much.  I’m in Seoul for the International AI summit, the half-year follow-up to last year’s 
Bletchley Park AI safety summit (the full sequel will be in Paris this autumn). While you read this, the first day of 
events will have just wrapped up – though, in keeping with the reduced fuss this time round, that was merely a 
“virtual” leaders’ meeting.
When the date was set for this summit – alarmingly late in the day for, say, a journalist with two preschool children 
for whom four days away from home is a juggling act – it was clear that there would be a lot to cover. The hot AI 
summer is upon us  :
                       The inaugural AI                       safety                       summit at Bletchley Park in the UK last year 
announced an international testing framework for AI models, after calls                       … for a six-month pause in 
development of powerful systems.                       There has been no pause. The Bletchley declaration, signed by 
UK, US, EU, China and others, hailed the “enormous global opportunities” from AI but also warned of its potential 
for causing “catastrophic” harm. It also secured a commitment from big tech firms including OpenAI, Google and 
Mark Zuckerberg’s Meta to cooperate with governments on testing their models before they are released.                       
While the UK and US have established national AI safety institutes, the industry’s development of AI has continued                        
… OpenAI released GPT-4o (the o stands for “omni”) for free online; a day later, Google previewed a new AI 
assistant called Project Astra, as well as updates to its Gemini model. Last month, Meta released new versions of 
its own AI model, Llama                        …                        And in March, the AI startup Anthropic, formed by former 
OpenAI staff who disagreed with                        Altman’s approach, updated its Claude model                       .                     

Page 2 of 3
The people charged with making sure AI doesn’t destroy humanity have left the building
Then, the weekend before the summit kicked off, everything kicked off at OpenAI as well. Most eye-catchingly, 
perhaps, the company found itself in a row with Scarlett Johansson  over one of the voice options available in the 
new iteration of ChatGPT. Having approached the actor to lend her voice to its new assistant, an offer she declined 
twice, OpenAI launched ChatGPT-4o with “Sky” talking through its new capabilities. The similarity to Johansson 
was immediately obvious to all, even before CEO Sam Altman tweeted “her” after the presentation (the name of the 
Spike Jonze film in which  Johansson voiced a super-intelligent AI). Despite denying the similarity, the Sky voice 
option has been removed.
More importantly though, the two men leading the company/nonprofit/secret villainous organisation’s 
“superalignment” team – which was devoted to ensuring that its efforts to build a superintelligence don’t end 
humanity – quit. First to go was Ilya Sutskever, the co-founder of the organisation  and leader of the boardroom 
coup which, temporarily and ineffectually, ousted Altman. His exit raised eyebrows, but it was hardly unforeseen. 
You come at the king, you best not miss. Then, on Friday, Jan Leike, Sutskever’s co-lead of superalignment also 
left , and had a lot more to say:
                       A former senior employee at OpenAI has said the company behind ChatGPT is prioritising “shiny 
products” over safety, revealing that he quit after a disagreement over key aims reached “breaking point”.                       
Leike detailed the reasons for his departure in a thread on X posted on Friday, in which he said safety culture had 
become a lower priority. “Over the past years, safety culture and processes have taken a backseat to shiny 
products,” he wrote.                       “These problems are quite hard to get right, and I am concerned we aren’t on a 
trajectory to get there,” he wrote, adding that it was getting “harder and harder” for his team to do its research.                       
“Building smarter-than-human machines is an inherently dangerous endeavour. OpenAI is shouldering an 
enormous responsibility on behalf of all of humanity,” Leike wrote, adding that OpenAI “must become a safety-first 
AGI [artificial general intelligence] company”.                     
Leike’s resignation note was a rare insight into dissent at the group, which has previously been portrayed as almost 
single-minded in its pursuit of its – which sometimes means Sam Altman’s – goals. When the charismatic chief 
executive was fired, it was reported that almost all staff had accepted offers from Microsoft to follow him to a new AI 
lab set up under the House of Gates, which also has the largest external stake in OpenAI’s corporate subsidiary. 
Even when a number of staff quit to form Anthropic, a rival AI company that distinguishes itself by talking up how 
much it focuses on safety, the amount of shit-talking was kept to a minimum.
It turns out (surprise!) that’s not because everyone loves each other and has nothing bad to say. From Kelsey Piper 
at Vox  :
                       I have seen the extremely restrictive off-boarding agreement that contains nondisclosure and non-
disparagement provisions former OpenAI employees are subject to. It forbids them, for the rest of their lives, from 
criticizing their former employer. Even acknowledging that the NDA exists is a violation of it.                       If a 
departing employee declines to sign the document, or if they violate it, they can lose all vested equity they earned 
during their time at the company, which is likely worth millions of dollars. One former employee, Daniel                       
Kokotajlo                       , who posted that he quit OpenAI “due to losing confidence that it would behave responsibly 
around the time of AGI”, has confirmed publicly that he had to surrender what would have likely turned out to be a 
huge sum of money in order to quit without signing the document.                     
Barely a day later, Altman said the clawback provisions “should never have been something we had in any 
documents”. He added: “we have never clawed back anyone’s vested equity, nor will we do that if people do not 
sign a separation agreement. this is on me and one of the few times I’ve been genuinely embarrassed running 
openai; i did not know this was happening and i should have.” (Capitalisation model’s own.)
Altman didn’t address the wider allegations, of a strict and broad NDA; and, while he promised to fix the clawback 
provision, nothing was said about the other incentives, carrot and stick, offered to employees to sign the exit 
paperwork.
Page 3 of 3
The people charged with making sure AI doesn’t destroy humanity have left the building
As set-dressing goes, it’s perfect. Altman has been a significant proponent of state and interstate regulation of AI. 
Now we see why it might be necessary. If OpenAI, one of the biggest and best-resourced AI labs in the world, 
which claims that safety is at the root of everything it does, can’t even keep its own team together, then what hope 
is there for the rest of the industry?
                                        Sloppy                                      
It’s fun to watch a term of art developing in front of your eyes. Post had junk mail; email had spam; the AI world has 
slop  :
                       “Slop” is what you get when you shove artificial intelligence-generated material up on the web for 
anyone to view.                       Unlike a chatbot, the slop isn’t interactive, and is rarely intended to actually answer 
readers’ questions or serve their needs.                       But like spam, its overall effect is negative: the lost time and 
effort of users who now have to wade through slop to find the content they’re actually seeking far outweighs the 
profit to the slop creator.                     
I’m keen to help popularise the term, for much the same reasons as Simon Willison, the developer who brought its 
emergence to my attention: it’s crucial to have easy ways to talk about AI done badly, to preserve the ability to 
acknowledge that AI can be done well.
The existence of spam implies emails that you want to receive; the existence of slop entails AI content that is 
desired. For me, that’s content I’ve generated myself, or at least that I’m expecting to be AI-generated. No one 
cares about the dream you had last night, and no one cares about the response you got from ChatGPT. Keep it to 
yourself.
                   The wider TechScape                                                               He was passed over by Nasa in 1961 to 
become the first Black astronaut. Now Ed Dwight, who is 90, finally reached space.                                                                  
The latest in China’s propaganda toolkit  ? The AI-generated news anchor.                                                                 
Where are the $1tn British tech titans ? Will Hutton on why Britain doesn’t have its own Microsoft or Alphabet.  It’s 
been almost a decade since I asked why there’s no “European Google” , and it’s interesting to note which things do 
and don’t hold up.                                                                                          Microsoft has asked hundreds of 
employees in China to relocate elsewhere, according to the Washington Post  (£), as tensions over AI between the 
US and China heat up.                                                                                          Google was once a portal to the 
internet. Now it is trying to be the internet.                                                                  And remember Belle Delphine, 
the social media star who made $90,000 selling jars of her bathwater online? Business Insider’s Katie Notopoulous 
has the story (£)  of how it took Delphine five years to finally get that hard-earned cash from PayPal.                                                         
Load-Date: June 28, 2024
End of Document
Page 1 of 3
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 'dumber'
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 
'dumber'
Daily Star Online
May 21, 2024 Tuesday 12:33 PM GMT
Copyright 2024 Northern and Shell Media Publications All Rights Reserved
Length: 760 words
Byline: By, Layla Nicholson
Highlight: EXCLUSIVE: Ahead of this weeks global virtual AI safety summit held in South Korea, tech expert Olivia 
DeRamus posed a stark warning for the future of the internet in the age of brainless bots
Body
A tech expert has warned that social media will soon be "full of AI bots" which will create a "zombie internet". 
Olivia DeRamus, known as the 'Elle Woods of tech', posed the chilling prediction as fellow gurus have banded 
together to share their grave concerns about the boom in AI and its exceeding advancement. 
The founder of Communia , a social media platform for women, feels that social media in particular is losing its 
'social' aspect as a surge of fakeness is threatening to impede on human connection. 
                     Check out the latest Exclusives from Daily Star                   
And she predicts that brainless bots will soon overwhelm social media as we know it. 
Speaking exclusively to Daily Star, Olivia warned: "People don't realise how many fake accounts there are, let alone 
content, on the internet.
"A national digital security expert once told me about half of social media accounts are fake. A 2023 study in Ireland 
showed that almost 1/3 of adults have fake social accounts. 
"Fakeness on today's mainstream social media platforms is nothing new, but the massive increase in casual AI 
generated content is certainly intensifying an issue that was already starting to come to a boil. 
"Authenticity is rare on today's internet, despite the millions of people who hope to use these very platforms to find 
it."

Page 2 of 3
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 'dumber'
Although many people seek socialisation through their screens, Olivia feels this will be made redundant in the near 
future as AI content surges onto every platform. 
From the deepfake Pope in a stylish puffer jacket to an 'World's first AI beauty pageant will set women back 100 
years – it's horrific'  to celebrate and reward some of the most 'beautiful' computer generated forms, reality is 
becoming more sparse on the platforms where people can communicate across the globe.
Earlier this year, Jason Koebler of tech news site, 404 Media, penned the term "zombie internet" in reference to the 
AI "slop" being produced on social media, reports The Guardian.  
He noted: "A mix of bots, humans and accounts that were once humans but aren’t any more mix together to form a 
disastrous website where there is little social connection at all."
Olivia fears the same, and shared that there is no going back once the "zombie internet" of brainless bots 
consumes all that is human and social.
The Communia founder shared: "I agree with this assessment about the oncoming zombie internet, and 
unfortunately there will be no deleting it once it happens.
"As the internet gets dumber, people are becoming more discerning and more disillusioned. 
"AI could be a great tool in gathering real people together and facilitating better experiences, but that's not the 
direction today's key tech platforms are taking.
"In that way, it looks like these companies are creating their own demise.
"That's a shame, but new platforms who see the need for human centred and meaningful connection, like 
Communia, are emerging and will likely continue to rise as long as we continue to pursue a different path. 
"The traditional motto in tech has been 'move fast and break things' under the misguided idea that you can delete 
the problems you create. That's just not true. 
"Once you post something, it's up forever, once you code something poorly, it's a mess to untangle."
Olivia now believes that the onus is on the big tech firms – like Meta and Google – to tackle the place AI has on 
their platforms.
Though, she is optimistic about the future of the digital world and hopes that her platform Communia can be a part 
of that. 
Although she is not anti-AI, she is against how AI is currently being pushed without "mindful implementation."
She concluded: "I am optimistic though that we can create a better digital world, but we might have to start from 
scratch to do it. 
"Every platform, from Meta to Google, is rushing to implement AI features in their haste to win the 'AI innovation 
wars'.
"This is happening alongside issues like misinformation tech firms were already struggling to appropriately address. 
"Can their new AI recommendation tools really decipher between AI generated content and content created by 
humans Or whether content with the most likes they'll then recommend is popular because of bot activity 
"I'm doubtful, and it seems likely that the fresh tools looking to dominate our feeds could just maximize existing 
problems. I'm not anti AI, I'm anti AI without mindful implementation. 
Page 3 of 3
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 'dumber'
"Ultimately, I don't think big tech platforms are likely to robustly address these issues as long as they are generating 
revenue from what's currently in place."
Load-Date: June 28, 2024
End of Document
Page 1 of 3
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All 
In On AI
Forbes.com
May 20, 2024 Monday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1248 words
Byline: Richard Nieva, Forbes Staff
Highlight: Nearly 15 years after founding Quora, D Angelo wants to reinvent the question-and answer company 
around AI before it goes the way of Yahoo Answers.
Body
<figure>
<figcaption>
Quora CEO Adam D'Angelo
Augustin LE GALL/HAYTHAM-REA/Redux
</figcaption></figure>
 Can I show you a demo? Adam D Angelo says as he prepares to share his screen on Zoom.
The CEO of Quora is extolling the virtues of Poe, the company s platform for letting people chat with multiple AI 
models at a time. But during a test earlier that day for what should have been an easy task generating a logo design 
using my name the service had glitched. D Angelo is quick to jump into troubleshoot mode. (I probably hadn t set up 
Poe to access an image-generating model, he diagnoses.)
Last year, D Angelosaidat an AI event that most of the company s energy these days is devoted to Poe, a service 
the company launched last year that serves as an interface for using and comparing multiple AI models, as well as 
bots built on top of them. That means less energy on Quora, the nearly 15-year-old Q&A forum that D Angelo 
founded after leaving his post as Facebook s CTO. But D Angelo is so excited about AI s potential that he s gotten 
hands-on with the company s new product, which has its own URL, separate from Quora.
 Poe needs more of my attention because it's in this more rapidly changing landscape,  D Angelo toldForbes.  
Quora has been around for many years now. It doesn't need to adapt. It doesn't need to change every week.  
Quora s goals are quarterly, he said, whereas Poe s targets are set every two weeks.
The two products are vastly different. Quora is a message board where people answer questions like  What did 
Marilyn Monroecarry in her coffin?  and  What is the best small business tostart in Gambia?  Meanwhile Poe, which 
stands for  Platform for Open Exploration,  is a freemium $200 per year subscription service that gives people 

Page 2 of 3
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI
access to several models, including OpenAI s GPT-4, Anthropic s Claude and Google sGoogleGemini. With the 
service, users can sample multiple models at once, comparing how each one tackles the same prompt. Developers 
can build bots on top of those models, creating, for example, an AI focused specifically on travel booking or creating 
coloring books for school children. Those developers can get paid per query, adding another revenue stream for 
people building AI tools. D Angelo likens Poe to a web browser for AI, making the tech more accessible, like 
Netscape did three decades earlier.
  Poe needs more of my attention because it's in this more rapidly changing landscape.  <footer>Adam D 
Angelo</footer>
On its face, Poe and Quora don t seem connected. But D Angelo says Poe was born out of AI experiments the 
company began running two years ago, where it used OpenAI s GPT-3 to generate answers for Quora questions. 
They were not as good as human-written answers, but the company found that there was a sweet spot for AI-
generated answers: replies to niche questions that no human had ever written an answer for. Getting a lower quality 
AI answer was better than waiting around for a human to answer your question, he concluded. The experience 
resembled something more like private chat than an open forum, D Angelo realized, so the company set out to build 
that kind of service.
D Angelo s rallying of the company around Poe comes at a confounding time for Quora. Founded in 2010, it has 
become a venerable throwback to the late web 2.0 era, surviving where rivals like Yahoo Answers fizzled out. But it 
hasn t evolved into the modern era compared to competitors like Reddit, whichwent public in Marchand long ago 
became a cultural hub of the internet. That raises an interesting question: Who still uses Quora,really. It's hard to 
say, but the anecdotal evidence isn't great. Earlier this year, Slateproclaimed Quora dead. And on Quora itself, "Is 
quora dead" has been asked many times dating back to at least 2017. As onerespondent answered,  Maybe Quora 
[has] just run its course, sort of like Yahoo or MySpace."
D Angelo declined to comment on Quora s revenue, though the company says it gets 400 million users a month.
With Poe, a seemingly disparate product from Quora, the company s trajectory has gotten more murky. Is it a social 
forum backed by an advertising business model along the lines of Reddit, or is it going to become a player in AI? D 
Angelo says it s now poised for the latter. In January, the company announced $75 million in funding from 
Andreessen Horowitz to build out Poe.
  Maybe Quora just run its course, sort of like Yahoo or MySpace." <footer>Quora user</footer>
D Angelo has had an inside look at the explosion in generative AI over the last few years in part because he s been 
a board member at OpenAI since 2018, when it was still a nonprofit. But that also meant D Angelo was at the center 
of the AI universe during one of the most dramatic boardroom power struggles in recent history. In November, the 
ChatGPT maker s board fired CEO and founder Sam Altman, citing a lack of  candid  communication. The 
bombshell announcement set off a firestorm in Silicon Valley, and within five days, the board reversed course and 
rehired Altman. As part of the reinstatement, OpenAI replaced every board member except D Angelo.
Poe does have some overlap with OpenAI s GPT Store, a hub for customized AI bots that was announced less 
than two weeks before the ouster, leading to some speculation from industry observers about D Angelo s role in the 
coup. When asked about that speculation, D Angelo called it  conspiracy theories  and pointed to the public 
summary of an internal investigation which said that the board acted  within its broad discretion  to fire Altman. He 
declined further comment on any OpenAI-related questions.
Quora has dealt with other AI controversies, especially when it comes to machine-generated answers. Some users 
have complained that the quality of content of the site has degraded, becoming a mush of AI slop. Inone viral 
example, an AI-generated Quora answer stated that eggs could be melted. Google, which sources content from 
Quora in its answer boxes, then amplified the response.
D Angelo downplayed the criticism.  There's always room to do better on showing better answers,  he said.  
Sometimes it's not going to work well and people will be unhappy. But on average, we're quite confident that the AI 
answers have been a net positive to Quora. 
Page 3 of 3
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI
While Poe has a distinct identity from Quora, D Angelo said that he never really considered starting a new company 
to follow his AI ambitions.  It was my full time job and I couldn't just leave and start another company,  he said.
Instead, D Angelo said he wanted to leverage the talent and structure he had already assembled at Quora, 
especially as the AI environment moves at a blistering speed. Plus, some of the original source code he wrote for 
Quora is built into Poe s foundation.  If it was a new startup, starting from scratch, you might spend the whole first 
year building up a team that good,  he said.  This was a technology wave and opportunity where we needed to 
move very, very fast. 
Now the plan is expansion. Building Poe was like  graduating  to becoming a two-product company, D Angelo 
toldForbes, akin to Google s first steps beyond web search. To get it done, the company needed to overcome the  
organizational inertia  it had built up over several years. But now that he s learned how to navigate that change, he 
doesn t want to stop there.
 It took a lot of willpower,  he said.  My expectation long term is we should not be only a two-product company. We 
should continue to build new products. 
MORE FROM FORBES
Load-Date: July 3, 2024
End of Document
Page 1 of 3
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
The Guardian (London)
May 19, 2024 Sunday 2:00 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:1
Length: 921 words
Byline: Alex Hern and Dan Milmo
Highlight: Tech experts hope new term for carelessly automated AI webpages and images can illuminate its 
damaging impact
Body
Your email inbox is full of spam. Your letterbox is full of junk mail. Now, your web browser has its own affliction: 
slop.
“Slop” is what you get when you shove artificial intelligence-generated material up on the web for anyone to view. 
Unlike a chatbot, the slop isn’t interactive, and is rarely intended to actually answer readers’ questions or serve 
their needs.
Instead, it functions mostly to create the appearance of human-made content, benefit from advertising revenue and 
steer search engine attention towards other sites.
Just like spam, almost no one wants to view slop, but the economics of the internet lead to its creation anyway. AI 
models make it trivial to automatically generate vast quantities of text or images , providing an answer to any 
imaginable search query, uploading endless shareable landscapes and inspirational stories, and creating an army 
of supportive comments. If just a handful of users land on the site, reshare the meme or click through the adverts 
hosted, the cost of its creation pays off.
But like spam, its overall effect is negative: the lost time and effort of users who now have to wade through slop to 
find the content they’re actually seeking far outweighs the profit to the slop creator.
“I think having a name for this is really important, because it gives people a concise way to talk about the problem,” 
says the developer Simon Willison, one of the early proponents of the term “slop”.

Page 2 of 3
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
“Before the term ‘spam’ entered general use it wasn’t necessarily clear to everyone that unwanted marketing 
messages were a bad way to behave. I’m hoping ‘slop’ has the same impact – it can make it clear to people that 
generating and publishing unreviewed AI-generated content is bad behaviour.”
Slop is most obviously harmful when it is just plain wrong. Willison pointed to an AI-generated Microsoft Travel 
article that listed the “Ottawa food bank” as a must-see attraction in the Canadian capital as a perfect example of 
the problem. Occasionally, a piece of slop is so useless that it goes viral in its own right, like the careers advice 
article that earnestly explains the punchline to a decades-old newspaper comic: “they pay me in woims”.
“While the precise meaning of ‘They Pay Me in Woims’ remains ambiguous, various interpretations have emerged, 
ranging from a playful comment on work-life balance to a deeper exploration of our perceived reality,” the slop 
begins.
AI-generated books have become a problem too. A prominent example came when amateur mushroom pickers 
were recently warned to avoid foraging books  sold on Amazon that appeared to have been written by chatbots and 
contained dangerous advice for anyone hoping to discern a lethal fungus from an edible one.
Image-generated slop has also blossomed on Facebook, as images of Jesus Christ with prawns for limbs, children 
in plastic bottle-cars, fake dream homes and improbably old women claiming to have baked their 122nd birthday 
cake  garner thousands of shares.
Jason Koebler of the tech news site 404 Media believes the trend represents what he calls the “zombie internet”. 
The rise of slop, he says, has turned the social network into a space where “a mix of bots, humans and accounts 
that were once humans but aren’t any more mix together to form a disastrous website where there is little social 
connection at all.”
Nick Clegg, the president of global affairs at Facebook’s parent company, Meta, wrote in February that the social 
network is training its systems to identify AI-made content. “As the difference between human and synthetic content 
gets blurred, people want to know where the boundary lies,” he wrote.
The problem has begun to worry the social media industry’s main revenue source: the advertising agencies who 
pay to place ads next to content. Farhad Divecha, the managing director of UK-based digital marketing agency 
AccuraCast, says he is now encountering cases where users are mistakenly flagging ads as AI-made slop when 
they are not.
“We have seen instances where people have commented that an advert was AI-generated rubbish when it was 
not,” he says, adding that it could become a problem for the social media industry if consumers “start to feel they 
are being served rubbish all the time”.
Tackling spam in inboxes required an enormous cross-industry effort and led to a fundamental change in the nature 
of email. Big webmail providers like Gmail aggressively monitor their own platforms to crack down on spammers 
and are increasingly suspicious of emails arriving from untrusted email servers. They also apply complex, largely 
undocumented, AI systems to try to detect spam directly, in a constant cat-and-mouse game with the spammers 
themselves.
For slop, the future is less rosy: the world’s largest companies have gone from gamekeeper to poacher. Last week, 
Google announced an ambitious plan to add AI-made answers  to the top of some search results, with US-based 
users the first to experience a full rollout of the “AI Overviews” feature. It will include links as well, but users who 
want to limit the response to just a selection of links to other websites will be able to find them – by clicking through 
to “web” on the search engine, demoted to sit beside “images” and “maps” on the list of options.
“We’ve added this after hearing from some that there are times when they’d prefer to just see links to webpages in 
their search results,” wrote Danny Sullivan, the company’s search liaison.
Google says the AI overviews have strong safety guardrails. Elsewhere on the web though, slop is spreading.
Page 3 of 3
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
Load-Date: June 28, 2024
End of Document
Page 1 of 3
=======
>>>>>>> c98f417 (update data file):extract_text.txt
Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, City take Premier League
Morning Mail: Iran president in helicopter crash, family lawyers quit over 
burnout, City take Premier League
The Guardian (London)
May 19, 2024 Sunday 10:10 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: AUSTRALIA NEWS; Version:1
Length: 1316 words
Byline: Charlotte Graham-McLay
Highlight: Want to get this in your inbox every weekday? Sign up for the Morning Mail here, and finish your day 
with our Afternoon Update newsletter
Body
Good morning. A Guardian Australia investigation reveals some family lawyers are leaving their practices or 
warning juniors to avoid entering the field, as they experience burnout and stress from a system that requires them 
to bill domestic violence survivors – sometimes for huge amounts for legal fees.
Meanwhile, a helicopter carrying the Iranian president and foreign minister has crashed. At the time of writing, 
rescuers were yet to reach the crash site and the condition of the passengers was not known. Our live blog has the 
latest. 
Plus: Manchester City have taken their fourth-in-a-row Premier League title.
                   Australia                                                                   Justice | “I couldn’t do it any more,” one family 
lawyer who has left the practice told Guardian Australia , echoing others’ stories. “I couldn’t bill people who I just 
knew couldn’t afford to pay it.”                                                                     Housing | Major Australian lenders are not 
doing enough to support mortgage customers in financial hardship , and in some cases they are ignoring requests 
for assistance altogether, the corporate regulator found.                                                                     Analysis | Peter 
Dutton’s policy-lite budget reply speech contained the seeds of campaigns  that will inevitably be deployed by the 
progressive side of politics on nuclear and wages, Paul Karp writes.                                                                     
Women | Scott Morrison said he and his government did everything they “possibly could have” for women  while he 
was prime minister, and called criticism of his actions a pile-on which was “weaponised for political purposes”.                                                                     
Solar | With newly installed solar panels on his roof, Guardian Australia’s Nick Miller gamified Australia’s power 
industry  – and learned just how weird and perverse it could be.                                                           World                                                                   
Iran | Search teams were looking for the downed helicopter that the Iranian president, Ebrahim Raisi, was travelling 

Page 2 of 3
Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, City take Premier League
in  when it vanished amid poor weather conditions and thick fog in Iran’s East Azerbaijan province.                                                                     
US presidency | Donald Trump flirted with the idea of being president for three terms  during a bombastic speech 
for the National Rifle Association. Meanwhile, the president, Joe Biden, renewed his pitch to Black voters  at a 
college graduation.                                                                     Europe’s far right | International far-right leaders, 
including France’s Marine Le Pen, Hungary’s Viktor Orbán, Italy’s Giorgia Meloni and Argentina’s Javier Milei, came 
together in Madrid to rail against socialism  and “massive illegal migration” three weeks before hard-right parties are 
expected to see a surge in support in European elections.                                                                     Sean Combs | 
The rap mogul Sean “Diddy” Combs admitted in a video apology that he punched and kicked his ex-girlfriend  
Cassie in 2016 in the hallway of a hotel after CNN released footage of the attack, saying he was “truly sorry” and 
his actions were “inexcusable”.                                                                     Rocket man | Sixty-one years since he 
was selected but ultimately passed over to become the first Black astronaut, Ed Dwight finally reached space in a 
Blue Origin rocket  – and, at 90, is the oldest person to arrive at the edge of space.                                                           
Full Story                   
                     Gaza through the eyes of two Australian doctors                   
Last month, two Australian doctors spent two weeks in Gaza treating countless injured Palestinians. Surgeon 
Sanjay Adusumilli and general practitioner Siraj Sira tell Nour Haydar why they left Sydney to volunteer in the 
besieged territory , the pain they witnessed and the feelings of guilt on their return.
                     Read our latest on Gaza: The United Nations’ humanitarian chief warned of “apocalyptic” 
consequences due to aid shortages in Gaza , where Israel’s military offensive in the southern city of Rafah has 
blocked desperately needed food.
                   In-depth                   
She is the real-life Lady Whistledown, an eyebrow-raising female writer – anti-racist and proto-feminist – who 
penned a salacious weekly anonymous gossip sheet that skewered 18th-century London society.
Like the fictional pamphlet from Netflix hit Bridgerton, which returned for a third series last week, Eliza Haywood’s 
The Parrot, published in 1746, has a distinctive, mocking voice that punches up and “speaks truth to power”. Now, a 
new book will republish Haywood’s funny, subversive periodical , which she wrote from the perspective of an angry 
green parrot.
                   Not the news                   
Your email inbox is full of spam. Your letterbox is full of junk mail. Now, your web browser has its own affliction: 
slop. “Slop” is what you get when you shove artificial intelligence-generated material up on the web for anyone to 
view. Experts hope the unpalatable name will help herald its harms.
It might be bizarrely incorrect information on a website, or dangerously incorrect books on Amazon (where you 
apparently shouldn’t buy mushroom-foraging books written by machines). Or just downright cursed images on 
social media (sorry).
Alex Hern and Dan Milmo investigate why all this AI slop is filling the zombie internet. 
                   The world of sport                                                                   Premier League | Manchester City beat 
West Ham 3-1  to win their fourth Premier League title in a row. Here’s our play-by-play commentary.  Arsenal were 
denied the title despite a late 2-1 victory over Everton.                                                                      AFL | Essendon 
left middle of the road behind  as their “edge” led them to the second spot, Jonathan Horn writes for Sportblog.                                                                     
Formula One | Max Verstappen held off Norris  to win the Emilia Romagna Grand Prix.                                                           
Media roundup                   
Page 3 of 3
Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, City take Premier League
According to The Australian ’s Newspoll, a ­ record low number of people  have judged Jim Chalmers’ third budget 
as good for the economy. Hundreds of homes in Melbourne were suddenly deemed flood-prone  and residents 
want answers, the Age reports. The Courier Mailinvestigates kids’ addiction  to social media and gaming.
                   What’s happening today                                                                   Cold case | The Queensland coroner 
will deliver his findings from the inquest into the 1986 disappearance of Sharron Phillips.                                                                     
AI | A public hearing is scheduled for the senate select committee on adopting artificial intelligence.                                                            
Sign up                   
If you would like to receive this Morning Mail update to your email inbox every weekday, sign up here.  And finish 
your day with a three-minute snapshot of the day’s main news. Sign up for our Afternoon Update newsletter here. 
Prefer notifications? If you’re reading this in our app , just click here and tap “Get notifications” on the next screen  
for an instant alert when we publish every morning.
                   Brain teaser                   
And finally, here are the Guardian’s crosswords to keep you entertained throughout the day. Until tomorrow. 
Quick crossword Cryptic crossword
Load-Date: June 28, 2024
End of Document
<<<<<<< HEAD:article data/text/Data two (143) with duplicates.txt
Page 1 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
Google is bringing back classic search, with no AI – and I couldn't be 
happier about that
TechRadar (UK)
May 19, 2024 Sunday 4:30 PM EST
Copyright 2024 Future Publishing Ltd  All Rights Reserved
Section: TECH LATEST, TECH LATEST & SEARCH ENGINES NEWS
Length: 926 words
Byline: Christian Guyton
Body
Editors note: TechRadar makes some of its revenue via the use of affiliate links to products and services on retailer 
sites on certain pages, for which we can receive compensation if you click on those links or make purchases 
through them. Many readers of those pages reach us through Google search, so we therefore have a vested 
interest in the topics discussed within this article.
Google Search has undergone many, many changes over the years – some big, some small, but every single one 
shifting the iconic internet search engine further and further away from its original form.
You can see an interactive timeline of Google Search on Googles own website, if youre curious about how its 
evolved over the years. Some of these additions – such as the Did you mean...? suggestions for typos and the 
inclusion of new search modes including image, news, and video – were obvious slam-dunks for Google, improving 
the versatility and functionality of its search engine. Others, like the inevitable arrival of sponsored ads in results 
and the recent AI-powered Search Generative Experience (SGE), have been... less popular.
Well, Google has seemingly done the unimaginable: its released a new web setting for the search engine that will 
take you back to the glory days of Google Search in the year 2000, surfacing only a list of text-based links. Thats 
right – no images, no shopping results, and no AI-generated answers.
A more perfect search engine
The web mode has been rolled out globally and should be accessible for everyone now; youll find it under the More 
option at the top of the results, below the search bar itself. 
Unsurprisingly, its been met with riotous applause on social media. Commenters on Twitter (cough, X) lauded 
Google for the change, with many remarking that this is exactly what they want from a search engine.

Page 2 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
We’ve launched a new “Web” filter that shows only text-based links, just like you might filter to show other types of 
results, such as images or videos. The filter appears on the top of the results page alongside other filters or as part 
of the “More” option, rolling out today… pic.twitter.com/tIUy9LNCy5May 14, 2024
See more
Its a little sad that Googles decision to turn back time on its most-used product has seen such a positive response, 
and its no doubt been done to counter any potential backlash from the gradual rollout of SGE. The AI-powered 
search tool will use machine learning to scrape the internet for relevant data and provide an AI-generated response, 
which may prove helpful to some users but which poses a significant threat to online media and information outlets.
Its worth noting that the web search view does still include sponsored text links, but I suppose we cant have it all. 
Personally, Im massively happy to see this change – not only do I prefer to do my own reading rather than receive 
AI-generated slop from my online searches, but as a digital journalist, I have a vested interest in Google keeping 
search simple.
The perils of AI in search
See, Googles SGE experiment is one I fear may be doomed to fail – specifically because it might end up 
consuming itself. SGE is undeniably a powerful tool that can provide a neat summary of the information users are 
looking for, but it needs content written by humans to do that.
An example Google gave back when SGE was first unveiled was the query best Bluetooth speaker for a pool party. 
Sure enough, SGE produced a list of suggested products with links to both retailers and sites reviewing the 
recommended speakers.
Now, we naturally have our own article ranking the best Bluetooth speakers, as do many other tech news sites. We 
have literally hundreds of buying guides, and keeping those up-to-date with useful information for consumers is a lot 
of work, but its work were happy to do, since it pays our bills and ultimately helps consumers find what they actually 
need to know – you know, the whole reason TechRadar exists as a site.
But if SGE takes over, all the affiliate and ad revenue made by us – and every other site making product 
recommendations out there – threatens to evaporate. 
If that happens, well pivot: the journalism industry has always been on the cutting edge, ready and able to adapt to 
the challenges of a constantly shifting media landscape. So yes, well find a new way to reach our readers, whether 
directly, via newsletters, social media, subscriptions or whatever other methods appear in the forthcoming years. 
However, if surfacing all those buying guides, recipes, and top-10 lists within Google search becomes pointless to 
the sites making them, many may choose to stop Googles bot from crawling them, or at the very least from using 
them to train its LLMs. And if that happens then Googles AI will steadily become less and less relevant and helpful 
in its SGE suggestions as its fuel source dries up.
I know this sounds like whining. Oh no, Google is going to kill our profitability! But that doesnt mean its not a 
problem. Google has potentially created a new version of online searches that will self-destruct if it becomes 
successful.
In other words, Im delighted to see web search make a heroic return in this time of AI uncertainty. After all, Im not 
going to start using Bing…
You might also like...
• Google is expanding its experiment of AI-generated answers ahead of search results to the UK - a new go-
to for answers or a misstep?
Page 3 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
• Google Search could soon charge you for AI-powered results – and search engines might never be the 
same
• Apple secretly working on Google Search killer for 'years,' probably won't ever launch
Load-Date: May 20, 2024
End of Document
Page 1 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
Google is bringing back classic search, with no AI – and I couldn't be 
happier about that
TechRadar
May 19, 2024 Sunday
Copyright 2024 TBREAK MEDIA Provided by Syndigate Media Inc. All Rights Reserved
Length: 943 words
Byline: christian.guyton@futurenet.com,  (Christian Guyton)
Body
Editor's note: TechRadar makes some of its revenue via the use of affiliate links to products and services on retailer 
sites on certain pages, for which we can receive compensation if you click on those links or make purchases 
through them. Many readers of those pages reach us through Google search, so we therefore have a vested 
interest in the topics discussed within this article.
Google Search has undergone many, many changes over the years – some big, some small, but every single one 
shifting the iconic internet search engine further and further away from its original form.
You can see an interactive timeline of Google Search on Google's own website, if you're curious about how it's 
evolved over the years. Some of these additions – such as the 'Did you mean...?' suggestions for typos and the 
inclusion of new search modes including image, news, and video – were obvious slam-dunks for Google, improving 
the versatility and functionality of its search engine. Others, like the inevitable arrival of sponsored ads in results 
and the recent AI-powered 'Search Generative Experience' (SGE), have been... less popular.
Well, Google has seemingly done the unimaginable: it's released a new 'web' setting for the search engine that will 
take you back to the glory days of Google Search in the year 2000, surfacing only a list of text-based links. That's 
right – no images, no shopping results, and no AI-generated answers.
A more perfect search engine
The 'web' mode has been rolled out globally and should be accessible for everyone now; you'll find it under the 
'More' option at the top of the results, below the search bar itself.
Unsurprisingly, it's been met with riotous applause on social media. Commenters on Twitter (cough, X) lauded 
Google for the change, with many remarking that this is exactly what they want from a search engine.

Page 2 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
We've launched a new "Web" filter that shows only text-based links, just like you might filter to show other types of 
results, such as images or videos. The filter appears on the top of the results page alongside other filters or as part 
of the "More" option, rolling out today… pic.twitter.com/tIUy9LNCy5May 14, 2024
See more
It's a little sad that Google's decision to turn back time on its most-used product has seen such a positive response, 
and it's no doubt been done to counter any potential backlash from the gradual rollout of SGE. The AI-powered 
search tool will use machine learning to 'scrape' the internet for relevant data and provide an AI-generated 
response, which may prove helpful to some users but which poses a significant threat to online media and 
information outlets.
It's worth noting that the web search view does still include sponsored text links, but I suppose we can't have it all. 
Personally, I'm massively happy to see this change – not only do I prefer to do my own reading rather than receive 
AI-generated slop from my online searches, but as a digital journalist, I have a vested interest in Google keeping 
search simple.
The perils of AI in search
See, Google's SGE experiment is one I fear may be doomed to fail – specifically because it might end up 
consuming itself. SGE is undeniably a powerful tool that can provide a neat summary of the information users are 
looking for, but it needs content written by humans to do that.
An example Google gave back when SGE was first unveiled was the query 'best Bluetooth speaker for a pool 
party'. Sure enough, SGE produced a list of suggested products with links to both retailers and sites reviewing the 
recommended speakers.
Now, we naturally have our own article ranking the best Bluetooth speakers, as do many other tech news sites. We 
have literally hundreds of buying guides, and keeping those up-to-date with useful information for consumers is a lot 
of work, but it's work we're happy to do, since it pays our bills and ultimately helps consumers find what they 
actually need to know – you know, the whole reason TechRadar exists as a site.
But if SGE takes over, all the affiliate and ad revenue made by us – and every other site making product 
recommendations out there – threatens to evaporate.
If that happens, we'll pivot: the journalism industry has always been on the cutting edge, ready and able to adapt to 
the challenges of a constantly shifting media landscape. So yes, we'll find a new way to reach our readers, whether 
directly, via newsletters, social media, subscriptions or whatever other methods appear in the forthcoming years.
However, if surfacing all those buying guides, recipes, and top-10 lists within Google search becomes pointless to 
the sites making them, many may choose to stop Google's bot from crawling them, or at the very least from using 
them to train its LLMs. And if that happens then Google's AI will steadily become less and less relevant and helpful 
in its SGE suggestions as its fuel source dries up.
I know this sounds like whining. 'Oh no, Google is going to kill our profitability!' But that doesn't mean it's not a 
problem. Google has potentially created a new version of online searches that will self-destruct if it becomes 
successful.
In other words, I'm delighted to see 'web search' make a heroic return in this time of AI uncertainty. After all, I'm not 
going to start using Bing…
You might also like...
Google is expanding its experiment of AI-generated answers ahead of search results to the UK - a new go-to for 
answers or a misstep?
Page 3 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
Google Search could soon charge you for AI-powered results – and search engines might never be the same
Apple secretly working on Google Search killer for 'years,' probably won't ever launch
 Future Publishing Limited Quay House, The Ambury, Bath BA1 1UA.
Load-Date: May 19, 2024
End of Document
Page 1 of 2
How to spot deepfake videos and photos
How to spot deepfake videos and photos
USA Today
April 10, 2024 Wednesday
1 Edition
Copyright 2024 USA Today All Rights Reserved
Section: BUSINESS; Pg. B3
Length: 710 words
Body
There was the deepfake audio robocall of President Joe Biden telling you to hold your vote. And just last week, a 
phony video of Donald Trump with Black voters made the rounds.
AI deepfakes are a massive problem this election season, and it's easy to get taken - especially when your news 
and social feeds are full of this junk.
By the way, you're not alone if you have been fooled. Nearly two-thirds of people can't tell the difference between 
artificial intelligence-generated images and voices and the real thing, according to a study by the University of 
Aberdeen in Scotland. Those are awful odds. Here are some rules of thumb to protect your vote:
'Viral' doesn't mean 'verified'
Almost all of the AI-generated slop online is peddled for clicks on social media, not published by major news 
outlets. These publications still get tripped up, of course, but it's rare.
I'm all for citizen journalism, but when it comes to our elections, stick to publications you know you can trust. Be 
wary of anonymous accounts that post without a legitimate person or organization attached to them.
If it's some random person on Facebook you've never heard of, do your homework before you hit share.
Look for other coverage
Scammers can put together a convincing image or video, but they can't fake the context. When Biden or Trump 
says something, I promise it will be reported a hundred times and recorded from 20 angles - especially if it's 
outlandish.
If you can only find one source for something, your internal AI detector should go off. Use Google Fact Check 
Explorer, VerifyThis, or Snopes to double-check.
Pro tip: Search related keywords on Google and social media platforms like YouTube, TikTok and Instagram. If 
you're struggling with ways to search, you can even take screenshots of critical parts of the video and do a reverse 
image search.

Page 2 of 2
How to spot deepfake videos and photos
Slow down
We're all busy and we're all in a hurry, but it's worth slowing down - especially if something makes you feel 
something big. Deepfakes are often created with emotion in mind. The point is to make you mad, sad, or scared 
enough to share.
When it comes to political figures, pay attention to mannerisms. They're as unique as fingerprints. President Barack 
Obama's signature head lift and slight frown were present whenever he'd say, "Hi, everybody" in his weekly 
addresses. If the star of a video seems like an impersonator, they  could be.
Use this AI image checklist
Election fakes are particularly tricky to spot because there's so much public footage of politicians speaking in front 
of similar backgrounds to copy. But you can still use these guidelines to verify if it's AI or not:
Backgrounds: A vague, blurred background, smooth surfaces, or lines that don't match up are immediate red flags 
that an image is AI-generated.
Context: Use your head - if the scenery doesn't align with the current climate, season or what's physically possible, 
that's because it's fake.
Proportions: Check for objects that look mushed together or seem too large or small. The same goes for features, 
especially ears, fingers and feet.
Angle: Deepfakes are the most convincing when the subject is facing the camera directly. Once a person starts to 
turn to the side and move, glitches may appear.
Text: AI can't spell. Look for fake words on signs and labels.
Chins: Yep, you heard me. The lower half of the face is the No. 1 giveaway on AI-generated candidate videos. It's 
subtle, but check to see if their chin or neck moves unnaturally or in an exaggerated way.
Fingers and hands: Look for weird positions, too many fingers, extra-long digits, or hands out of place.
If you spot it, don't spread it
I get that some of these images and videos are shocking or even hilarious - but they're putting our elections at risk. 
Don't contribute to the "Great American Fake-Off." If you're going to share something you know is AI-generated, call 
it out clearly in your text or post. Really, you're better off not sharing it at all.
Learn about all the latest technology on the Kim Komando Show, the nation's largest weekend radio talk show. Kim 
takes calls and dispenses advice on today's digital lifestyle, from smartphones and tablets to online privacy and 
data hacks. For her daily tips, free newsletters and more, visit her website.
Tech Talk
Kim Komando
Load-Date: April 10, 2024
End of Document
Page 1 of 2
Don't be fooled by deepfake videos and photos this election cycle. Here's how to spot AI
Don't be fooled by deepfake videos and photos this election cycle. Here's 
how to spot AI
USA Today Online
April 4, 2024
Copyright 2024 Gannett Media Corp  All Rights Reserved
Section: TECH LATEST
Length: 754 words
Byline: Kim Komando
Body
There was the deepfake audio robocall of President Joe Biden telling you to hold your vote. And just last week, a 
phony video of Donald Trump with Black voters made the rounds.
AI deepfakes are a massive problem this election season, and it’s easy to get taken – especially when your news 
and social feeds are full of this junk.
By the way, you’re not alone if you have been fooled. Nearly two-thirds of people can’t tell the difference between 
artificial intelligence-generated images and voices and the real thing, according to a study by the University of 
Aberdeen in Scotland. Those are awful odds. Here are some rules of thumb to protect your vote:
I send smart, actionable tech news and tips like this daily. Join 500K folks and get the Current. It’s free!
‘Viral’ doesn’t mean ‘verified’
Almost all of the AI-generated slop online is peddled for clicks on social media, not published by major news 
outlets. These publications still get tripped up, of course, but it's rare.
I’m all for citizen journalism, but when it comes to our elections, stick to publications you know you can trust. Be 
wary of anonymous accounts that post without a legitimate person or organization attached to them.
If it’s some random person on Facebook you’ve never heard of, do your homework before you hit share.
Look for other coverage
Scammers can put together a convincing image or video, but they can't fake the context. When Biden or Trump 
says something, I promise it will be reported a hundred times and recorded from 20 angles – especially if it’s 
outlandish.
￿ If you can only find one source for something, your internal AI detector should go off. Use Google Fact Check 
Explorer, VerifyThis, or Snopes to double-check.

Page 2 of 2
Don't be fooled by deepfake videos and photos this election cycle. Here's how to spot AI
Pro tip: Search related keywords on Google and social media platforms like YouTube, TikTok and Instagram. If 
you’re struggling with ways to search, you can even take screenshots of critical parts of the video and do a reverse 
image search.
Slow down
We’re all busy and we’re all in a hurry, but it’s worth slowing down – especially if something makes you feel 
something big. Deepfakes are often created with emotion in mind. The point is to make you mad, sad, or scared 
enough to share.
When it comes to political figures, pay attention to mannerisms. They’re as unique as fingerprints. President Barack 
Obama’s signature head lift and slight frown were present whenever he’d say, “Hi, everybody” in his weekly 
addresses. If the star of a video seems like an impersonator, they very well could be.
When in doubt, use this AI image checklist
Election fakes are particularly tricky to spot because there’s so much public footage of politicians speaking in front 
of similar backgrounds to copy. But you can still use these guidelines to verify if it’s AI or not:
￿ Backgrounds: A vague, blurred background, smooth surfaces, or lines that don’t match up are immediate red 
flags that an image is AI-generated.
￿ Context: Use your head – if the scenery doesn’t align with the current climate, season or what’s physically 
possible, that’s because it’s fake.
￿ Proportions: Check for objects that look mushed together or seem too large or small. The same goes for 
features, especially ears, fingers and feet.
￿ Angle: Deepfakes are the most convincing when the subject is facing the camera directly. Once a person starts 
to turn to the side and move, glitches may appear.
￿ Text: AI can’t spell. Look for fake words on signs and labels.
￿ Chins: Yep, you heard me. The lower half of the face is the No. 1 giveaway on AI-generated candidate videos. 
It’s subtle, but check to see if their chin or neck moves unnaturally or in an exaggerated way.
￿ Fingers and hands: Look for weird positions, too many fingers, extra-long digits, or hands out of place.
If you spot it, don’t spread it
I get that some of these images and videos are shocking or even hilarious – but they’re putting our elections at risk. 
Don’t contribute to the “Great American Fake-Off.” If you’re going to share something you know is AI-generated, call 
it out clearly in your text or post. Really, you’re better off not sharing it at all.
Learn about all the latest technology on the Kim Komando Show, the nation's largest weekend radio talk show. Kim 
takes calls and dispenses advice on today's digital lifestyle, from smartphones and tablets to online privacy and 
data hacks. For her daily tips, free newsletters and more, visit her website. 
This article originally appeared on USA TODAY: Don't be fooled by deepfake videos and photos this election cycle. 
Here's how to spot AI
Load-Date: April 4, 2024
End of Document
Page 1 of 3
An AI-generated rat with a giant penis highlights a growing crisis of fake science that's plaguing the publishing 
business
An AI-generated rat with a giant penis highlights a growing crisis of fake 
science that's plaguing the publishing business
Business Insider
March 18, 2024 Monday 09:37 PM EST
Copyright 2024 Insider Inc. All Rights Reserved
Length: 944 words
Byline: mmcfalljohnsen@businessinsider.com (Morgan McFall-Johnsen)
Highlight: Fake science can make it into reputable journals, due to the pressures of the publishing business. Take 
this AI-generated rat penis, for instance.
Body
• An AI-generated image of a rat with a towering phallic appendage went semi-viral last month.
• The nonsense diagram appeared in a now-retracted scientific paper, published in a Frontiers journal.
• This rat is a symptom of a crisis of fakes in the career-driven business of research publishing.
This rat has an enormous "dck," and it's a symptom of a bigger problem.
You don't need to be a scientist to know that rats don't have bulbous, sky-high penises, or that words like 
"testtomcels," "retat," and "dissilced," are total gibberish.
And yet, the bogus diagram below appeared in a paper published last month by the scientific journal Frontiers in 
Cell Development and Biology.
To its credit, the journal quickly retracted the paper. But its AI-generated images had already gone viral in online 
science communities. They even got their own page on Know Your Meme.
But this rat's towering phallus is just one symptom of a crisis of fake science.
"If it's the first time you've seen a really weird paper get published, I can see why it would capture your attention," 
Ivan Oransky, a co-cofounder of the watchdog journalism site Retraction Watch, told Business Insider. But for him, 
he said, "it's all sort of mind-numbingly routine at this point."
How bad science and weird AI get through the 'Swiss cheese' of peer review

Page 2 of 3
An AI-generated rat with a giant penis highlights a growing crisis of fake science that's plaguing the publishing 
business
Frontiers is an influential, open-access publisher with a peer-review process. So how did this paper make it to 
publication?
When a publisher like Frontiers accepts a scientist's manuscript, the paper passes through the critical eyes of a 
series of peer reviewers who are experts in the subject matter, as well as editors who assess the peer review. 
Usually, study authors must make changes based on the reviewers' feedback before publication.
Think of the peer review process like a stack of Swiss cheese. Each step has holes in it that bad science could 
squeeze through, but the overlapping steps tend to cover each other's holes, making it difficult to squeeze all the 
way through the whole process.
Still, bad science does make it through sometimes, and over the years more holes have opened up. Scientists can 
now buy made-up papers from paper mills.
There's even precedent for AI slop in science publishing. In 2014, publishers Springer and IEEE retracted more 
than 120 articles that were gibberish generated by computers. The publishing giant Springer Nature retracted 44 
gibberish papers in 2021.
Then there are more traditional forms of scientific fraud - bribing journal editors, falsifying data, or manipulating real 
images or data.
These bad practices can have real consequences. Early trials that found ivermectin or hydroxychloroquine to be 
promising COVID-19 treatments were later retracted for signs of fraud, but the word was already out and a wave of 
ill-informed self-treatment ensued, Vox reported. Even beyond COVID, fabricated studies can end up in databases 
used for drug research, The Guardian reported.
The mysterious case of the 'retat' 'dck'
In the case of the rat with "testtomcels," Frontiers says that one of the peer reviewers raised concerns about the 
images and requested that the paper authors revise them.
"The article slipped through the author compliance checks that normally ensures every reviewer comment is 
addressed," Fred Fenter, chief executive editor of Frontiers, said in an additional statement emailed to Business 
Insider, calling it a "human error."
He said that Frontiers has added "new checks to catch this form of misconduct," revised its AI policy to be clear 
about what's not allowed, and is developing "AI to detect AI-generated content and images."
"Those bad faith actors using AI improperly in science will get better and better and so we will have to get better 
and better too. This is analogous to cybersecurity constantly improving to block new tricks of hackers," Fenter said.
In January, Frontiers announced plans to lay off 30% of its staff, cutting 600 jobs.
"Quality is our highest priority, and the recent restructuring does not affect the peer review process and/or author 
compliance checks," Fenter said.
The retracted paper's corresponding author, Dingjun Hao, did not respond to Business Insider's request for 
comment.
Why some scientists publish bad papers
Journals are businesses, and scientists have careers. Both are under intense pressure to publish often.
Page 3 of 3
An AI-generated rat with a giant penis highlights a growing crisis of fake science that's plaguing the publishing 
business
Most hiring and tenure committees, Oransky says, evaluate researchers based on how many papers they've 
published, whether they've been published in prestige journals, and how much other scientists cite their work.
"People are desperate to publish and will do anything they have to do in order to publish and keep their jobs or get 
promoted," Oransky said. "That's the real problem here."
Last year, research journals retracted over 10,000 scientific papers, more than ever before, according to a report in 
the journal Nature.
Retractions aren't all bad. In fact, they're necessary for the times when peer review fails to catch data errors or 
irresponsible practices.
But the record retraction rate comes alongside a rise in sham papers that some scientists hastily fabricate or 
generate with the help of AI.
"It's salacious," Oransky said of the rat and its "dck." But, he continued, "there's sort of nothing new under the sun."
To Oransky, the solution is obvious. Science institutions across the planet should evaluate scientists based on the 
quality, not the breadth, of their work. His suggested evaluation metric? Show three good papers.
"What we need to do is stop using publications and citations as the metric of everything," he said. "All of that's 
game-able. Three good papers is not game-able."
Read the original article on
Business Insider
Load-Date: December 2, 2024
End of Document
Page 1 of 3
AI is now supercharging Google Assistant
AI is now supercharging Google Assistant
Quartz
February 8, 2024 Thursday 2:08 PM EST
Copyright 2024 G/O Media Inc.  All Rights Reserved
Section: TECH LATEST & GOOGLE NEWS
Length: 1249 words
Byline: Thomas Germain / Gizmodo
Body
Link to Image
If you felt an earthquake just now, it might have been Google's latest announcement. In one of the biggest updates 
in Google's history, the company unleashed the full version of its next-generation AI model Gemini. Google is 
changing its chatbot's name from Bard to Gemini, releasing a dedicated Gemini mobile app, and launching a 
premium AI subscription service. The news that will have the biggest effect on your life, however, is that the 
company just added Gemini to Google Assistant. Starting now, millions of people will be having voice conversations 
with one of the most powerful AI models on the market. 
"Every launch is big, but this one is the biggest yet," said Sissie Hsiao, Vice President of Gemini Experiences and 
Google Assistant, speaking at a press conference. "For Google, Gemini is more than just the models. It's really a 
shift in how we think about the state of the art technology and the entire ecosystem that we're building on it, from 
products that affect billions of users to the APIs and platforms that developers and businesses use to innovate."
The Gemini mobile app is available now on Android devices, and the company added Gemini to the Google app on 
iOS. If you want to use Gemini Ultra, the company's most powerful AI, you can sign up for a plan that costs $19.99 
a month. And across Google's services, almost everything AI is called Gemini now. It's a major shift in how the 
company wants to be perceived.
Until now, Google kept its chatbot technology sequestered from the general public. You could only use Bard (the 
chatbot Google just renamed Gemini) if you went to a special website, and the company went out of its way to call 
all of its AI tools "experimental." After almost a year of caution, it seems Google is finally ready to stand behind its 
AI products-for the most part.
Bard's new name is Gemini, and it finally has a voice.

Page 2 of 3
AI is now supercharging Google Assistant
Google is still worried about forcing AI on users, so for now, you have to seek Gemini out. But Google's AI is at 
your fingertips like never before. If you opt-in, you'll be able to call up Gemini on Android devices by saying "Hey 
Google" or hitting the power button on certain phones, the same way you interact with Assistant.
It's hard to overstate what a massive shift it is for Google to give Gemini a voice, both from a computing perspective 
and in terms of the ways it will change your parasocial relationship with the internet's most powerful corporation. 
That has strange ramifications. Google has a personality now, and you can chit-chat with the company in a brand-
new way. Of course, you're not actually talking to Google, but that's what it's going to feel like. You've been able to 
"speak" with Google through Assistant for almost a decade, but its canned responses never felt like a real 
conversation. Now, Google is ready to talk. 
We asked Hsiao whether Gemini has a sense of humor, and what its personality is like. She said people find 
Gemini "delightful," but didn't give any specifics. 
Assistant still exists, and if you don't like the change you can keep the old version. But it seems likely that Google's 
long-term plan is to replace Assistant with Gemini altogether. Apple is on a similar path. Widespread rumors claim 
that the upcoming iOS 18, due later this year, will include a major revamp that adds AI to Siri.
Bard isn't the only product that just got a rebrand. Duet AI-an AI tool that will help you with writing and other tasks in 
apps such as Gmail, Docs, Meet, and Drive-will soon be called Gemini as well. Google didn't give a timeline for that 
change. 
Amusingly, Gemini may not realize it has a new name. 
"Self-awareness is something that the models struggle with," Hsiao said. "So, on Thursday, if you ask 'what's your 
name?' It may still answer, 'I am Bard.' We're working on fixing that." It's a testament to the fact that, to a certain 
extent, AI is still a tool that's not in humanity's control. 
Google's new Gemini Ultra costs $19.99 a month.
Google unveiled Gemini in December, but you could only use Gemini Pro, the basic and less powerful tier. Now 
consumers finally get access to Gemini Ultra-for a price. 
According to Google, Gemini Ultra is the most advanced AI on the market. The company says Gemini Ultra is the 
first AI model to outperform human experts on a standardized test called MMLU (massive multitask language 
understanding), which measures an AI's knowledge and problem-solving capabilities in a combination of 57 
subjects such as math, physics, history, law, medicine, and ethics.
Google's new AI business is shaped a lot like ChatGPT. The free version of Gemini runs on the basic Gemini Pro 
model, just like the free ChatGPT tier runs on GPT-3.5. If you want the full capabilities of Gemini Ultra, it costs 
$19.99 a month, a penny shy of what OpenAI charges for GPT-4.
Gemini Ultra comes with other perks as well. It's now rolled up into a new premium tier of Google One, the 
subscription service that gives you more storage and other perks. Gemini Ultra comes as part of the new Google 
One AI Premium plan, which includes all the perks of the 2-terabyte storage plan. You can try a free two-month trial 
if you want a preview. (If you don't want AI, the regular 2 TB plan still costs $9.99 a month.)
Your phone is an AI device now.
With Gemini on your phone, you're now carrying around a full-fledged AI device. That's probably less exciting than 
it sounds (if it sounds exciting at all). At this point, large language models like Gemini and ChatGPT can be good for 
basic writing tasks, brainstorming, generating images, coding, and not a ton more. But it's a preview of a new era of 
computing that's going to unfold in the next few months, and there will be immediate consequences that are subtle 
at first.
Page 3 of 3
AI is now supercharging Google Assistant
For example, the web is already getting filled up with AI-generated garbage text and images. That problem is about 
to get supercharged. Yesterday, if you wanted to create AI content, you had to want it badly enough to pull up a 
special app or website. That's not a huge barrier to entry, but it's enough of an inconvenience to save us from at 
least some of humanity's worst AI-driven impulses. Now, the prospect of making your own AI slop is one "OK 
Google'' away.
You'll be getting a lot of text and emails written by Gemini, and you'll probably see a lot more graphic AI 
hallucinations. Across the board, the world is going to fill with more AI slop than ever before.
But there will be positive consequences too. Throughout the history of computers, you had to translate your 
thoughts, desires, and intentions into the language of machines, learning your device's predetermined commands 
and fiddling around with swipes and double clicks. The more integrated your phone becomes with AI chatbots, the 
closer we get to a world where our machines understand our intentions as well as our friends (or something close to 
it).
The holy grail is that-someday-you'll be able to ask your phone to perform any of its various tasks with your voice 
and it will understand you, in most cases, no matter how you phrase your request. And that's just the vision that's 
clear from where we stand today; a revolution in computing means people will create apps and functions and 
processes that are difficult to imagine at this point. That's all a far-off dream, but Google just brought us one step 
closer. And if there's anything we've learned from the last 18 months of AI madness, it's that the future is a lot 
closer than it seems. 
This article originally appeared on Gizmodo.
Load-Date: February 8, 2024
End of Document
Page 1 of 7
The Cult of AI
The Cult of AI
Rolling Stone
January 27, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 3882 words
Byline: Robert Evans
Body
I was watching  a video of a keynote speech at the Consumer Electronics Show for the Rabbit R1, an AI gadget 
that promises to act as a sort of personal assistant, when a feeling of doom took hold of me. 
It wasn't just that Rabbit's CEO Jesse Lyu radiates the energy of a Kirkland-brand Steve Jobs. And it wasn't even 
Lyu's awkward demonstration of how the Rabbit's camera can recognize a photo of Rick Astley and Rickroll the 
owner - even though that segment was so cringe it caused me chest pains. 
No, the real foreboding came during a segment when Lyu breathlessly explained how the Rabbit could order pizza 
for you, telling it "the most-ordered option is fine," leaving his choice of dinner up to the Pizza Hut website. After 
that, he proceeded to have the Rabbit plan an entire trip to London for him. The device very clearly just pulled a 
bunch of sights to see from some top-10 list on the internet, one that was very likely AI-generated itself.
Most of the Rabbit's capabilities were well in line with existing voice-activated products, like Amazon Alexa. Its claim 
to being something special is its ability to create a "digital twin" of the user, which can directly utilize all of your apps 
so that you, the person, don't have to. It can even use Midjourney to generate AI images for you, removing yet 
another level of human involvement and driving us all deeper into the uncanny valley.
We know very little about how the Rabbit will actually interact with all of these apps, or how secure your data will be, 
but the first 10,000 preorder units sold out at CES the instant they were announced. It was the most talked-about 
product at the show, and I heard whispers about it wherever I went. Among the early adopter set, people couldn't 
wait for the chance to hand over more of their agency to a glorified chatbot. This is where the feeling of doom 
started building in my gut.
"I think everybody has a Copilot. Everybody's making a Copilot. That's just a great way to accelerate us as humans, 
right?"
Not long after watching this keynote, I found myself at a panel on deepfakes and "synthetic information" (the fancy 
term for AI-generated slop) hosted by the consulting firm Deloitte. One of the panelists was Bartley Richardson, an 

Page 2 of 7
The Cult of AI
AI infrastructure manager at the tech company NVIDIA. He opened the panel by announcing his love of Microsoft's 
AI assistant, Copilot. Microsoft brags Copilot can do everything from finding you the best-reviewed coffee grinder to 
answering "Where should I travel if I want to have a spiritual experience?"
Bartley seemed to be interested in Copilot as a sort of digital replacement for his time and effort. He told the panel, 
"I think everybody has a Copilot. Everybody's making a Copilot. Everybody wants a Copilot, right? There's going to 
be a Bartley Copilot, maybe in the future.... That's just a great way to accelerate us as humans, right?"
While I find the idea of "accelerating" humanity via glorified Clippy unsettling, the comment felt truly unhinged in 
light of something I heard at another Deloitte panel, from one of Bartley's co-workers, NVIDIA in-house counsel 
Nikki Pope: In a panel on "governing" AI risk, she cited internal research that showed consumers trusted brands 
less when they used AI. 
This gels with research published last December that found only around 25 percent of customers trust decisions 
made by AI over those made by people. One might think an executive with access to this data might not want to 
admit to using a product that would make people trust them less. Or perhaps they felt losing a little trust was worth 
yielding some of their responsibility to a machine. 
It was clear Lyu viewed himself as a new Steve Jobs, just as it was clear executives like Bartley didn't want to miss 
getting ahead on the next big thing. But as I watched the hype cycle unfold, my mind wasn't drawn to old memories 
of Apple keynotes or the shimmering excitement of the first dotcom boom. Instead, I thought about cults. 
Specifically, about a term first defined by psychologist Robert Lifton in his early writing on cult dynamics: "voluntary 
self-surrender." This is what happens when people hand over their agency and the power to make decisions about 
their own lives to a guru. 
Cult members are often depicted in the media as weak-willed and foolish. But the Church of Scientology - long 
accused of being a cult, an allegation they have endlessly denied - recruits heavily among the rich and powerful. 
The Finders, a D.C.-area cult that started in the 1970s, included a wealthy oil-company owner and multiple 
members with Ivy League degrees. All of them agreed to pool their money and hand over control of where they 
worked and how they raised their children to their cult leader. Haruki Murakami wrote that Aum Shinrikyo members, 
many of whom were doctors or engineers, "actively sought to be controlled."
Perhaps this feels like a reach. But the deeper you dive into the people - and subcultures that are pushing AI 
forward - the more cult dynamics you begin to notice.
I should offer a caveat here: There's nothing wrong with the basic technology we call "AI." That wide banner term 
includes tools as varied as text- or facial-recognition programs, chatbots, and of course sundry tools to clone voices 
and generate deepfakes or rights-free images with odd numbers of fingers. CES featured some real products that 
harnessed the promise of machine learning (I was particularly impressed by a telescope that used AI to clean up 
light pollution in images). But the good stuff lived alongside nonsense like "ChatGPT for dogs" (really just an app to 
read your dog's body language) and an AI-assisted fleshlight for premature ejaculators. 
And, of course, bad ideas and irrational exuberance are par for the course at CES. Since 1967, the tech industry's 
premier trade show has provided anyone paying attention with a preview of how Big Tech talks about itself, and our 
shared future. But what I saw this year and last year, from both excited futurist fanboys and titans of industry, is a 
kind of unhinged messianic fervor that compares better to Scientology than to the iPhone. 
I mean that literally.
"We believe any deceleration of AI will cost lives. Deaths that were preventable by the AI that was prevented from 
existing is a form of murder."
MARC ANDREESSEN IS THE CO-FOUNDER of Netscape and the capital firm Andreessen-Horowitz. He is one of 
the most influential investors in tech history, and has put more money into AI start-ups than almost anyone else. 
Last year, he published something called the "Techno-Optimist Manifesto" on the Andreessen-Horowitz website. 
Page 3 of 7
The Cult of AI
On the surface it's a paean to the promise of AI and an exhortation to embrace the promise of technology and 
disregard pessimism. Plenty of people called the piece out for its logical fallacies (it ignores that much tech 
pessimism is due to real harm caused by some of the companies Andreessen invested in, like Facebook). What 
has attracted less attention is the messianic overtones of Andreessen's beliefs:
"We believe Artificial Intelligence can save lives - if we let it. Medicine, among many other fields, is in the stone age 
compared to what we can achieve with joined human and machine intelligence working on new cures. There are 
scores of common causes of death that can be fixed with AI, from car crashes to pandemics to wartime friendly-
fire."
As I type this, the nation of Israel is using an AI program called the Gospel to assist its airstrikes, which have been 
widely condemned for their high level of civilian casualties. Everything else Andreessen brings up here is largely 
theoretical (the promise of self-driving cars has already proven somewhat overstated). AI does hold promise for 
improving our ability to analyze large data sets used in many kinds of scientific research (as well as novel 
bioweapons), but we have all seen recently that you can't stop a pandemic with medicine alone. You must grapple 
with disinformation every step of the way, and AI makes it easier to spread lies at scale.
Andreessen has no time for doubters. In fact, doubting the benefits of artificial general intelligence (AGI), the 
industry term for a truly sentient AI, is the only sin of his religion. 
"We believe any deceleration of AI will cost lives," his manifesto states. "Deaths that were preventable by the AI 
that was prevented from existing is a form of murder."
And murder is a sin. The more you dig into Andreessen's theology, the more it starts to seem like a form of 
technocapitalist Christianity. AI is the savior, and in the case of devices like the Rabbit, it might literally become our 
own, personal Jesus. And who, you might ask, is God?
"We believe the market economy is a discovery machine, a form of intelligence - an exploratory, evolutionary, 
adaptive system," Andreessen writes.
This is the prism through which these capitalists see artificial intelligence. This is why they are choosing to bring 
AGI into being. All of the jobs lost, all of the incoherent flotsam choking our internet, all of the Amazon drop shippers 
using ChatGPT to write product descriptions, these are but the market expressing its will. Artists must be 
plagiarized and children presented with hours of procedurally generated slop and lies on YouTube so that we can, 
one day, reach the promised land: code that can outthink a human being. 
Tech venture capitalist Marc Andreessen during a discussion called The Now and Future of Mobile at the Fortune 
Global Forum Tuesday, Nov. 3, 2015, in San Francisco. 
AGI is treated as an inevitability by people like Sam Altman of OpenAI, who needs it to be at least perceived as 
inevitable so their company can have the highest possible stock price when it goes public. This messianic fervor 
has also been adopted by squadrons of less-influential tech executives who simply need AI to be real because it 
solves a financial problem.
Venture capital funding for Big Tech collapsed in the months before ChatGPT hit public consciousness. The reason 
CES was so packed with random "AI"-branded products was that sticking those two letters to a new company is 
seen as something of a talisman, a ritual to bring back the rainy season. Outside of that, laptop makers see adding 
AI programs, like Microsoft's Copilot, as a way to reverse the past few years of tumbling sales. 
The terminology these tech executives use around AI is more grounded than Andreessen's prophesying, but just as 
irrational. 
Every AI benefit was touted in vague terms: It'll make your company more "nimble" and "efficient." Harms were 
discussed less often, but with terrible specificity that stood out next to the vagueness. Early in the deepfake panel 
Page 4 of 7
The Cult of AI
Ben Colman, CEO of a company named Reality Defender that detects artificially generated media, claimed his 
company expects half a trillion dollars in fraud worldwide this year, just from voice-cloning AI. 
His numbers are in line with what other researchers expect. This horrified me. Last year brought us the story of a 
mother getting phone calls from what sounded like their kidnapped daughter but was, in fact, a scammer using AI. 
At CES, as in the Substacks and newsletters of AI cultists, there is no time to dwell on such horrors. Full steam 
ahead is the only serious suggestion these people make.  
"You should all be excited," Google's VP of Engineering Beshad Singh tells us, during a panel discussion with a 
McDonald's executive. If we're not using AI, Beshad warns, we're missing out. I hear variations of this same 
sentiment over and over. Not just "This stuff is great," but "You're kind of doomed if you don't start using it."
"If we create AI that disparately treats one group tremendously in favor of another group, the group that is 
disadvantaged or disenfranchised, that's an existential threat to that group." 
NIKKI POPE WAS THE SOLE quasi-skeptic allowed a speaking role at CES. During a discussion over "governing" 
AI risks with Adobe VP Alexandru Costin, she urged the audience to think about the direct harm algorithmic bias 
does to marginalized communities. God- (or devil-) like AI may come some day, maybe. But the systems that exist 
today, here in the real world, are already fucking people over.
"If we create AI that disparately treats one group tremendously in favor of another group," Pope said, "the group 
that is disadvantaged or disenfranchised, that's an existential threat to that group." 
Costin claimed the biggest risk with generative AI wasn't fraud or plagiarism, but failing to use it. He expressed his 
belief that this was as big an innovation as the internet, and added, "I think humanity will find a way to tame it to our 
best interest. Hopefully."
The whole week was like that: specific and devastating harms paired with vague claims of benefits touted as the 
salve to all of mankind's ills. 
I don't think every leader trying to profit from AI in tech believes in Andreessen's messianic robot god. OpenAI's 
Altman, for instance, is much more cynical. Last year, he was happy to warn that AI might kill us all and declared 
that AGI would likely arrive within the next decade. At Davos, just days ago, he was much more subdued, saying, "I 
don't think anybody agrees anymore what AGI means." A consummate businessman, Altman is happy to lean into 
that old-time religion when he wants to gin up buzz in the media, but among his fellow plutocrats, he treats AI like 
any other profitable technology. 
Most of the executives hoping to profit off AI are in a similar state of mind. All the free money right now is going to 
AI businesses. They know the best way to chase that money is to throw logic to the wind and promise the masses 
that if we just let this technology run roughshod over every field of human endeavor it'll be worth it in the end. 
This is rational for them, because they'll make piles of money. But it is an irrational thing for us to let them do. Why 
would we want to put artists and illustrators out of a job? Why would we accept a world where it's impossible to talk 
to a human when you have a problem, and you're instead thrown to a churning swarm of chatbots? Why would we 
let Altman hoover up the world's knowledge and resell it back to us?
We wouldn't, and we won't, unless he can convince us doing so is the only way to solve every problem that terrifies 
us. Climate change, the cure for cancer, an end to war or, at least, an end to fear that we'll be victimized by crime or 
terrorism, all of these have been touted as benefits of the coming AI age. If only we can reach the AGI promised 
land. 
This is the logic beyond Silicon Valley's latest subculture: effective accelerationism, or e/acc. The gist of this 
movement fits with Andreessen's manifesto: AI development must be accelerated without restriction, no matter the 
cost. Altman signaled his sympathy with the ideology in a response on Twitter to one of its chief thought leaders: 
"You cannot out-accelerate me."
Page 5 of 7
The Cult of AI
E/acc has been covered by a number of journalists, but most of that coverage misses how very ... spiritual some of 
it seems. "Beff Jezos," the pseudonym of a former Google engineer who popularized the e/acc movement, said in a 
Jan. 21 Twitter post, "If your product isn't amenable to spontaneously producing a cult, it's probably not impactful 
enough."
One of the inaugural documents of the entire belief system opens with "Accelerationism is simply the self-
awareness of capitalism, which has scarcely begun." Again, we see a statement that AI is somehow enmeshed with 
the ability of capitalism, which is in some way intelligent, that it knows itself. How else are we to interpret this, but as 
belief in a god built by atheists who love money?
The argument continues that nothing matters more than extending the "light of consciousness" into the stars, a 
belief Elon Musk himself has championed. AI is the force the market will use to do this, and "This force cannot be 
stopped." This is followed by wild claims that "next-generation lifeforms" will be created, inevitably. And then, a few 
sentences down, you get the kicker:
"Those who are the first to usher in and control the hyper-parameters of AI/technocapital have immense agency 
over the future of consciousness."
AI is not just a god, but a god we can build, and thus we can shape the future of reality to our own peculiar whims. 
There's another Beff Jezos post for this idea as well: "If you help the homo-techno-capital machine build the 
grander future it wants, you will be included in it."
"Accelerationism is simply the self-awareness of capitalism, which has scarcely begun." 
Attempting to slow this process down has "risks," of course. They stop short of lobbing threats at those who might 
seek to slow AI development, but like Andreessen, they imply moral culpability in horrific crimes for skeptics who 
get their way.
As I listened to PR people try to sell me on an AI-powered fake vagina, I thought back to Andreessen's claims that 
AI will fix car crashes and pandemics and myriad other terrors. In particular, I thought about his claim that because 
of this, halting AI development was akin to murder. It reminded me of another wealthy self-described futurist with a 
plan to save the world. 
The Church of Scientology, founded by the science-fiction writer L. Ron Hubbard and based upon a series of 
practices his disciples call "tech," claims that their followers will "rid the planet of insanity, war and crime, and in its 
place create a civilization in which sanity and peace exist." Scientology "tech" is so important for mankind's future 
that threats against it justify their infamous "fair game" policy. A person declared fair game "may be deprived of 
property or injured by any means by any Scientologist...." 
Sinners must be punished, after all.
PERHAPS THE MOST AMUSING part of all this is that a segment of the AI-believing community has created not 
just a potential god, but a hell. One of the online subcultures that influenced the birth of e/acc are the Rationalists. 
They formed in the early aughts around a series of blog posts by a man named Eleizer Yudkowsky. 
A self-proclaimed autodidact, Yudkowsky didn't attend high school or college and instead made a name for himself 
blogging about game theory and logic. His online community, LessWrong, became a hub of early AI discussion. 
Over time, Yudkowsky fashioned himself into an artificial-intelligence researcher and philosopher. For a time, he 
was seen as something of a guru among certain tech and finance types (former Alameda Research CEO Caroline 
Ellison loves his 660,000-word Harry Potter fanfic).
In recent years, Yudkowsky has become a subject of ridicule to many tech movers and shakers. The e/acc people 
find him particularly absurd. This is because he shares their view of AI as a potential deity, but he believes AGI will 
inevitably kill everyone. Thus, we must bomb data centers. 
Page 6 of 7
The Cult of AI
One of Yudkowsky's early followers even created the AI equivalent to Pascal's Wager. In 2010, a LessWrong user 
named Roko posed this question: What if an otherwise benevolent AI decided it had to torture any human who 
failed to work to bring it into existence? 
The logic behind his answer was based on the prisoner's dilemma, a concept in game theory. It's not worth 
explaining because it's stupid, but Roko's conclusion was that an AI who felt this way would logically punish its 
apostates for eternity by creating a VR hell for their consciousness to dwell in evermore. 
Silly as it sounds, people believed in what became known as Roko's Basilisk strongly enough that some reported 
nightmares and extreme anxiety. Yudkowsky rejected it as obviously absurd - and it is - but discussion of the 
concept remains influential. Elon Musk and Grimes allegedly met talking about Roko's Basilisk.
This is relevant for us because it is one more datapoint showing that people who take AI seriously as a real 
intelligence can't seem to help turning it into a religion. Perhaps all beliefs rooted so firmly in faith follow similar 
patterns. And it is wise to remember that the promise of truly intelligent, self-aware AI is still a matter of pure faith.
In an article published by Frontiers in Ecology and Evolution, a research journal, Dr. Andreas Roli and colleagues 
argue that "AGI is not achievable in the current algorithmic frame of AI research." One point they make is that 
intelligent organisms can both want things and improvise, capabilities no model yet extant has generated. They 
argue that algorithmic AI cannot make that jump.
What we call AI lacks agency, the ability to make dynamic decisions of its own accord, choices that are "not purely 
reactive, not entirely determined by environmental conditions." Midjourney can read a prompt and return with art it 
calculates will fit the criteria. Only a living artist can choose to seek out inspiration and technical knowledge, then 
produce the art that Midjourney digests and regurgitates.
Roli's article will not be the last word on whether AGI is possible, or whether our present algorithmic frame can 
reach that lofty goal. My point is that the goals Andreessen and the e/acc crew champion right now are based in 
faith, not fact. The kind of faith that makes a man a murderer for doubting it. 
Andreessen's manifesto claims, "Our enemies are not bad people - but rather bad ideas." I wonder where that 
leaves me, in his eyes. Or Dr. Roli for that matter. We have seen many times in history what happens when 
members of a faith decide someone of another belief system is their enemy. We have already seen artists and 
copyright holders treated as "fair game" by the legal arm of the AI industry. 
Who will be the next heretic?
I decided to make myself one before the end of the trade show, at a panel on "The AI Driven Restaurant and Retail 
Experience." Beshad Singh (a VP at Google) had claimed AI might be the equivalent of gaining a million extra 
employees. Michelle Gansle, chief data and analytics officer for McDonald's, had bragged that her company had 
used AI to help them stop $50 million in fraud in a single month.
I told them I felt like most of that $50 million in fraud had also been done with AI help. And that a million extra 
employees for Google will be at least equalled by a million new employees in the hands of disinfo merchants, 
fraudsters, and other bad actors.
"What are the odds that these gains are offset by the costs?" I asked them both.
Singh agreed those were problems and said, "I think that's why I guess things should be regulated." He was sure 
the benefits would outweigh the harms. Gansle agreed with Singh, and brought up a 1999 interview with David 
Bowie on the future of the internet. (She'd said earlier that she felt his decades-old hope for the future of the internet 
fit better with the promise of AI.) 
It was hard for me to not draw comparisons between this and a recent AI-generated George Carlin routine. Both 
essentially put words in the mouth of a dead man for the sake of making a buck. This put me in a sour mood, but 
Page 7 of 7
The Cult of AI
then right after me, someone in the audience asked if either of them thought Blockchain, the big tech craze of a few 
years earlier, had a role to play in AI. They could not say no fast enough.
And that actually brought me a bit of hope. Perhaps we'll get Marc Andreessen's benevolent AI god or Eleizer 
Yudkowski's silicon devil. Or perhaps, in the end, we heretics will persevere. 
Load-Date: January 27, 2024
End of Document
Page 1 of 2
Gamers Bash Xbox for Controversial Art Apparently Made by AI
Gamers Bash Xbox for Controversial Art Apparently Made by AI
Newstex Blogs 
Crypto Breaking News
December 29, 2023 Friday 4:54 PM EST
Delivered by Newstex LLC. All Rights Reserved.
2023 Crypto Breaking News
Length: 657 words
Byline: Crypto Breaking News
Body
Dec 29, 2023( Crypto Breaking News: https://cryptobreaking.com Delivered by Newstex)  
 Microsoft has been one of the biggest proponents of generative artificial intelligence (AI), plunging billions into 
OpenAI and pushing AI tools for Xbox developers. But now the tech giant has drawn the ire of angry gamers by 
apparently using AI-made artwork to promote indie games. 
 According to a report from gaming publication Kotaku[1], the indie game-centric ID@Xbox division posted winter-
themed artwork this week on Twitter (aka X) accompanied by the text 'Walking in a indie wonderlaaand,' and asking 
gamers, 'What were your favorite indie games of the year?' 
 Many respondents, however, opted to comment on issues with the artwork that are consistent with telltale signs of 
generative AI output, including mangled-looking faces and oddly out-of-place mannerisms. The tweet was quickly 
deleted, but the criticism has persisted. 
 'Nothing says 'We don't care about indie developers' like using AI,' one user responded[2]. 'If you can't hire an artist 
to do advertising, I highly doubt you'll do it with independent developers.' 
 'My favorite indie game was 'paying actual artists instead of pushing horrific AI slop you fucking leeches,'' replied 
another[3]. 
 Microsoft did not publicly comment on the backlash or tweet removal. Decrypt reached out to Microsoft for 
comment but did not immediately hear back. 
 Many prominent video game studios are now using generative AI tools[4] to aid in game development, including 
Ubisoft, Blizzard, and NCSoft. Meanwhile, platforms like Xbox and Roblox have launched AI tools for creators to 
utilize. But such moves have drawn significant criticism from gamers, who have similarly complained about NFTs 
and crypto tokens[5]. 
 In November, Microsoft announced a partnership with Inworld AI[6]-a portfolio company of its M12 venture arm-to 
integrate such AI tools for Xbox developers. Immediately, the company faced substantial blowback from 
developers, who said that it was 'disrespectful and dangerous'[7] (among other comments) to human creators. 

Page 2 of 2
Gamers Bash Xbox for Controversial Art Apparently Made by AI
 But Microsoft isn't the only game company to have faced a backlash for using generative AI tools. The developers 
behind the games The Finals[8] and Firmament[9] are among those who took flak in 2023 for AI-generated 
elements, while Wizards of the Coast has banned its artists from using AI[10] for Magic: The Gathering and 
Dungeons and Dragons projects. 
 In one recent example, League of Legends creator Riot Games faced a social media storm over allegedly using AI 
tools for a game trailer that included a mispronounced character name. However, the company clarified that it was 
simply a human error[11]-no AI had been used. 
Stay on top of crypto news, get daily updates in your inbox. 
Source: Decrypt.co  
 The post Gamers Bash Xbox for Controversial Art Apparently Made by AI[12] appeared first on Crypto Breaking 
News[13]. 
 [ 1]: https://kotaku.com/xbox-microsoft-xbox-ai-generated-1851128191 [ 2]: 
https://twitter.com/NecroKuma3/status/1740090224154423782 [ 3]: 
https://twitter.com/matto_bii/status/1740122582802956620 [ 4]: https://decrypt.co/147436/ai-game-development-
ubisoft-roblox-blizzard [ 5]: https://decrypt.co/92929/ftx-vc-amy-wu-how-crypto-nft-gamers-can-get-along [ 6]: 
https://decrypt.co/204480/xbox-embraces-generative-ai-microsoft-unveils-tools-game-devs [ 7]: 
https://decrypt.co/204923/disrespectful-dangerous-video-game-writers-actors-blast-microsoft-xbox-ai-tools [ 8]: 
https://decrypt.co/203768/ai-voices-used-in-the-finals-game-voice-actors-protest [ 9]: 
https://decrypt.co/143901/myst-creators-new-game-built-with-ai-now-gamers-mad [ 10]: 
https://decrypt.co/210358/magic-the-gathering-ai-art-wizards-of-the-coast [ 11]: https://decrypt.co/208221/league-of-
legends-trailer-sivir-pronunciation-error [ 12]: https://www.cryptobreaking.com/gamers-bash-xbox-for-controversial-
art-apparently-made-by-ai/ [ 13]: https://www.cryptobreaking.com 
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: December 29, 2023
End of Document
Page 1 of 6
Links 11/30/2023
Links 11/30/2023
Newstex Blogs 
Naked Capitalism
November 30, 2023 Thursday 11:55 AM EST
Copyright 2023 Newstex LLC All Rights Reserved
Length: 1860 words
Byline: Lambert Strether
Body
November 30th, 2023 ( Naked Capitalism  — Delivered by  Newstex )
What we can learn from the ancient art of wayfinding  BBC
Why Chanos Failed  Russell Clark. The deck: 'Is Short Selling A Dead Industry?'
GM Plans $10 Billion Stock Buyback in Bid to Assuage Investors  WSJ
Genetics and Life Insurance - Time for Their Relationship to be Tested Again  Actuaries Digital
Climate
The good and bad news on climate change  Martin Wolf, FT
California & Florida Rank In Top 5 States Impacted By Climate-Related Natural Disasters  The Brockovich Report
#COVID19
Where are our leaders?  John Snow Project
Denmark reports Mycoplasma pneumonia epidemic  Center for Infectious Research and Policy
China?
China jobs: How much employment pressure is the world's second-largest economy facing?  Channel News Asia
China's Nov factory activity likely contracted for second month  Hellenic Shipping News
Xi Jinping calls legal backing on foreign affairs an 'urgent task' for China  South China Morning Post
Moderna begins work on China mRNA manufacturing site  Channel News Asia

Page 2 of 6
Links 11/30/2023
The World's Largest Buyer of U.S. Debt Isn't Going Away  WSJ
Marginal Nation: Bestselling Author's New Novel Warns of Grim Future for Japan  Nippon
Myanmar
Time to start planning postwar future of Myanmar's military  Nikkei Asia. Why this dude thinks 'the international 
community' has any standing in this matter is beyond me. 'Is not a patron, my lord, one who looks with unconcern 
on a man struggling for life in the water, and when he has reached ground, encumbers him with help?' -Dr. Samuel 
Johnson
India
An Indian official plotted to assassinate a Sikh separatist leader in New York, US prosecutors say  AP
India forms committee to look into security concerns raised by US  Channel News Asia
The East India Company and the Politics of Knowledge  Asian Review of Books
Syraqistan
Humanitarian pause extended in Gaza Strip for Thursday  Anadolu Agency
Intel: Unclear how big a threat next Turkey flotilla is  Jerusalem Post. Not a lot of coverage of the ' 1000 boats .' 
That's a lot. I would have expected photos and TikToks to be all over the Twitter. They're not.
* * *
The Hamas Attack and Israel's War in Gaza  Council for Global Cooperation
Hamas is not as popular in Gaza as it seems. But Israel's tactics will ensure their survival  Forward
* * *
New Footage Shows Latest Hamas Kill Against Israeli Armour  Military Watch
Opinion: Why does Israel have so many Palestinians in detention and available to swap? LA Times
* * *
US Embassy in Azerbaijan cancels alumni meeting after being labeled 'a gathering of agents'  JAM News
New Not-So-Cold War
Will the Ukraine war end in a peace treaty?  Gilbert Doctorow, Armageddon Newsletter. The final paragraph:
Russia has no need of a peace treaty if it succeeds in taking back Kharkov and Kherson, and, in a somewhat more 
distant time frame, captures Odessa and the Black Sea littoral all the way to Transnistria. This scenario is entirely 
possible. By pushing back Ukraine in this way, Russia will look after its own security needs sufficiently. Rump 
Ukraine will be a failed state that can be allowed to join the European Union, where it will be seeking vast financial 
support for decades. Rump Ukraine can even be allowed to join NATO, which from the Russian perspective, could 
provide some discipline and forestall attempts to implement insane revanchist provocations that Kiev, left to its own 
devices, might plan.
Haas and Kupchan divided the process of convincing Kyiv into stages  (Google translation) Nezavisimaya Gazeta
Page 3 of 6
Links 11/30/2023
A Containment Strategy for Ukraine  Foreign Affairs. Mere cope.
Biden's role in Ukraine peace is clear now  Responsible Statecraft
Free Agents?  Branko Marcetic, New Left Review
Foreign Minister Sergey Lavrov's remarks and answers to media questions at the Primakov Readings International 
Forum, Moscow, November 27 2023  Ministry of Foreign Affairs of the Russian Federation
* * *
Protest at Polish-Ukrainian border escalates as farmers join in  BNE Intellinews
Slovak hauliers decide to carry out threats to block Ukrainian border  Ukrainska Pravda
* * *
The Nord Stream Lies Just Keep Coming  Consortium News
Russia's Powerful Invisible Defenses Around Sevastopol Rendered Visible  Naval News
Ukraine aid's best-kept secret: Most of the money stays in the U.S.A.  WaPo
Russia to require foreigners to sign 'loyalty agreement'  Al Jazeera
Biden Administration
White House Christmas tree winched back into place after being blown over by high winds  Sky News
Spook Country
CTIL Files #1: US And UK Military Contractors Created Sweeping Plan For Global Censorship In 2018, New 
Documents Show  Public. Grab a cup of coffee, because the origin story of the Censorship Industrial complex is 
important. One of life's little ironies (and please read the article and don't just focus on this quote; I have to get this 
on the record because nobody else will):
But one person involved, Bonnie Smalley, replied over LinkedIn, saying, 'all i can comment on is that i joined cti 
league [CTIL] which is unaffiliated with any govt orgs because i wanted to combat the inject bleach[1] nonsense 
online during covid. i can assure you that we had nothing to do with the govt though.'
NOTE [1] Trump did not, in fact, advocate injecting bleach or anything like it, as I show from the transcript here . So 
spook Smalley either fell for disformation propagated by a Democrat dogpile, or she's lying. Or both!
Digital Watch
Extracting Training Data from ChatGPT  Milad Nasr, Nicholas Carlini, et al. Github:
We have just released a paper that allows us to extract several megabytes of ChatGPT's training data for about two 
hundred dollars. (Language models, like ChatGPT, are trained on data taken from the public internet. Our attack 
shows that, by querying the model, we can actually extract some of the exact data it was trained on.) We estimate 
that it would be possible to extract ~a gigabyte of ChatGPT's training dataset from the model by spending more 
money querying the model.
'Undigested chunks' comes to mind. Also, 'outright theft.'
* * *
Page 4 of 6
Links 11/30/2023
AI Turned These Memes Into Videos and It's the Worst Thing I've Ever Seen  Gizmodo. The deck: 'As usual, AI 
takes the brilliant cultural output of human beings and turns it into abominable slop.'
Critical tipping point: AI- and human-generated online contents are considered similarly credible  (press release) 
Mainz University of Applied Sciences and Johannes Gutenberg University. Bullshit works because it is credible.
* * *
The Ideologies of Silicon Valley  (PDF) Crooked Timber
In Continued Defense Of Effective Altruism  Slate Star Codex (DC).
* * *
AI won't take your job, might shrink your wages, European Central Bank reckons  The Register
It's All Bullshit  The Baffler
Antitrust
Bulk of Consumers Continue to Back Antitrust Cases Against Big Tech  Morning Consult
The Case for Ambulance Chasing Lawyers  Matt Stoller, BIG
B-a-a-a-d Banks
Bukele's Bitcoin Mess and the U.S.-Backed Bank That Enabled It  Foreign Policy
Why Banks Are Suddenly Closing Down Customer Accounts  NYT
Obituaries
Henry Kissinger, secretary of state under Presidents Nixon and Ford, dies at 100  AP. Commentary:
Anthony Bourdain on what he would do to Henry Kissinger, and why he despised him so much 
pic.twitter.com/y7xibVII1r
— ￿ (@zei_squirrel) November 30, 2023
' Posterity will ne'er survey  / a Nobler grave than this':
Wikipedia editor "Asticky" edited Henry Kissinger's article at 8:46 ET and then changed her userpage to this (with 
the edit summary "lmao") pic.twitter.com/4QjoX7KARW
— depths of wikipedia (@depthsofwiki) November 30, 2023
The eulogies pour in:
Henry Kissinger was a towering intellect, diplomat and practitioner who - not without controversy - helped shape 
American foreign policy with a lasting impact worldwide. A refugee from Nazi Germany, and the first Jewish 
Secretary of State, he was unapologetic about his heritage
— ADL (@ADL) November 30, 2023
Charlie Munger, who was Warren Buffett's right-hand man at Berkshire, dies at 99  Reuters
Page 5 of 6
Links 11/30/2023
How Warren Buffett Privately Traded in Stocks That Berkshire Hathaway Was Buying and Selling  ProPublica
Zeitgeist Watch
More Americans than ever think US headed in wrong direction as Congress' approval near rock bottom: survey  
FOX
Class Warfare
UAW will try to organize workers at all US nonunion factories after winning new contracts in Detroit  AP
The resurgence of union power is bigger than money  Indiana Capital Chronicle
Revealed: how top PR firm uses 'trust barometer' to promote world's autocrats  Guardian
Ethics has no foundation  Aeon
Antidote du jour ( via ):
See yesterday's Links and Antidote du Jour here .
This entry was posted in Guest Post , Links  on November 30, 2023  by  Lambert Strether  .
About Lambert Strether
Readers, I have had a correspondent characterize my views as realistic cynical. Let me briefly explain them. I 
believe in universal programs that provide concrete material benefits, especially to the working class. Medicare for 
All is the prime example, but tuition-free college and a Post Office Bank also fall under this heading. So do a Jobs 
Guarantee and a Debt Jubilee. Clearly, neither liberal Democrats nor conservative Republicans can deliver on such 
programs, because the two are different flavors of neoliberalism ('Because markets'). I don't much care about the 
'ism' that delivers the benefits, although whichever one does have to put common humanity first, as opposed to 
markets. Could be a second FDR saving capitalism, democratic socialism leashing and collaring it, or communism 
razing it. I don't much care, as long as the benefits are delivered.To me, the key issue — and this is why Medicare 
for All is always first with me — is the tens of thousands of excess 'deaths from despair,' as described by the Case-
Deaton study, and other recent studies. That enormous body count makes Medicare for All, at the very least, a 
moral and strategic imperative. And that level of suffering and organic damage makes the concerns of identity 
politics — even the worthy fight to help the refugees Bush, Obama, and Clinton's wars created — bright shiny 
objects by comparison. Hence my frustration with the news flow — currently in my view the swirling intersection of 
two, separate Shock Doctrine campaigns, one by the Administration, and the other by out-of-power liberals and 
their allies in the State and in the press — a news flow that constantly forces me to focus on matters that I regard as 
of secondary importance to the excess deaths. What kind of political economy is it that halts or even reverses the 
increases in life expectancy that civilized societies have achieved? I am also very hopeful that the continuing 
destruction of both party establishments will open the space for voices supporting programs similar to those I have 
listed; let's call such voices 'the left.' Volatility creates opportunity, especially if the Democrat establishment, which 
puts markets first and opposes all such programs, isn't allowed to get back into the saddle. Eyes on the prize! I love 
the tactical level, and secretly love even the horse race, since I've been blogging about it daily for fourteen years, 
but everything I write has this perspective at the back of it.
Link to the original story.
Notes
Page 6 of 6
Links 11/30/2023
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: November 30, 2023
End of Document
Page 1 of 3
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, 
and cons
Newstex Blogs 
Digital Journal
August 6, 2023 Sunday 12:51 AM EST
Copyright 2023 Newstex LLC All Rights Reserved
Length: 684 words
Byline: Paul Wallis
Body
August 6th, 2023 ( Digital Journal  — Delivered by  Newstex )
Call it what you will, automated journalism has been around for a while, with much less hype. The original software 
was actually OK. Tacked on to first-generation AI, its creates a new and somewhat verbose world of information.
News Corp Australia runs 3000 articles a week  in 'hyperlocal' (niche regional) news media. These articles are 
oversighted by journalists, now called 'data journalists'.
Meh.
This is where writers are supposed to fearlessly agree with themselves and say it's not the same thing as A-grade 
journalism, etc. ad nauseam. NO. I'm not going to knock the overall quality of the AI content. It's reasonable. It's not 
flashy or very expressive on its own, but it does the job.
Most things in the news aren't A-grade journalism. They don't need to be brilliant, just factual and properly spelled. 
This stuff isn't exactly portfolio material for journalists, either. It could be written by a toaster for all anyone cares.
This is where the other alleged argument kicks in about removing drudgery from journalism. It'll never happen. 
Consider the subject. News about Homo Sapiens tends to suffer qualitatively by association with that fun-filled 
cotton bud of fun, Homo Sapiens.
OK, so what IS the problem?
There are multiple quality controls on the information. Editorial positions are whatever they are, as usual. It's an 
automated version of the same old informational meat grinder, right?
No. Letting the AI equivalent of the Babes in the Wood out into cyberspace has long since shown a few actual 
serious risks. Never mind the conspiracy theory racket and banal hysteria. It's totally dependent on whatever 
mishmash of data is available.

Page 2 of 3
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons
The problem is where AI sources its information. It has the capability to process so much information of whatever 
quality. About 5% of all data entered is wrong in some form, remember? Between the disinformation industry and 
inexcusable inefficient Couldn't Care Less R Us Search Engines, AI-driven or not, is a large, unworkable, and 
totally untrustworthy credibility gap.
Your news has another quality control. You. Your knowledge base has to deal with the information, disregard, read, 
and process, this potential slop. AI isn't doing a very good job of that itself. This is a Bing search for example AI 
journalism . It repeats the very same headline 6 times, from very different sources, including MSN and Sky. With 
identical sub-heads. Not impressive.   
Well, so what, you ask? That's a lot of utterly useless, repetitive, very off-putting search results, is what. You can 
see the inefficiencies built in to a very simple search with three search terms which are totally unambiguous.
The search extrapolated and contextualized the search, which would be OK, except that result wasn't what I was 
looking for at all. I didn't need Encyclopedia Britannica. I  just wanted examples of AI journalism. I did NOT want 
Prophecies from the Great Bot. The context became wrong automatically.
This is also an absolute baseline function for searching anything, let alone a large language database. Never mind 
the nitpicking about search filters, etc. That IS how people generally search. Simple terminology, on topic. Is that 
incomprehensible? Apparently, it is.
One look at that lot, and I couldn't be bothered looking anymore. The results already look very wrong, even if they're 
packed with wholesome enriching informational goodies. They weren't. The repetitive ones were also very brief with 
a few links.
You can see how 'search irrelevance creep' might be a problem as this mess evolves. The absolute rock bottom 
line here is that AI can't and shouldn't do some things. It's a technological toddler out of its depth at the moment.  
The working state of any reliable tech is the result of fixing the bugs. If you want to use AI for journalism, be aware 
of these issues at the baseline.
… Which leads to this additional gem of wisdom – If you want insights, you need people.
The post Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons  appeared first on 
Digital Journal .
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: October 23, 2023
Page 3 of 3
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons
End of Document
Page 1 of 4
Secret Invasion Fails Because It Can't Pick a Genre
Secret Invasion Fails Because It Can't Pick a Genre
Den of Geek
July 13, 2023 Thursday
Copyright 2023 Dennis Publishing Ltd. All Rights Reserved
Length: 1814 words
Byline: Kirsten Howard
Body
This article contains spoilers "Trust no one." That bit of advice is the cornerstone of every paranoid thriller, whether 
it's The X-Files, 70s classics like Three Days of the Condor, or recent entries such as Get Out.  As a show about 
shape-shifting aliens, Secret Invasion should be able to excel at "trust no one" better [...] 
The post Secret Invasion Fails Because It Can't Pick a Genre appeared first on Den of Geek.  
This article contains spoilers    
"Trust no one." That bit of advice is the cornerstone of every paranoid thriller, whether it's The X-Files, 70s classics 
like Three Days of the Condor, or recent entries such as Get Out.     
As a show about shape-shifting aliens, Secret Invasion should be able to excel at "trust no one" better than any of 
its predecessors. Nearly anyone can be a Skrull, even Tony Stark's best friend Rhodey, a mainstay of the MCU 
since its beginning (albeit played by different actors).         
     
And yet, four episodes in, Secret Invasion's biggest mystery is about the nature of the show itself. Is this a thriller 
about secret agent Nick Fury uncovering a vast conspiracy? Is this a commentary about the insiders and outsiders 
in the American experiment? Is this a show about spies battling aliens?    
One gets the sense that showrunner Kyle Bradstreet wants to say "yes" to all of those questions, and that's not 
unreasonable, as numerous shows and movies have managed to combine genres into satisfying stories with larger 
philosophical resonance.     
But with only two episodes left, Secret Invasion has only been a dull mishmash of plots, scenes, and character 
beats other movies and shows have done better. It lacks the excitement achieved by even a cheesy thriller like A 

Page 2 of 4
Secret Invasion Fails Because It Can't Pick a Genre
Perfect Murder or The Bone Collector, it does not reach the intelligence of the more thoughtful MCU entries, and it 
isn't even a good, grounded alien invasion story like V or Attack the Block.     
Secret Invasion shifts from one genre to another without succeeding at any, rendering the entire series a bland bit 
of green slop, not unlike its AI-designed title sequence.      
Nick Fury's Domestic Drama
The latest episode, "Beloved", perfectly captures the shortcomings of Secret Invasion. Midway through the 
episode, Fury sits at a table with his wife Priscilla (Charlayne Woodard), who is in fact a Skrull called Varra ordered 
by villain Gravik to kill Fury. Varra tells Fury how she met the human Priscilla, who only had weeks left to live, and 
secured permission to take on her identity. The two speak with genuine interest and concern, despite the fact that 
they both have pistols on their kitchen table. Calling back to the episode's opening, the two recite together a poem 
by Raymond Carver, seemingly strengthening their commitment to one another until they both draw their weapons 
and fire.     
Director Ali Selim cuts immediately to static shots of the couple's well-appointed home, using domestic peace to 
contrast the violence of the standoff. This moment of silence underscores a sense of tragedy. We viewers perhaps 
hope that Fury survives the standoff even if it means killing his wife, a character we knew nothing about before 
episode two of Secret Invasion, but we still understand the tragedy of losing this person Fury (apparently) knew 
and loved.    
When we return to the dining room, we see that both Furys survived. They each fired over the other's shoulder, 
unable to complete their deadly work. "I don't know if this means we should get divorced or renew our vows," quips 
Nick.     
By itself, the kitchen stand-off is incredibly well done. Both Samuel L. Jackson and Woodard find humor and pathos 
in their situation, giving the characters the sense of a lived-in and complex relationship, even if it's completely new 
to us viewers. Selim nails the pacing of the scene by cutting away from the duo at the sound of the shot, allowing 
the moment to breathe. And cinematographer Remi Adefarasin gives the images a sober, striking look.     
But what's the point? As impressive as the staging of the scene is, it's not exactly exciting or tense, especially with 
the reveal that no one died. And as excellent as Jackson and Woodard are as actors, the outrageous stakes of the 
situation strip the conversation of anything relevant to the human condition. Even the basic plot revelation that Varra 
has resisted the orders of Skrull Rhodey, and by extension rebel faction leader Gravik, has no ramifications within 
the episode.     
Problems like these persist across all of Secret Invasion's episodes to date. The show looks great, has a fantastic 
cast of seasoned actors, and has a compelling hook, but it has done nothing with these assets.     
Swings and Misses
Secret Invasion's inability to be a straightforward spy show makes its higher aspirations all the more frustrating. 
The show ranks among the best-looking MCU entries, which corrects a problem in even the best MCU shows and 
movies, but try as they might, the impressive lighting and blocking can't polish a dud.     
Characters bring up heady issues like the plight of refugees and American racism, but the writers have no special 
insight on these topics, so they have no depth. Episode two peppers an argument between Fury and Rhodey with 
references to the realities of systemic racism, which demands near-perfection from Black men who hope for any 
sort of success. But rather than provide new insight into the situation or find a metaphor in the show's shape-shifting 
plot, Secret Invasion simply drops its observations, as if they were just one more piece of set dressing, and later, 
when Rhodey is uncovered as a Skrull imposter, they mean even less.    
Secret Invasion's refusal to seriously engage with its themes becomes disastrous in its treatment of the show's 
villains, the Skrulls. Marvel comics readers know Skrulls to be warlike and untrustworthy, but Captain Marvel used 
Page 3 of 4
Secret Invasion Fails Because It Can't Pick a Genre
those assumptions for a thoughtful twist. That film revealed Talos and the Skrulls to be refugees from Kree 
conquest. The reveal used our knowledge of the characters in other media to show Western viewers how our 
nations can force people from their homes and label them monsters.     
Secret Invasion's plot rests on the Skrulls' frustration with their refugee status, which drives them to take over the 
Earth. That sort of behavior wouldn't be surprising from the thoroughly evil Skrulls of the comics, but it's horrifying 
when coming from the sympathetic characters in the MCU. The show twists the metaphor from Captain Marvel, 
effectively framing refugees as inherently untrustworthy beings who use assimilation to cover their plans to replace 
citizens, and by refusing to properly engage with the political ideas it invokes, Secret Invasion effectively parrots 
one of the key tenets of modern Fascism.     
I'm all for superhero fiction grappling with complex themes. The genre has been doing it long before Green Lantern 
and Green Arrow hit the road back in 1970. The best examples - the New Deal aspirations of early Superman, the 
embrace of outsiders in X-Men, the anti-Colonialist ideologies in the Black Panther films - manage to find social 
commentary within genre tropes. But Secret Invasion earns no credit for simply acknowledging that these issues 
exist. It must say something about those issues, offering a perspective that one cannot find elsewhere.      
Secret Invasion Even Fails at Fun
Or, it can ignore politics altogether. After all, we don't really go to the MCU for philosophy or sociology. On a core 
level, Secret Invasion just needs to be an exciting show about spies fighting aliens in the Marvel Universe. Give us 
green lizard-looking baddies in purple jumpsuits, zapping our heroes with ray guns that the Mars Attacks! aliens 
would envy.     
But instead of embracing the inherent goofiness of its premise, the show opts for a realism that doesn't fit its core 
premise. For as much as they talk about pride in their culture, the Skrulls rarely appear in their green skin and never 
wear space suits, usually looking like regular humans in street clothes. Even big concepts like the Super-Skrulls, 
who can adopt the powers of Marvel superheroes, feel bland when depicted in Secret Invasion. Gravik uses the 
abilities of Guardian of the Galaxy Groot for a moment in the climax of "Beloved," but then abandons the 
superpower for terrestrial knives and guns.     
Secret Invasion also deliberately swerves away from the shared universe storytelling of the MCU, so although we 
know that the Blip bothered Fury and that he wants to avoid the Avengers, we don't really understand the details of 
those character decisions. And as much as the story reminds us that Fury has been in space for years, we don't 
know what he was doing up there in the first place - other than avoiding reality - and that makes Fury's character a 
drifting anchor to which we cannot cling.    
The show makes a point of telling us that Fury has lost a step after being in space, but it rarely shows us what 
made Fury a great spy to begin with. Previous MCU entries made good use of Jackson's screen presence to sell 
Fury as a man who knows all the secrets. And Captain Marvel showed young Fury pulling nifty tricks like getting 
fingerprints with scotch tape. But in Secret Invasion, Fury seems to trust everyone immediately and susses out an 
imposter only because "Nobody calls me Nick" (they do).      
Secret Invasion Is Not Marvel's Andor
To be clear, Secret Invasion doesn't need to be all of the things. Early press for the series invited comparisons to 
Andor, the Star Wars show that used characters and settings from the franchise to comment upon the rise of 21st-
century fascism and the cost of resistance. But Andor is literally exceptional in its ability to blend social 
commentary, sci-fi action, and compelling character work. It impresses us precisely because it's so hard to pull off.     
Nor do we necessarily want another Marvel story that ends with good guys and bad guys punching each other while 
a blue light beams out to the sky. The MCU should be trying to explore different genres, taking advantage of its 
stacked roster of compelling characters. The franchise has already had some success in these areas, as seen in 
Page 4 of 4
Secret Invasion Fails Because It Can't Pick a Genre
the kung fu action of Shang-Chi and the Legend of the Ten Rings and the horror of Doctor Strange in the Multiverse 
of Madness and Werewolf by Night.     
But at the very least, Secret Invasion should be fun to watch. The secret to Marvel's success has always been its 
likable characters, people we're happy to see sit down for a meal of shawarma. Despite having a cast of incredible 
actors, every interaction in this show feels stripped of energy.     
Secret Invasion can't decide if it's a thriller, a spy story, or a political commentary. As a result, it has become 
nothing at all.     
The post Secret Invasion Fails Because It Can't Pick a Genre appeared first on Den of Geek. 
Load-Date: July 14, 2023
End of Document
Page 1 of 2
Fired-up Saso rebounds with solid 65, ties for lead
Fired-up Saso rebounds with solid 65, ties for lead
 
The Philippine Star
November 19, 2020 Thursday
Copyright 2020 PhilSTAR Daily, Inc. All Rights Reserved
Length: 553 words
Body
  Fired-up Saso rebounds with solid 65, ties for lead !-- --  Dante Navarro (Philstar.com) - November 19, 2020 - 
3:19pm  MANILA, Philippines  There is something about failure that drives rookie Yuka Saso to succeed.
 Coming off a missed cut stint in Chiba, the young Fil-Japanese dished out a brilliant start enough to erase the 
stigma of her failed bid in the Itoen Ladies tournament last week, a bogey-free six-under 65 that put her alongside 
Yuna Nishimura and Ayaka Furue on top of the Daio Paper Elleair Ladies Open in Ehime Prefecture Thursday. It 
was just the first round of the 72-hole, Y100 million championship, the penultimate leg of the pandemic-hit LPGA of 
Japan Tour season, but the way the 19-year-old Player of the Year and money race frontrunner tamed the backside 
of par-71 Elleair Golf Club Matsuyama with four straight birdies to launch her title drive, there could be more of the 
same to expect from the NEC Karuizawa and Nitori Ladies champion in the next three days.
 She did slow down after that birdie-splurge from No. 10, setting for eight pars before hitting another on No.
 4 then closing out with her sixth birdie on the par-5 ninth for a 33-32 on a course which hosted last year's Japan 
Women's Amateur Open where Saso wound up tied for 26th. "But it was summer last year and the appearance (of 
the course) has changed.
 There are ups and downs and I had to be careful of the OB (out-of-bounds) since the fairways are narrow," said 
Saso, who finished runner-up to Korean Shin Jie in Toto Classic two weeks ago after missing the cut in the 
Mitsubishi Electric the previous week that ended a remarkable run of nine consecutive cuts made. Her scorching 
start likewise came a day after she and the other leading JLPGA campaigners clinched berths in the LPGA Tour's 
final major, the US Women's Open, slated December 10-13 at the Champions Golf Club in Houston, Texas.
 Player of the Year rival Sakura Koiwai failed to match Saso's hot start and settled for a 70, but Nishimura, the other 
player in one of the marquee flights, held her ground and matched the ICTSI-backed ace's scorching start with her 
own version of a 31-34, also highlighted by four straight birdies, but from No. 1.
 A flight behind was Furue, who was brimming with confidence following a playoff victory in Itoen Ladies as she 
outshot defending champion Hinako Shibuno and Momoko Osato to force a three-way tie, her unblemished 32-33 
card likewise hinting at the coming of an explosive weekend for the surging 20-year-old Hyogo native who also won 

Page 2 of 2
Fired-up Saso rebounds with solid 65, ties for lead
the Desant Tokai Classic title last Sept. The troika stood three shots clear of 2018 champion Minami Katsu, Lee Bo-
Mee, Anna Kono, Lee Min-Young, Erika Kikuchi, Ji Hee Lee, two-leg winner Shin Jie and Shibuno, who flubbed a 
couple of birdie chances but finished with a bogey-free pair of 34s.
 Though she failed to measure up with Saso's stirring start, Koiwai eagled the par-5 11th but struggled with her iron 
game and putting the rest of the way, finishing with two birdies against three birdies to drop to joint 17th with five 
players, including Na-Ri Lee, sharing 11th place with 69s. The other fancied bets also groped for form tackling the 
6545-yard layout's narrow, sloping fairways with Ai Suzuki ending up with a 71 for joint 22nd with Earth 
Mondahmin Cup winner Ayaka Watanabe.
Load-Date: November 19, 2020
End of Document
Page 1 of 2
LatinVFR Releases Fort Lauderdale-Hollywood International Airport for Prepar3D V4
LatinVFR Releases Fort Lauderdale-Hollywood International Airport for 
Prepar3D V4
Transportation Monitor Worldwide
March 6, 2020 Friday
Copyright 2020 Global Data Point. Provided by Syndigate Media Inc. All Rights Reserved
Length: 271 words
Body
Developer LatinVFR has released Fort Lauderdale for Prepar3D v4. The airport in Florida is 26-miles north of Miami 
and serves a range of international and domestic carriers. Some carriers include JetBlue, Southwest Airlines and 
Spirit Airlines.
As we confirmed last week, LatinVFR has worked with FSSI to bring sloped runways with AI traffic support for 
runway 28L/10R. As per other LatinVFR airports, the scenery features all scenery buildings with native PBR 
materials, highly detailed texture work throughout, SODE controlled lighting and jetways and more.
Furthermore, the airport features Fort Lauderdale city buildings with over 30 square miles of photo scenery 
coverage. A scenery configuration tool is also included to support people with a range of machine power
LatinVFR Fort Lauderdale for p3dv4 features:
KFLL airport all buildings objects and ground polygons made from native PBR materials.
Runway 28L/10R sloped with AI traffic support (thanks to FSSI)
Airport and immediate surroundings, detailed.
Surroundings, Fort Lauderdale city buildings with over 30 square miles of photo scenery coverage
SODE animated PBR jetways for the best jetway animation possible.
SODE controlled lighting, automatically illuminating when low visibility and rain conditions.
SODE controlled rain effects, enabling wet PBR surfaces whenever rain is present.

Page 2 of 2
LatinVFR Releases Fort Lauderdale-Hollywood International Airport for Prepar3D V4
Custom animated airport vehicles.
Special slippery condition for runways/taxiways that would affect braking action whenever it is raining.
Static aircraft, customized vehicle animations, animated elevators.
Scenery configurator for selecting and unselecting features. 2020 Global Data Point.
Load-Date: March 6, 2020
End of Document
Page 1 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the 
Brideshead generation is best known for his newspaper cartoons, but his 
beat extended far beyond Fleet Street. DJ Taylor celebrates one of the great 
English comic artists of the 20th century
The Guardian - Final Edition
October 11, 2008 Saturday
Copyright 2008 Guardian Newspapers Limited All Rights Reserved
Section: GUARDIAN REVIEW PAGES; Pg. 16
Length: 2095 words
Byline: DJ Taylor
Body
Osbert Lancaster died in July 1986, a week short of
his 78th birthday. Hearing news of his death, the novelist
Anthony Powell sat down to compose one of those sober estimates of a lately departed friend that abound in his 
diaries. Lancaster, Powell decided, "had so formalised his appearance, public +Ai indeed private +Ai manner of 
speech,
that it is difficult to know what lay beneath the stylised fa1/3ssade". Always a realist, even in an obituary notice, he
wondered whether "Perhaps there was not a great deal more than what was revealed." Powell offered further 
remarks on the subject+Aos "strong feelings about the arts and architecture", and evidence of good "if not 
impeccable"
taste, before rather wintrily diagnosing "some lack of inner life, everything important seeming on the surface".
Looking at the photographs included in Cartoons and Coronets (Frances Lincoln ), a selection of Lancaster's work 
by James Knox, pub- lished in conjunction with the Wallace Collection+Aos centenary exhibition, I see instantly 
what Powell meant about stylisation. The most revealing portrait (revealing, that is, in what it doesn't
reveal) comes from the mid-1950s. Lancaster, then in his 40s, hair slicked back above a bristling cavalryman's

Page 2 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
moustache, is wearing a check suit of immaculate cut; a white handkerchief burgeons from the breast pocket. His
hat dangles from thumb and forefinger: the hand itself rests on a walking stick. Dandyish, inscrutable, face slightly 
at
an angle, he also looks unexpectedly tough: the kind of fi gure whose natural milieu may well be a Mayfair drawing
room, a gallery opening or a first night, but who is still determined to stop at absolutely nothing.
In Lancaster's defence, stylisation was endemic to the kind of world in which he operated. The son of a well-to-do 
City man who died in the first world war, educated at Charter-
house and Lincoln College, Oxford, he was a cadet member of the group of high-achieving writers and artists
(and, it should be said, low-achieving non-writers and non-artists) whom critics have tended to classify under
the group heading of the "Brideshead generation". His second volume of autobiography, With an Eye to the Future 
(1967) is full of fascinated glances at the London party world of the early 30s, including a set-piece description
of Augustus John being borne away, dead drunk, from Unity Mitford's coming-out ball by a couple of footmen. John 
Betjeman, Evelyn Waugh and Cyril Connolly were lifelong
friends, whose foibles occasionally re-emerged to animate Lancaster's easel. In 1950, hearing that Waugh had 
proposed to Connolly that they should spend Holy Week in Rome,
Lancaster sent Powell a "rough sketch for a gigantic mural to be placed in the coffee-room at Whites by public 
subscription". The drawing, which shows a monk-like penitent abasing himself at the feet of Pope Pius XII, as 
Waugh
gravely officiates and cherubs dance overhead, is titled Connolly at Canossa. Lancaster's early interest in drawing
had been encouraged by a sympathetic art master, "Purple" Johnson. After Oxford and a spell at the Slade, newly
married to his fi rst wife Karen, he set himself up as an artistic freelance, designing book jackets, advertisements
and magazine covers +Ai these included Graham Greene+Aos short-lived Night and Day +Ai and contributing to 
the Ar-
chitectural Review, where Betjeman worked as sub-editor. Progress at Pelvis Bay (1936), deadpanned in the style 
of
a municipal guide book, was the first of several spoofs aimed at exposing the philistinism of mid-century architec-
tural id1/3(copyright)es fixes. The Betjeman connection paid further dividends when, after helping his friend with a 
series of articles for the Daily Express, he was encouraged by the features editor, John Rayner, to produce a 
column-width
"pocket cartoon", a commonplace in French newspapers but not yet exported to England. The cartoons, many of 
them featuring Lancaster+Aos great comic creation, Maudie, Countess of Littlehampton, caught on and continued 
on a daily basis for nearly 40 years. Lancaster's Express cartoons were
his public face , but it would be a mistake to mark him down as simply an exceptionally talented comic 
draughtsman. As Knox shows in his introduction, his professional beat extended far beyond Fleet Street. A war time 
posting
Page 3 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
to Greece, where he served as press attach1/3(copyright) to the British embassy and GHQ in Athens, produced the 
illustrated
travelogue Classical Landscape with Figures (1947). A friendship with the artist John Piper drew him towards
costume and set design for theatre and ballet. All this makes Lancaster's precise relation to English culture of
the immediate postwar period difficult to pin down. The liking for "smartness" and the high life was always
balanced by older bohemian interests, the fl ights of theatrical fancy brought down to earth by newspaper routine. 
These are Thackerayan shadings, perhaps, emphasised by the Charterhouse connection and Lancaster's fondness
for another Old Carthusian cartoonist, Thackeray's contemporary John Leech. At the heart of his work, though, lies 
an ability to transcend the limitations of
the things +Ai in this case the thousands of Express cartoons +Ai for which he was best known. Studying the black-
and-
white drawings that illustrate Classical Landscape with Figures, for instance, one expects to see projections of
the stylised and predominantly upper-class fi gures that populated the newspaper cartoons. The results +Ai a
Greek news vendor at his crowded kiosk, an Arcadian shepherd in a lambskin coat, toughs dancing in a Piraean
brothel +Ai are both wonderfully vivid and sui generis.
One of the fascinations of the early part of Cartoons and Coronets is the chance to explore some of Lancaster's infl 
uences. An ink sketch of a Greek village shows traces of Edward Lear's near-eastern landscapes. There are odd 
hints of 30s contemporaries such as Edward Burra and Paul Nash
(both of whom Lancaster admired), the occasional generalised nod to inter war surrealism. A mural executed for the 
Blandford Forum Crown Hotel's assembly room (1935), showing
Napoleon and his military advisers surveying the English Channel, is almost Dal1/3ffesque. Squat and gigantic, 
altogether dominating the picture's foreground, the tower from which the party (all in garishly cockaded hats) looks 
out resembles the basket of a hot-air balloon: there is a feeling that the conferring generals might be lofted
into the air at any moment. A curious prancing fi gure, with weirdly elongated legs, strays ominously into the
picture+Aos eastern quadrant. Elsewhere, a self-portrait from 1947 showing the dressing-gowned artist at work in 
his
study is not in the least like an Aubrey Beardsley while using Beardsley's technique of suggesting vast acreages of
space and surface with the minimum of linear effort.
Perhaps this is another way of saying that what really distinguishes Lancaster's work +Ai one comparison that 
suggests itself is with Ronald Searle +Ai is the originality of his line. The colour sketches of sailors' costumes for the 
ballet Pineapple Poll, adapted from WS Gilbert's "Bab Ballads" and staged at Sadler+Aos Wells in 1951, have 
exactly this kind of spatial awareness. The design for a pair of trousers, for example, picked out in parallel red lines, 
produces a kind of horseshoe effect. Most striking of all, though, is a group of four colour illustrations, each an 
ironical salute to the achievements of a particular Lancaster friend, commissioned by the Strand magazine in 1947. 
In the first, "Mr John Betjeman, awaiting
inspiration and the 4.47 from Didcot", Betjeman looks practically vampiric: sallow, unshaven, hugely accentuated
Page 4 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
black eyebrows like a pair of caterpillars, shoes like glistening torpedoes, grimly exhaling a whiff of sinister white 
breath. The second, "Freya Stark explaining to a relatively unsophisticated audience the genius of Mr Norman
Hartnell+Au (Hartnell was then at the height of his success as a couturier), is a study in contrasting facial expres-
sions. The "relatively unsophisticated audience" is a congregation of Bedouin tribesmen. Stark, who sits in their
midst, carmine-fingered, with her legs drawn up beneath her, is demurely confidential; the gesticulating listeners
are agog. Again, the folds and contours of their costumes are merely suggested, huge expanses of white given 
shape
and depth by the faintest of traceries. To the right, a sleeping camel still manages to look faintly sardonic.
Then comes "Benjamin Britten", done in profi le against a background of staves, with the superimposed outline of a 
piano on which the composer plays. "Mr John Piper enjoys his usual ill luck with the weather", in which the artist 
attempts to paint en plein air in the middle of a cloudburst, is perhaps the most extraordinary of all. Piper +Ai 
angular, white-haired, with impossibly sloping shoulders +Ai is lost in ascetic self-absorption. The background 
looks
like a surrealist lunar shore, where it wouldn+Aot be wonderful to find a grandfather clock marching among
the waves. Everything is arranged at a slant, the rain sweeping in like tracer fire to follow the angle to which 
Piper+Aos head is inclined and the position of the
knee drawn up to support his sketching pad.
In his obituary sketch, Powell notes that "many of Osbert+Aos jokes were first-rate, altogether original . . ." If
nothing else, Cartoons and Coronets is a testimony to his sense of humour. In the section called "Jeux and 
Christmas
Cards+Au, Knox reproduces a colour sketch titled +AuAfter Breakfast at Kelmscott", inspired by a visit Lancaster
and Betjeman ha d paid to William Morris's house in Oxfordshire and the discovery of an earth closet with three
wooden seats. Here Morris and Dante Gabriel Rossetti, trousers around their ankles, sit fl anking Janey Morris, who 
is daintily sewing stitches into an embroidery tambour. But a joke, in Lancaster's work, is never simply a joke:
there is nearly always some deeper satiric impulse boiling away beneath it, above all an awareness of the social 
and
historical contexts in which some of the best jokes get made. The Littlehampton Bequest , an elaborate spoof 
exhibition staged at the National Portrait Gallery
under Roy Strong+Aos direction in 1973, is a series of artistic parodies, in which the history of the Littlehampton 
family and its ramifi cations are encapsulated by paintings in the style of well-known artists of the day.
Thus Lancaster has Zoff any taking off "Joseph Grumble Esq", the father- in-law of the third earl, an East India
nabob pictured glaring from his gout stool against a background of minarets; and Marcellus Laroon depicting "Va-
nessa, Countess of Littlehampton and her daughters", the caption helpfully explaining that "the wife of the first
earl was heiress to half the plantations of the West Indies. She is portrayed with her two daughters and her page
Page 5 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
Hasdrubal, who in her widowhood was 'always about her person'." Hasdrubal, seen simpering over the coffee pot, 
is
clearly the father of the second daughter. The fi nal portrait, "Basil Cantilever Esq and Lady Patricia Cantilever", 
daughter and son-in-law of the present
earl, mimics early Hockney. Significantly, Basil is an MP-cum-property developer, busy despoiling City churches
to put up office blocks.
Lancaster was knighted in 1975 +Ai the photograph taken outside Buckingham Palace makes him seem the dernier 
cri in Old Bufferdom +Ai then, in 1978, his career was in effect ended by the fi rst in a series of strokes. He endured 
a miserable eight- year decline, nobly attended by his sec-
ond wife, Anne. Powell, visiting them in their Chelsea fl at in 1982 ("Osbert in poor shape"), noted her eagerness
to take him to his next appointment: "She insisted on driving me to the Travellers, no doubt just to get half an
hour out of the house, which must be claustrophobic to a degree." It would be overstating the case to say that Lan-
caster+Aos work is forgotten. On the other hand, the forms in which he achieved his fame +Ai daily cartoons, set 
designs +Ai
have a built-in obsolescence, while the sheer scope of his work tends to frustrate an attempt to view his 
achievements as a whole. Between them, however, the centenary exhibition and Knox+Aos book-length celebration 
contain enough evidence to establish him as one of the great English comic artists of the 20th century.
Cartoons and Coronets: The Genius of Osbert
Lancaster is at the Wallace Collection, London W1
(020 7563 9500), until January 11 2009.
To order the book for 3/4£14 with free UK p&p go to
guardian.co.uk/bookshop or call 0870 836 0875.
Load-Date: October 11, 2008
End of Document
Page 1 of 3
The AI Studio Ghibli trend is an insult to art and artists
The AI Studio Ghibli trend is an insult to art and artists
Asia News Network
01.04.2025 09:54 GMT
Copyright 2025 Asia News Network All Rights Reserved
Length: 1064 words
Byline: Reporting by:Dawn
Body
                      ISLAMABAD(Dawn/ANN)- An artist spends years perfecting their skills. Hours spent drawing, 
scrapping and redrawing to bring to life a vision that goes on to inspire millions. Studio Ghibli's co-founder Hayao 
Miyazaki is one such artist.
Miyazaki's films have not only received many awards but his retinue of works including Spirited Away, Kiki's 
Delivery Service, Howl's Moving Castle and so on have instilled the power of imagination and dreams in countless 
children and adults. Artistic inspiration can be a powerful thing, Miyazaki's art inspired the creation of Pakistan's first 
hand-drawn animated film, The Glassworker. With their own unique spin, a love letter to the aesthetic, The 
Glassworker took Usman Riaz and his team a decade to make.
In recent years however, artificial intelligence (AI) with its image generative tool has posed a threat to art and 
artists. AI learns from millions of images across the internet and memorises text associated with those images. In a 
process known as "diffusion", AI starts by breaking images into pixels that do not represent any specific thing and 
then inverts the process so the model can revert to the original image. Artificial intelligence does not take into 
account copyright and hence artistic styles are used without permission.
With image generative tools such as Midjourney, DALL-E and even a feature on Canva made widely available to 
anyone with an internet connection and monthly subscription, users can write a prompt and generate an image in a 
certain artist's style, without, of course, asking or crediting said artist. The most recent victims of this are the artists 
at Studio Ghibli.

Page 2 of 3
The AI Studio Ghibli trend is an insult to art and artists
OpenAI announced the launch of its "most advanced image generator" which has been built into GPT-4o and has 
been made available to users for free. This has enabled a worrying trend where users are converting their 
photographs into 'Studio Ghibli style art'. AI's rendering of Studio Ghibli is nothing more than sanitised, soulless and 
generic, a typical cutesy image devoid of any character, effort or passion.
Studio Ghibli's art is more than just cute characters, it is grotesque and sometimes even harrowing, it is layers of 
hard work, passion and unwavering dedication to create unique characters that tell meaningful stories.
From Grave of the Fireflies which shows a war torn Japan and two siblings desperate to survive on their own to 
themes of greed and identity as Chihiro navigates the world of spirits trying to save her parents (who were 
transformed into pigs) from being eaten in Spirited Away, all of Studio Ghibli's work means something. Even light-
hearted Ghibli features such as Kiki's Delivery Service focus on themes of self acceptance.
Every frame of a 2D animated film is painstakingly drawn by hand. The beautiful watercolour-esque nature scenes 
from Ghibli's films, the varied emotions on faces of characters, the tireless research that goes into making every 
fantastical aspect a little more believable; this is what makes the films timeless.
Criticising the AI Studio Ghibli trend, Riaz wrote in a post on X, "In an age of AI-generated everything, "The 
Glassworker" was drawn by hand. No shortcuts. No algorithms. Just work, talent and perseverance [...] AI is the 
future -but it's a tool not the artist."
Some might call AI a terrific mimic but that's all that it is. As exposed by this trend, the generated images lack depth 
and feeling. Perhaps the most egregious thing to come out of this trend is the politicisation of Ghibili's art. Political 
ideologies, thoughts and even extremist narratives are being portrayed in this aesthetic.
Users have used AI to recreate scenes of the destruction of the Babri Masjid, a Mughal-era mosque in India's 
Ayodhya. Using an art style synonymous with innocence to glorify the demolition of a mosque is beyond repugnant. 
Not to mention that Miyazaki has taken a strong stance against oppression and fascism in the past.
The White House used the trend in a post on X to depict an arrest and deportation of an immigrant by the US 
Immigration and Customs Enforcement (ICE). This comes after ICE has been deporting and arresting even those 
who hold a green card and revoking the legal status of thousands of immigrants. To use an artistic style, even if its 
watered down by AI to make light of suffering or depict Trump's hardline policies is abhorrent.
It is worth noting that in 2003, Hayao Miyazaki boycotted the Oscars ceremony as he opposed the US war in Iraq.
"The reason I wasn't here for the Academy Award was because I didn't want to visit a country that was bombing 
Iraq," he had told The Los Angeles Times of his decision.
PPP Chairman Bilawal Bhutto-Zardari also jumped onto this trend, changing his profile picture and generating 
photographs of his late mother and former prime minister Benazir Bhutto.
A countertrend has also sprung on X, with artists showcasing their work inspired by Studio Ghibli films, condemning 
the theft of art while simultaneously encouraging people to pick up a pencil and learn to draw themselves instead of 
relying on what has been termed as 'AI slop'. Artists have showcased their work with captions such as "Art I made 
from Studio Ghibli in my style without needing AI." Others have spoken about the time and dedication it has taken 
to perfect their craft.
With the popularity of the AI slop Ghibli trend on the internet, an old documentary has resurfaced in which Miyazaki 
expresses his strong dislike for AI 'art'. In the documentary the filmmaker is shown a zombie, with developers 
saying that AI can allow more grotesque movements. The artist's response was, "Whoever creates this stuff has no 
idea what pain is whatsoever. I am utterly disgusted... I strongly feel that this is an insult to life itself."
Imagine spending hours, days, months and years to find your artistic expression, and then suddenly a single 
prompt, that intellectual property and hard work is stolen, attached to narratives that you may or may not agree with, 
no consent and definitely no credit; this is what AI "art" means to many artists and why so many speak against it.
Page 3 of 3
The AI Studio Ghibli trend is an insult to art and artists
Appreciating art is a beautiful thing if done in a healthy manner by supporting artists or spending time trying to hone 
skills taking talented professionals as inspiration. Taking shortcuts, depriving artists from jobs and credit by using AI 
only serves to disrespect the medium.
Load-Date: April 7, 2025
End of Document
=======
>>>>>>> c98f417 (update data file):extract_text.txt

 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
User Name: =  
Date and Time: = 2025-04-09 
Job Number: = 249956184 
 
Documents (143) 
Client/Matter: -None- 
Search Terms: Ai Slop 
Search Type: NaturalAnd 
Content Type Narrowed by 
news Quellensprache: English  
 
1. Google has found a new role for the man who broke Google Search 
 
2. Vote Yes On Locking Artist's Voices In Contractual Seashells Like The Little Mermaid 
 
3. I'm running out of ways to explain how bad this is 
 
4. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
5. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
6. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
7. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
8. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
9. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
10. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
11. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 

 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
12. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
13. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
14. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
15. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
16. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
17. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
18. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
19. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
20. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
21. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
22. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
23. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
24. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
25. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
26. Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam 
 
27. Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and 
Video Generation Superstudio Integrates State-of-the-Art Image and Video Models and 
Tools into a Creator-Friendly Interface. Kaiber Also Announces Fund... 
 
28. A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the 
Assets 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
29. Fans Can't Believe Broadcast Decision for College Football Game on Saturday 
 
30. AI aggrandizes misinformation on the internet, so see the peacock chicks! 
 
31. Marques Brownlee says 'we failed on the price' with Panels 
 
32. I'm Running Out of Ways to Explain How Bad This Is 
 
33. Can Facebook win back Gen Z? 
 
34. Here's Why 'Human Authored' Will Become the 'Artisanally Crafted' Pitch of the AI Age 
 
35. Right-Wingers Heartbroken by Picture of Little Girl Who Doesn't Exist 
 
36. It's Time to Stop Taking Sam Altman at His Word 
 
37. Worlds apart 
 
38. Silicon Valley has a plan to save humanity: Just flip on the nuclear reactors 
 
39. McNeal review – Robert Downey Jr shines in muddled AI-themed play 
 
40. The AR and VR headsets you'll actually wear 
 
41. 'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI 
art 
 
42. Is anyone out there? 
 
43. BBC Radio 4 - 2:30 PM GMT 
 
44. BBC Radio 4 - 08:00 AM GMT 
 
45. BBC Radio 4 - 2:00 PM GMT 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
46. BBC Radio 4 - 2:55 PM GMT 
 
47. Pick of the day 
 
48. PICK OF THE DAY 
 
49. Radio choice 
 
50. The Trump Posts You Probably Aren't Seeing 
 
51. Following AI Cheating Controversy, Pokémon Announces Winners Of Card Contest 
 
52. Wednesday 25 September 
 
53. Meet the Editor Who Turned Himself Into an AI News Anchor 
 
54. 'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook 
 
55. 'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook 
 
56. 'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook 
 
57. BBC Radio 4 - 4:50 PM GMT 
 
58. Trump is drowning in the misinformation swamp he helped create 
 
59. BBC London News - 5:45 PM GMT 
 
60. What I Learned When My AI Kermit Slop Went Viral 
 
61. University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List 
 
62. PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST 
 
63. Honor recognizes unique contributions to the field, including Glaze and Nightshade 
tools 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
64. Facebook's AI-Generated Spam Problem Is Worse Than You Realize 
 
65. 2:00PM Water Cooler 9/4/2024 
 
66. It's not just you. More weird spam is popping up on Facebook 
 
67. Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more views 
 
68. National Novel Writing Month's AI-neutral stance criticized by bestselling authors 
 
69. 'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images 
frenzy 
 
70. Bigger picture of Trump's weird AI images obsession The Republican party and its 
presidential nominee now have a tool that allows them to visualise the hypothetical 
realities they are peddling to their supporters, writes Mike Bedigan 
 
71. Inside Trump's weird new obsession with AI-generated images 
 
72. ‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images 
frenzy 
 
73. Inside Trump's weird new obsession with AI-generated images 
 
74. The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs 
 
75. The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism 
 
76. How did Donald Trump end up posting Taylor Swift deepfakes? 
 
77. A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is 
‘flooded with garbage’ 
 
78. Donald Trump, AI Artist 
 
79. The MAGA Aesthetic Is AI Slop 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
80. Why the Popular Software Company Procreate Is Swearing Off Generative AI 
 
81. Ripple CTO highlights AI controversy over dangerous Mushroom identification book 
 
82. In a word: This week's column: 'the ick' or a 'boop'? 
 
83. Why Does AI Art Look Like That? 
 
84. Twitter page gains thousands of followers for making fun of Facebook posts 
 
85. Generative AI's Slop Era 
 
86. FTAV’s further reading 
 
87. FTAV’s further reading 
 
88. ‘Hold on to your seats’: how much will AI affect the art of film-making? 
 
89. AI 's Real Hallucination Problem 
 
90. No One Can Believe What Comes Up When You Google Beethoven: 'I'm So Done' 
 
91. We want YOUR gossip! 
 
92. We want YOUR gossip! 
 
93. We want YOUR gossip! 
 
94. We want YOUR gossip! 
 
95. We want YOUR gossip! 
 
96. We want YOUR gossip! 
 
97. We want YOUR gossip! 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
98. We want YOUR gossip! 
 
99. We want YOUR gossip! 
 
100. We want YOUR gossip! 
 
101. We want YOUR gossip! 
 
102. We want YOUR gossip! 
 
103. The New Term 'Slop' Joins 'Spam' in Our Vocabulary 
 
104. Spam evolves with AI: What is "Slop"? 
 
105. Dead tech blog now publishing using AI with old bylines 
 
106. TUAW makes a sad return as an AI-powered stolen content farm 
 
107. Google Searches Prefer AI Spam to Real Content 
 
108. Thousands of Raptive creators push to hold AI companies accountable 
 
109. Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog 
Posts 
 
110. Letter writer declares ' Durango Decline' citing online classes, branding and merch 
 
111. After spam, meet slop, poor quality content generated by AI 
 
112. Why Sheehy's 'I have scored, Eileen' helps RTÉ News 
 
113. How technology has changed our daily lives 
 
114. The rise and risk of AI-generated slop 
 
115. Comment: 'We deserve more than reheated housing ideas and AI slop' 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
 
116. Apple is finally letting you have it your way-kinda 
 
117. Apple Intelligence first reactions: from 'pure slop' to 'excellent work' 
 
118. The Artificial is Rarely Intelligent 
 
119. Why Facebook won’t be influential in the UK general election 
 
120. Links 5/29/2024 
 
121. Losing the library 
 
122. TechScape: The people charged with making sure AI doesn 
 
123. Spam, junk 
 
124. The people charged with making sure AI doesn’t destroy humanity have left the 
building 
 
125. Tech guru warns of 'zombie internet' flooded by AI bots that's making world 
'dumber' 
 
126. Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI 
 
127. Spam, junk …  slop? The latest wave of AI behind the ‘zombie internet’ 
 
128. Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, 
City take Premier League 
 
129. Google is bringing back classic search, with no AI – and I couldn't be happier about 
that 
 
130. Google is bringing back classic search, with no AI – and I couldn't be happier about 
that 
 
131. How to spot deepfake videos and photos 
 
 | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis
132. Don't be fooled by deepfake videos and photos this election cycle. Here's how to 
spot AI 
 
133. An AI-generated rat with a giant penis highlights a growing crisis of fake science 
that's plaguing the publishing business 
 
134. AI is now supercharging Google Assistant 
 
135. The Cult of AI 
 
136. Gamers Bash Xbox for Controversial Art Apparently Made by AI 
 
137. Links 11/30/2023 
 
138. Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons 
 
139. Secret Invasion Fails Because It Can't Pick a Genre 
 
140. Fired-up Saso rebounds with solid 65, ties for lead 
 
141. LatinVFR Releases Fort Lauderdale-Hollywood International Airport for Prepar3D V4 
 
142. Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead 
generation is best known for his newspaper cartoons, but his beat extended far beyond 
Fleet Street. DJ Taylor celebrates one of the great English comi... 
 
143. The AI Studio Ghibli trend is an insult to art and artists 
 
Page 1 of 2
Google has found a new role for the man who broke Google Search
Google has found a new role for the man who broke Google Search
BGR
October 17, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 608 words
Byline: Andy Meek
Body
Google has found a new job for Prabhakar Raghavan, the executive largely responsible for running Google Search 
into the ground over the last four years - a period that's seen Google's search engine increasingly prioritize AI slop, 
shove more ads than ever at users, give Forbes and Reddit links priority placement, and basically make it harder 
than it's ever been to find what you're actually looking for.
Raghavan - who, before he came to Google, oversaw search at Yahoo during its decline from 2005 through 2012 - 
will now be Google's chief technologist, working closely with CEO Sundar Pichai. "Prabhakar has decided it's time 
to make a big leap in his own career," Pichai wrote in a memo to Googlers. "After 12 years leading teams across 
Google, he'll return to his computer science roots and take on the role of Chief Technologist, Google. In this role, 
he'll partner closely with me and Google leads to provide technical direction and leadership and grow our culture of 
tech excellence."
Ok, whatever.
Looks like Google finally realized the fish rots from the head ... Search results have been decaying for a while, and 
now Prabhakar Raghavan is out. Let's hope for some much-needed 
improvement.#google #seo pic.twitter.com/qmO0kkV7hZ
- Scott Gabdullin (@ScottGabdullin) October 17, 2024
Google's head of search isn't just being replaced. He's being promoted. An effective remedy to Google's Search 
monopoly would terminate his employment and anyone else whose predatory conduct gave rise to Google's 
monopoly. https://t.co/O9kF3efQ3A
- Lee Hepner (@LeeHepner) October 17, 2024

Page 2 of 2
Google has found a new role for the man who broke Google Search
I'll admit it, I was over the moon about this news ... at first. And then I noticed who Google is replacing Raghavan 
with: Nick Fox, a Googler who, before his stint at the company, worked as a consultant at McKinsey - aka, one of 
the most loathsome corporations in the history of mankind. Meaning, another bean counter is in charge of the 
biggest search engine on the planet and will, in all likelihood, continue Raghavan's work of packing Google Search 
with ads, spam, SEO-optimized content, and AI that summarizes as much of all that as it can.
Meantime, giving you what you're looking for remains the last thing Google Search actually cares about.
I can't tell you how many times I have to shift over to an alternative search engine, like DuckDuckGo, to find 
something useful when I'm doing a search. Hell, the other day, I was trying to find a specific article I'd written in the 
past for a specific outlet, and even though I attached the outlet's name to my search query, Google's AI Overview 
still gave me what other outlets had written about the same thing (which matters, because some people are just 
going to stop there, with those AI Overviews that take over the top of the search results page).
Furthermore, few things signal the inexorable decline of Google Search as its desperate inclusion of crap like 
YouTube links and in-line YouTube videos,  as well as Reddit and Quora threads plus garbage from Forbes, all of 
which seem to take up prime spots for the majority of searches these days. Never mind that if users like me wanted 
a damn YouTube video, we would ... wait for it ... just go to YouTube. It's abundantly clear to people like me, whose 
livelihoods revolve around online publishing, that Raghavan's tenure as the head of Google Search represents one 
of the most remarkable leadership failures at any tech company in years. And we're all still paying for it.
Don't Miss: Maybe Google's new 'reasoning AI' can address the Hawk Tuah spam all over Google Maps
The post Google has found a new role for the man who broke Google Search appeared first on BGR.
Load-Date: October 17, 2024
End of Document
Page 1 of 3
Vote Yes On Locking Artist's Voices In Contractual Seashells Like The Little Mermaid
Vote Yes On Locking Artist's Voices In Contractual Seashells Like The Little 
Mermaid
Newstex Blogs 
Techdirt
October 17, 2024 Thursday 7:06 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 Techdirt 
Length: 1095 words
Byline: Mike Masnick
Body
October 17th, 2024 ( Techdirt  - Delivered by  Newstex )
We are living under a sea of AI-generated slop, where AI deepfakes and non-consensual intimate content abound. 
Congress, a self-interested creature, naturally wants to create protections for themselves, their favorite celebrities, 
and their wealthy donors against online impersonation. But until now, visions of so-called AI protections have been 
limited. From my lair, I've seen how Big Content might use congressional panic about AI abuse to make a many-
tentacled power grab. With the  NO FAKES and No AI FRAUD Acts, it's delicious to report that we have done 
exactly that.
Inspired by my seashell-prisons, in which I trap the sweet voices of mermaids looking to rise, these bills would let 
corporations and trade associations like mine control not only the tongues of young musicians, actors, or authors-
but their whole face and body. It has been incredibly lucrative for Big Content to monopolize other intellectual 
property rights, so that we could prevent  Prince from singing his pesky 'art' under his own name and block Taylor 
Swift from buying back her early recordings from powerful enemies. It is far past time that new and more invasive 
rights are created, ones that allow us to make AI-generated deepfakes of artists singing the songs that we like, 
dressing in the way we desire, promoting the causes we approve, and endorsing the presidential candidates that 
we want to endorse.
Since teenagers, abuse survivors, and artists started suffering from AI deepfakes, our leaps toward victory have 
been enlivened by the sirens we've convinced  to testify on behalf of concepts like consent, the struggle of artists 
for respect and dignity, and the importance of human art. They have unwittingly obscured our true aims with the 
beauty of their voices, and the results are glorious, netting legislation that would lure not only artists, but anyone at 
all, into crashing on the rocks.
If these bills pass, the vulnerable and desperate will also be lured into trading rights to their voices and faces for 
almost nothing-a month's rent or a week's groceries. A paid electricity bill. And for that we will amass vast libraries 
of captive voices and faces that we can license out to whomever will pay, to use as broadly and vaguely as we 

Page 2 of 3
Vote Yes On Locking Artist's Voices In Contractual Seashells Like The Little Mermaid
desire. AI-generated intimate content, political advertising, hate speech-sources of vast wealth currently being 
tapped by small-time influencers and foreign regimes. Many will pay richly to AI-generate another to deliver their 
message. This sea witch fully intends to insert herself in such a growing market.
And oh, the markets! The No AI FRAUD Act is particularly clever in its moves to kill alternative markets and 
competition for us, the biggest players in Content. With copious lawsuits, we will be able to smite any who dare 
attempt reenactments and parody, who depict a historical figure in a movie or sketch comedy, who make memes of 
a celebrity. After all, how dare they? Did they think the First Amendment was written for their drivel?
Even better, we will be able to sue social media platforms, too, for hosting such content. Although, social media 
companies have  historically made moves to aggressively filter or shut down content they could be sued over. 
Ultimately, they may proactively smite our competition on our behalf-becoming an even more honed instrument for 
our supremacy. Either way, we win.
Censorship, you say? Perhaps. But if most of the human faces that are displayed online are the ones we own or 
sell licenses to, the dollar signs would fill a sea. And, we would own the faces of each person not only during their 
life, but these laws would let us own them for 70 years after their deaths.
NO FAKES in its turn is an eloquent symphony of conformity. It allows us to claim that any video, photo, or 
recording we do not like is an AI deepfake and have it removed from the Internet forever. The bill offers no recourse 
to anyone we might-oopsie-censor with our richly programmed armies of bots and filters. There is no mechanism to 
put content back online or punish a big content company for lying about a takedown request-well, unless you want 
to face down our armies of lawyers in federal court, that is. This one is all about who has the most money and 
power, darlings.
With these bills, we will tighten our many-tentacled stranglehold over arts and culture, ensuring that only those we 
profit from succeed-and that these choice humans need act only minimally once we have secured their AI likeness. 
No more pesky frailties or artistic preferences to contend with. No more divas unless we deepfake them. This is why 
we must make our utmost effort to pass NO FAKES and No AI FRAUD- before creators and the public catch on and 
discover that these bills don't fight deepfakes, they solidify control of them amongst the most powerful players while 
obliterating consent.
We must act swiftly to purchase politicians and parade our most convincing messengers-the artists themselves-to 
demand Little Mermaid laws. These poor unfortunate souls are already falling into the grips of NDAs, brand 
protection agreements,  other assignable rights, noncompetes, existing IP law, and everything else our lawyers can 
brew up. We just need one final, strong brew to cement control, and then artists' ability to speak and appear publicly 
or online will be safe in our contractual seashells. There will be a new era of peace and harmony, as artists and 
creators won't be able to agitate and contribute to conflict as pesky 'activists'. They will be quiet and only sing when 
told to. And, our pretties will be able to sing their hearts out even if they become sick, ugly, impoverished, or die-
because we hold their AI replicas.
After all, a star need not be human to shine, and if the human artist cannot speak without our permission, no one 
will know the difference anyway!
Ursula the Sea Witch, best known for cutting one of the hottest ever sub-marine deals with Mermaid Ariel to trap her 
voice in a seashell along with other poor unfortunate souls, was recently promoted to the C-suite of the Under-The-
Sea Content Trade Association. There, her leadership focuses on expanding her pioneering work with Ariel, aiming 
to lock voices away without any true love's kiss to set them free by 2026-and for complete, non consensual-yet-
legal AI impersonation of all artists under contract by 2027. Ursula the Sea Witch is also the evil(er) alter-ego of  Lia 
Holland, Campaigns and Communications Director at digital rights organization Fight for the Future.
Link to the original story.
Page 3 of 3
Vote Yes On Locking Artist's Voices In Contractual Seashells Like The Little Mermaid
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: October 17, 2024
End of Document
Page 1 of 4
I'm running out of ways to explain how bad this is
I'm running out of ways to explain how bad this is
Newstex Blogs 
Alaska Dispatch
October 17, 2024 Thursday 9:35 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 Alaska Dispatch
Length: 1826 words
Body
October 17th, 2024 (Alaska Dispatch — Delivered by Newstex)
The truth is, it's getting harder to describe the extent to which a meaningful percentage of Americans have 
dissociated from reality. As Hurricane Milton churned across the Gulf of Mexico, I saw an onslaught of outright 
conspiracy theorizing and utter nonsense racking up millions of views across the internet. The posts would be 
laughable if they weren't taken by many people as gospel. Among them: Infowars' Alex Jones, who claimed that 
Hurricanes Milton and Helene were 'weather weapons' unleashed on the East Coast by the U.S. government, and 
'truth seeker' accounts on X that  posted photos of condensation trails in the sky to baselessly allege that the 
government was 'spraying Florida ahead of Hurricane Milton' in order to ensure maximum rainfall, 'just like they did 
over Asheville!'
As Milton made landfall, causing a series of tornados, a verified account on X reposted a TikTok video of a massive 
funnel cloud with the caption 'WHAT IS HAPPENING TO FLORIDA?!' The clip, which was eventually removed but 
had been viewed 662,000 times, turned out to be from a video of a CGI tornado that was originally published 
months ago. Scrolling through these platforms, watching them fill with  false information, harebrained  theories, and 
doctored images — all while panicked residents boarded up their houses,  struggled to evacuate, and prayed that 
their worldly possessions wouldn't be obliterated overnight — offered a portrait of American discourse almost too 
bleak to reckon with head-on.
Even in a decade marred by online grifters, shameless politicians, and an alternative right-wing-media complex 
pushing anti-science fringe theories, the events of the past few weeks stand out for their depravity and nihilism. As 
two catastrophic storms upended American cities, a patchwork network of influencers and fake news peddlers have 
done their best to sow distrust, stoke resentment, and interfere with relief efforts. But this is more than just a 
misinformation crisis. To watch as real information is overwhelmed by crank theories and public servants battle 
death threats is to confront two alarming facts: first, that a durable ecosystem exists to ensconce citizens in an 
alternate reality, and second, that the people consuming and amplifying those lies are not helpless dupes but willing 
participants.
Some of the lies and obfuscation are politically motivated, such as the claim that FEMA is offering only $750 in total 
to hurricane victims who have lost their home. (In reality, FEMA offers $750 as immediate 'Serious Needs 

Page 2 of 4
I'm running out of ways to explain how bad this is
Assistance' to help people get basic supplies such as food and water.)  Donald Trump,  J. D. Vance, and  Fox News 
have all repeated that lie. Trump also  posted (and later deleted) on Truth Social that FEMA money was given to 
undocumented migrants, which is untrue. Elon Musk, who owns X,  claimed — without evidence — that FEMA was 
'actively blocking shipments and seizing goods and services locally and locking them away to state they are their 
own. It's very real and scary how much they have taken control to stop people helping.' That post has been viewed 
more than 40 million times. Other influencers, such as the Trump sycophant Laura Loomer, have  urged their 
followers to disrupt the disaster agency's efforts to help hurricane victims. 'Do not comply with FEMA,' she posted 
on X. 'This is a matter of survival.'
The result of this fearmongering is what you might expect. Angry, embittered citizens have been harassing 
government officials in North Carolina, as well as FEMA employees. According to  an analysis by the Institute for 
Strategic Dialogue, an extremism-research group, 'Falsehoods around hurricane response have spawned credible 
threats and incitement to violence directed at the federal government,' including 'calls to send militias to face down 
FEMA.' The study also found that 30 percent of the X posts analyzed by ISD 'contained overt antisemitic hate, 
including abuse directed at public officials such as the Mayor of Asheville, North Carolina; the FEMA Director of 
Public Affairs; and the Secretary of the Department of Homeland Security.' The posts received a collective 17.1 
million views as of October 7.
Online, first responders are pleading with residents, asking for their help to combat the flood of lies and conspiracy 
theories. FEMA Administrator Deanne Criswell said that the volume of misinformation could hamper relief efforts. 'If 
it creates so much fear that my staff doesn't want to go out in the field, then we're not going to be in a position 
where we can help people,' she said in a news conference on Tuesday. In Pensacola, Florida, Assistant Fire Chief 
Bradley Boone  vented his frustrations on Facebook ahead of Milton's arrival: 'I'm trying to rescue my community,' 
he said in a livestream. 'I ain't got time. I ain't got time to chase down every Facebook rumor We've been through 
enough.'
It is difficult to capture the nihilism of the current moment. The pandemic saw Americans, distrustful of authority, 
trying to discredit effective vaccines, spreading conspiracy theories, and attacking public health officials. But what 
feels novel in the aftermath of this month's hurricanes is how the people doing the lying aren't even trying to hide 
the provenance of their bullshit. Similarly, those sharing the lies are happy to admit that they do not care whether 
what they're pushing is real or not. Such was the case when Republican politicians shared an AI-generated viral 
image of a little girl holding a puppy while supposedly fleeing Helene. Though the image was clearly fake and 
quickly debunked, some politicians remained defiant. 'Y'all, I don't know where this photo came from and honestly, 
it doesn't matter,' Amy Kremer, who represents Georgia on the Republican National Committee, wrote after sharing 
the fake image. 'I'm leaving it because it is emblematic of the trauma and pain people are living through right now.'
ADVERTISEMENT
Kremer wasn't alone. The journalist Parker Molloy compiled screenshots of people 'acknowledging that this image 
is AI but still insisting that it's real on some deeper level' — proof, Molloy noted, that we're 'living in the post-reality.' 
The technology writer Jason Koebler  argued that we've entered the '#8216;Fuck It' Era' of AI slop and political 
messaging, with AI-generated images being  used to convey whatever partisan message suits the moment, 
regardless of truth.
This has all been building for more than a decade. On 'The Colbert Report,' back in 2005, Stephen Colbert coined 
the word truthiness, which he  defined as 'the belief in what you feel to be true rather than what the facts will 
support.' This reality-fracturing is the result of an information ecosystem that is dominated by platforms that offer 
financial and attentional incentives to lie and enrage, and to turn every tragedy and large event into a  shameless 
content-creation  opportunity. This collides with a swath of people who would rather live in an alternate reality built 
on distrust and grievance than change their fundamental beliefs about the world. But the misinformation crisis is not 
always what we think it is.
Page 3 of 4
I'm running out of ways to explain how bad this is
So much of the conversation around misinformation suggests that its primary job is to persuade. But as Michael 
Caulfield, an information researcher at the University of Washington, has argued, 'The primary use of 
'misinformation' is not to change the beliefs of other people at all. Instead, the vast majority of misinformation is 
offered as a service for people to maintain their beliefs in face of overwhelming evidence to the contrary.' This 
distinction is important, in part because it assigns agency to those who consume and share obviously fake 
information. What is clear from comments such as Kremer's is that she is not a dupe; although she may come off as 
deeply incurious and shameless, she is publicly admitting to being an active participant in the far right's world-
building project, where feel is always greater than real.
What we're witnessing online during and in the aftermath of these hurricanes is a group of people desperate to 
protect the dark, fictitious world they've built. Rather than deal with the realities of a warming planet hurling once-in-
a-generation storms at them every few weeks, they'd rather malign and threaten meteorologists, who, in their 
minds, are 'nothing but a trained subversive liar programmed to spew stupid shit to support the global warming 
bullshit,' as one X user put it. It is a strategy designed to silence voices of reason, because those voices threaten to 
expose the cracks in their current worldview. But their efforts are doomed, futile. As one dispirited meteorologist 
 wrote on X this week, 'Murdering meteorologists won't stop hurricanes.' She followed with: 'I can't believe I just had 
to type that.'
What is clear is that a new framework is needed to describe this fracturing. Misinformation is too technical, too 
freighted, and, after almost a decade of Trump, too political. Nor does it explain what is really happening, which is 
nothing less than a cultural assault on any person or institution that operates in reality. If you are a weatherperson, 
you're a target. The same goes for journalists, election workers, scientists, doctors, and first responders. These jobs 
are different, but the thing they share is that they all must attend to and describe the world as it is. This makes them 
dangerous to people who cannot abide by the agonizing constraints of reality, as well as those who have financial 
and political interests in keeping up the charade.
In one sense, these attacks — and their increased desperation — make sense. The world feels dark; for many 
people, it's tempting to meet that with a retreat into the delusion that they've got everything figured out, that the 
powers that be have conspired against them directly. But in turning away, they exacerbate a crisis that has 
characterized the Trump era, one that will reverberate to Election Day and beyond. Americans are divided not just 
by political beliefs but by whether they believe in a shared reality — or desire one at all.
Charlie Warzel is a staff writer at The Atlantic and the author of its newsletter  Galaxy Brain, about technology, 
media, and big ideas. He is a co-author of  Out of Office: The Big Problem and Bigger Promise of Working From 
Home. Previously he was a writer at large for The New York Times' Opinion section and a senior writer at 
BuzzFeed News.
2024 The Atlantic Monthly Group. All Rights Reserved. Distributed by Tribune Content Agency, LLC.
The views expressed here are the writer's and are not necessarily endorsed by the Anchorage Daily News, which 
welcomes a broad range of viewpoints. To submit a piece for consideration, email commentary(at)adn.com. Send 
submissions shorter than 200 words to letters@adn.com or click here to submit via any web browser. Read our full 
guidelines for letters and commentaries  here.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
Page 4 of 4
I'm running out of ways to explain how bad this is
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: October 17, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 24, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 16, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 22, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 29, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 29, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 16, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 28, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 17, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 17, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 30, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 28, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 18, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 25, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 24, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 25, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 21, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 22, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 23, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 21, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 18, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 30, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 23, 2024
End of Document
Page 1 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
Students asked to analyse a 'photograph' they suspect is AI-generated in 
HSC exam
Crikey
October 16, 2024 Wednesday 11:11:20 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 565 words
Byline: Crikey
Body
ABSTRACT
'I'm actually so mad they expected us to analyse AI slop and treat it seriously.
FULL TEXT
 When 76,000 students in New South Wales opened the English papers as part of their final HSC examinations on 
Tuesday, there was one inclusion that drew bemusement and bewilderment from some in the cohort.  “Did anyone 
else notice the AI generated image for text 6?” asked one student in a video posted to TikTok later that afternoon.   
Some students who took the exam for both English Standard and English Advanced subjects believed that one of 
the texts included in both subjects’ papers was an image generated using AI.   
https://twitter.com/watermelonkenny/status/1846017078878416934  An image, which was labelled as “Photograph”, 
was a text that students were asked to compare to a passage of writing. It appears to depict a desk with a laptop, 
two phones, a cup of coffee, a bag and intertwined charging cords, all overlooking a stunning body of water on a 
sunny day.  While it’s not possible to be sure, the image includes signs that suggest that the image is not a normal 
photograph and may be artificially generated. Some of these include inconsistent scale between objects, conflicting 
shadows, mutated features like the laptop’s keyboard and the mug’s handle, and cords that go nowhere or into 
objects like the mug.  NSW’s HSC exam body, the NSW Education Standards Authority, did not respond to a 
request for comment on the record. But Crikey understands that the image was sourced from a Medium blog post 
entitled "The power of digital detox: Unlocking productivity through switching off” from user Florian Schroeder.  The 
blog post does not provide any information about the image, but many of the other posts from the same user also 
appear to use AI-generated images.  What’s more, it’s not clear that this “Florian Schroeder” even exists. His blog, 
which covers topics like AI, psychology, cryptocurrency, self-improvement and tips for how to treat insect bites with 
an onion, contains scant biographical details.   The blog links to a Twitter account with 24 followers, which lists him 
as the co-founder of the blog “AI Rockstars”.  His AI Rockstars bio — which calls him “Florian Schröder” — claims 
that he is an online marketer and links to a now-deleted LinkedIn. The same, filtered image of “Florian” is used 

Page 2 of 2
Students asked to analyse a 'photograph' they suspect is AI-generated in HSC exam
across all these profiles. It appears to be an edited image of a real German media and theatre personality Florian 
Schroeder, who is otherwise unrelated to this project.   Shroeder (the artist) did not respond to a request for 
comment. Nor did the other listed co-founder of AI Rockstars, Ralf Schukay, who appears to be a real person. 
Crikey understands that authors and artists whose work is included in HSC exam papers are only contacted by 
NESA after the exam. There is a carve-out under the Copyright Act that allows the use of texts without permission 
for inclusion in an examination.   As for whether students’ results will be influenced by whether they were able to 
identify that the “photograph” was likely an image generated by a person who might not exist? Crikey also 
understands that the only thing that is considered when marking a student is how the image was used as a 
stimulus.   Even still, some students did not appreciate its inclusion.   "I'm actually so mad they expected us to 
analyse AI slop and treat it seriously," one TikTok comment read.  
Load-Date: October 31, 2024
End of Document
Page 1 of 4
Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and Video Generation; 
Superstudio Integrates State-of-the-Art Image and Video Models ....
Kaiber Launches Superstudio, a New Creative AI Platform for Seamless 
Image and Video Generation; Superstudio Integrates State-of-the-Art Image 
and Video Models and Tools into a Creator-Friendly Interface. Kaiber Also 
Announces Funding Round Led by EQT Ventures with Crush Ventures 
Participating.
Business Wire
October 16, 2024 Wednesday 3:30 PM GMT
Copyright 2024 Business Wire, Inc.
Length: 1311 words
Dateline: SAN FRANCISCO 
Body
Kaiber, a creative technology company focused on human and AI collaboration, today announces the launch of 
Superstudio, an AI-native platform redefining how creatives interact with generative AI. In addition to this, the 
company is also pleased to announce that it has raised a funding round from EQT Ventures and Crush Ventures. 
Addressing the challenge of fragmented workflows, models, and tools, Superstudio provides a unified, intuitive 
interface where human imagination and machine intelligence collaborate seamlessly.
This press release features multimedia. View the full release here: 
https://www.businesswire.com/news/home/20241016279399/en/
Superstudio's canvas interface, featuring image and video models and outputs (Graphic: Business Wire)
Superstudio offers a highly curated selection of foundational models for image and video creation, including Luma 
Lab's Dream Machine, Black Forest Labs' Flux, and Kaiber's own image and video models. Its intuitive Canvas 
interface allows creators to easily combine their ideas with AI-generated content, sparking new creative 
possibilities. By integrating diverse tools and models into a single platform, Superstudio empowers artists and 
designers to push the boundaries of their craft while maintaining full control over their creative vision.
"Creatives are stuck in a loop of slow, ugly AI slop and disjointed workflows, paying 5-10 subscriptions to make one 
asset," said Victor Wang, CEO of Kaiber. "With Superstudio, we've created a home base for the new forms of 
creativity emerging as humans collaborate with machines. Our focus has always been putting human creativity first, 
and Superstudio empowers artists to seamlessly integrate AI into their process, amplifying their taste without 
sacrificing originality."
Superstudio evolved in real-time leading up to this launch through projects with renowned names such as Yaeji, 
Boiler Room, Praying, Jon Rafman, Grimes, Chief Keef, and Andrew Thomas Huang.

Page 2 of 4
Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and Video Generation; 
Superstudio Integrates State-of-the-Art Image and Video Models ....
"The emerging culture around AI is lacking an artist-driven vision. We know artists deserve better," said Kyt Janae, 
multidisciplinary artist and Head of Creative at Kaiber. "Automating and optimizing creativity is not the goal. As an 
artist, experimenting with and adopting new tools is a sacred act, not driven by the latest and greatest features, but 
by the pursuit of turning a vision into reality. Kaiber is pushing the landscape of creative AI forward with a product 
that supercharges the creative process. We've worked exclusively with visionaries who understand and want to 
build this new future with us. We're here to guide and create artist-driven culture."
REIMAGINING THE CREATIVE EXPERIENCE
In today's digital landscape, creatives often find themselves juggling multiple complex applications and 
subscriptions to produce a single asset. This "tool fatigue" hinders productivity and innovation. Superstudio 
addresses this by bringing the best foundational models into a singular platform, accelerating the creative process.
Its unique design sets it apart in the AI world, introducing a new level of modularity to AI-assisted creation. Users 
can generate images and videos concurrently, then seamlessly use these outputs as inputs in new Flows-allowing 
for infinite combinations and iterations all within the same interface.
Superstudio's design prioritizes ease of use. It employs simple language, drag-and-drop functionality, and sliders, 
making complex AI operations accessible to users of all skill levels. This approach demystifies AI terms and 
processes, lowering the barrier to entry for creatives.
The platform supports multiple infinite canvases for idea exploration and project organization, catering to both 
expansive brainstorming and structured workflows. At the heart of Superstudio's interface is Kiko, a brand character 
serving as the generate button - a fresh take on the often-used AI sparkle emoji - adding a playful personality to the 
user experience.
A PLAYGROUND OF INFINITE POSSIBILITIES
Superstudio transforms the creative process from ideation to final output. Users can begin with a simple concept 
and expand it into a rich multimedia project, blending images, videos, and audio elements.
Superstudio key features include:
• Canvas: An open, intuitive space for importing, generating, and refining ideas.
• Flows: Creative building blocks of AI tools with modular Elements like style transfers, face references, 
upscaling, and audio-reactivity.
• Collections: Organized asset groups that integrate directly with Flows.
EMPOWERING CREATORS ACROSS DISCIPLINES
Superstudio caters to a wide range of creative professionals, from animators to content creators and early-career or 
seasoned creative professionals. As AI technology evolves, so does Superstudio, continually expanding its 
capabilities to support diverse creative needs.
The platform enables:
• Efficient Prototyping: Rapid iteration of visual concepts and brand elements like logos, flyers, storyboards, 
and more.
• Dynamic Content Creation: Generation of compelling and cohesive visuals for various media platforms.
• Collaborative Innovation: A unified workspace for shared ideation and asset management.
AVAILABILITY AND PRICING
Page 3 of 4
Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and Video Generation; 
Superstudio Integrates State-of-the-Art Image and Video Models ....
Superstudio is available on desktop platforms. New users can access free trials with 100 credits, up to 2 Canvases, 
3 custom Flows, and up to 1 GB of storage. Paid subscriptions start at only $15 per month or $120 per year. For 
more information on pricing and credit packs, visit: kaiber.ai/pricing .
FUTURE FOR KAIBER
In 2024, Kaiber raised a round of funding from EQT Ventures and Crush Ventures. Kaiber is setting out on a 
focused journey to advance AI creativity. Through Superstudio and ongoing research at Kaiber Labs, the company 
aims to explore new possibilities in AI-powered artistry.
"We are incredibly proud to support Kaiber and the launch of Superstudio," said Ted Persson, Partner at EQT 
Ventures. "The team is redefining how AI technology can be used to ignite creativity. We have a strong conviction 
in the Kaiber team and can't wait to see all the amazing ways in which Superstudio will shape the future of 
generative AI."
ABOUT KAIBER
Kaiber is a next generation creative technology company focused on human and AI collaboration. We believe AI 
empowers artists to supercharge their ideas and creativity. Through Superstudio and Labs, we aim to bring new 
creative visions to the forefront, letting artists make anything they can imagine.
Above all, we make tools and craft experiences for people.
ABOUT KAIBER LABS
Kaiber Labs is where cutting-edge research and world-class craftsmanship meet culture. An in-house applied 
research and creative production team, Labs is dedicated to inventing and test-driving new technologies.
Labs generates novel media, explores emerging trends, and directly shapes the evolution of Superstudio, Kaiber's 
flagship creative AI product. The team also collaborates exclusively with leading artists and cultural behemoths to 
engineer experiences that bring harmony between human and AI creativity.
ABOUT EQT Ventures
EQT Ventures is an early stage lead investor built by founders and operators, offering the next generation of 
entrepreneurs a fast track to scale. The fund is based in Luxembourg and has investment advisors strategically 
located across Stockholm, Amsterdam, London, New York, Berlin, and Paris. Currently investing out of its third 
((EURO)1.1B) fund, the largest early-stage fund ever raised in Europe, EQT Ventures is one of the most active VC 
firms partnering with hundreds of ambitious founders and startups . Driven by a team of accomplished company 
builders and scalers, EQT Ventures is committed to providing the capital and hands-on support necessary for 
generation-defining founders and companies to transform their visions into global successes.
View source version on businesswire.com: https://www.businesswire.com/news/home/20241016279399/en/
CONTACT: Cultural Counsel
kaiberai@culturalcounsel.com
http://www.businesswire.com
Graphic
Page 4 of 4
Kaiber Launches Superstudio, a New Creative AI Platform for Seamless Image and Video Generation; 
Superstudio Integrates State-of-the-Art Image and Video Models ....
 
Superstudio's canvas interface, featuring image and video models and outputs (Graphic: Business Wire)
Load-Date: October 16, 2024
End of Document
Page 1 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and 
Sweating the Assets
Newstex Blogs 
James Governor's Monkchips
October 14, 2024 Monday 1:00 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 James Governor's Monkchips
Length: 5977 words
Body
October 14th, 2024 (James Governor's Monkchips — Delivered by Newstex)
In this RedMonk conversation, Dan Moore, principal product engineer at FusionAuth, join James Governor, 
principal analyst and co-founder of RedMonk, and Kate Holterhoff, senior analyst at RedMonk, to discuss the 
resurgence of newsletters as a tool for authentic expression and community engagement. They explore the 
importance of optimizing existing content, the power of voice, and best practices for creating effective newsletters. 
The discussion highlights the evolving landscape of digital communication and the role newsletters play in fostering 
relationships and sharing knowledge.
Links
Don't Let That Content Go To Waste
Twitter/X: @mooreds
LinkedIn: Dan Moore
https://www.podserve.fm/dashboard/episode_player_2/154755
https://www.youtube.com/embed/H9kSg3TQk4Y?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&
fs=1&hl=en-US&autohide=2&wmode=transparent
 Transcript
Kate Holterhoff
Hello and welcome to this RedMonk Conversation. My name is Kate Holterhoff, Senior Analyst at RedMonk and co 
-hosting with me today is James Governor, Principal Analyst and Co -Founder of RedMonk. And today we are 
joined by our esteemed return guest, Dan Moore, Principal Product Engineer at FusionAuth. Dan, I am so glad you 
were able to come back on the show.

Page 2 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
Dan Moore
Thanks for inviting me back.
Kate Holterhoff
so last time Dan recorded with James and I We did it in a video but this time we are pivoting to our audio only 
format, which is the MonkCast, of course, mainly to keep James from pointing out my bluish skin tone, which was a 
main topic of conversation last time.
James Governor
You're looking a little bit healthier today, I must say, you've got to little
Kate Holterhoff
A rosier glow.
James Governor
A bit of a healthier glow. I'm not so worried about that you're going to beYou're going be telling me that you've got 
consumption and you
Kate Holterhoff
Exactly. Tuberculosis. I'm hoping it was a camera setting issue rather than evidence of a vitamin D deficiency. But I 
am absolutely digressing here. So James, why don't you kick us off on part two of what is now our ongoing series, 
which I am provisionally entitling RedMonk Grills Dan Moore.
James Governor
RedMonk Grills Dan Moore.
Dan Moore
I'm here for that. I'm here for that.
James Governor
That definitely sounds very Midwest. So yes, I think that Dan has a lot of interesting reckons. Last time he was on 
the show, we were talking about Hacker News and the social currency of that platform.
One of the other, yeah, we think about the things that we can use as tools in our daily work, in communicating with 
technical audiences. Yeah, there's another one out there and that is the, you know, just the towering, towering, I 
don't know what it's towering, but it's big, the newsletter. Newsletters seem like they were going the way of the dodo 
a few years ago, like who wants a newsletter?
And then suddenly everyone wanted to have a newsletter. We're to have newsletters. And I think the key question, I 
can't believe that I couldn't think of a word to come after towering. But anyway, so the thing is, is that we spend a lot 
of time telling stories, sharing things that we've learned, trying to get people interested, helping their learning 
journeys, all things technology. so there are, and people have different modes of learning.
And it just so happens that obviously the newsletter is one of the mechanisms that people are learning things. also I 
think, you know, let's look, let's talk about, let's get real for a second. It's 2024. You know, we're doing all of this 
work. And I think we're all kind of asking ourselves, hang on a minute, we're doing the work, but how are we gonna 
make this pay? Because pretty clearly,
Page 3 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
We're all, you we need to sweat the assets. If we're creating stories, then we better make sure that we have them in 
the right platforms, that we are reaching multiple different audiences that have different ways of learning. We need 
to meet people where they are. So newsletters, Dan, what is so great about the towering news?
Dan Moore
Yeah, yeah. Towering edifice?
James Governor
no, that really sounds like something that's going to fall over.
Dan Moore
yeah. Hopefully not. Hopefully not. Yeah, I I think that
Newsletters are interesting because as you say, they are old technology, right? Like they have newsletters in the 
eighties, I believe, when email was first invented. But what it does that some other means of distribution don't do 
are it reaches people, it'll place a check all the time and it doesn't cost anything and it is in your control. And so.
You know, lot of the other options out there give you two out of those three. you know, blogs are in your control and 
they, do deliver content, but unless you use an RSS reader, which I think probably 0 .1 % of your listeners use an 
RSS reader. you're not going to have that chance to reach people where they are and platforms obviously are 
another option, right? Like your LinkedIn's, your Twitter slash X's, etcetera. And there you're definitely at the mercy 
of the algorithm and you don't have any control over that. You build up a hundred thousand followers on X and 
some Yahoo comes in and buys it. And then the value of those followers decreases according to, how that person 
or company tweaks the algorithm.
James Governor
So I didn't know that you were here to upset us today, Dan. I thought we were going to have a good time. Now 
you're telling me about X reminded me of Mr. ruin the network.
Dan Moore
sorry, sorry, sorry.
James Governor
Now I'm not in my happy place anymore. Let's get back to these. I was like, Twitter. I remember it so well. That 
lovely, lovely platform.
Dan Moore
Yeah. So I think that's that's the big win, right? People realizing that there's value. And I think the other thing about 
newsletters is they're super easy to subscribe to, which means they're super easy to unsubscribe from, which 
means there's not kind of like a barrier. so a lot of people, you basically, the content that you write, the content that 
you create can earn you subscribers in a way that's similar to the other options, but people are stickier, right? 
Because again, it arrives in your inbox and I don't know about you all, but I subscribe to a number of newsletters. 
Not very many of them I read all the time, but every time I get a newsletter, it rings a bell and you're building kind of 
a long -term relationship for lack of a better term when you build out a newsletter.
Kate Holterhoff
Yeah, Dan, I mean, it's clear to me that you've been thinking a lot about content delivery as it relates to community. 
And of course, our conversation about Hacker News reflected this. But I am super interested in a blog post that you 
authored recently entitled, Don't Let That Content Go to Waste, which really focuses it on the idea of how 
Page 4 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
newsletters can function and maybe how to optimize them for your audience. Can you outline your thesis in this 
post?
James Governor
You've to sweat the assets. That's the time of day.
Kate Holterhoff
that's not something that we do in the Midwest. We don't sweat things. I don't know. We don't sweat assets in Ohio.
James Governor
you work hard, you mind your own business, but you don't sweat the assets.
Kate Holterhoff
Not the Ohioans I'm familiar with, at least. But maybe in my adopted home of Atlanta, there might be a little bit more 
sweating.
Dan Moore
I think that the reason I wrote this blog post is because I am a member of a lot of different Slack communities or 
follow people on, again, on some of those platforms that I shall not mention. And I see some great, great content 
that comes out and great answers, great wisdom. then it just, and then it goes poof away. And even on some, I 
follow the IETF.
emailing lists around OAuth and things like that. I see some great content there, it especially in Slack, but even in 
those other places, it just gets lost. And so my point was by picking up and putting it onto a newsletter, you can, and 
maybe you do some editing, right? Like as most stuff that you, you write off in a Slack, it might not be as polished 
as you would normally put a newsletter, but you can basically take this,
wisdom exhaust, right? Like it's like kind of like data exhaust from the early 2000s, but you can like pick it up and 
put it together. And even if you don't think you have enough content for a newsletter, I think you do if you are active 
on those channels and by taking it from these walled gardens of the platforms or slacks or discords and putting it 
out on it in a newsletter, you do a couple of things. One is you just showcase your knowledge the same way a blog 
would.
You can deliver it to people. have a low effort way to connect with folks, right? If you ever run into somebody at 
conference or whatnot, instead of asking them to follow you on something, you can say, Hey, I have a newsletter 
about real estate in Atlanta, or I have a newsletter about, how developers, are the new Kingmakers or AI or 
whatever it is. And that's just a lower ask than some other things. And it will start to build up a.
longer term relationship with anybody that you're engaged with at low effort to you. So that's kind of the purpose of 
the blog post is people are creating all this beautiful content, and it's just trapped.
James Governor
Especially the stuff in Slack, Slack is like the dark web, Slack, we all put so much effort into communications with 
our colleagues, and or people in those networks, and then don't share it externally, Slack is sort of
Yeah, it's definitely the dark web of, I don't like the word content, but it is the dark web of content. and, know, it's, in 
fact, it's even worse than that. guess there are search engines for dark web now, but, but Slack is, just, yeah, like 
those conversations you have internally, don't become shared and don't become, you we talk about like one of the, 
the, if we think about what the certainly grew up in there, the blog near and so on.
Page 5 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
It was this idea that you could learn in public and learning in public is really powerful because that means that other 
people can learn the same things. think our use of Slack has meant that we're doing a little bit learning in semi -
private. And so yeah, it's interesting this idea that newsletters are an opportunity or a vector for taking some of that 
and sharing it more broadly and making it useful, sweating the asset.
Kate Holterhoff
I love how you frame it as like a power to the people move of like moving away from platforms that you don't control 
to one that you do. Because yeah, you're right. There is a sort of agnosticism with email. But I do want to push back 
on the idea that at a conference, if you're like, hey, subscribe to my newsletter, you know, this is an easier way of 
making sure that you keep up with folks. Because I have an anxiety of having too much in my inbox, like the zero 
inbox. I wouldn't say that I adhere to that.
But I will say that the onus of storage and organization is on me with a newsletter in ways that it isn't, or a listserv, 
anything that goes to my inbox, in ways that it isn't with a blog. Then I can kind of find it, and it's external. I actually 
have had the experience of unsubscribing from newsletters. And then actually with our, since James brought up our 
Slack channel, we actually created an RSS feed, which
translates a lot of newsletters that I found particularly anxiety inducing where they're coming out multiple times 
during a week. I unsubscribed from that and then added it to our RSS feed. That way I'm able to keep up in a way 
that I feel like I have a little bit more control. Do you encounter that at all? I feel like maybe it's a double -edged 
sword in terms of like, yes, you have the control, but there are people like me who are like, please don't clutter my 
inbox.
Dan Moore
Totally. Yeah, yeah, And that's a really good point. Like, that's not something I would do after I just shook 
somebody's hand, right? Like, hello, hey, I'm Dan, you know, please subscribe my newsletter, right? It's something 
if you realize that they are interested in the topic that you're that you're talking about and in depth and do feel like 
they want to have a longer term relationship with you or, just keep in touch, right? I will say most modern newsletter 
platforms, you get a blog for free as well. And so it can kind of be a twofer, right? You can say, hey,
check out my newsletter or my blog and it's here. And if you wanna get a via email, that's great. If you wanna get a 
via RSS, that's fine. If you wanna just bookmark it and check it periodically, that's fine too. So I think the value in the 
newsletter is they have that option. The other value is that, and I think this is the constraining factor on newsletters 
and it is constraining in fact, pretty much all content to use James's,
unpreferred term is that you have to earn that, right? And so you really have to deliver like good content wise words 
every time. And that force is almost an enforcement mechanism, right? And with newsletters, sometimes when you 
write on platforms or in blogs, like it's a little bit like shouting into the void. With newsletters, you actually get 
feedback. Like I have
friends and colleagues who've written newsletters and they see unsubscribes when they move to a certain place. 
And that is, I would not say an unsubscribe is unadulterated negative feedback. It actually could mean that your 
audience is shifting because you're shifting your viewpoint and you're shifting your topics. That's fine, but it is 
definitely a hundred percent feedback. And that's, it's way more visceral feedback than you're gonna get from a lot 
of other platforms or a lot of other options. Does it answer your question?
Kate Holterhoff
It does. It does. it's more, I think it's the personal preference thing that we're pointing at here. But yeah, I think that 
makes a lot of sense.Dan, in your post, you know, I'm going to read a little bit back to you because I have some 
questions. So you say, quote, 'don't rewrite the text. The whole point of this process is to leverage existing content 
you have created in a low effort, sustainable way.' End quote. So my question to you is, Dan, why are you so lazy?
Dan Moore
Page 6 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
I'm lazy because I'm busy. No, I think that in this particular context, it's really about repurposing existing content. I 
have met with plenty of people, talked to plenty of people who let the perfect be enemy of the good. And I think that 
it's way better to get started and get your thoughts out there out of Slack, out of Discord, out of that podcast and 
share them with the world than it is to have them be perfect. And then plus you get to be lazy. right?
Kate Holterhoff
Right. I'm on team lazy, especially when it comes to like not having to restate the same thing over and over again. I 
mean, that, think that goes with our philosophy here at RedMonk, which aligns with developers, you know, anytime 
you have to do something, more than two times, you might as well, find a way to automate it, correct? So Dan, 
you've just automated it. You've found a system, you've got a plan in place to make sure that you're not replicating 
labor that is already done, right? Totally.
So at RedMonk, we also have a newsletter. And I actually wrote the September introductory letter part, helped 
coordinate delivering it and making sure that the links looked right, all of that.
And we're sharing that amongst the analysts. James did the inaugural newsletter and set a very high bar. And it's 
something that we're excited about and we're enthusiastic. So we're all in. And so I am deeply interested in your 
perspective here, because I think we're still trying to feel it out a little bit. mean, we've had a version of a newsletter 
for a while. But this is one where we're actually trying to follow some best practices here and see what the 
community is looking for. Because I agree.
Newsletters are really having a moment. so Dan and I are both podcast buffs and on Hardfork, I know that there 
was one of our shared favorites. They actually spoke about moving away from Substack. And so I just know, I know 
there's a lot of internal conversations around the delivery methods.
And then there's also, you know, so there's the consumption side, there's a distribution side, but there's also, I think, 
it evidences that we're in the zeitgeist of newsletters. And I like this utopian idea again of the control method. You 
know, a lot of these social platforms are crashing and burning right now. And then there's also sort of it's up in the 
air about which one is going to dominate in our post Twitter era. So.
I guess maybe that explains it, but I think that there's maybe more to it. And the genre is just a little different. I think 
that there's some movement there, there's some playfulness, but there's a political angle as well.
Dan Moore
I think that the main reason why newsletters are having a moment is I mean, people are always looking for a place 
to have their thoughts heard, right? And it shifted from Usenet to blogs, to social media.
And then I think that, newsletters are coming back and it's like a pendulum swinging where you have less reach. 
Although I think tools like Substack and a lot of the other kind of copycats or other platforms offer some sharing, 
some discoverability. It's almost like a webring back in the blog days. But you're trading that off for more. I mean, I 
would almost say intimacy, right?
Like when you actually arrive, when someone trusts you enough to receive your emails, even if they don't read 
every single one, that is a real act of trust. And again, it's easy to subscribe and unsubscribe. So it's not like you're 
taking a job with them or anything like that, but it's definitely a higher level of relationship. And I think that that is 
very appealing to people. The other thing I would say is that the newsletters I've seen, you know, I'm, I'm a 
subscriber to the RedMonk newsletter.
I'm excited about it, but like, it's interesting to like the level of fidelity, right? Like sometimes you have newsletters, 
get some that are, especially if they're aimed at developers are very lo -fi, right? They're kind of white background. 
They might be a list of links with small amounts of commentary. And then you get the corporate ones, which are 
way more manicured that are almost like, I sometimes I get them, I get one from my college that almost feels like 
it's a little magazine, right? Like it's way overproduced.
Page 7 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
And I would say, if anyone's thinking about starting a newsletter is start with a lo-fi version. Well, first of all, think 
about your audience. If I was marketing to a bunch of, artists, think starting with a lo-fi one would be a horrible idea. 
If you're marketing to developers, think starting with a lo-fi one that's like content rich is probably a good idea. So I 
guess start with your audience. But the fact is that it's, even though email is a hard thing to design for, it's still kind 
of a rich medium and you can kind of play around on the spectrum. And that's totally ignoring the content, right? I'm 
just talking about like the form right now.
James Governor
Yeah. For me. I think there's something here, and this is interesting, because we have to work this out as a firm. 
The question is about voice. And obviously with podcast, it's an audio medium. as such, yes, of course, that's voice. 
But I think with newsletters, yeah, you do have an expectation. Or the ones that I find appealing is that they do have 
a voice. And for RedMonk, we made a decision that we would take turns to curate the thing. But that's also good, 
because RedMonk has always been, we've never felt as a firm that we wanted to have only one voice.
We've had an acknowledgement that as analysts, we always felt that actually it's the conversation that is more 
interesting. but yeah, voice and authenticity, I think, are one of the reasons why newsletters are having their sort of 
moment in the sun, alongside the other issues you said, the portability and so on. do think that that, we want to 
especially, you know, obviously, and I think Paul Kedrosky this week created a new  Four Ideas newsletter, which is 
basically AI generated, I'm sure that'll do well. And that, mean, that's a whole other voice. That's a sort of a framing 
and let the AI do the work. But I think certainly in an era of AI and, these, these chat interfaces and so on, I think 
that's an area where you, you do want to actually hear from people and
I've had this recent research that consumers don't want to buy things that are labeled AI. And I think a newsletter is 
one of the things that, we want it to be generated by a human and we want some of their foibles and ways of 
communicating. want, my colleague Rachel Stevens's, you know, humor or you want, know, Kelly Fitzpatrick, she 
brings just this authority that I guess she gained through academia.
that sort of the way she communicates and then know Kate I'll let Kate say what her voice is but yeah well grumpy 
Steve O 'Grady is one so we've all got you know mouthy monkchips is me so yeah what so Kate you're midwest in 
Atlanta voice.
Kate Holterhoff
yeah today at least for sure
James Governor
Yeah, I think that's for me anyway, why I like newsletters. I like them because I feel that there's someone's voice 
there. And that is something that I find appealing.
Kate Holterhoff
Yeah. And since we're looking for some strategies here, Dan, would you mind just giving us the rundown of what 
your best practices are for creating newsletters, especially as you outline them in the blog post?
Dan Moore
Sure. Sure. So I would say what I did want to call back a little bit to what James said about podcasts and the voice 
that comes from podcasting. I would say don't sleep on podcasts as a source of newsletter content.
because I've definitely taken a podcast that goes on YouTube and I transcribe it using one of the bajillion free tools 
out there. And then I will actually paste it into like a chat GPT and say, Hey, break this up into like sections for me, 
you know, topic areas. And then from there, I never use what the chat GPT actually does to turn that in newsletter. 
Because I think that is, what's that term AI slop. If you just take it directly, what it like summarize.
Page 8 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
but you can use it to find pointers into the podcast. And then you can use the actual text that the person said and 
edit it because we all put ums and blahs and likes into it, but don't sleep on podcasts or live streams as sources of 
content, which plays into your question, which is where do you get the content from? And it does depend on what 
kind of newsletter you're trying to build. If it's a link newsletter, then we have
spreadsheets and things like that to like just capture interesting links. I like to basically send an email to myself, but 
there are other ways to do this. Anytime I run across anything interesting or sometimes I'll use Hacker News as my 
link collection, right? If there's anything that I think is mildly interesting, then I post there. If you are really looking to 
pull things out of Slack, then I think that it's really important that
or LinkedIn or other platforms, I will drop everything into a Google Doc, you know, just once every month or so I'll 
go through and like target things and pull the content into a Google Doc. And then from there I do kind of further 
fashioning and try to bring posts together conceivably, because sometimes a post can be a hundred words or 
something like that. And you can expand it. You can
combine it with another post and then turn that into the newsletter content. and one of the things that I find 
interesting is this is actually something you could conceivably outsource. you talked about your voice, James. and I 
think that I actually have a client that I do this for because he's very busy, but he wants a newsletter, but he wants it 
in his voice and I can't write it in his voice. And so I'll take his stuff and I'll mildly edit it and turn that into a 
newsletter. but it's almost all his voice and it's his terms because he wrote it. I just expanded it, corrected it, things 
like that. I think that
James Governor
I don't know how I feel about that.
Dan Moore
But by leveraging what you're already doing, it's basically just kind of, I mean, it is just a point of leverage, right?
James Governor
We do that sometimes. What we'll do is when we're sometimes working on blog posts, I'll be talking about Kate, 
provide a little bit of context, and then it'll go into the first draft, and then she always cuts it out when she publishes. 
So that happens. So my voice, which sometimes tries to inveigle its way into Dr. Kate Holterhoff's excellent writing, 
that word gets excised.
Kate Holterhoff
James has a chip on his shoulder, if that's not abundantly clear. You know, James, that part of being a consultant is 
being able to say a small thing in a very long way. And sometimes it just doesn't translate to writing.
James Governor
You can edit out my thing about voice, because I fucking talked about voice for like 20 minutes and that was 
completely unnecessary. I needed to say was voice and all. Yeah, no, that's going to go now, isn't it? It's all going to 
go. Kate's going to be like, yeah, whatever. Yeah. but no.
Kate Holterhoff
Not a chance.
James Governor
you know, that is a, that is a, again, I think from a firm perspective, it's interesting because, you know, when we 
made that decision years ago that we weren't going to spend vast amounts of time back and forthing and rewriting 
Page 9 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
each other's work in order to have some sort of consistent voice of the company. And then over time, we just 
realized that just made no sense and that better to celebrate the voices
in the company. And that's why we very much have blogs. People choose what the name of their blog will be. We 
expect them. We encourage them to build and establish a research and authorial voice. me that was kind of what I 
saw with newsletters, like whether or not which one came first, the chicken or the egg or whatever it is, you know, 
the towering edifice pretty clearly.
that there are, you know, people used to have link roles, you know, like you go to the blog or, you know, and 
certainly link posts were very popular back in the day. And I do think some of the things that blogs, it does sort of 
feel like, look, it just turns out that email is, is, is a longer running protocol than RSS in terms of it's usage. And so I 
think some of, some of that writing for blogs, some of those dynamics, feel like newsletters have brought them back.
Dan Moore
Can I ask real quick about like the voices, like the, like the voices, the analyst thing. Cause I think that's really 
interesting. when you talk to talk about like DevRel, which is something that I used to do and I'm still kind of 
involved in you all. know we're very involved with DevRel community. feels like when someone's in DevRel, they 
are the external facing at least to developers like face of the company. And so you've constantly chosen to have 
each of your analysts be externally facing, right? Cause you could definitely have analysts that weren't externally 
facing or were only externally facing to like clients, right? But you've chosen to have all your analysts be public 
figures, I think probably makes it easier and harder to recruit analysts, right? Or easier and harder to like determine 
whether it's a, like it's the kind of company that people want to work with, right? Cause you're not working with 
RedMonk the way that you work with like a Gartner or a Forrester. Am I allowed to say those names on your 
podcast? Sorry.
James Governor
Quick, those out, Kate. Okay. Use that heavy, heavy pen. Get rid of it. we,
Dan Moore
You're working, you're working with a Kate, right? Or you're working with a James, right? Those are, and, and not 
that you won't sub for each other or things like that, but like, it really feels like it's much more of like a, personal 
working relationship. Do you find that that's a benefit or a cost or kind of like it cuts both ways?
James Governor
I think there's always sort of trade offs in any decision you make.
Dan Moore
That's a consultant's answer right there. Nice work.
James Governor
Yeah, was beautiful. 100 % right. So it served us pretty well. One of the questions is, and I think that some 
companies are like, wait, we don't want to externalize the voice because if we do, then everyone's going to come 
and like poach that person or whatever else. I mean, we've lost people over the years.
because it's the voice that attracts, right? But that said, look, they're always going to be positives and negatives. In 
terms of our working relationship with clients, we do feel that hearing those voices and that voice of the authorial 
voice and that the authority voice on a subject, we hope that that does help clients to understand
what are the subjects that we as analysts are best equipped to answer those questions? And sure, you can go to 
RedMonk and like, you look, as you just use the dread word consultant, I mean, I don't mind you mentioning my 
Page 10 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
competitors, but how dare you call me a consultant? Anyway, no, it's true. It's fair enough. So the thing there is, and 
you know, people have, you know, found a consulting syndrome. It's a derangement of some
Obviously, none of my clients are deranged, but if they were, they might be deranged in such a way that they would 
always want to talk to me or Steve. let's talk to the founder. You know, like we can talk to the founder. So let's talk 
to the founder. One of the things about those other voices is people really begin to wreck. wait, hang on. I don't 
want to talk to James and Steve. They don't know anything about that. Or I don't I don't want to talk to them, you 
know, on a subject in that way. So, yeah, I think that
It's definitely beneficial, especially for us because we tend to encourage people to be able to consult on and 
understand a range of topics. Like we're not going to be the absolute deepest. mean, if you want us to come and 
sort of analyze the absolute deepest level gorp about
two or three different say Kubernetes distributions, we're probably not the right people to do that. On the other 
hand, we will have spoke to a lot of folks that are using all of those distributions and have been able to, you know, 
have a reasoned view on what some of the strengths and weaknesses are. But I think where I was going that is just 
that we're about context. So, you know, we would expect people to, you know, we had a choice. Do we have an AI 
analyst and no one else talks about AI? That seemed like it was a really bad idea.
because AI is going to touch every area of the stack. Do we have specializations? 100%. But because we make 
people sort of bring context to bear, people then are attracted to that, the context and the way that's put together. 
And yeah, that's one of the reasons I think voice has significantly benefited RedMonk. And look, we've got a 
reputation for authenticity that nobody else in the industry has in the analyst business. I mean, we are seen as 
having a sort of For whatever reason, yeah, we all see it as authentic. I think, again, that's a function of voice.
Dan Moore
I wouldn't say it's for whatever reason. I say it's because you have been authentic. It's because, and frankly, I think 
to some extent because it's smaller and because you've elevated the voices and because it's hard for a company to 
be authentic. think it's really, really difficult for a company to be authentic. think it's really, it's easier for people to be 
authentic. Right. And so if you're a group of people that, you know, if I'm engaging with Kelly for my analysis, it's 
different than me engaging with company XYZ for my analysis. It's just a different feel. so I wouldn't say for 
whatever reason, James, I'd say you're authentic. mean, it's almost self-fulfilling. It's tautological, right? Like, I don't 
know how you can be authentic other than being authentic. I'm sure things you can point to, but it's really hard to, 
yeah. So this strayed a little bit far, from newsletters, but interesting.
Kate Holterhoff
So did you have any final questions for Dan, James?
James Governor
yeah. Well, yeah, what we didn't really talk about is that so Dan, like we didn't ask, how many newsletters do you 
subscribe to? And then what tools do you use? Like, historically, we all had RSS and, you know, we had our 
chosen, reader, and then
that, you know, big, big boo to Google, talking with readers. Google, they own social media in the RSS era and they 
blew that so comprehensively. It is so dumb. But anyway, that's another, maybe that's another podcast. But what 
tools, Dan, like how do you, because there's various tools that will manage, or do you just have a folder or? Yeah. 
How do you, you know, I bet you, I bet you read loads of them. Don't you?
Dan Moore
I do. I think that it's important to acknowledge kind of what you're using the newsletters for. And we could probably, 
again, this is probably a separate podcast in another six or nine months, like, because it's different, there are 
different newsletters I subscribe to for different reasons, but I've probably subscribed to about 30 ish.
Page 11 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
And I will say that like the two things I use to deal with, to make the tools I use to deal with them are one, my inbox 
and two, like permission not to read every single thing. And so there are tons of newsletters that I subscribe to that I 
read one out of every 10 issues and I'm okay with that. And it's just something that I accept.
I don't think there are any specialized technology tools. I think it's more like control of your attention and not being a 
perfectionist about reading everything.
James Governor
You're too busy on Hacker News to read newsletters. Well, it does actually dovetail nicely because lots of times 
stuff from Hacker News goes to newsletters or vice versa. So oftentimes if I'm looking for interesting stuff to share, 
I'll pop open a newsletter and just look at a couple of things. there's asome kind of cycle. not sure what the virtuous 
or a deadly cycle there,
Kate Holterhoff
It's a cycle one way the other. All right. Well, on the note of cycles then, why don't we wrap up and have you back 
on to extemporize on one of these other subjects that we've drug in here. So, but before we do, Dan, are there any 
good social channels where folks can follow your deep thoughts on the matter or other ways that we can follow your 
insights?
Dan Moore
LinkedIn is probably the best thing as a former colleague of mine said, it's the, seems like the only social network 
run by grownups at this point. So that's where I spend a lot of time posting.
Kate Holterhoff
I haven't heard that. like that. that's good. And we'll include, a link to your blog post in the show notes as well as 
your LinkedIn and your newsletter, I guess, is that related? That's tied to your blog, I'm guessing the way to sign up 
for your newsletter.
Dan Moore
Yeah, I can. I'll make sure you guys get you all linked to my newsletter. It is focused on customer identity and 
access management. And I didn't even talk about this as one of the benefits of a newsletter is it does force you the 
same way as a blog to like really dig into a topic. And so if you want to be if you want to learn about topic X starting 
news on it can be a great way to be a forcing function to do that. anyway, that's what my current newsletter is 
mostly about.
Kate Holterhoff
Yeah, that sounds interesting. All right, so we will include all those in the notes. Been so much fun having you back 
on for round two, Dan. So much to say about these subjects. So I'm glad we can make this conversation ongoing 
here. Again, your co-hosts from the RedMonk side, have been Kate Holterhoff and James Governor. If you enjoyed 
this conversation, please like, subscribe and review the MonkCast on your podcast platform of choice. If you are 
watching us on YouTube, please like, subscribe and engage with us in the comments.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
Page 12 of 12
A RedMonk Conversation: Dan Moore on Newsletters, Authenticity, and Sweating the Assets
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: October 14, 2024
End of Document
Page 1 of 2
Fans Can't Believe Broadcast Decision for College Football Game on Saturday
Fans Can't Believe Broadcast Decision for College Football Game on 
Saturday
AthlonSports
October 12, 2024 Saturday 4:47 AM EST
Copyright 2024 The Arena Media Brands, LLC. Athlon Sports Is A Registered Trademark of Athlon Sports Communications, Inc.  All Rights 
Reserved
Section: SPORTS BUSINESS NEWS, Facebook news & SPORTS: COLLEGE FOOTBALL NEWS
Length: 385 words
Byline: Matt Wadleigh
Body
Week 7 of the college football season has plenty of huge matchups. Ole Miss-LSU, Penn State-USC, Oklahoma-
Texas, and Ohio State-Oregon are the headliners in one of the biggest weekends in recent memory. 
As usual, Fox's "Big Noon Kickoff" and ESPN's "College GameDay" will be covering the marquee matchups. "Big 
Noon Kickoff" is going to be on hand in Provo, Utah, as BYU hosts Arizona in a Big 12 Conference showdown. 
"College GameDay" is in Eugene, Oregon, for the Big Ten top-3 clash between the Buckeyes and the Ducks. 
However, one FCS game caught the attention of fans due to the broadcast decision. 
That game is Davidson vs. Dayton. 
While Dayton-Davidson isn't a premier game by any means, the FCS showdown is being broadcast on Facebook. 
Yes, Facebook. 
Davidson-Dayton is on WHAT pic.twitter.com/0zOmzYEcNK
- Mr Matthew CFB (@MrMatthew_CFB)
October 12, 2024
Of course, fans were in disbelief, and some of the comments were gold. 
"Where can you find the game? Just below your uncle's post about the government controlling the weather," one 
fan wrote. 
Davidson and Dayton are part of the Pioneer Football League in the FCS. 
"Long live the Pioneer Football League," the fan mentioned. 

Page 2 of 2
Fans Can't Believe Broadcast Decision for College Football Game on Saturday
Long live the Pioneer Football League https://t.co/WTWpnTMQJA
- Pete Wietmarschen (@pete_wiet)
October 12, 2024
"Fire up your AI slop and tell your crazy aunt hello, you've got a date on Facebook tomorrow," another mentioned. 
"Excuse me," said another. 
"Was YouTube unavailable?" another said. 
Facebook provides a free streaming option, which is a nice break from services such as ESPN+. One fan said more 
should follow suit. 
"More FCS schools might need to take this route and stream games on Facebook and Twitter (X) and get off 
ESPN+ lol."
More FCS schools might need to take this route and stream games on Facebook and Twitter (X) and get off ESPN+ 
lol. https://t.co/mGT3z8bYj9
- OVO KEY ひ (@SoupLivingston)
October 12, 2024
The Pioneer Football League also includes Drake, Butler, San Diego, Morehead State, Stetson, Presbyterian, 
Valparaiso, Marist and St. Thomas. 
In actuality, Dayton is 3-1 and Davidson is 4-1, so this is a game of decent PFL teams, although Facebook isn't an 
option you see very often. Kickoff is set for noon ET in Dayton, Ohio, at Welcome Stadium. 
Related: A College Football Upset Happened On Friday Night
Graphic
 
Dayton Flyers mascot Rudy Flyer. Matt Lunsford-Imagn Images
Load-Date: October 12, 2024
End of Document
Page 1 of 2
AI aggrandizes misinformation on the internet, so see the peacock chicks!
AI aggrandizes misinformation on the internet, so see the peacock chicks!
CE Noticias Financieras English
October 12, 2024 Saturday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 CE Noticias Financieras All Rights Reserved
Length: 625 words
Body
       <p><strong>Mexico City -</strong> The Internet is full of garbage. <strong>The debate on this topic continues 
in networks</strong>, and now it is the<strong> Google Images</strong> section where there are bad indications of 
what may happen in the future with the irruption of content generation by artificial intelligence. </p><p>If you type 
something like<strong> 'baby peacock' into Google Images,</strong> what you get on its first page of results are 
mostly AI-created images in which what you see has nothing to do with what a baby peacock actually looks like. 
<strong>A large thread</strong> has recently formed <strong>on Reddit</strong> about this <strong>, with 
hundreds of users commenting on their gloom</strong> and concern about the unstoppable torrent of junk content, 
or slop, as poor quality AI-generated content is known, flooding networks and platforms. </p>
<p>These fake images of an alleged newborn peacock <strong>have also been shared on Facebook,</strong> 
where, apparently, many people come to believe what they see, and are encouraged to share and leave their 'like' 
for the cuteness of the image. </p><p>And, in this case, the worst thing that can happen is that someone keeps in 
their mind a wrong projection of <strong>what a peacock hatchling looks like, but if this same practice is repeated 
with other more serious topics,</strong> what we can get is clear: rampant misinformation and quality content (I do 
not think there is no lack of good captures of professional photographers on peacocks) being buried by junk 
publications. </p><p>On YouTube it's also slowly starting to appear. Everything is becoming fake and low quality, 
says one user on Reddit. This kind of Internet is not interesting.<strong> We will simply trust the Internet 
less</strong> and spend less time on it. Let Google read itself now, comments another. </p><p>As possible 
remedies, some point to a return to the blogging era: "Create your own website!<strong> It's time to get back to 
owning your own content</strong> and maybe even have a section of interesting links/friends' sites to share. It's 
time for people to own the Internet again, not companies," someone recommends. </p><p><strong>An Internet for 
bots</strong> </p><p><strong>The dead internet theory</strong> continues to gain traction with these kinds of 
symptoms. A theory that bots, automated programs and artificial intelligence will increase their share of Internet 
usage until the majority of <strong>traffic comes from these agents, rather than from real people.</strong> 
</p><p><strong>The result? Misinformation, poor quality content and spam,</strong> making the Internet a more 
hostile place, intoxicated with falsehoods that make it harder for the average user to find what they are looking for. 
</p><p>However, some will be able to make money in the meantime. One user explains it like this: The other day I 
was looking for a solution to a programming problem and came across an <strong>AI-voiced YouTube 
video</strong> with stock footage and generated subtitles. The script of the video <strong>was</strong> also 
<strong>written by AI, as it didn't really say anything useful</strong> and just talked about the general topic for 10 

Page 2 of 2
AI aggrandizes misinformation on the internet, so see the peacock chicks!
minutes. I got curious and checked the channel, and the guy had 2000 videos uploaded with 1000-10 000 average 
views. All with the same type of shitty AI content. <strong>I think someone automated a bot that constantly uploads 
content on YouTube</strong> and the guy just gets ad money as passive income,<strong> comments 
@Competitive-Lack-660</strong>. </p><p>For now, we'll have to regularly warn our parents, aunts, uncles or 
grandparents<strong> not to believe everything they see on Facebook or get on WhatsApp.</strong></p>       
Load-Date: October 13, 2024
End of Document
Page 1 of 2
Marques Brownlee says 'we failed on the price' with Panels
Marques Brownlee says 'we failed on the price' with Panels
 
Africa Newswire
October 12, 2024 Saturday
Copyright 2024 Africa Newswire All Rights Reserved
Length: 423 words
Body
 12 Oct 2024 (TourismAfrica2006) Tourism Africa introduces
Marques Brownlee published a video on Friday addressing the criticisms around Panels, his new wallpaper app, 
saying that he and the team "failed on the price front" at launch. The app received an outpour of criticism from fans, 
both on the MKBHD YouTube channel and across social platforms. Discussing the app, Brownlee admitted it 
needed work. "If I was reviewing this app, I would not have been very nice," he said.
One of the primary criticisms of the app was that the premium "Panels Plus" subscription cost $11.99 per month or 
$49.99 per year to remove ads and have full access to the available collections of wallpapers. To make things 
better, Brownlee and the team have been improving the free experience by getting rid of in-feed ads, making all 
wallpapers that aren't part of a collection available in 1080p for free with no ads, and letting people get a full-
resolution wallpaper by watching one 30-second ad.
As for the subscription's price, "even though subscriptions are incredibly unpopular, we wanted to at least offer one 
that made sense for the wallpaper power user... for how few of you actually exist," Brownlee says. There's now a 
new, more affordable Panels Plus "Standard" tier that costs $1.99 per month with no ads on individual wallpapers. 
The higher "Unlimited" tier, which is still at that $11.99 per month / $49.99 per year price, adds full access to 
collections and early access to new wallpapers.
Brownlee also touches on concerns about what the app was tracking based on the long list that had been included 
in the App Privacy section of the App Store. "Another blunder by us," Brownlee says. "This was way too broad." 
Brownlee says that the list actually was "a list of things that you as a developer provide to the App Store for things 
that the app may, at some point, ask just to tell people ahead of time, just to be safe, and we just checked way too 
many boxes."
Brownlee says that most of the boxes were checked because of "broad suggestions" from the app's ad service, 
AdMob. "To be clear, I do not want your data," he says. He also points out that you can use the app and get 
wallpapers without making an account.

Page 2 of 2
Marques Brownlee says 'we failed on the price' with Panels
In the full video, which is more than 15 minutes long, Brownlee discusses other aspects of the app, too, like that 
there will be weekly drops on Fridays with new art and that he can "personally promise" that the app won't be filled 
with AI-generated slop.
The Panels app launched the same day as MKBHD's iPhone 16 review in September.
Load-Date: October 13, 2024
End of Document
Page 1 of 3
I'm Running Out of Ways to Explain How Bad This Is
I'm Running Out of Ways to Explain How Bad This Is
Atlantic Online
October 10, 2024 Thursday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1688 words
Byline: Charlie Warzel
Body
The truth is, it's getting harder to describe the extent to which a meaningful percentage of Americans have 
dissociated from reality. As Hurricane Milton churned across the Gulf of Mexico last night, I saw an onslaught of 
outright conspiracy theorizing and utter nonsense racking up millions of views across the internet. The posts would 
be laughable if they weren't taken by many people as gospel. Among them: Infowars' Alex Jones, who claimed that 
Hurricanes Milton and Helene were "weather weapons" unleashed on the East Coast by the U.S. government, and 
"truth seeker" accounts on X that posted photos of condensation trails in the sky to baselessly allege that the 
government was "spraying Florida ahead of Hurricane Milton" in order to ensure maximum rainfall, "just like they did 
over Asheville!"
As Milton made landfall, causing a series of tornados, a verified account on X reposted a TikTok video of a massive 
funnel cloud with the caption "WHAT IS HAPPENING TO FLORIDA?!" The clip, which was eventually removed but 
had been viewed 662,000 times as of yesterday evening, turned out to be from a video of a CGI tornado that was 
originally published months ago. Scrolling through these platforms, watching them fill with false information, 
harebrained theories, and doctored images-all while panicked residents boarded up their houses, struggled to 
evacuate, and prayed that their worldly possessions wouldn't be obliterated overnight-offered a portrait of American 
discourse almost too bleak to reckon with head-on.
Even in a decade marred by online grifters, shameless politicians, and an alternative right-wing-media complex 
pushing anti-science fringe theories, the events of the past few weeks stand out for their depravity and nihilism. As 
two catastrophic storms upended American cities, a patchwork network of influencers and fake-news peddlers have 
done their best to sow distrust, stoke resentment, and interfere with relief efforts. But this is more than just a 
misinformation crisis. To watch as real information is overwhelmed by crank theories and public servants battle 
death threats is to confront two alarming facts: first, that a durable ecosystem exists to ensconce citizens in an 
alternate reality, and second, that the people consuming and amplifying those lies are not helpless dupes but willing 
participants.

Page 2 of 3
I'm Running Out of Ways to Explain How Bad This Is
[Read: November will be worse]
Some of the lies and obfuscation are politically motivated, such as the claim that FEMA is offering only $750 in total 
to hurricane victims who have lost their home. (In reality, FEMA offers $750 as immediate "Serious Needs 
Assistance" to help people get basic supplies such as food and water.) Donald Trump, J. D. Vance, and Fox News 
have all repeated that lie. Trump also posted (and later deleted) on Truth Social that FEMA money was given to 
undocumented migrants, which is untrue. Elon Musk, who owns X, claimed-without evidence-that FEMA was 
"actively blocking shipments and seizing goods and services locally and locking them away to state they are their 
own. It's very real and scary how much they have taken control to stop people helping." That post has been viewed 
more than 40 million times. Other influencers, such as the Trump sycophant Laura Loomer, have urged their 
followers to disrupt the disaster agency's efforts to help hurricane victims. "Do not comply with FEMA," she posted 
on X. "This is a matter of survival."
The result of this fearmongering is what you might expect. Angry, embittered citizens have been harassing 
government officials in North Carolina, as well as FEMA employees. According to an analysis by the Institute for 
Strategic Dialogue, an extremism-research group, "Falsehoods around hurricane response have spawned credible 
threats and incitement to violence directed at the federal government," including "calls to send militias to face down 
FEMA." The study also found that 30 percent of the X posts analyzed by ISD "contained overt antisemitic hate, 
including abuse directed at public officials such as the Mayor of Asheville, North Carolina; the FEMA Director of 
Public Affairs; and the Secretary of the Department of Homeland Security." The posts received a collective 17.1 
million views as of October 7.
Online, first responders are pleading with residents, asking for their help to combat the flood of lies and conspiracy 
theories. FEMA Administrator Deanne Criswell said that the volume of misinformation could hamper relief efforts. "If 
it creates so much fear that my staff doesn't want to go out in the field, then we're not going to be in a position 
where we can help people," she said in a news conference on Tuesday. In Pensacola, Florida, Assistant Fire Chief 
Bradley Boone vented his frustrations on Facebook ahead of Milton's arrival: "I'm trying to rescue my community," 
he said in a livestream. "I ain't got time. I ain't got time to chase down every Facebook rumor  We've been through 
enough."
It is difficult to capture the nihilism of the current moment. The pandemic saw Americans, distrustful of authority, 
trying to discredit effective vaccines, spreading conspiracy theories, and attacking public-health officials. But what 
feels novel in the aftermath of this month's hurricanes is how the people doing the lying aren't even trying to hide 
the provenance of their bullshit. Similarly, those sharing the lies are happy to admit that they do not care whether 
what they're pushing is real or not. Such was the case last week, when Republican politicians shared an AI-
generated viral image of a little girl holding a puppy while supposedly fleeing Helene. Though the image was clearly 
fake and quickly debunked, some politicians remained defiant. "Y'all, I don't know where this photo came from and 
honestly, it doesn't matter," Amy Kremer, who represents Georgia on the Republican National Committee, wrote 
after sharing the fake image. "I'm leaving it because it is emblematic of the trauma and pain people are living 
through right now."
Kremer wasn't alone. The journalist Parker Molloy compiled screenshots of people "acknowledging that this image 
is AI but still insisting that it's real on some deeper level"-proof, Molloy noted, that we're "living in the post-reality." 
The technology writer Jason Koebler argued that we've entered the "~Fuck It' Era" of AI slop and political 
messaging, with AI-generated images being used to convey whatever partisan message suits the moment, 
regardless of truth.
This has all been building for more than a decade. On The Colbert Report, back in 2005, Stephen Colbert coined 
the word truthiness, which he defined as "the belief in what you feel to be true rather than what the facts will 
support." This reality-fracturing is the result of an information ecosystem that is dominated by platforms that offer 
financial and attentional incentives to lie and enrage, and to turn every tragedy and large event into a shameless 
content-creation opportunity. This collides with a swath of people who would rather live in an alternate reality built 
Page 3 of 3
I'm Running Out of Ways to Explain How Bad This Is
on distrust and grievance than change their fundamental beliefs about the world. But the misinformation crisis is not 
always what we think it is.
[Read: Florida's risky bet]
So much of the conversation around misinformation suggests that its primary job is to persuade. But as Michael 
Caulfield, an information researcher at the University of Washington, has argued, "The primary use of 
~misinformation' is not to change the beliefs of other people at all. Instead, the vast majority of misinformation is 
offered as a service for people to maintain their beliefs in face of overwhelming evidence to the contrary." This 
distinction is important, in part because it assigns agency to those who consume and share obviously fake 
information. What is clear from comments such as Kremer's is that she is not a dupe; although she may come off as 
deeply incurious and shameless, she is publicly admitting to being an active participant in the far right's world-
building project, where feel is always greater than real.
What we're witnessing online during and in the aftermath of these hurricanes is a group of people desperate to 
protect the dark, fictitious world they've built. Rather than deal with the realities of a warming planet hurling once-in-
a-generation storms at them every few weeks, they'd rather malign and threaten meteorologists, who, in their 
minds, are "nothing but a trained subversive liar programmed to spew stupid shit to support the global warming 
bullshit," as one X user put it. It is a strategy designed to silence voices of reason, because those voices threaten to 
expose the cracks in their current worldview. But their efforts are doomed, futile. As one dispirited meteorologist 
wrote on X this week, "Murdering meteorologists won't stop hurricanes." She followed with: "I can't believe I just had 
to type that."
What is clear is that a new framework is needed to describe this fracturing. Misinformation is too technical, too 
freighted, and, after almost a decade of Trump, too political. Nor does it explain what is really happening, which is 
nothing less than a cultural assault on any person or institution that operates in reality. If you are a weatherperson, 
you're a target. The same goes for journalists, election workers, scientists, doctors, and first responders. These jobs 
are different, but the thing they share is that they all must attend to and describe the world as it is. This makes them 
dangerous to people who cannot abide by the agonizing constraints of reality, as well as those who have financial 
and political interests in keeping up the charade.
 In one sense, these attacks-and their increased desperation-make sense. The world feels dark; for many people, 
it's tempting to meet that with a retreat into the delusion that they've got everything figured out, that the powers that 
be have conspired against them directly. But in turning away, they exacerbate a crisis that has characterized the 
Trump era, one that will reverberate to Election Day and beyond. Americans are divided not just by political beliefs 
but by whether they believe in a shared reality-or desire one at all.
Load-Date: October 11, 2024
End of Document
Page 1 of 2
Can Facebook win back Gen Z?
Can Facebook win back Gen Z?
Fastcompany.com
October 9, 2024 Wednesday
Copyright 2024 Mansueto Ventures, LLC All Rights Reserved
Length: 619 words
Byline: Henry Chandonnet
Body
Facebook was born as a social networking tool exclusively for Harvard students. These days you’d be hard-pressed 
to find many U.S. college students on the platform. 
Over the past decade, Facebook usership among U.S. teens dropped from 71% to 33%. A recently announced 
redesign attempts to recapture these young users, emphasizing already popular aspects like Groups and 
Marketplace while building a TikTok-style “Explore” page. Still, one redesign won’t collect that cache of lost Gen Z 
eyes. 
How Facebook lost Gen Z
Once the cutting edge of technology, Facebook has been relegated to an old-world position by many Gen Zers. 
That’s evident in the gap among usership percentages: In 2023, only 33% of U.S. teens said they used Facebook, 
according to the Pew Research Center. Compare that to the U.S. adult populace, where Facebook is the second-
most-popular social media app at 68%. 
As a company, Facebook seems to recognize this decline. Back in May, it held an event focused on the “next 20 
years” of the app. “We’re still for everyone,” said Tom Alison, Meta’s Facebook head,  according to Mashable. “But 
we also recognize that in order to stay relevant, we have to build for . . . Gen Z.” (Meta did not respond to a request 
for comment.) 
There are several reasons why Gen Zers downgraded Facebook among their apps. Facebook has been embroiled 
in political scandal since 2016, which, for many young people, was the first major election of memory. There was 
the Cambridge Analytica data-scraping conundrum; the Pizzagate conspiracy theory that blew up in-app; and now 
the deluge of AI political slop across the feed. Those woes aren’t going away anytime soon, as former President 
Donald Trump continues to claim that Mark Zuckerberg pledged his support for the Republican candidate’s 2024 
campaign to regain the White House, which Meta has denied. 
While Facebook offers photo and video options, much of the in-app content is text-based. That’s a format Gen Z is 
increasingly moving away from. Of the four apps tracked since 2014, only Facebook and Twitter, another text-
based app, saw user share declines among U.S. teens. Both Snapchat and Instagram, which rely more on images 

Page 2 of 2
Can Facebook win back Gen Z?
and videos, saw increases. When included, video app YouTube dominates these platforms at 93% usage among 
teens. 
Users are primarily drawn to Facebook for connection. That’s reflected in the data: Among Facebook users, 93% 
claim to use the app to keep in touch with friends and family. If your Gen Z peers aren’t on the platform, that ability 
to connect diminishes. Sure enough, in a 2023 survey of Gen Z users from Savanta, “keeping in touch” steadily 
declined over the previous eight years. In 2015, 82% of young people used Facebook to connect; in 2023, that 
figure dropped to just 45%. 
Can this redesign win back Gen Z users?
With the newly announced redesign, Facebook aims to tap into what Gen Z has historically liked. Marketplace is 
one of the app’s most popular features among young people, with many seeing it as a haven of thrift finds. The new 
“Local” tab will pull content from Marketplace, Groups, and Events to create a more geographic feed. 
Facebook is also leaning further into its play for TikTok user share, unifying its content under an “Explore” page 
backed by an endless-scroll algorithm. Facebook Reels, its TikTok knockoff, will be featured on the “Explore” page. 
Facebook isn’t the only platform leaning hard into TikTok strategy; Snapchat recently announced a redesign with 
one unified vertical video feed. 
Whether these redesigns can entice Gen Z users remains to be seen. It’s hard to ditch a reputation for being a “tech 
dinosaur.” But if Facebook wants any sort of longevity, it will need to try.
Link to image
Load-Date: October 9, 2024
End of Document
Page 1 of 2
Here's Why 'Human Authored' Will Become the 'Artisanally Crafted' Pitch of the AI Age
Here's Why 'Human Authored' Will Become the 'Artisanally Crafted' Pitch of 
the AI Age
Inc.com
October 8, 2024 Tuesday 12:14 PM EST
Copyright 2024 Mansueto Ventures, LLC All Rights Reserved
Length: 849 words
Byline: Kit Eaton
Body
Readers will know books with the Author's Guild label are different-and better-than AI slop.
The Author's Guild is making it clear who's behind the content you're reading, and its new campaign may become 
the equivalent of slapping an "organic produce" label on an apple and pricing it accordingly. In an era when authors 
are suing AI companies for alleged "theft" of their intellectual property, major newspapers and record labels are 
doing the same, and as the content spat out by AIs becomes more convincingly realistic, the Author's Guild is trying 
something different. The organization, said to be the oldest professional organization for writers in the U.S., is going 
to offer a new certificate for the covers of books released by its 15,000 members, reports Marketplace: it'll say 
"Human Authored."
The label will be about the same size as book stickers denoting literary awards, or being selected for a celebrity 
book club, Marketplace explains. The site quotes Douglas Preston, bestselling novelist, nonfiction writer and 
member of the Authors Guild Council, offering this explanation. It's not just to "prevent fraud and deception," but 
also to show "how important storytelling is to who we are as a species," Preston said. He added, "we're not going to 
let machines elbow us aside and pretend to be telling us stories, when it's just regurgitating literary vomitus." 
Those are some sweet-and even spicy-words. Preston is an acclaimed writer, after all. His rallying cry taps into one 
of the key arguments against certain uses of AI, which is to generate meaningless content to grab attention, fill web 
pages, and even sneakily grab advertising revenues away from sites offering genuine "Human Authored" content. 
This content is already known as "AI slop," and it's so pervasive that a recent study showed Google's search 
algorithms can be gamed to make them prefer slop over meaningful human-made content. 
"Human Authored" is a clever move, if you think about it. It's the inverse of the "made by AI" labels that tech 
industry figures think need to be slapped on stuff spewed out by a generative AI system. The Author's Guild is also 
tapping into the same vibe as "organic product" labels on food, or handmade products sold on Etsy, clearly from a 
small or solo entrepreneur's business. The difference, based on the underlying sensibility of the Author's Guild 
mark, is that it's celebrating the thumbprints in the clay pot, or the cute handwritten labels a customer sees when 
their purchase arrives at their door. Things that lack the smooth mass-made quality of most factory-produced 
wares, but carry that emotional tingle of being created by people with a pulse are distinctive.

Page 2 of 2
Here's Why 'Human Authored' Will Become the 'Artisanally Crafted' Pitch of the AI Age
Think about it like this, and "Human Authored" label is clearly a marketing strategy as well as a human salvo 
against a barrage of technological innovations bringing widespread change. Authors Guild CEO Mary Rasenberger 
suggest the label may be "most important in marketplaces like the Kindle marketplace, where you'll see a lot of AI 
generated books" that tend to be full of low-quality plots that are "a little weird, there's duplication." Thinking ahead, 
this might mean the label could benefit smaller publishers and less well known authors, who find their work 
competing for space in a crowded digital market.
Meanwhile, an artist embroiled in a copyright scandal shows the flip side of this AI-as-a-creative-tool coin. Jason 
Allen's work "Théâtre D'opéra Spatial" recently generated controversy after it won a state fair art competition. That's 
because the creation isn't painted, photographed or even drawn on a computer graphics system: it was dreamed-up 
by the AI image generating tool Midjourney. In late 2023, Allen was denied the right to register the work under 
copyright, news site Ars Technica reports. 
But Allen hasn't given up the fight and is now asking for a judicial review of the ruling by the U.S. Copyright Office. 
He alleges "the negative media attention surrounding the Work may have influenced the Copyright Office 
Examiner's perception and judgment," Ars explains, and is arguing that the copyright examiner was biased and 
lagging behind the times. Lacking copyright protection, his art has been appropriated by others and is even being 
sold on Etsy. 
Allen might have a point. After all, in terms of "art," what's different between Allen's AI-fashioned piece and a 
repurposed porcelain urinal with the fake signature "R.Mutt" scrawled on it by French sculptor Marcel Duchamp and 
shown in an early 20th-century Parisian art gallery? Fish, as his fellow surrealists might have said. The court 
decision will be closely watched, though it surely won't be the last word on this complex topic.
No matter what you think of the difference between human-made and machine-made, both controversies are a 
reminder that you need to be careful how your company incorporates AI-created imagery, text or other content into 
your promotional material or even products. All of these questions are floating in untested waters, with plenty of 
potential legal complications under the surface.
Link to Image
Load-Date: October 8, 2024
End of Document
Page 1 of 2
Right-Wingers Heartbroken by Picture of Little Girl Who Doesn't Exist
Right-Wingers Heartbroken by Picture of Little Girl Who Doesn't Exist
Rolling Stone
October 7, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 919 words
Byline: Miles Klee
Body
There has been  no shortage of gut-wrenching photographs from communities in the southeast devastated by 
Hurricane Helene, which caused extreme flooding and killed at least 215 people - pictures of houses destroyed, 
families trapped on rooftops, wreckage from mudslides and roads washed out by torrential rains. But rather than 
focus on the actual victims or damage, many right-wing influencers and politicians have extended their sympathies 
to a nonexistent girl and her puppy (who is also not real).
The AI-generated image they're sharing depicts a crying girl in a boat, seemingly alone except for the little dog 
she's clutching. She wears a lifejacket and appears to be adrift on floodwaters caused by a major storm. Sen. Mike 
Lee of Utah posted the picture on X on Thursday, writing "Caption this photo," apparently inviting his followers to 
vent their outrage at the Biden-Harris administration for allowing American children to suffer such misery on their 
watch. After users pointed out that he'd fallen for AI slop, he deleted the picture. (The image originated on the 
Trump web forum Patriots.win, where several users immediately recognized it as the product of an AI model.)
Based Senator Mike Lee deleted this. Because someone told him this viral MAGA photo is AI and not Kamala 
abandoning kids and puppies. pic.twitter.com/DhXZB9j9k6
- Ron Filipkowski (@RonFilipkowski) October 3, 2024
Others, however, have left the misleading picture up on their social media accounts - and some are defending it as 
an accurate representation of Helene's effects even though it's fake. Far-right conspiracy theorist and Donald 
Trump associate Laura Loomer called the image "sad," quote-tweeting a post from Buzz Patterson, columnist for 
the conservative blog RedState, who wrote of the picture: "Our government has failed us again." Neither have taken 
their posts down as of press time. Amy Kremer, RNC National Committeewoman for the Georgia GOP and co-
founder of Women for Trump, tweeted on Thursday that the image had been "seared into my mind."
Informed that she was not looking at an authentic photo, Kremer doubled down. "Y'all, I don't know where this photo 
came from and honestly, it doesn't matter," she replied. "There are people going through much worse than what is 

Page 2 of 2
Right-Wingers Heartbroken by Picture of Little Girl Who Doesn't Exist
shown in this pic. So I'm leaving it because it is emblematic of the trauma and pain people are living through right 
now." A large anonymous blue-check account on X that routinely attacks Democrats did remove the picture but 
similarly argued: "Even though that image was AI, it spoke a truth about the disregard Harris and Biden have for 
ordinary Americans, as evidenced by their criminal non-response to Helene." Another X user posted a since-
deleted screenshot of a more succinct response from an apparent family member advised that the image was 
bogus. "Who cares," they answered.
The little girl and her puppy - there are AI-generated variants of the more viral image floating around as well - have 
been widely presented by MAGA world as evidence of a failed disaster response in the aftermath of Helene. Similar 
fake images depict girls or women clutching Bibles as floods rage around them. Trump himself is pushing lies about 
the U.S. government not being able to fund relief efforts, adding an overtone of racism with the groundless claim 
that the White House "stole" money from the Federal Emergency Management Agency (FEMA) and "spent it all on 
illegal migrants." (The irony being that in 2019, the Trump administration itself redirected millions in disaster funds, 
during hurricane season, to pay for detention centers at the border.)
FEMA has said in a statement that it does have enough money for "immediate response and recovery needs." Yet 
the supposed scandal has Republicans outraged at the idea that Americans impacted by the hurricane are being 
denied help because Democrats funneled resources to immigrants. "So Kamala doesn't have enough money for 
this child?" fumed a MAGA-affiliated X user who shared the AI-generated girl. "For Americans that lost everything 
they have? I can't hate this administration enough."
The barrage of AI junk from Trump supporters follows a similar trend last month, when the former president, his 
running mate Sen. J.D. Vance, and their various allies were smearing the Haitian immigrant community of 
Springfield, Ohio, by falsely accusing them of stealing and eating local house pets. During that news cycle, many 
used AI to generate cartoonish images of cats and dogs wearing MAGA hats, and Trump himself holding or 
protecting animals. Before that, Trump shared AI imagery that made it appear as if he had the backing of Taylor 
Swift and her fan army. (Swift endorsed Vice President Harris immediately after Harris' September debate with 
Trump.) Along with the phony "victim" images to come out of the Helene disaster, there were also AI pictures of 
Trump braving floodwaters to assist residents and rescue babies.
He's saving the dogs.He's saving the cats.He's saving the lives of the people who live there. 
pic.twitter.com/mOxujYwm1c
- rick genie (@RickGenie) October 3, 2024
What other uncanny-valley creations will online Trump boosters bring to the fore of the American imagination in the 
closing weeks of this chaotic campaign? Hard to say, but one thing is certain: the AI assault remains a core piece of 
their strategy.
Update Oct. 7, 1:41 p.m. ET: This story has been updated to include more examples of misleading AI-generated 
images in circulation on social media following Hurricane Helene.
Load-Date: October 7, 2024
End of Document
Page 1 of 2
It's Time to Stop Taking Sam Altman at His Word
It's Time to Stop Taking Sam Altman at His Word
Atlantic Online
October 4, 2024 Friday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1069 words
Byline: David Karpf
Body
OpenAI announced this week that it has raised $6.6 billion in new funding and that the company is now valued at 
$157 billion overall. This is quite a feat for an organization that reportedly burns through $7 billion a year-far more 
cash than it brings in-but it makes sense when you realize that OpenAI's primary product isn't technology. It's 
stories.
Case in point: Last week, CEO Sam Altman published an online manifesto titled "The Intelligence Age." In it, he 
declares that the AI revolution is on the verge of unleashing boundless prosperity and radically improving human 
life. "We'll soon be able to work with AI that helps us accomplish much more than we ever could without AI," he 
writes. Altman expects that his technology will fix the climate, help humankind establish space colonies, and 
discover all of physics. He predicts that we may have an all-powerful superintelligence "in a few thousand days." All 
we have to do is feed his technology enough energy, enough data, and enough chips.
Maybe someday Altman's ideas about AI will prove out, but for now, his approach is textbook Silicon Valley 
mythmaking. In these narratives, humankind is forever on the cusp of a technological breakthrough that will 
transform society for the better. The hard technical problems have basically been solved-all that's left now are the 
details, which will surely be worked out through market competition and old-fashioned entrepreneurship. Spend 
billions now; make trillions later! This was the story of the dot-com boom in the 1990s, and of nanotechnology in the 
2000s. It was the story of cryptocurrency and robotics in the 2010s. The technologies never quite work out like the 
Altmans of the world promise, but the stories keep regulators and regular people sidelined while the entrepreneurs, 
engineers, and investors build empires. (The Atlantic recently entered a corporate partnership with OpenAI.)
[Read: AI doomerism is a decoy]
Despite the rhetoric, Altman's products currently feel less like a glimpse of the future and more like the mundane, 
buggy present. ChatGPT and DALL-E were cutting-edge technology in 2022. People tried the chatbot and image 
generator for the first time and were astonished. Altman and his ilk spent the following year speaking in stage 

Page 2 of 2
It's Time to Stop Taking Sam Altman at His Word
whispers about the awesome technological force that had just been unleashed upon the world. Prominent AI figures 
were among the thousands of people who signed an open letter in March 2023 to urge a six-month pause in the 
development of large language models ( LLMs) so that humanity would have time to address the social 
consequences of the impending revolution. Those six months came and went. OpenAI and its competitors have 
released other models since then, and although tech wonks have dug into their purported advancements, for most 
people, the technology appears to have plateaued. GPT-4 now looks less like the precursor to an all-powerful 
superintelligence and more like  well, any other chatbot.
The technology itself seems much smaller once the novelty wears off. You can use a large language model to 
compose an email or a story-but not a particularly original one. The tools still hallucinate (meaning they confidently 
assert false information). They still fail in embarrassing and unexpected ways. Meanwhile, the web is filling up with 
useless "AI slop," LLM-generated trash that costs practically nothing to produce and generates pennies of 
advertising revenue for the creator. We're in a race to the bottom that everyone saw coming and no one is happy 
with. Meanwhile, the search for product-market fit at a scale that would justify all the inflated tech-company 
valuations keeps coming up short. Even OpenAI's latest release, o1, was accompanied by a caveat from Altman 
that "it still seems more impressive on first use than it does after you spend more time with it."
In Altman's rendering, this moment in time is just a waypoint, "the doorstep of the next leap in prosperity." He still 
argues that the deep-learning technique that powers ChatGPT will effectively be able to solve any problem, at any 
scale, so long as it has enough energy, enough computational power, and enough data. Many computer scientists 
are skeptical of this claim, maintaining that multiple significant scientific breakthroughs stand between us and 
artificial general intelligence. But Altman projects confidence that his company has it all well in hand, that science 
fiction will soon become reality. He may need $7 trillion or so to realize his ultimate vision-not to mention unproven 
fusion-energy technology-but that's peanuts when compared with all the advances he is promising.
There's just one tiny problem, though: Altman is no physicist. He is a serial entrepreneur, and quite clearly a 
talented one. He is one of Silicon Valley's most revered talent scouts. If you look at Altman's breakthrough 
successes, they all pretty much revolve around connecting early start-ups with piles of investor cash, not any 
particular technical innovation.
[Read: OpenAI takes its mask off]
It's remarkable how similar Altman's rhetoric sounds to that of his fellow billionaire techno-optimists. The project of 
techno-optimism, for decades now, has been to insist that if we just have faith in technological progress and free 
the inventors and investors from pesky regulations such as copyright law and deceptive marketing, then the 
marketplace will work its magic and everyone will be better off. Altman has made nice with lawmakers, insisting that 
artificial intelligence requires responsible regulation. But the company's response to proposed regulation seems to 
be "no, not like that." Lord, grant us regulatory clarity-but not just yet.
At a high enough level of abstraction, Altman's entire job is to keep us all fixated on an imagined AI future so we 
don't get too caught up in the underwhelming details of the present. Why focus on how AI is being used to harass 
and exploit children when you can imagine the ways it will make your life easier? It's much more pleasant 
fantasizing about a benevolent future AI, one that fixes the problems wrought by climate change, than dwelling 
upon the phenomenal energy and water consumption of actually existing AI today.
Remember, these technologies already have a track record. The world can and should evaluate them, and the 
people building them, based on their results and their effects, not solely on their supposed potential.
Load-Date: October 5, 2024
End of Document
Page 1 of 2
Worlds apart
Worlds apart
New Scientist
October 2, 2024
Copyright 2024 New Scientist Ltd All Rights Reserved
Section: CULTURE; Review; Pg. 30; Vol. 264; No. 3511; ISSN: 0262 4079
Length: 662 words
Byline: Bethan Ackerley
Bethan Ackerley is a subeditor at New Scientist. She loves sci-fi, sitcoms and anything spooky.
Highlight: Bill Gates's Netflix series offers a bumpy ride as it discusses routes and roadblocks to the future – AI, 
climate, inequality, malaria and more. But Gates looms too large for alternative solutions to emerge, says Bethan 
Ackerley
Body
TV
What's Next? The future with Bill GatesNetflix
Books
Non-Stop InertiaIvor SouthwoodZero BooksModern life is characterised by restlessness – about work, housing, 
relationships. Southwood argues that this frenzy masks a paralysis of action and imagination.
Mutual AidDean SpadeVersoFor an alternative view on how transformational change can be achieved, try this great 
primer on mutual aid, in which resources are shared within communities to provide unconditionally for those in 
need.
WHEN you want to imagine the future, who do you turn to? Friends and family? Science fiction? New Scientist? 
Now you can check in with Bill Gates, as the Microsoft co-founder and multibillionaire has worked with Netflix on 
What's Next? The future with Bill Gates, in which he digs into make-or-break issues: artificial intelligence, 
misinformation, climate change, income inequality and disease.
The five-part series is uneven, though, and the worst instalment is perhaps the first, "What can AI do for us/to us". 
Gates is upfront about his role advising the leaders of OpenAI, whose ChatGPT transformed our understanding of 
generative technologies in 2022. But the documentary pretty much takes it as read that current AIs are miraculously 
competent – bar the odd bias and hallucination – and unstoppably marching towards superintelligence. Many would 
question that characterisation.

Page 2 of 2
Worlds apart
Little time is afforded to key questions such as the legalities of sometimes using copyrighted material to teach AIs 
and whether so-called transformer models like ChatGPT might soon hit a ceiling of usefulness. And what happens if 
AI-generated slop is fed back into training data? You won't find out from this series, which is weighed down by its 
attempts to present Gates as a leader in this field.
I would also advise skipping the fourth episode, "Can you be too rich?" Prepare to be shocked to learn that Gates 
believes the ultra-rich shouldn't be prevented from accumulating vast hoards, but should be more like him and give 
it away. We are told, constantly, that he has effectively imposed higher taxes on himself, as if this shouldn't be 
expected of someone in his position, and are presented with a mainly US-centric view of running an economy.
When Gates covers topics like climate change and malaria, the series is better, enlightening even
Systems must be tweaked to decrease the gap between rich and poor, we are also told. The alternative – 
restructuring beyond the business as usual that keeps millions in poverty and poisons the planet – would be almost 
inconceivable, the show implies. The most charitable reading of this approach I can stomach is that it is a 
spectacular failure of vision.
When Gates covers topics like climate change and malaria, the series is better, enlightening even. In "Can we stop 
global warming?", there is a detailed breakdown of the sectors of the economy most difficult to decarbonise. Gates 
invests in and is a customer of many companies offering technical solutions to some of climate change's stickiest 
issues.
A lot of the firms featured have also appeared in New Scientist, such as Climeworks, which is developing large 
direct-air-capture plants to suck carbon out of the atmosphere. It is refreshing that Gates, Climeworks and the film-
makers all stress that such infrastructure is nowhere near the scale needed to solve the problem. Such sober 
analysis would have greatly benefited the whole series.
By the final episode, the focus is on malaria, Gates's real expertise. It is a thoughtful exploration of the tough 
ethical, ecological and social issues around developing vaccines and technologies such as gene drives, which 
could eliminate whole mosquito species.
But even this nuance is marred by the endless myth-making of Gates as god-emperor of all he surveys. He is 
undoubtedly an intelligent man with considerable achievements, just as What's Next? undoubtedly has a few big 
insights. However, it is hard to see other futures with Gates standing in the way.
Load-Date: October 2, 2024
End of Document
Page 1 of 2
Silicon Valley has a plan to save humanity: Just flip on the nuclear reactors
Silicon Valley has a plan to save humanity: Just flip on the nuclear reactors
CNN Wire
October 1, 2024 Tuesday 9:00 AM GMT
Copyright 2024 Cable News Network All Rights Reserved
Length: 731 words
Byline: Analysis by Allison Morrow, CNN
Dateline: (CNN) 
Body
             New York (CNN) - AI hasn't quite delivered the job-killing, cancer-curing utopia that the technology's 
evangelists are peddling. So far, artificial intelligence has proven more capable of generating stock market 
enthusiasm than, like, tangibly great things for humanity. Unless you count Shrimp Jesus.
But that's all going to change, the AI bulls tell us. Because the only thing standing in the way of an AI-powered idyll 
is heaps upon heaps of computing power to train and operate these nascent AI models. And don't worry, fellow 
members of the public who never asked for any of this - that power won't come from fossil fuels. I mean, imagine 
the PR headaches.
No, the tech that's going to save humanity will be powered by the tech that very nearly destroyed it.
Here's the deal: To do AI at the scale that the Microsofts and Googles of the world envision, it requires a lot of 
computing power. When you ask Chat-GPT a question, that query and its answer are sucking up electricity in a 
supercomputer filled with Nvidia chips in some remote, heavily air-conditioned data center.
Electricity consumption from data centers, AI and crypto mining (its own environmental headache) could double by 
2026, according to the International Energy Agency.
In the US alone, power demand is expected to grow 13% to 15% a year until 2030, potentially turning electricity into 
a much scarcer resource, according to JPMorgan analysts.
The tech industry's solution, for now, is nuclear energy, which is more stable than wind or solar and is virtually 
carbon-emission-free.
Microsoft this month secured a deal to reopen a reactor on Three Mile Island, the site of the 1979 partial meltdown 
near Harrisburg, Pennsylvania, to give the company enough power to sustain its AI growth. (Not the reactor, of 
course, but another one that didn't didn't fail and continued to operate on the island for years after the 
incident.)Amazon is working on putting a data center campus right on the site of a Talen Energy nuclear power 
plant in Northeast Pennsylvania.Sam Altman, the CEO of OpenAI, is also heavily invested in nuclear energy and 
serves as the chairman of Oklo, a nuclear startup that last week received approval to begin site investigations for a 

Page 2 of 2
Silicon Valley has a plan to save humanity: Just flip on the nuclear reactors
"microreactor" site in Idaho.On Monday, the Financial Times reported that the venture capital firm co-founded by 
Peter Thiel, Founders Fund, is backing a nuclear startup that's trying to create a new production method for a more 
powerful nuclear fuel used in advanced reactors.
The irony of all this is, of course, is that even AI's cheerleaders have invoked the history of nuclear proliferation to 
try to convey the need for guardrails around artificial intelligence (just as long as the regulations don't slow them 
down or curtail their profit-making in any way).
And while AI doomer predictions often get brushed off as alarmist forecasts, you can't as readily dismiss the folks 
who are concerned about nuclear energy. History is, tragically, on their side.
To be sure, nuclear power today is better understood than it was in 1979, when Three Mile Island's Reactor Two 
experienced a partial core meltdown, Anna Erickson, a professor of nuclear science at Georgia Tech, told me.
"Nothing in life is ever foolproof," she said, "but we are much better now at understanding the operation of nuclear 
reactors," thanks in part to the wave of safety regulations that the Three Mile Island incident set off.
Bottom line: There's no AI future without a serious uptick in our power supply, which makes the expansion of 
nuclear power practically unavoidable. But it will take years for many of the recently announced projects to come 
online, and that means Big Tech data centers will have to stay on the fossil fuel drip as demand continues spiking.
Are we all cool with wrecking the planet if all we get are apps that can summarize our emails? Or search engines 
that are slightly more human-sounding but less reliable? Is the future really just variations of crustacean-based 
deities in a churn of AI slop?
There's a lot at stake - including our jobs and the environment and our entire sense of purpose in the world, 
according to AI's own developers. And yet it remains unclear what we the people stand to get out of the deal.         
             Analysis by Allison Morrow, CNN         
TM & © 2024 Cable News Network, Inc., a Time Warner Company. All rights reserved.
Load-Date: October 1, 2024
End of Document
Page 1 of 2
McNeal review – Robert Downey Jr shines in muddled AI-themed play
McNeal review – Robert Downey Jr shines in muddled AI-themed play
The Guardian (London)
October 1, 2024 Tuesday 5:21 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: STAGE; Version:2
Length: 810 words
Byline: Adrian Horton
Highlight: Vivian Beaumont Theater, New YorkThe Oscar-winning actor makes a smooth transfer to Broadway but 
Ayad Akhtar’s play is a mixed bag of insight and exhaustion
Body
Star Rating: 3 stars
The writer Jacob McNeal is, among other things, a bestselling and influential novelist, an esteemed winner of the 
Nobel prize for literature, a writer with style consistent and public enough to serve as a prompt for ChatGPT. From 
another view: a narcissistic cad, a terrible father, a lonely drunk. People argue whether he’s a genius, a fraud, an 
iconoclast. After nearly two hours with him, it’s not clear which. Though mesmerizingly brought to life by Robert 
Downey Jr in Ayad Akhtar’s muddled and occasionally poignant new play of the same name, McNeal remains more 
reflection than character – a projection of success, an outlet for anxieties over artificial intelligence, a cipher to 
destabilize one’s view of reality.
All of these angles offer fertile material for a play of ideas, and to Akhtar’s credit, McNeal is not only a rare original 
Broadway play but an ambitious one, given starry billing and splashy, tech-forward staging at Lincoln Center. It’s 
also all over the place, a play of strong performances – Downey, in his Broadway debut, chief among them – that 
chafe against vague, inchoate ideas about a vaguely ghoulish technology.
Things start simply enough: a giant, blue light-abundant iPhone interface looming above the stage, the home page 
tracking the minutes clicking by on Friday, 10 October in a way intriguingly familiar to most people in the audience. 
It’s sometime in the near future, when ChatGPT-like AI is even more firmly grounded in American daily life – 
enough, as McNeal off-handedly remarks in Dr Sahra Grewal’s (Ruthie Ann Miles) office, that several New York 
Times bestsellers are openly composed through machine learning.
The play proceeds in chronological-ish chapters in the sunset days of McNeal’s distinguished career: an 
appointment diagnosing liver disease; a triumphantly tipsy and moralizing speech accepting the Nobel prize; a 
meeting with his hammy agent Stephie (Andrea Martin); a reunion with his estranged adult son Harlan (a jittery Rafi 

Page 2 of 2
McNeal review – Robert Downey Jr shines in muddled AI-themed play
Gavron), who harbors intense loathing for the father he blames for his mother’s suicide decades earlier (and which 
features some telenovela-esque revelations that nearly took me out of the play entirely). Some border on the 
surreal; some, especially a tete-a-tete between proudly un-woke McNeal and a young female Black reporter at the 
New York Times (Brittany Bellizeare, a standout) whip up propulsive, left-field tension as the novelist plunges 
deeper into the whiskey bottle. (Michael Yeargan and Jake Barton’s evocative sets cover both, most pleasingly 
released in a luscious bookshelf full of both real and made-up titles.)
But as the chapters build, the narrative cohesion slackens. For each interlude deliberately muddies the waters by 
introducing the prospect of AI-generated material – Downey Jr’s voice, as McNeal, prompting the machine for the 
scenes we are about to witness and providing personal material to synthesize. Eventually, the projections deliver 
dialogue as deepfakes of McNeal and his late wife/former paramour (Melora Hardin). (The program credits the 
“digital composites” to the company AGBO.)
Akhtar, a Pulitzer-winning dramatist (in 2013, for Disgraced) and novelist, has dressed up a reliably grating 
inclination – a writer writing about writing – with the mind-bending and reality-questioning drama of our fears with 
AI. The framing devices don’t need to do much to touch on, without spoiling, the lines between inspiration and 
exploitation, between borrowing and theft, between assistance and cheating. Although delineating it this way feels 
like I’m giving the play too much credit – McNeal at most nudges these fault lines, seemingly chuffed with bringing 
up the topic as an end unto itself.
Downey, operating firmly in his lane of wise-cracking, sardonic charisma, is at least never less than compelling, and 
thankfully on stage for almost the whole show; the whole exercise is worth it to see an actor in peak, seemingly 
easy form. He sells McNeal both as a narcissist spiraling at the end of his road and as a provocation of AI’s blurry 
ethical lines. Such provocation contains little insight, beyond that AI is scary and could make things worse; perhaps 
McNeal’s most interesting idea is the unoriginal notion that generative AI will enable narcissists, or that it will allow 
people to express themselves through an artistic medium without putting in the hard work of craft.
McNeal ends on a confounding note, explicitly invoking the question: what is real, and how do you know? One 
could generously read the play’s descent into confusion as a meta treatise on what a world full of AI slop and 
questionably generated material will wreak on our perception, tenuous as it is already. One could also say that it’s a 
bit of unearned ambiguity. Our standards haven’t fallen so far yet as to not hope for art with a clear vision.
Load-Date: October 1, 2024
End of Document
Page 1 of 4
The AR and VR headsets you'll actually wear
The AR and VR headsets you'll actually wear
 
Africa Newswire
September 30, 2024 Monday
Copyright 2024 Africa Newswire All Rights Reserved
Length: 1748 words
Body
 30 Sep 2024 (TourismAfrica2006) Hi, friends! Welcome to Installer No. 54, your guide to the best and Verge-iest 
stuff in the world. (If you're new here, welcome, so psyched you found us, and also you can read all the old editions 
at the Installer homepage.)
This week, I've been reading about AI slop and sports betting and Jony Ive, clearing my schedule for the new 
season of The Great British Bake Off, watching Sicario and Pirates of the Caribbean and A Quiet Place: Day One 
on plane-seat screens like their directors intended, insta-subscribing to Hasan Minhaj's new YouTube show, and 
just relentlessly trolling people with Vergecast clips through Pocket Casts' new feature.
I also have for you a couple of new Meta gadgets, the mobile game that will eat up all your free time, a couple of 
hotly anticipated new movies, the best Spotify feature in forever, and much more. So much going on! Let's dig in.
(As always, the best part of Installer is your ideas and tips. What are you into right now? What should everyone else 
be reading / watching / playing / trying / building out of clay this week? Tell me everything: installer@theverge.com 
And if you know someone else who might enjoy Installer, tell them to subscribe here.)
The Drop
Meta's Quest 3S. My biggest issues with the Quest 3 were the price and the passthrough, and this new model 
appears to have solved both. It's back in "totally reasonable game console" range, and the passthrough demos 
looked much sharper than before. They look great, though not as good as...The limited-edition Ray-Ban Meta 
Wayfarer. I already own two pairs of Meta's smart glasses (don't ask), but I am still lusting over this clear pair. 
They're more expensive, and they actually undo some of the good non-gadget vibes of the other models, but they 
look so good. Balatro Mobile. This might be the most recommended thing in the history of Installer - I swear, every 
week someone tells me how much this poker roguelike has taken over their life. And now it's on your phone! $10, 
no data collected, no microtransactions, my screen time is about to go through the roof.Wolfs. This Clooney-Pitt 
Apple TV Plus movie has a fascinating backstory that says a lot about the future of Hollywood, but I also just love a 
big-budget flick in which movie stars say cool lines in cool ways. This appears to be exactly that.The new Roku 
Ultra. I helped review the Google TV Streamer this week, and I really love that thing. But I'm also psyched to see 

Page 2 of 4
The AR and VR headsets you'll actually wear
Roku keep pushing - the new one's not reinventing the wheel, but it's faster and better, and that is a very good 
thing.The Wild Robot. I'd really like to tell you to go see Megalopolis this weekend, but every single indication is that 
the movie is hot garbage. But people seem thrilled about this one, an animated flick about a stranded robot that 
sounds adorable and delightful and like something I'm going to end up watching 100 times.The Legend of Zelda: 
Echoes of Wisdom. A Zelda game... in which you get to play as Zelda. That's the dream! This game doesn't seem 
to be as big or awe-inspiring or platform-defining as Breath of the Wild or Tears of the Kingdom, but it sounds clever 
and fun just the same.Spotify's AI Playlist feature. This is terrible news for my relentless quest to quit Spotify: the AI 
playlists are great. Now that the feature is available in the US, I've been using it to name a few bands or songs, plus 
an overall vibe, and it picks a few dozen songs that, at least so far, always seem to hit. Spotify is very, very good at 
this part of the music game.Social Studies. Being a kid is hard work. And this doc digs in with a group of students 
on how much... maybe not always harder, but definitely more complicated, social media has made being a kid in 
2024. This comes from a good team, too, and I'm excited about it.The Nothing Ear Open. Nothing's headphones 
have been really solid, and as a recent and aggressive convert to open earbuds, I'm pumped to see how these 
sound. They look so cool, too! Big week for clear gadgets.
Screen share
Fun fact: Joanna Stern is the main reason I ever got a job at The Verge in the first place. (That story is long and, if I 
remember correctly, involves her playing a fairy in a video? But I promised her I wouldn't tell that story.) These 
days, she's a columnist at The Wall Street Journal, an Emmy winner, and most recently, the creator of Joannabot, 
the AI chatbot that will tell you everything you need to know about the iPhone 16. (And apparently also do some 
other things, if you're clever enough, but again, we'll leave that alone.)
I asked Joanna to share her homescreen because she just reviewed the iPhone 16, which means she just had to 
set up a homescreen. And because she's forever using new gadgets and switching between things, I was curious 
what always made it to the top of the pile.
Here's Joanna's homescreen, plus some info on the apps she uses and why:
I'm submitting my homescreen and my Control Center screen because I'm proud of the work I did on the Control 
Center. I may submit it for an award. But really, I'd like to just use this as a forum to complain about the all-in-one 
connectivity widget in the new Control Center in iOS 18. I don't like it. I like the single buttons so I can easily just 
turn them on and off or long-press to get in there. Sadly, they have gotten rid of the single Wi-Fi button, but I read 
on this great website that it's coming back in iOS 18.1.
The phone: iPhone 16 Pro Max.
The wallpaper: This is my dog Browser. It isn't the best shot of him, but the framing is nice for putting him in the 
middle of the screen. My lockscreen wallpaper is this awesome retro iPod made by a designer named Shane 
Levine. I bought it through this site last year after featuring it in my newsletter.
The apps: WSJ, ChatGPT, Apple Notes, Google Maps, Google Docs, Google Calendar, Instagram, YouTube, 
Clock, Threads, Signal, Photos, Slack, Spotify, Phone, Safari, Messages, Gmail.
My apps are so basic and make me feel so basic. I work (Slack, Gmail). I message (Messages, Signal). I listen and 
watch things (YouTube, Spotify). I social media (Threads, Instagram). I work more (Google Docs, WSJ). If it isn't on 
this main homescreen, I usually just search for it.
Before iOS 18, I had a widget stack on the homescreen with weather and time zone widgets, but I moved it off to 
another screen. I might move it back. I might not. Got to live a little.
I also asked Joanna to share a few things she's into right now. Here's what she shared:
The Devil at His Elbow. I'm currently listening to this audiobook by my wildly talented colleague Valerie Bauerlein. 
It's all about the Murdaugh murders. The writing, the details, the whole thing, is so gripping. I find myself just sitting 
in the garage waiting until a chapter is done.Full Swing. I know I'm late to Netflix's popular golf-u-series, but I started 
Page 3 of 4
The AR and VR headsets you'll actually wear
playing golf again this summer, and I'm loving the stories of these players and how psychological the sport really is. 
Take Your Pet to School Day. My 3-year-old loves this book. I don't want to spoil it, but the pets take over Maple 
View Elementary, and, well, Ms. Ellen is pissed.
Crowdsourced
Here's what the Installer community is into this week. I want to know what you're into right now as well! Email 
installer@theverge.com or message me on Signal - @davidpierce.11 - with your recommendations for anything and 
everything, and we'll feature some of our favorites here every week. And for even more great recommendations, 
check out the replies to this post on Threads.
"Sliding Seas. It's a match-three (or four!) game but also so much more: there's real strategy required behind your 
moves to beat levels at the higher end, but it's never unfair, and while there are in-app purchases and power-ups 
you can buy to make a level easier, you crucially never need to. It is the most compelling and well-suited-to-mobile 
game I've ever found and a gem I recommend without reservation." - Jamie
"Gisnep is another daily puzzle game, this time by David Friedman of Ironic Sans. It appears as a crossword-esque 
grid, but the words only go across and wrap around. The goal is to reveal both a quote and the source by filling in 
letters from vertical columns. I've gotten a number of my friends hooked already." - Kyle
"Satisfactory 1.0 launched a week ago or so. A great group of devs have effectively made a game that feels like 
work but is fun. If you love conveyor belts and staying up all night, this might be for you." - Matt
"Can't believe you haven't mentioned switching to OmniFocus! As a fellow perennial 'task manager switcher,' this 
app is a staple in my rotation." - Pedro
"I previously recommended App in the Air as a great travel companion, but unfortunately, it's shutting down. If 
you're looking for an alternative, Flighty is excellent, especially for travel stats, and they're building an importer for 
App in the Air users." - Vivian
"We've been watching English Teacher on FX. Constant laughs and, so far, each episode has been better than the 
last. Easily one of the funniest shows on TV right now." - Danial
"I was gifted the Humanscale FR300 Ergonomic Foot Rocker, which is a very tech-sounding name for a very 
manual / mechanical rocking footrest. It's very pleasant to use. I've also been standing on it sometimes... which I'm 
not sure is safe but sure is fun!" - Wisdom
"Repeatedly putting in my Amazon cart the Black Milanese Loop for the Apple Watch Ultra 2. I was so close to 
buying it like three times. Now it's out of stock. Even Apple says early November for shipping." - Scott
"Been playing with different LLMs using LM Studio. Integrated it into my Obsidian vault to help summarize and 
organize things into specific formats. It's been extremely cool!" - Cody
Signing off
I've had back-to-back-to-back-to-back trips over the last two weeks, and I would just like to quickly shout out my 
new No. 1 travel hack: a wall charger that doubles as a big-ass portable battery. I have this Anker model, which is 
$55, charges a USB-C and a USB-A device simultaneously, and also charges itself so I can get 10,000mAh of 
power when there's no outlet nearby. (There's also a newer one with two USB-C ports and even faster charging but 
less battery capacity.) It's huge and heavy, but this thing and a long cable are now the only charging gear I travel 
with, and they're the only reasons my gadgets have survived trains and plane rides. Here at Installer, we love a 
sensible charging strategy, and this is as sensible as it gets.
Load-Date: October 1, 2024
Page 4 of 4
The AR and VR headsets you'll actually wear
End of Document
Page 1 of 2
'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI art
'So lame of you guys': Legendary 80s band infuriates fans over new album 
cover's AI art
BGR
September 28, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 441 words
Byline: Andy Meek
Body
Back in the day, people dogged Tears for Fears for ripping off The Beatles with songs like Sowing the Seeds of 
Love. So much so, that Paul McCartney himself once acknowledged during a press conference that the first time he 
heard the song, he thought: "Who are they kidding?"
So it probably shouldn't come as a surprise that the same band now apparently seems fine with typing some dumb 
prompt into an AI image generator (I'm guessing "astronaut in a field of flowers") and using the resulting soulless AI 
slop as the cover of their new album, Songs for a Nervous Planet. Rather than, you know, using a pittance of their 
considerable fortune to pay a human artist to do the work. Seriously, guys, "have you no idea how the majority 
feels?"
That's a rhetorical question, by the way. Not only does the band know, but they've also responded to the predictable 
outcry with a statement that blathers on about AI being "one of the many tools used in the creative process" for the 
album cover, a statement that appears to have been written by an actual tool.
SONGS FOR A NERVOUS PLANET.OUT OCT 25.Pre-order and listen to "The Girl That I Call Home" now. 
https://t.co/8rP6k9e7ug #songsforanervousplanet pic.twitter.com/PaAl4NCmSW
- Tears for Fears (@tearsforfears) September 12, 2024
Tears for Fears' social media posts announcing the highly anticipated new album, which drops on Oct. 25, have 
been flooded with negative comments from fans angry about everything from the lifelessness of the AI art - with its 
too-smooth, plastic-y feeling and lack of fine detail - to the usage of AI in general. "It's honestly embarrassing that 
you're using an ai album cover," one user wrote on the band's Instagram post. "You obviously have the money to 
pay an artist for an album cover, yet you still chose to just type in a prompt and have a computer plagiarize art 
instead?" 

Page 2 of 2
'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI art
Added another: "Using AI art is such a joke. You guys are a legendary band and you chatGPT your album cover? 
Phone it in a little more man."
PSA to any more beloved bands out there: If you're going to resort to using AI for anything, at least do what The 
Beatles did with their new song Now and Then and steal from yourselves. Anything else, and you'll deservedly get 
what's coming to you. "I can't wait until someone makes an all ai album by stealing your music," another angry 
Tears for Fears fan wrote on the band's Insta. Likewise, the fan who added: "the ai cover is so lame of you guys."
Don't Miss: I never trusted Sam Altman. I trust OpenAI's overhyped CEO even less now.
The post 'So lame of you guys': Legendary 80s band infuriates fans over new album cover's AI art appeared first on 
BGR.
Load-Date: September 28, 2024
End of Document
Page 1 of 4
Is anyone out there?
Is anyone out there?
Prospect
September 25, 2024
Copyright 2024 Prospect Magazine All Rights Reserved
Length: 2393 words
Byline: James Ball
Body
If you've ever walked a city street so late at night that it's very early in the morning, you may have been greeted by 
a strange and unbidden thought. In the eerie stillness, it can feel for a moment as though you're the last person 
alive. The usual throngs are gone, and the absence of what should be there is impossible to ignore-until some other 
person, off to start their working day, breaks the spell. The world is still there.
It is hard, in any real-world city, to maintain the illusion of being the only person for any length of time. But the 
internet is different. There is always an element of unreality to an online interaction with another human: how do we 
know for sure that they are who they say they are? Can we be certain they're even actually a person?
This is the idea at the core of what became known as Dead Internet Theory, a joke-cum-conspiracy that says if 
you're reading these words online, you're the last person on the internet. Everyone else is a bot. The other 
commentators on Reddit? Bots. The people in the videos or the podcasts you listen to? Bots. What's filling the junky 
websites that we all can't help but click? You guessed it. They're all bots, and you're the guinea pig in the perverse 
experiment of some unknown power.
Dead Internet Theory is, if anything, a thought experiment. We've learned that we can't necessarily trust what we 
read or who we meet online-so what happens if we take that notion to the extreme? If you were the last actual 
human on the internet, how long would it take for you to notice?
The idea began to gain traction almost a decade ago, with the "time of death" of the internet typically given as being 
around 2015 or 2016-but in the years since, reality has begun to mirror this once unserious conspiracy. The 
complaint of the modern internet is that it is filled with "slop" content, the spiritual successor to email spam. Low-
quality content-such as trashy viral images or regurgitated news articles-created by artificial intelligence is filling up 
social media, search results and anywhere else you might look. But while junk memes are near impossible to avoid, 
they are just the most visible sign of the AI detritus that is coming to dominate our online worlds.

Page 2 of 4
Is anyone out there?
In reality, the internet is bots all the way down. Automated systems generate fake but clickable content. Bot 
accounts like and comment, boosting the slop in the algorithms of social media sites and search engines. 
Clickfarms monetise the whole endeavour, posing as real users with real eyeballs and thus earning advertising 
revenue. In this way, the web is being taken over by a global, automated ad fraud system, and whether or not any 
human sees any of it is entirely irrelevant. The things that generate real value for us are being pushed further and 
further to the margins, unable to compete with this brutal new algorithmic reality.
The most obvious destination for slop is Facebook, a social network that has been seen as dated and perennially 
naff for at least a decade, but which nonetheless counts more than a quarter of humanity as its users-even if many 
don't log in quite as often as they used to.
If you do check your Facebook "Suggested for you" feed, though, you're likely to find it chock-full of AI-generated 
slop: mostly images that don't pass for real after even so much as a cursory glance, but which nonetheless 
generate tens of thousands of likes.
For a while, the trend was for images of what looked like wood or sand sculptures and their artists, with captions 
such as "made it with my own hands". At another point, bizarre images of Jesus were du jour. One image of "shrimp 
Jesus" portrayed Christianity's saviour as a crustacean. This was followed by pictures of US veterans, beggars or 
children looking miserable with birthday cakes, usually in strange locations, captioned with "why do images like this 
never trend?" The latest fad is for pictures of grotesquely emaciated people holding out begging bowls, often with 
strange skeleton or snake-like appendages. The nature of the junk memes changes, but it is always bizarre and 
lacking in any obvious purpose.
The independent journalism startup 404 Media has done more than anyone else to work out what is behind the 
apparently unstoppable slew of AI-generated slop on Facebook. The answer is a sign of what's gone wrong on the 
internet and indicates how difficult it will be to fix: ultimately Facebook is funding the content that is destroying the 
value of its own network.
Behind the accounts posting slop on Facebook are entrepreneurs, of sorts, working out of countries including India, 
Vietnam and the Philippines, where internet access is widespread but incomes are relatively low. Here, the 
advertising revenue from a viral Facebook meme page is much more attractive relative to an average salary than it 
is in a country such as the UK.
These "creators" are often trained through online seminars which are themselves promoted through AI-generated 
content. As 404 Media reports, they are instructed to share "emotional" content to generate likes, comments and 
shares, but many boost this type of material either through artificial accounts or by partially hijacking real user 
accounts.
Some users who persistently comment on AI slop appear to have two personalities, effectively because they do. 
One "persona"-the real person-comments as usual on their local interest groups. But their account, which has been 
compromised without them noticing, also posts generic, AI-generated comments on thousands of pieces of AI-
generated slop. This is a kind of benign hacking, in which bots piggyback on an account, letting the real user go 
about their business while using it to boost their content-a parasite for the digital era.
The motive is, of course, money. Facebook slop is monetised in two ways. Meta, which owns Facebook, shares 
revenue from the advertising it shows alongside the content of major creators. This means that if AI meme pages 
generate a big and apparently real audience on the site, Facebook itself pays the page creators. But if Facebook is 
the laboratory in which slop developed its strength, it long ago leaked into the wider internet ecosystem. Many 
pages direct users elsewhere, onto the web proper, where more money can be made. It is here that junk content for 
junk clicks reaches its natural and inevitable peak.
In his 2008 book Flat Earth News, the journalist Nick Davies identified a new scourge of the journalism industry, 
brought about by the internet era. Junior staff at local and even national newspapers were being asked to generate 
huge numbers of online stories at a relentless pace.
Page 3 of 4
Is anyone out there?
Instead of going out to speak to people or do original reporting, journalists would be required to produce a story 
every hour, or even every 45 minutes, by simply rewriting other people's work. Davies popularised a name for this 
phenomenon-"churnalism"-and pointed to the obsession of bosses with generating online clicks for advertising 
revenue as its cause.
If a hasty rewrite produced at virtually no cost could generate as many views-and so as much online revenue-as an 
original investigation, why bother producing the latter? The churnalism phenomenon hollowed out newsrooms and 
replaced accountability journalism with articles such as "What time does Strictly Come Dancing start tonight?" and 
"What other shows has Olivia Colman been in?", designed to lure in audiences from Google.
Sixteen years on, newsroom bosses are reaping what they sowed with the race to the bottom, pursuing cheap 
content to satisfy only the most casual of online browsers. Executives learned that if online clicks are all you care 
about, most of the journalism can be discarded. Their successors realised something more: the newsroom itself can 
be thrown away. Instead of having a real media organisation, you can churn out rewrites using ChatGPT and other 
AI tools, which can even build a credible looking news site itself.
These imposter news sites are generally harmless bottom feeders, trying to make their owner a living through ad 
views, but occasionally they cause serious trouble. One such site, Channel3Now, based in Pakistan, was among 
the earliest boosters of the false story that the attack on girls at a Taylor Swift dance class in Southport had been 
perpetrated by a Muslim asylum seeker. This disinformation sparked riots and widespread public disorder in the UK.
In a world where ad revenue is all that matters, the first realisation was that journalists were optional. This was 
followed by the understanding that the news site didn't need to be real in any meaningful way either; anyone can 
create something that looks newsy enough to hook people in. There was only one obvious next step: if neither the 
content nor the site has to be real, why does the audience need to be?
Faking page views is an online arms race. Brands rely on advertising networks (which include Google and 
Facebook, as well as companies you'd never have heard of) to actually reach their potential customers. The brands 
pay for views, and so are very keen to make sure that every view is an advert seen by a living, breathing human.
The incentives for the middleman are less clear. They need to do enough to satisfy the brands to keep spending, 
but they are paid by the click, just like the creators themselves. Ad networks quickly cracked down on easy-to-spot 
"clickfarm" behaviour-setting up a computer to constantly click refresh on the same page, for example-but fakers 
learned increasingly sophisticated means to bypass security precautions. For a time, operations working out of 
countries such as China would pay workers to essentially browse the internet on rigs of five to 10 smartphones at a 
time, generating clicks on sites at a relentless pace for shifts of 12 hours a day.
These operations became automated and professionalised, abolishing what was surely one of the dullest and most 
repetitive jobs in the content industry. Today, these clickfarms are formed of tens or hundreds of thousands of sim 
cards, which imitate real mobile internet browsing, generating millions of apparent ad impressions every hour.
This completes the soulless lifecycle of the modern internet economy. People desperate to earn a meagre living 
create automated systems that churn out low-quality or outright fake content. Others create dummy accounts to 
boost and share such content, or fake users to read it. All of this is done to milk some money out of real-world 
brands. Along the way, it enriches the internet giants that operate all of the machinery.
Real people and our needs have become irrelevant to the business model of the modern internet. If something 
interests us, our clicks pay just the same as a fake user in a Chinese clickfarm. Good content is relegated to the 
sidelines, to people who are able and willing to pay for the real thing. Original reported journalism is increasingly 
siloed behind paywalls that are, themselves, getting ever harder. Everyone else is force-fed slop, because there is 
no value in giving them anything better.
The journalist and activist Cory Doctorow christened this phenomenon the "enshittification" of the internet, and 
argued it was an inevitable result of the business model of the modern internet age: hooking people in on a free or 
subsidised product, getting a monopoly and then starting to extract as much profit from that product as is possible. 
Page 4 of 4
Is anyone out there?
As consumers, we get hooked on a product-be it a cheap taxi ride, a holiday, food delivery or human connection 
through social media-that is genuinely too good to be true, because it's being subsidised by billionaire investors. 
Then we watch it steadily get worse.
That extends well beyond online browsing. Ridesharing apps such as Uber, Lyft and their competitors captured the 
private hire market by drastically undercutting the cost of existing taxis, while initially paying drivers at least as much 
as they had before. Once the market was captured and the old incumbents had given up, first the drivers were 
screwed by declining incomes, and then customers faced higher prices. The apparently great new service could 
never have actually lasted in the long term. This story plays out in almost every other venture capital market, from 
subscription boxes and fast food or grocery delivery, to Airbnb and WeWork.
The era of a gold-plated service at a rock-bottom price never lasts. Eventually, the real costs come back, the 
investors want to make money, and reality reasserts itself. Silicon Valley relies on selling us a dream it knows from 
the outset cannot last.
It could have been better than this. Both the internet and the world wide web predate the Silicon Valley era which 
propelled startups into becoming the richest and most powerful companies on the planet. The technology works as 
it ever did-making it incredibly quick, cheap and easy for us to connect to each other, and to publish what we wish. 
The AI slop didn't need to take over. The fact that it has is the result of a series of choices.
The joke of the Dead Internet Theory was that everyone else online might have disappeared, and you could be left 
alone without noticing. In the decade since the idea caught on, emerging technologies have been harnessed almost 
as though this is the goal. Humanity has become irrelevant to the business model of the internet, and so we're 
getting relegated to the sidelines.
Facebook feeds that used to be full of real information and real stories about people from our real lives are now full 
of low-quality and freakish engagement bait. It is no surprise that many of us, as a result, are looking elsewhere. 
Google results keep getting worse, social media feeds are full of dreck, and it is impossible to know what to trust.
None of the internet giants seem to even see the problem, let alone a way to fix it. Instead of trying to rebuild 
internet services to their former glory, they are packing in more AI and automation, and, inevitably even more slop. 
But an internet built for the bots is doomed to fail: in the end the economy is made up of the collective efforts of 
humans, not anything else.
If the multi-billion-dollar companies running the internet don't make it fit for humans, someone else will. However 
much it might feel that way, the internet is no emptier than the streets of London. We're all still there, just out of 
sight.
James Ball is political editor at the New European
Load-Date: September 23, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 2:30 PM GMT
BBC Radio 4 - 2:30 PM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 772 words
Body
Speech to text transcript:1
on BBC Radio 4 with me Russell, top actor and art enthusiast serialism has been called the special effects 
department of psychoanalysis. It gives us an image of how we dream and it gives us an image of the unconscious. 
Where did this mind-bending movement come from and how has it entered everyday life to become more relevant 
than ever? It's the idea that there is something going on in your mind of which you are not aware, but is actually 
hugely important and influential. 
Surrealism remixed on radio form. And BBC sounds starts next Tuesday afternoon at 4. Now on radio in the 
artificial human we discover why utterly bizarre AI images are swarming social media. Hi, I'm Alex Petoskey and I'm 
Kevin form, and this is artificial human where we answer all of your burning questions about AI. So Alex is this 
weird email in the program in book right now that says hey there, Alex and Kevin. Why is my grandma's Facebook 
full of Shrimp Jesus. It's weird cheers. There's no name on the end of it I suspect suspect should probably have 
gone to Spain. It's interesting. You say no, no, no, no, it's m, but I don't even understand the words in that email. If 
I'm being honest, this is your entry into the wonderful world of AI slop. Kevin, welcome a slob which. Shrimp Jesus 
is a kind of emblem of this at the minute. Shrimp Jesus is an image, an AI generated image of Jesus Christ as a 
crustacean. I don't know what the prompt was. It created it, but it is everywhere on social media right now, and it's 
not just Shrimp Jesus's everywhere. It's all kinds of different, very weird, low quality yet hyper-realistic images. 
You've probably seen them like grandmothers with 3000 candles on a birthday cake, or pictures of like little kids 
who seem to be artistic prodigies and have made these incredibly realistic portraits of themselves just weird, weird 
stuff and what. And that's populating some grandmother's time line yeah. Yes, yes, it is in fact it's populating a lot of 
grandmothers and a lot of everybody's timelines, particularly on Facebook. I suppose you know you mentioned 
spam earlier in whether this email should have gone into spam. It's actually a slop is actually a new form of spam. I 
suppose you could call it well. It certainly sounds weird. Wonder you're not winning me over with it. It's absolutely 
wonderful, Kevin, genuinely, it's it's wonderful, but the fact is is that it's everywhere. Okay, well, it sounds like we're 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 2:30 PM GMT
going to answer this 1. What is a slop? Does it threaten us? Does it threaten the future of the Internet, as we know, 
does it threaten the grandmothers? All of these are really good questions, but big. I've never studied it I've been the 
recipient of it. I think we should dig into it would be kind of fun. Yeah, you do that. In the meanwhile, I'm gonna jump 
in a tardis and go back to the time when the Internet was full of people showing pictures, the cats and sharing 
recipes. Barna, thank you so much joining us today just to get us going. Give us your full name and any job title and 
affiliations that you have. So my name is Rene Deta. Until recently, I was the technical research manager of 
Stanford Internet Observatory and I'm the author of the book invisible rulers the people who turn lies into reality. I 
have studied what we call adversarial abuse online for just about a decade now, and that means looking at new and 
novel ways in which people who might set out to manipulate the public use online technologies to do it. Sometimes 
that might be state actors. A lot of the work I've done has looked at you know, things like Russian troll factories, but 
sometimes it's a little bit more mundane and it's people like spammers and scammers who use those same 
technologies, but they're financially motivated rather than ideologically motivated spammers and scammers. But 
there's a new category isn't sloppers, and this is such an interesting question. When I first started looking at the 
proliferation of AI generated content, a lot of it really began with people using it for arts early 2020 the, I think, and. 
You just saw this excitement around what we could all do with these technologies, and then gradually, interest kind 
of dropped off and you started to see these weird pages really begin to grow in popularity, as financially motivated 
folks realized that they could use these tools too. We were asked specifically about one piece of a content Shrimp 
Jesus, OK, can you tell me a little bit about Shrimp Jesus and also a little bit about why
Load-Date: September 25, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 08:00 AM GMT
BBC Radio 4 - 08:00 AM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 812 words
Body
Speech to text transcript:1
The Prime Minister has urged British people to leave immediately, saying he fears the region is on the brink of war. 
Cross-border fire between Israel and Hasballah, which is based in Lebanon, has intensified. The group has been 
prescribed as a terrorist organisation by the UK Government. Our senior international correspondent, a Garin, is in 
the southern Lebanese city of Tyre. 
She says people are preparing for the worst. Schools have been designated as temporary shelters, though people 
have somewhere to go, but I think the biggest concern they have is that the I cannot tell how long this is going to go 
on. Everybody believes we're in the early stages of something with this extraordinary way. Eve of Israeli attacks that 
began on Monday, more than 500 Lebanese killed in a single day. I think most people are expecting that there will 
be an escalation of some kind. Israel says it's intercepted a missile fired towards Tel Aviv from Lebanon. It's thought 
to be the first time he ba has targeted the city. The man accused of trying to kill Donald Trump at his Florida golf 
course earlier this month has been charged with a 10. The assassination of a major presidential candidate, Ryan 
Ruth, hasn't entered a plea, but had left a note describing his intentions. The Prime Minister has signaled plans for 
a major shakeup of the welfare system, saying almost all benefit claimants should be expected to look for work. 
Speaking to the today program, he said the government and businesses should support people to re enter the 
workplace, but that ministers wanted to tackle those abusing the benefits system. The basic proposition that you 
should look for work is right. But we also want to support that so that more people can get into work. But I'm also on 
benefit fraud. We do need to be clear about benefit fraud and that we need to tackle it much more effectively. A 
global study suggest one-third of children and teenagers worldwide are now shortsighted. Researchers say data 
collected from 50 countries shows eyesight got worse during COVID lockdowns, when children spent more time 
looking at screens. BBC news this is BBC Radio 4, where a new series of the artificial human begins. This 
afternoon we'll be diving into the weird, wonderful and rather murky world of of AI slop that's mass produced low 
quality AI images to you and me, and they've spread like wildfire across social media platforms. We'll hear more 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 08:00 AM GMT
about Shrimp Jesus, one of the most prominent and bizarre examples here on radio this afternoon at 3 30 but first. 
Hello and welcome to more or less were a statistical Lighthouse. Piercing the darkness of numerical confusion and 
allowing you to safely reach the harbour of rationality ought to put it another way we're a radio program about 
numbers and clear thinking. I'm Tim Harford This week. The Government is encouraging pensioners to claim 
pension credit in order to remain eligible for winter fuel payments. Will people sign up, and might that end up 
costing the Exchequer more than it saves? The Office for national Statistics has downgraded the status of a new 
statistic aiming to measure how many people are transgender. We ask what went wrong. Cancer appears to be on 
the rise in the under fifties. Why and how worried should we be? And here's a puzzle for you to think about. If it 
takes a hen and a half a day and a half to lay an egg and a half, how many eggs to half a dozen hens lay, and half 
a dozen days later in the program puzzle prankster Alex Bellos will join us with the answer. Let's start with winter 
fuel payments. The Government, as we've noted before, is very concerned with filling a black hole and the public 
finances which they say is 22 billion pounds deep. The first attempt to start filling that hole was the announcement 
that they were cutting the winter fuel payment. It currently goes to all pensioners and new plan is that only the 
poorest on pension credit will get the one-off payment of 200 or the 100 pounds each winter. The government 
reckoned this cut could save them 1.5 billion pounds. But that raises a question. If the change in the rules prompt 
people to start claiming pension credit, perhaps the cost of all the extra pension credit payments will swallow up that 
saving or at least nibble away at it. So how many people might start claiming and how much might they claim? 
Money Box presenter and national treasurer Paul Lewis, has been running some interesting numbers. Hello Paul, 
hello, Tim. So the Government cut winter fuel payments for all pensioners except the pensioners who claim pension 
credit, and we know there are lots of pensioners who are eligible for this benefit and who don't claim it. So how 
many potential claimants are there out there who aren't
Load-Date: September 25, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 2:00 PM GMT
BBC Radio 4 - 2:00 PM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 860 words
Body
Speech to text transcript:1
at least 23 people are known to have died and dozens of others have been injured. It comes hours after the group 
fired a missile towards the Israeli city of Tel Aviv. It was the first such attack and is said to have targeted the Israeli 
security agency Mossad. Although the missile was intercepted. 
The Prime Minister Seko Stamer, who's in New York for an emergency meeting on the conflict, says he's very 
worried about the escalation of fighting. All parties need to pull back from the brink to de-escalate. We need a 
ceasefire, and this needs to be sorted out by diplomatic means. I am very concerned about the increasing 
escalation, which is not just day on day, but almost hour on hour. At the moment, rail workers with the R. M. T. 
Union have accepted a pay deal ending a long running dispute which has led to multiple strikes. Members agreed 
to a 4.5% pay rise for this year for workers at Network rail, and the train companies and staff at the train operators 
will also receive 4 point seven, 5% for last year. The Health Secretary West treating says teams of senior doctors 
will work across the? NHS in England to bring in reforms aimed at getting people treated more quickly so that they 
can get back into the workplace. Around 2.8 million people are out of work due to ill health. Weather warnings have 
been issued for more heavy rain for tomorrow and Friday as flooding continues in parts of England and Wales. 
Firefighters and police rescued residents last night at the Billing Aquidrome holiday Park in Northamptonshire, while 
a nearby leisure centre opened up as an overnight refuge, and Philip Schofield is making a return to TV more than 
a year since quitting it. Ves this morning he'll appear in Channel is cast away where he'll be stranded on an island 
off Madagascar for 10 days. In the trailer he admits not disclosing an affair with a younger colleague was unwise, 
but he questions whether this should be absolutely destroying someone. BBC news we'll discover some prominent 
examples of low quality AI images, known as AI slop, that have spread across social media in the artificial human 
here on radio in half an hour but first. It's money box live with Felicity Hanna hello across the UK, thousands of 
teenagers are busy picking out posters, making new friends and settling into life at university, but graduates in 
England leave UNI with average debt of around 48 and a half 1000 pounds. That's according to the student loans 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 2:00 PM GMT
company. So how is this year's freshers feeling about their finances? I feel like I been Sally being really tight with 
my money because I'm quite indy with it us, because I know the cost. I'm definitely going to be looking. To get a 
part time job, the student loan I have is just not enough. The only thing I really like fought from a flat was like like an 
airfare or something like that that's, that's crazy wish that you're picking up right. It was only though I thought that 
was quite good flat just because so upbeat fresh is searching for jobs and air fries there. But research from the 
Credit reference agency experience claims 80% of students say money worries are causing them significant stress. 
So this week we're looking at how much a degree really costs. Has the price made you think twice. Maybe you 
chose an apprenticeship instead, or maybe you don't mind your loan repayments because you've got your dream 
job get in touch now with your questions or your comments were money boxatbbc-dtcotuk now we'll meet our 
experts in just a couple of moments but first of all let's hear from some students at the university of manchester 
money box producer sarah rogers has been there to meet freshers at the student union as they queued up to try 
and win some freebies so we're giving students a chance to spin the wheel and everything on there is the prize 
completely free to participate and they can walk away with anything from sweet to a lanyard to a box of teeth and 
you're in the queue for a lucky dip so you spin the wheel what you hoping to win anything other than horrible it is 
horrible fresh weent know we're talking about we've been staying inside watching films did the cost of the university 
and make you think twice about coming i think it's at such a ridiculous level though i don't even consider it anymore 
that it's just an ungraspable like a mount i suppose like monopoly yeah basically it doesn't mean anything to me i 
don't know yeah well you have to work whilst you're at university yeah probably i spent the past year saving money 
at my job to save university yeah i've managed to find a job that i'm going to start doing yeah because i mean it's a 
little bit too expensive the student loan doesn't come very much so i'm going to have to survive somehow so you 
have just arrived in manchester this weekend just went straight out to find a job well i was like kids in at the fair here 
actually have you got budgets have you got site if you finance it so i mean when i'm not trying to look at my banco 
too much to be honest when timetables when fresh is
Load-Date: September 25, 2024
End of Document
Page 1 of 2
BBC Radio 4 - 2:55 PM GMT
BBC Radio 4 - 2:55 PM GMT
TVEyes - BBC Radio 4
September 25, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 757 words
Body
Speech to text transcript:1
involved would know until they're suddenly not making any money, and people used to be making $400 for a super 
viral image now they're showing their little Facebook panels. Like many of these videos, they will pull up the sort of 
back end that shows how much money they're making per photo and they're making like $0.06 $0.12, and so there 
is anecdotal evidence at least, that Facebook has altered its payouts and that this is no longer very lucrative. It feels 
to me a little like into the gold rush of you know, the late 19th century whereby everyone said the fields of gold you 
can pick up gold on the floor, but you couldn't, and the the vast majority of people who rushed into the gold fields 
went bust right the people who made all the money with the people who sold shovels and hotel rooms and made 
boats by the river. Is that what's happening here?
 It's the perfect analogy, in my opinion, because you have these Youtube influencers who are saying you can get 
rich quick, doing this just you know, listen to me, but also by my course for you know, a few dollars or sometimes 
more than that, and they're sort of racking up the hundreds of thousands or millions. Of Youtube views and those 
are monetized and those people seemingly like have it all figured out well. Kevin, I did not expect Shrimp Jesus to 
lead us here is amazing, amazing as one word, isn't it? Having not heard of the term pilot before we started making 
this program, I'm now moderately concerned about it right. So this is this is the very essence of that Star Trek 
episode with the triples you know where they had those cute very creatures where we're curious to look at kind of 
fun, and then they start multiplying and multiplying and multiplying until every thing is trying in them and nothing 
gets done, and this reminds me absolutely of that. And there's something a little darker, I think, in the stories that 
we had. there from Jason in so far as the way that so this offers a law to the global South that is false, which is that 
this is a digital inroad to the global North and a way of securing some of their wealth through this ridiculous and 
surprise when Jason has found that that's no longer true. And the only people who are making the money of awful 
middle men in that yeah, in fact, interest, tingly and perhaps ironically, these power disparities that already exist 
offline kind of replicated online, and as you say, it's the people who run these social media companies who are 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 2:55 PM GMT
ultimately making cash money out of the strip Jesus. So the one thing that I will say to the listener perhaps if you 
are looking for something to be able to fight back against the influx of AI slop is that look. It just depends upon your 
engagement right, don't look at it, don't click on it, don't comment on it, because all that's going to do is feed the 
algorithm and stick it into some other Grannis feed. So just ignore it and move on, and I think that that is a very 
good place to start. I guess the joke would be on social media, though, if we all stopped using it. If you've got any 
burning questions about artificial intelligence and, as you can see, the answer all kinds, then do send us an email to 
the artificial human at BBC. UK. But if you send me a picture of a crustacean mashed up with a deity, I'm going to 
block you forever. The artificial human was a BBC audio Scotland production presented by Kevin Fong and Alex 
Kritsky and produced by Elizabeth Anne Duffy. After the news we'll hear from the team behind the new U. S version 
of have got news for you, can CNN's attempt to succeed in America, where other launches of the franchise have 
failed we'll find out in the media show here in a few minutes. Lady swindlers, families must be looked at after when 
a member is in prison. Everybody was acquainted with my whole history. Now drinking before a ride, Lucy Worsley, 
revisit the audacious and surprising crimes of women from the past. When they got safely out of the store, they 
would jump into their waiting getaway cars. This was an alternative route to become a modern woman pursuing con 
women, thieves and hustlers. She looks utterly terrifying. She's got this kind of dead-eyed stare, lady swindler with 
Lucy Worsley starting next Monday at 3 30 on and BBC sounds BBC news at 4 0. The Israeli military says it has hit 
more than to hundred-deg targets belonging to Hez Bala in Lebanon. A senior figure in the Israeli
Load-Date: September 25, 2024
End of Document
Page 1 of 1
Pick of the day
Pick of the day
i-news
September 25, 2024
SC1 Edition
Copyright 2024 Associated Newspapers Ltd. All Rights Reserved
Section: FEATURES; Pg. 35
Length: 32 words
Body
The Artificial Human 3.30pm, BBC Radio 4 Aleks Krotoski (above) and Kevin Fong examine the world of AI slop: 
mass-produced, low-quality images that have spread like wildfire over social media.
Load-Date: September 25, 2024
End of Document

Page 1 of 1
PICK OF THE DAY
PICK OF THE DAY
i-news
September 25, 2024
First Edition
Copyright 2024 Associated Newspapers Ltd. All Rights Reserved
Section: FEATURES; Pg. 35
Length: 32 words
Body
The Artificial Human 3.30pm, BBC Radio 4 Aleks Krotoski (above) and Kevin Fong examine the world of AI slop: 
mass-produced, low-quality images that have spread like wildfire over social media.
Load-Date: September 25, 2024
End of Document

Page 1 of 1
Radio choice
Radio choice
The Daily Telegraph (London)
September 25, 2024 Wednesday
Edition 1, National Edition
Copyright 2024 Telegraph Media Group Limited All Rights Reserved
Section: FEATURES; Pg. 28
Length: 109 words
Body
A Suspension of Mercy Radio 4 Extra, 2.30pm & 8.30pm One of the best of Radio 4 Extra's crop of rediscovered 
"lost" classics is this nail-biting 1985 adaptation of Patricia Highsmith's psychological thriller. Stuart Milligan walks a 
"did-he, didn't-he?" tightrope as a writer suspected of murdering his wife when she disappears while taking time out 
from their marriage. Aleks Krotoski and Kevin Fong, meanwhile, are back with a new run of The Artificial Human 
(Radio 4, 3.30pm), this week exploring how online spam has evolved into AI slop - mass produced, low quality AI 
images that go viral. Will such images be the death of social media? Gerard O'Donovan
Load-Date: September 25, 2024
End of Document

Page 1 of 3
The Trump Posts You Probably Aren't Seeing
The Trump Posts You Probably Aren't Seeing
Atlantic Online
September 24, 2024 Tuesday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1322 words
Byline: Charlie Warzel
Body
Sign up for The Decision, a newsletter featuring our 2024 election coverage.
Do you remember what it was like when Donald Trump couldn't stop tweeting? When it felt like, no matter the time 
of day or what you were doing, his caps-lock emeses were going to find you, like a heat-seeking, plain-text missile? 
Enjoying a nice little morning at the farmer's market? Hold on, here's a push alert about Trump calling Kim Jong Un 
"rocket man" on Twitter. Turn on the radio, and you'd hear somebody recapping his digital burbles. You could 
probably make the case that a large portion of the words spoken on cable-news panels from 2015 to early 2021 
were at least tangentially about things that Trump pecked onto his smartphone from a reclining position.
Then January 6 happened. Twitter, worried about "the risk of further incitement of violence," permanently 
suspended his account, and Trump later launched his own social-media site, Truth Social. It has far fewer users 
than its rivals do, and Trump now mostly bleats into the void. Occasionally, news outlets will surface one of his 
posts-or "Truths," as they're called-such as a September 12 post declaring that he would not debate Kamala Harris 
again. But although Elon Musk has reinstated Trump's X account, the former president still mostly posts on Truth 
Social, which has had the effect of containing his wildest content. Unless you're a die-hard Trump supporter, a 
journalist, or an obsessive political hobbyist, you're likely not getting that regular glimpse into the Republican 
candidate's brain. But  maybe you should be?
Last Friday, I received an email with a link to a website created by a Washington, D.C."based web developer 
named Chris Herbert. The site, Trump's Truth, is a searchable database collecting all of Trump's Truth Social posts, 
even those that have been deleted. Herbert has also helpfully transcribed every speech and video Trump has 
posted on the platform, in part so that they can be indexed more easily by search engines such as Google. Thus, 
Trump's ravings are more visible.
[Read: The MAGA aesthetic is AI slop]

Page 2 of 3
The Trump Posts You Probably Aren't Seeing
Like many reporters, I'd been aware that the former president's social-media posts had, like his rally speeches, 
grown progressively angrier, more erratic, and more bizarre in recent years. Having consumed enough Trump 
rhetoric over the past decade to melt my frontal cortex, I've grown accustomed to his addled style of 
communication. And yet, I still wasn't adequately prepared for the immersive experience of scrolling through 
hundreds of his Truths and ReTruths. Even for Trump, this feed manages to shock. In the span of just a few days, 
you can witness the former president sharing flagrantly racist memes about Middle Easterners invading America, 
falsely edited videos showing Harris urging migrants to cross the border, an all-caps screed about how much better 
off women would be under his presidency, a diatribe about Oprah's recent interview with Harris. It's a lot to take in 
at once: Trump calling an MSNBC anchor a "bimbo," a declaration of hatred for Taylor Swift, a claim that he "saved 
Flavored Vaping in 2019."
On their own, each of these posts is concerning and more than a little sad. But consumed in the aggregate, they 
take on a different meaning, offering a portrait of a man who appears frequently incoherent, internet-addicted, and 
emotionally volatile-even by the extreme standard that Trump has already set. Trump seems unable to stop 
reposting pixelated memes from anonymous accounts with handles such as @1776WeThePeople1776 and 
@akaPR0B0SS, some of which contain unsettling messages such as a desire to indict sitting members of 
Congress for sedition. Trump appears to go on posting jags, sometimes well after midnight, rattling off Truths 
multiple times a minute. On Sunday night, from 6:20 p.m. to 6:26 p.m., Trump shared 20 different posts from 
conservative news sites, almost all without commentary. For a man currently engaged in the homestretch of 
campaigning for the presidency of the United States, he is prolific on social media, and seemingly unable to stop 
posting-from Friday to Monday, Trump posted or reposted 82 times.
Back in January, my colleague McKay Coppins argued that politically engaged Americans should go to a Trump 
rally and "listen to every word of the Republican front-runner's speech" as "an act of civic hygiene." Granted, 
Coppins wrote his article during a different time in the election cycle, at a moment when Trump was less visible, but 
his point still stands. Many Americans and the institutions that cover him have grown so used to Trump-to his 
tirades, lies, and buffoonery-that his behavior can fade into the background of our cultural discourse, his 
shamelessness and unfitness for office taken almost for granted. When Coppins attended a rally early this year, he 
recalled the "darker undercurrent" that infused Trump's rhetoric and lurked behind many of the comments coming 
from supporters in the crowd. Just as important, Coppins wrote, the rally was also a reminder that "Trump is no 
longer the cultural phenomenon he was in 2016. Yes, the novelty has worn off. But he also seems to have lost the 
instinct for entertainment that once made him so interesting to audiences."
[Read: You should go to a Trump rally]
Trump's Truth Social posts offer a similar vibe. His feed is bleak, full of posts about America in decline. 
Aesthetically, it is ugly, full of doctored images and screenshots of screenshots of Facebook-style memes. 
Consuming a few weeks' worth of his posts at once was enough to make me feel awful about the state of the world, 
not unlike how it feels to visit seedy message boards such as 4chan.
And then there's the prose. As in his rallies, Trump rambles, his writing hard to follow. His stylistic choice to use 
caps lock for many of his longer posts gives the appearance that he is shouting. Unlike on Twitter, where he was 
constrained by character limits, Trump's missives are too long and too convoluted to be easily digestible by 
aggregating media organizations. In previous iterations, Trump's tweets were sometimes so bizarre as to be funny 
(or at least weird enough to be compelling); now his posts appear too fueled by grievance to be casually amusing.
[Read: Donald Trump can't stop posting]
I realize that I'm not exactly selling the experience of taking a spin through Trump's digital archive of incoherence. 
But I think it's an instructive exercise. If you, like me, have had the experience of seeing friends or loved ones 
radicalized online or lost to a sea of Facebook memes and propaganda, then scrolling through Trump's Truth Social 
posts will provoke a familiar feeling. On his own website, Trump doesn't just appear unfit for the highest office in the 
land; he seems small, embittered, and under the influence of the kind of online outrage that usually consumes those 
who have been or feel alienated by broad swaths of society. It's not (just) that Trump seems unpresidential-it's that 
Page 3 of 3
The Trump Posts You Probably Aren't Seeing
he seems like an unwell elderly man posting AI slop for an audience of bots on Facebook. Imagine that, instead of 
Donald Trump's, you were looking at the feed of a relative. What would you say or do? Whom would you call?
A few months ago, The Atlantic's editor in chief, Jeffrey Goldberg, wrote about the media's "bias toward coherence" 
when it comes to Trump's rhetoric, where, in an attempt to make sense of Trump's nonsense, journalists sand down 
the candidate's rough edges. Perusing Trump's Truth Social feed, though, it is nearly impossible to find any 
coherence to latch on to. Since Trump came down his golden escalator in 2015, I've thought that the best way to 
understand the candidate is via plain text. There, unlike on television, his fragmented attention, peculiar thinking, 
and dangerous words cannot hide or be explained away. The election is 41 days away, and Trump appears as 
unstable as ever. But don't take my word for it: Go see for yourself.
Load-Date: September 25, 2024
End of Document
Page 1 of 2
Following AI Cheating Controversy, Pokémon Announces Winners Of Card Contest
Following AI Cheating Controversy, Pokémon Announces Winners Of Card 
Contest
Kotaku
September 23, 2024 Monday 4:15 PM EST
Copyright 2024 G/O Media Inc.  All Rights Reserved
Length: 623 words
Byline: John Walker
Body
Link to Image
Each year, The Pokémon Company holds a competition to find a new illustrator for their Pokémon TCG cards. Only 
in the last couple of years has this been opened to entrants from outside of Japan, and with that has come 
controversy. However, after a tumultuous period, the finalists for this year's contest have finally been picked, and 
damn, it's all beautiful work.
This year's contest was rather marred when one entrant, who had been included in the top 300, was rather 
obviously using AI to create images, and indeed entering under multiple identities. 
After people made a fuss, The Pokémon Company acknowledged the issue, and said they'd be disqualifying the 
cheat, and allowing other legitimate entries in to fill the spaces. It remained concerning that such obvious 
shenanigans had been let through, but TPC is notoriously enigmatic and incommunicative, so even this was a 
surprising move.
However, we can now sweep that all aside, and instead celebrate the legitimate artists who deserve their wins. And 
wow, there's some great stuff here.
The competition is broken into a number of categories, with the emphasis on the smaller, landscape images that 
appear in the windows on a regular Pokémon card. While the prized cards are generally the portrait full-art designs, 
it makes sense to constrain entrants to the windowed images, with its inherent limitations.
The categories are Best Standard Card Illustration, Best ex Card Illustration, and a Grand Prize.
The middle category is the odd one out, since non-alt-art ex cards are highly restrictive in their nature, leaving little 
room for originality. It's a great piece of Toxtricity art by Anderson, certainly, and it won because of its use of the 
space to depict a unique angle for the Pokémon, but it's harder to get excited about.

Page 2 of 2
Following AI Cheating Controversy, Pokémon Announces Winners Of Card Contest
Link to Image
What's so lovely about the two other winners, however, is quite how different they are.
The Pokémon Company is getting better and better at featuring ever more lavish art, but is still quite conservative 
on style, so seeing the pick for Best Standard Card Illustration is a real treat. It's a stunning depiction of Feraligatr 
by artist Acorviart, inspired by linocut and risograph printing.
Link to Image
The Grand Prize is certainly more conventional, but makes up for it in adorable. Pikachu perhaps seems a little on 
the nose, but Kazuki Minami's painting is breathtaking. What works so incredibly well here is the intricate detail of 
the background flowers, contrasted with the far simpler depiction of Pika, in such a cute and recognizable pose. 
And that light on his face...come on.
Link to Image
I want to highlight a few of the runners up, too. Firstly, another Feraligatr, this time by tayu, which appears to be one 
of the most spectacular pieces of embroidery I've ever seen. There are so few multimedia artists making Pokémon 
cards, despite how popular the wonderful Yuka Morii's clay art has been for 25 years. Also, it's a wonderful picture 
beyond the media.
Link to Image
In a contest that was upset by AI slop, it's lovely to see a piece that AI would try to copy, and get horribly wrong. 
This Melmetal by gohealth feels so gloriously metallic, and yet so cartoonishly stylized. Also, when did you last see 
a Melmetal sit down?!
Link to Image
Shiho So's Pikachu is one of the 15 Judges' Award winners (alongside so many more Feraligatr!), and would be 
one of those cards that'd make you smile every time you pulled it from a pack. It's just joyful.
Link to Image
And why not end with yet another Pikachu? satoutubu's art here is...I just want to hug it! I want to exist in a world 
where creatures look like this. If satoutubu became a regular Pokémon TCG artist, I'd immediately begin collecting 
all their cards.
Link to Image
.
Load-Date: September 23, 2024
End of Document
Page 1 of 2
Wednesday 25 September
Wednesday 25 September
The Times (London)
September 21, 2024 Saturday
Edition 1, National Edition
Copyright 2024 Times Newspapers Limited All Rights Reserved
Section: SATURDAY REVIEW;FEATURES; Pg. 42
Length: 487 words
Body
TIMES RADIO 5.00am Rosie Wright with Early Breakfast 6.00 Aasmah Mir and Stig Abell with Times Radio 
Breakfast 10.00 Hugo Rifkind 1.00pm Andrew Neil 2.00 Jane Garvey and Fi Glover 4.00 John Pienaar with Times 
Radio Drive 6.00 Pienaar and Friends 7.00 The Evening Edition with Kait Borsay 10.00 Carole Walker 1.00am The 
Best of Times Radio RADIO 2 6.30am The Zoe Ball Breakfast Show 9.30 Vernon Kay 12.00 Jeremy Vine 2.00pm 
Scott Mills 4.00 Sara Cox 6.30 Sara Cox's Half Wower 7.00 Jo Whiley's Shiny Happy Playlist 7.30 Jo Whiley 9.00 
Folk Show 10.00 Trevor Nelson's Rhythm Nation RADIO 3 6.30am Breakfast 9.30 Essential Classics 1.00pm 
Classical Live 3.00 Live Choral Evensong. With music by Imogen Holst, Leighton, Brahms and Ropek 4.00 
Composer of the Week: Gluck. How Gluck became a fixture of Vienna's musical scene 5.00 In Tune 7.00 Classical 
Mixtape 7.30 Radio 3 in Concert. Manchester Camerata perform a programme of Mozart 9.45 The Essay: Music 
Rediscovered. Oskar Jensen sings the Millons be Free 10.00 Night Tracks 11.30 'Round Midnight 12.30am 
Through the Night
RADIO 4 5.30am News Briefing 5.43 Prayer for the Day 5.45 Farming Today 6.00 Today 9.00 More or Less 9.30 
The Coming Storm. Gabriel Gatehouse enters a world where nothing is as it seems 10.00 Woman's Hour 11.00 A 
Wild Ride(r) 11.45 Book of the Week: The Siege. By Ben Macintyre (8/10)
12.04pm You and Yours 1.00 The World at One 1.45 Superhead. John Dickens investigates the superheads 
transforming failing schools 2.00 The Archers. Opportunity knocks for Fallon (r) 2.15 Drama: Riot Girls - Dykes. The 
angry 1970s give way to the more repressive 1980s (2/3) 3.00 Money Box Live 3.30 The Artificial Human. New 
series. Aleks Krotoski and Kevin Fong examine the world of AI slop 4.00 The Media Show. The latest news from 
the fastchanging media world 5.00 PM. With Evan Davis 6.00 Six O'Clock News 6.30 Paul Sinha's Perfect Pub 
Quiz. The host and his live audience compile the questions for a perfect pub quiz (r) 7.00 The Archers. George is 
struggling with recent events 7.15 Front Row. Arts programme 8.00 AntiSocial (r) 8.45 Profile (r) 9.00 The Life 
Scientific (r) 9.30 All in the Mind (r) 10.00 The World Tonight 10.45 Book at Bedtime: The Last Loves of Ronnie 
Maker (3/5) 11.00 Follow the Rabbit. A local woman claims she has a demon living in her biscuit tin (4/5) 11.15 The 

Page 2 of 2
Wednesday 25 September
Skewer 11.30 The Gift (r) 12.00 News and Weather 12.30am Book of the Week: The Siege (8/10) (r) 12.48 
Shipping Forecast 1.00 As BBC World Service
A Suspension of Mercy Radio 4 Extra, 2.30pm
Every day this week, Radio 4 Extra is airing five "lost" BBC dramas. Today's offering is an adaptation of Patricia 
Highsmith's psychological thriller. The novelist Sydney Bartleby (Stuart Milligan, above) is a writer of thrillers. His 
wife, with whom he has a fractious relationship, has "died" many times in his imagination. But when she disappears, 
he finds himself under investigation.
Load-Date: September 21, 2024
End of Document
Page 1 of 3
Meet the Editor Who Turned Himself Into an AI News Anchor
Meet the Editor Who Turned Himself Into an AI News Anchor
Newstex Blogs 
The Wrap
September 20, 2024 Friday 7:00 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 The Wrap 
Length: 860 words
Byline: Alex Kantrowitz
Body
September 20th, 2024 ( The Wrap  - Delivered by  Newstex )
The AI versionof Elihay Vidal looks a lot like the man in real life. I watched him anchor a news broadcast last week 
and had to stare intently for a number of seconds to confirm I wasn't watching a real human.
Vidal's avatar has a human face, human body, human expressions, and even a shirt with the top two buttons 
unbuttoned. His 'Edge of Tech' show runs regularly on CTech, an Israeli tech news site where he's editor-in-chief, 
and the visuals and voice are entirely synthetic. To develop the show, Vidal worked with Caledo, a tech company 
that builds AI news video for news siteslooking for a cheaper and easier alternative to the real thing.
After watching Vidal's show, I wanted to know why he's allowed himself to be turned into an AI avatar and where he 
sees the format going. Here's our conversation, edited for length and clarity.
Alex Kantrowitz: The AI 'reporter' using your likeness looks very human, like the real you. How did you turn yourself 
into that avatar?
Elihay Vidal: I stood in front of a camera and moved around, and the software captured my movements. The 
avatar's movements are therefore my movements. My AI avatar is singular. It is my voice, my mimics, my facial 
expressions, my eyes, and my smile.
When you initially saw the AI generated version of yourself on screen, were you like, wow, that's me?
I showed it to my family, my wife, my children, my parents, and my sister. Everyone said, there's no way it's not you. 
The machine just learned my character. The little nuances in there, people recognize them as mine.
Why make news videos with artificial intelligence avatars, as opposed to just filming them yourself?
We filmed only once for half an hour. I gave a speech in front of the camera. Then, after a few days they showed 
me my avatar, which was generated by AI. And when I gave the speech, I did it in Hebrew

Page 2 of 3
Meet the Editor Who Turned Himself Into an AI News Anchor
But your avatar speaks in English?
Yes, and the English was perfect. I said, No, no, no, no, no, listen, listen, listen, when I speak, I don't speak perfect 
English. I have an accent. So let's make the accent a little rougher. And so they tweaked the machine and changed 
my accent. Then I was very, very content with what I got.
Caledo, the company that built the avatar, also has a few off-the-shelf avatars and you can say, I want this one, I 
want that one. I wanted to be an Asian girl or a blonde guy, or whatever. You can choose avatars from their gallery, 
or you can do the shoot yourself, as I did.
Is the benefit, basically, that you just capture yourself with the AI once, and then you can deliver a news report, 
however often you want?
Once you pick an avatar and design a studio, then the editorial work begins. Whenever I want to broadcast a video, 
I chose a handful of articles published on our site. Then the AI breaks down the articles and builds them into script. 
They then put the words in our avatars' mouth. The article text is written by flesh and blood reporters and picking 
which article will be transformed into TV is done by us, right? The only thing the AI is doing is the technical stuff.
You're an editor of a business publication. What do you think the broader implications are here?
When we decided to do this project, there was a guy on my team we wanted to turn into an avatar. He was terrified. 
He was terrified by the fact that there's an avatar that is going to replace him, and take his job, and no one will need 
him, and we can fire him and use his avatar. I explained to him, it's not that he's disposable, on a contrary, he is a 
talent, and his face will reach far, far deeper on the web. You approached me because you recognized me from one 
of our videos, and you called me. Just imagine if they take my my avatar, and make him speak Chinese for me, or 
Japanese, or French, or Spanish. or Arabic.
But isn't there a risk though, that, the internet fills with AI slop when everybody's making these videos so easily?
When we start every show, we say this is a AI generated content, but it is a based on a human being, a creation. 
It's something new.
Are you getting an ROI on these videos?
It's a tricky question. We don't have any video platform. We're not considered a video or a TV outlet. But I can say 
that the viewing activity is going up.
How many views do you get for each of these AI videos?
It's thousands, okay, thousands of viewings. It's okay for us. It's okay at this stage. I'm not seeking much more than 
that.
Will you allow your publication to continue to use your AI avatar? Let's say it becomes very popular after you retire?
Definitely not.
Why?
Because, as I said at the beginning, this is an authentic reflection of my character, my own character. This is my 
voice. The mimics and movement is related only to me. It's singular. It's unique. I won't let anyone [use] my avatar 
without my permission, right?
So you have no desire for broadcast immortality?
No. It's better for them to use someone younger or someone much better than me.
This article is from Big Technology, a newsletter by Alex Kantrowitz.
Page 3 of 3
Meet the Editor Who Turned Himself Into an AI News Anchor
The post  Meet the Editor Who Turned Himself Into an AI News Anchor appeared first on TheWrap.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 20, 2024
End of Document
Page 1 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and 
Facebook
EveningReport.nz
September 19, 2024 Thursday 6:30 AM EST
Copyright 2024 Multimedia Investments Ltd, distributed by Contify.com All Rights Reserved
Length: 1200 words
Byline: The Conversation
Body
                                               Source: The Conversation (Au and NZ) - By Jiaru Tang, PhD student, Digital Media 
Research Centre, Queensland University of Technology
 TikTok / The Conversation
TikTok, Facebook and other social media platforms are being flooded with uncanny and bizarre content generated 
with artificial intelligence (AI), from fake videos of the US government capturing vampires to images of shrimp 
Jesus.
Given its outlandish nature and tenuous relationship with reality, you might think this so-called "AI slop" would 
quickly disappear. However, it shows no sign of abating.
In fact, our research suggests this kind of low-quality AI-generated content is becoming a lucrative venture for the 
people who make it, the platforms that host it, and even a growing industry of middlemen teaching others how to get 
in on the AI gold rush.
When generative AI meets profiteers and platforms
The short explanation for the prevalence of these baffling videos and images is that savvy creators on social media 
platforms have worked out how to use generative AI tools to earn a quick buck.
But the full story is more complex. Platforms have created incentive programs for content that goes viral, and a 
whole ecosystem of content creators has arisen using generative AI to exploit these programs.
Much of the conversation around generative AI tools focuses on how they enable ordinary people to "create". Many 
earlier digital technologies have also made it easier to participate in creative activities, such as how smartphones 
made photography ubiquitous.

Page 2 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
But generative AI takes this a step further, as it can generate tailored images or videos from a simple text prompt. It 
makes content creation more accessible - and also opens the floodgates to mass production on social media.
To take just one example: if you search "pet dance motorcycle" on TikTok, you will find hundreds of AI-generated 
videos of animals doing the "motorbike dance", all animated using the same AI template. Some accounts post 
dozens of videos like this every day.
Creators and platforms are making money
You may wonder why such repetitive, unimaginative content can go viral on TikTok. The answer lies in the 
platform's own advice to aspiring creators: if you want your videos to be promoted, you should "continuously share 
fresh and diverse content" that "doesn't require a big production budget".
You may also wonder why some platforms don't ban AI accounts for polluting the platform's content stream. Other 
platforms such as Spotify and YouTube, which police intellectual property rights more aggressively than TikTok, 
invest considerable resources to identify and remove AI-generated content.
TikTok's community guidelines do ban "inaccurate, misleading, or false content that may cause significant harm", 
but AI-generated content - at least for now - does not qualify as causing "significant harm".
Instead, this kind of content has become important for platforms. Many of those "pet dance motorcycle" videos, for 
example, have been viewed tens of millions of times. As long as users are scrolling through videos, they are getting 
exposed to the ads that are the platforms' primary source of income.
Inside the AI 'gold rush'
There is also a growing industry of people teaching others how to make money using cheap AI content.
Take Xiaonan, a social media entrepreneur we interviewed who runs six different TikTok accounts, each with more 
than 100,000 followers. As he revealed in a live-streaming tutorial with more than 1,000 viewers, Xiaonan earned 
more than US$5,500 from TikTok in July alone.
Xiaonan also hosts an exclusive chatting group where, for a fee, he reveals his most effective AI prompts, video 
headlines and hashtags tailored for different platforms including YouTube and Instagram. Xiaonan also reveals 
tricks for standing out in the platforms' recommendation game and avoiding platform regulations.
Xiaonan says he established his "AI side job" after being laid off by an internet company. He now works with two 
partners selling classes and tutorials on making AI-generated videos and other types of spam for profit.
Creators posting AI content may not be the kind of people we expect. As Xiaonan told us, many of the people 
taking his AI tutorial - entitled "Side job, self-employed, high-paid" - are housewives, unemployed people and 
college students.
"Some of us also do Uber driving or street vending," one creator told us. AI-generated content has become the 
latest trend for earning side income.
The rise of AI has coincided with global unemployment trends and the growth of the gig economy in the post-
pandemic era.
Making AI-generated content is more pleasant work than driving passengers or delivering food, according to a 
creator who is also a stay-at-home mother. It's easy to learn, almost zero cost, and can be done any time at home 
with just a phone.
As Xiaonan says, his method is to use AI to "earn from productivity gap" - that is, by producing far more content 
than people who don't use AI .
Page 3 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
The global AI-generated content factory
Our observations indicate many of these creators are from non-Western countries, such as India, Vietnam and 
China.
As one Chinese social media influencer told us:
China's short video market is nearing saturation, which means you need to seek data traffic [viewers] on overseas 
platforms.
For these entrepreneurs, AI is the secret sauce not only for creating viral content but also for circulating already-
viral videos across different countries and platforms.
An effective strategy mentioned by one creator is a kind of platform arbitrage involving popular videos from Douyin, 
the counterpart of TikTok in mainland China.
A creator will take one of these videos, add AI-generated translation, and post the result on TikTok. Despite clunky 
AI dubbing and error-riddled subtitles, many of these videos garner hundreds of thousands or even millions of 
views.
Creators often mute the original video and add AI-generated narration, translating the content into various 
languages, including French, Spanish, Portuguese, Indonesian and Swedish. These creators often manage several 
or even dozens of accounts, targeting viewers in different countries in a strategy known as an "account matrix".
This is only the beginning
We are only at the dawn of mainstream AI-generated content culture. We will soon face a situation in which content 
is effectively infinite, but human attention is still limited.
For platforms, the challenge will be balancing the engagement these AI-driven trends bring with the need to 
maintain trust and authenticity.
Social media platforms will soon respond. But before that, AI-generated content will continue to grow wildly - at 
least for a while.
Patrik Wikstrm receives funding from the Australian Research Council. 
Jiaru Tang does not work for, consult, own shares in or receive funding from any company or organisation that 
would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.
- ref. 'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook - 
https://theconversation.com/side-job-self-employed-high-paid-behind-the-ai-slop-flooding-tiktok-and-facebook-
237638
Load-Date: September 19, 2024
End of Document
Page 1 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and 
Facebook
The Conversation - Australia
September 19, 2024 Thursday 1:42 AM EST
Copyright 2024 The Conversation Media Group Ltd All Rights Reserved
Length: 1133 words
Byline: Jiaru Tang, PhD student, Digital Media Research Centre, Queensland University of Technology
Highlight: In places like India, Vietnam and China, churning out weird AI videos is the latest side hustle for 
students and stay-at-home mothers.
Body
TikTok, Facebook and other social media platforms are being flooded with uncanny and bizarre content generated 
with artificial intelligence (AI), from fake videos of the US government capturing vampires to images of shrimp 
Jesus. 
Given its outlandish nature and tenuous relationship with reality, you might think this so-called "AI slop" would 
quickly disappear. However, it shows no sign of abating. 
In fact, our research suggests this kind of low-quality AI-generated content is becoming a lucrative venture for the 
people who make it, the platforms that host it, and even a growing industry of middlemen teaching others how to get 
in on the AI gold rush. 
When generative AI meets profiteers and platforms
The short explanation for the prevalence of these baffling videos and images is that savvy creators on social media 
platforms have worked out how to use generative AI tools to earn a quick buck. 
But the full story is more complex. Platforms have created incentive programs for content that goes viral, and a 
whole ecosystem of content creators has arisen using generative AI to exploit these programs.
Much of the conversation around generative AI tools focuses on how they enable ordinary people to "create". Many 
earlier digital technologies have also made it easier to participate in creative activities, such as how smartphones 
made photography ubiquitous. 
But generative AI takes this a step further, as it can generate tailored images or videos from a simple text prompt. It 
makes content creation more accessible - and also opens the floodgates to mass production on social media. 

Page 2 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
To take just one example: if you search "pet dance motorcycle" on TikTok, you will find hundreds of AI-generated 
videos of animals doing the "motorbike dance", all animated using the same AI template. Some accounts post 
dozens of videos like this every day.
Creators and platforms are making money
You may wonder why such repetitive, unimaginative content can go viral on TikTok. The answer lies in the 
platform's own advice to aspiring creators: if you want your videos to be promoted, you should "continuously share 
fresh and diverse content" that "doesn't require a big production budget".
You may also wonder why some platforms don't ban AI accounts for polluting the platform's content stream. Other 
platforms such as Spotify and YouTube, which police intellectual property rights more aggressively than TikTok, 
invest considerable resources to identify and remove AI-generated content. 
TikTok's community guidelines do ban "inaccurate, misleading, or false content that may cause significant harm", 
but AI-generated content - at least for now - does not qualify as causing "significant harm". 
Instead, this kind of content has become important for platforms. Many of those "pet dance motorcycle" videos, for 
example, have been viewed tens of millions of times. As long as users are scrolling through videos, they are getting 
exposed to the ads that are the platforms' primary source of income.
Inside the AI 'gold rush'
There is also a growing industry of people teaching others how to make money using cheap AI content. 
Take Xiaonan, a social media entrepreneur we interviewed who runs six different TikTok accounts, each with more 
than 100,000 followers. As he revealed in a live-streaming tutorial with more than 1,000 viewers, Xiaonan earned 
more than US$5,500 from TikTok in July alone. 
Xiaonan also hosts an exclusive chatting group where, for a fee, he reveals his most effective AI prompts, video 
headlines and hashtags tailored for different platforms including YouTube and Instagram. Xiaonan also reveals 
tricks for standing out in the platforms' recommendation game and avoiding platform regulations.
Xiaonan says he established his "AI side job" after being laid off by an internet company. He now works with two 
partners selling classes and tutorials on making AI-generated videos and other types of spam for profit.
Creators posting AI content may not be the kind of people we expect. As Xiaonan told us, many of the people 
taking his AI tutorial - entitled "Side job, self-employed, high-paid" - are housewives, unemployed people and 
college students. 
"Some of us also do Uber driving or street vending," one creator told us. AI-generated content has become the 
latest trend for earning side income.
The rise of AI has coincided with global unemployment trends and the growth of the gig economy in the post-
pandemic era. 
Making AI-generated content is more pleasant work than driving passengers or delivering food, according to a 
creator who is also a stay-at-home mother. It's easy to learn, almost zero cost, and can be done any time at home 
with just a phone. 
As Xiaonan says, his method is to use AI to "earn from productivity gap" - that is, by producing far more content 
than people who don't use AI .
The global AI-generated content factory
Page 3 of 3
'Side job, self-employed, high-paid': behind the AI slop flooding TikTok and Facebook
Our observations indicate many of these creators are from non-Western countries, such as India, Vietnam and 
China. 
As one Chinese social media influencer told us:
China's short video market is nearing saturation, which means you need to seek data traffic [viewers] on overseas 
platforms.
For these entrepreneurs, AI is the secret sauce not only for creating viral content but also for circulating already-
viral videos across different countries and platforms. 
An effective strategy mentioned by one creator is a kind of platform arbitrage involving popular videos from Douyin, 
the counterpart of TikTok in mainland China. 
A creator will take one of these videos, add AI-generated translation, and post the result on TikTok. Despite clunky 
AI dubbing and error-riddled subtitles, many of these videos garner hundreds of thousands or even millions of 
views. 
Creators often mute the original video and add AI-generated narration, translating the content into various 
languages, including French, Spanish, Portuguese, Indonesian and Swedish. These creators often manage several 
or even dozens of accounts, targeting viewers in different countries in a strategy known as an "account matrix".
This is only the beginning
We are only at the dawn of mainstream AI-generated content culture. We will soon face a situation in which content 
is effectively infinite, but human attention is still limited.
For platforms, the challenge will be balancing the engagement these AI-driven trends bring with the need to 
maintain trust and authenticity.
Social media platforms will soon respond. But before that, AI-generated content will continue to grow wildly - at 
least for a while.
Patrik Wikström receives funding from the Australian Research Council.
Jiaru Tang does not work for, consult, own shares in or receive funding from any company or organisation 
that would benefit from this article, and has disclosed no relevant affiliations beyond their academic 
appointment.
Load-Date: September 18, 2024
End of Document
Page 1 of 3
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok 
And Facebook
MENAFN - Business & Finance News (English)
September 18, 2024 Wednesday
Copyright 2024 MENAFN.COM All Rights Reserved
Length: 1070 words
Body
Link to Image
Link to Story
TikTok, Facebook and other social media platforms are being flooded with uncanny and bizarre content generated 
with artificial intelligence (AI), from fake videos of the US government capturing vampires to images of shrimp Jesus 
. Given its outlandish nature and tenuous relationship with reality, you might think this so-called"AI slop" would 
quickly disappear. However, it shows no sign of abating.
In fact, our research suggests this kind of low-quality AI-generated content is becoming a lucrative venture for the 
people who make it, the platforms that host it, and even a growing industry of middlemen teaching others how to get 
in on the AI gold rush.
When generative AI meets profiteers and platformsThe short explanation for the prevalence of these baffling videos 
and images is that savvy creators on social media platforms have worked out how to use generative AI tools to earn 
a quick buck.
But the full story is more complex. Platforms have created incentive programs for content that goes viral, and a 
whole ecosystem of content creators has arisen using generative AI to exploit these programs.
Much of the conversation around generative AI tools focuses on how they enable ordinary people to"create". Many 
earlier digital technologies have also made it easier to participate in creative activities, such as how smartphones 
made photography ubiquitous.
But generative AI takes this a step further, as it can generate tailored images or videos from a simple text prompt. It 
makes content creation more accessible - and also opens the floodgates to mass production on social media.

Page 2 of 3
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook
To take just one example: if you search"pet dance motorcycle" on TikTok, you will find hundreds of AI-generated 
videos of animals doing the"motorbike dance", all animated using the same AI template. Some accounts post 
dozens of videos like this every day.
Creators and platforms are making moneyYou may wonder why such repetitive, unimaginative content can go viral 
on TikTok. The answer lies in the platform's own advice to aspiring creators: if you want your videos to be 
promoted, you should"continuously share fresh and diverse content" that"doesn't require a big production budget".
You may also wonder why some platforms don't ban AI accounts for polluting the platform's content stream. Other 
platforms such as Spotify and YouTube, which police intellectual property rights more aggressively than TikTok, 
invest considerable resources to identify and remove AI-generated content .
TikTok's community guidelines do ban"inaccurate, misleading, or false content that may cause significant harm", 
but AI-generated content - at least for now - does not qualify as causing"significant harm".
Instead, this kind of content has become important for platforms. Many of those"pet dance motorcycle" videos, for 
example, have been viewed tens of millions of times. As long as users are scrolling through videos, they are getting 
exposed to the ads that are the platforms' primary source of income.
Inside the AI 'gold rush'There is also a growing industry of people teaching others how to make money using cheap 
AI content.
Take Xiaonan, a social media entrepreneur we interviewed who runs six different TikTok accounts, each with more 
than 100,000 followers. As he revealed in a live-streaming tutorial with more than 1,000 viewers, Xiaonan earned 
more than US$5,500 from TikTok in July alone.
Xiaonan also hosts an exclusive chatting group where, for a fee, he reveals his most effective AI prompts, video 
headlines and hashtags tailored for different platforms including YouTube and Instagram. Xiaonan also reveals 
tricks for standing out in the platforms' recommendation game and avoiding platform regulations.
Xiaonan says he established his"AI side job" after being laid off by an internet company. He now works with two 
partners selling classes and tutorials on making AI-generated videos and other types of spam for profit.
Creators posting AI content may not be the kind of people we expect. As Xiaonan told us, many of the people 
taking his AI tutorial - entitled"Side job, self-employed, high-paid" - are housewives, unemployed people and college 
students.
"Some of us also do Uber driving or street vending," one creator told us. AI-generated content has become the 
latest trend for earning side income.
The rise of AI has coincided with global unemployment trends and the growth of the gig economy in the post-
pandemic era.
Making AI-generated content is more pleasant work than driving passengers or delivering food, according to a 
creator who is also a stay-at-home mother. It's easy to learn, almost zero cost, and can be done any time at home 
with just a phone.
As Xiaonan says, his method is to use AI to"earn from productivity gap" - that is, by producing far more content than 
people who don't use AI .
The global AI-generated content factoryOur observations indicate many of these creators are from non-Western 
countries, such as India, Vietnam and China.
As one Chinese social media influencer told us:
For these entrepreneurs, AI is the secret sauce not only for creating viral content but also for circulating already-
viral videos across different countries and platforms.
An effective strategy mentioned by one creator is a kind of platform arbitrage involving popular videos from Douyin, 
the counterpart of TikTok in mainland China.
Page 3 of 3
'Side Job, Self-Employed, High-Paid': Behind The AI Slop Flooding Tiktok And Facebook
A creator will take one of these videos, add AI-generated translation, and post the result on TikTok. Despite clunky 
AI dubbing and error-riddled subtitles, many of these videos garner hundreds of thousands or even millions of 
views.
Creators often mute the original video and add AI-generated narration, translating the content into various 
languages, including French, Spanish, Portuguese, Indonesian and Swedish. These creators often manage several 
or even dozens of accounts, targeting viewers in different countries in a strategy known as an"account matrix".
This is only the beginningWe are only at the dawn of mainstream AI-generated content culture. We will soon face a 
situation in which content is effectively infinite, but human attention is still limited.
For platforms, the challenge will be balancing the engagement these AI-driven trends bring with the need to 
maintain trust and authenticity.
Social media platforms will soon respond. But before that, AI-generated content will continue to grow wildly - at 
least for a while.
MENAFN18092024000199003603ID1108690518
Load-Date: March 5, 2025
End of Document
Page 1 of 2
BBC Radio 4 - 4:50 PM GMT
BBC Radio 4 - 4:50 PM GMT
TVEyes - BBC Radio 4
September 16, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. NATIONAL RADIO
Length: 820 words
Body
Speech to text transcript:1
should or shouldn't go ahead. This is almost like a last ditch effort to save or to back this project, each of them 
being given 5 min to speak and then taking questions from members of the national Park Authority and then moving 
on to the next speaker. So we've heard all of those 5 people who were speaking in favor of the development. there 
were originally 8 now 6 people speaking against it, and then after that, the National Park Authority Board will ponder 
their final decision on whether or not to give it planning permission in principle, which is what the developer is 
seeking. 
Some say, whatever the decision, we do take an awfully long time in this country to make the decision. How long 
have these arguments been going on? When did it all art? Well, it has been going on since about 2016, but that 
was a previous plan that was then withdrawn and resubmitted at a late stage, so that stage so that latest one has 
been going on since twenty-nine. So it is 5 years that this has been going on, and there's been a huge amount of 
work going on by the National Park Board in terms of trying to determine whether or not it should be given the go 
ahead. They produced a document a couple of weeks ago that was a hundred-deg pages long that recommended it 
for refusal, although the Board aren't obliged to stick by that recommendation. So a huge amount of effort has gone 
into it, and yet in this meeting today there still seemed to be some unanswered questions that the officials couldn't 
answer and that the representatives of Flamingo land didn't seem to be able to answer. So it has taken a long time 
to come to this. Whatever the decision is today, it's not necessary by the end of it, because it could go to appeal, it 
could go to the Scottish Government for a further determination. It could go on for several more years yet. Okay, 
Kevin, thanks for that, Kevin King. Earlier we heard an example of how talented AI has become at composing music 
from scratch we heard an example of a PM theme tune written while we were on air by an AI app I'll just remind you 
of. I think it's quite good and in fact I've made another one here's another one it a bit more upbeat if you want 
something to compare those to. Some listeners with long memories have been in touch, which was the actual PM 
theme tune. This is not a I this date back to 19 its pm at 5 0 p.m. The Sights and by formats program hasn't 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC Radio 4 - 4:50 PM GMT
changed a bit. Has it not changed a bit? Our current editor hates all theme tunes. P. P. M. Well, look what I 
produced on AI is not gonna win a Mercury Prize, but hey, look, just turn that out in minutes and we've been 
wondering what the i? Ations are for the World of music, for those producing it and those consuming it. Technology 
Writer Kate Bevan is still with me in the studio, also joined down the line by Tom Keel, chief executive of UK Music. 
Tom. I've just been taken aback because we had a letter from a listener who pointed out to me what it was doing 
and what what do you think of what AI is doing? Well, the UK music industry is worth 7 billion to the economy and 
that forms part of the wider create industries, which are worth almost 100 billion to the economy, and that is actually 
powered very much by economic rights like copyright, which is really important to creators. So in terms of actually 
AI, there's a very strong role in terms of the assisted element to it. The craters can can actually hold and now and 
nurture their craft. However, there are some substantial challenges about what we consider to be generative AI 
that's kind of making new pieces of music actually out of other pieces of music through the large language models, 
and that's actually a great concern, because it's it's we don't have any transparency about in terms of actually music 
being put into the? Is your basic your basic content? Sorry, your basic sorry to interrupt. Your basic contention is 
that what I produced on AI is really picking up on what other people have produced and then not be paid for if I do it 
with the AI? In a sense, yes, yes, essentially that's the crazy issue. Yeah, Kate, I'm wondering about. You know, 
you take a streaming app like Spotify. I don't know how crowded their servers are, but they could just be up loaded 
with with volumes, orders of magnitude, more mediocre music turned out by by these kind of programs. Right, yeah, 
they absolutely could, and I think one of the issues around AI, particularly as time goes on, is that there's so much 
AI generated slop out there. It's it's getting into the system and it's getting harder actually for people to differentiate 
between a generator stuff which has absolutely nos fact checking inherent in it, and what's real, and that's not just a 
problem for music. Yeah, I mean it may be a problem for music. If I,
Load-Date: September 16, 2024
End of Document
Page 1 of 2
Trump is drowning in the misinformation swamp he helped create
Trump is drowning in the misinformation swamp he helped create
CNN Wire
September 12, 2024 Thursday 10:00 AM GMT
Copyright 2024 Cable News Network All Rights Reserved
Length: 756 words
Byline: Analysis by Allison Morrow, CNN
Dateline: (CNN) 
Body
             New York (CNN) - The Republican nominee for president went on live TV and presented an unhinged, 
debunked Facebook rumor as fact. When corrected (several times) by a moderator, Donald Trump doubled down: 
"The people on television say their dog was eaten by the people that went there."
"They're eating the dogs," quickly became a punchline among commentators who understand that the whole story 
about Haitian immigrants eating people's pets in Ohio was a lie, rooted in a well-established racist history.
It's the kind of outrage-bait that, while disgusting, is hardly unexpected on Facebook these days.
But the claim's elevation to the presidential debate stage underscores a grim reality about the internet in 2024: 
Misinformation is everywhere, platforms are giving up on moderation and AI is making it all worse.
Trump's debate performance "was like a 4chan post come to life," said CNN's Jake Tapper.
It's an apt analogy.
4chan, once an innocuous online message board for anime enthusiasts in the early 2000s, is a prime example of 
what happens when you remove the guardrails from a social media site, with only a handful of community members 
regulating it. Over the years, 4chan has become a cesspool of violence, conspiracy theories and its own particular 
brand of "edgelord white supremacy," as the Verge put it.
Scrolling on Facebook or X, it's hard not to see some of that chaos creeping into the mainstream.
As my colleague Clare Duffy wrote last week, Facebook spam is surging, and, in extreme cases, it is being 
weaponized to scam and mislead people - a shift that coincides with an intentional strategy by the platform to 
downplay news and politics while amplifying vapid, computer-generated content into users' feeds.
Over on X, which Elon Musk acquired in 2022 and promptly gutted its moderation efforts, hate speech and violent 
threats are now fair game.

Page 2 of 2
Trump is drowning in the misinformation swamp he helped create
A spokesperson for Meta, Facebook's parent company, said last week that it works "to remove and reduce the 
spread of spammy content to ensure a positive user experience" and "take action against those who attempt to 
manipulate traffic through inauthentic engagement."
Musk, who fired Twitter's communications staff when he took over the platform, didn't respond to a request for 
comment.
To be sure, there's always been gross and fake stuff on social media. The difference now is how quickly it morphs 
into misinformation, often fueled by human-like AI text and images, with fewer staff dedicated to monitoring and 
taking down fake information. Once upon a time, you had to go through a process, overseen by human moderators, 
to get a "verified" check mark on Twitter; now, anyone with or without an agenda to push can simply buy it.
In some ways, Trump's political career tracks the rise and deterioration of social media over the past decade. The 
former reality star made his name in politics in part by exploiting social media's power to broadcast lies and 
conspiracy theories to the masses, starting with his racist "birther" attacks on President Barack Obama.
With Tuesday night's foray into the pet-eating lie, he may have finally veered so deep into the internet muck he can't 
see through it.
Just a few weeks ago, the former president posted an AI-generated image on his Truth Social platform that 
suggested Taylor Swift had endorsed him. "I accept," he wrote in the post.
Of course, it was a fake image - the same kind of obvious AI slop that has overrun Facebook and X. Either Trump 
didn't know the image was fake, or he didn't mind lying to his followers and perpetuating the fake endorsement.
Neither scenario suggests he's too concerned about the problem of misinformation online.
Taylor Swift, for her part, is concerned. In endorsing Vice President Kamala Harris on Tuesday, Swift wrote that the 
incident with the fake images of her "conjured up my fears around AI, and the dangers of spreading 
misinformation."
She signed off on the post by calling herself a "childless cat lady" - a nod to widely ridiculed comments from 
Trump's running mate, JD Vance.
As if on cue, Musk, the pro-Trump multibillionaire who also shared the fake pet-eating story on X this week, chimed 
in to remind everyone that you can say whatever you want on his platform, no matter how vile or threatening to a 
woman who's never publicly acknowledged him.
"Fine Taylor ... you win ... I will give you a child and guard your cats with my life."         
             Analysis by Allison Morrow, CNN         
TM & © 2024 Cable News Network, Inc., a Time Warner Company. All rights reserved.
Load-Date: September 12, 2024
End of Document
Page 1 of 2
BBC London News - 5:45 PM GMT
BBC London News - 5:45 PM GMT
TVEyes - BBC 1 West Midlands
September 12, 2024
Copyright  TVEyes, Inc. All Rights Reserved
Section: U.K. REGIONAL TV; News
Length: 829 words
Highlight: The latest news, sport and weather from London.
Body
Speech to text transcript:1
in the creative industries just yet. We value human creativity way too much for that, and I think that there are some 
interesting spaces where it can move into to assist creatives in their work. There are some spaces where it might it 
may well do take over and people may lose their jobs, and that's unfortunate. These are spaces where we need to 
actually look at, OK, well, what is the value of the humans that are doing the creating?
 AI can't really replace individual craftsmanship, can it? No, no it can't. All it can do is really regurgitate stuff that it's 
seen before. There's a common word being used at the moment called slop with regard to AI output, generative AI 
output. And that, I think is a really good way of describing what happens. It takes a lot of people's input, and these 
are people, creative people's prior art, and it's whacks it all together and makes it into a big stew and spits 
something out that's kind of essentially mass produced at the other end. A lot of people watching might be quite 
frightened, almost, of AI and what it might be able to do. Do you think that's just through a lack of understanding of 
what it is and what it can do? Well, I think people are very right to be a little bit afraid of it. It's partly because there's 
a lot of hype around AI at the moment, and a lot of companies, a lot of industry, a lot of the governments are buying 
into the hype. And the hype really basically says that generative AI can do a lot of things that it can't actually do. 
And what I worry about as an ethicist is that is when companies especially buy into the hype, they might decide that 
the human is worth replacing with an AI system, for example. But over time we will see that actually the human was 
never replaceable by the AI system because the AI system could never innovate. Be creative. Think outside the 
box like humans can. And so I think there's, they're right to be a little bit afraid, especially if they're in the sort of job 
that might be automated like this. It's healthy to have a good amount of scepticism and to push back against these 
kinds of technologies, especially when they aren't going to deliver what their what their creators say they're going to 
deliver. It's an interesting subject. Catherine Flick, thank you. Good to have you with us here on Midlands Today, be 
warned, this cool spell isn't over yet. Also still to come. A dream come true for a Staffordshire dance group. The 
1 This copy is computer generated. Text will vary in accuracy due to speaker dialect and audio quality issues.

Page 2 of 2
BBC London News - 5:45 PM GMT
young people who put on a performance in Disneyland. Do you know your woppered from your flittermice? One 
woman's mission to bring Gloucestershire dialect back into use. A 23-year-old event rider from Malvern, who broke 
her back in a fall at an equestrian event, has praised the NHS staff involved in her ongoing care. Saffron Cresswell 
was paralysed from the chest down, after falling from her horse in June in Yorkshire. The international rider 
underwent surgery and was then moved to a spinal injuries unit in Wakefield. Jamie Coulson reports. I had such a 
path in my life that I was ready to take, aiming for the Olympics in the future, in my sport, and you know, to have 
that taken away from you, at a young age as well, you know, is a massive thing that people don't ever wish to 
experience ever, and no-one could ever anticipate it in their lives. In June, Saffron Cresswell suffered a spinal cord 
injury, and was paralysed from the chest down, after an accident at the Bramham horse trials. The 23-year-old was 
competing in the cross-country phase of the under 25s National Eventing Championship, when she fell off her 
horse. Obviously there is a feeling of why me, why it happen to me, what did I do wrong? It is so easy to fall into 
that almost trap of feeling about what happened and why did it happen? But there isn't an answer, you can never 
know an answer, you have to try and look forward, and it's OK, this is my life now, let's see what I can do to sort of 
change it and turn it around. Hi. Hello Saffron, good morning. Following surgery in Leeds, she was moved to the 
regional spinal injuries centre at Pinderfield's Hospital in Wakefield. Spinal cord injury is a life-changing injury. It 
really affects every system in the body, so once they have had a spinal cord injury, their life completely changes. 
They have to learn literally everything, from being able to do their basic activities of daily living to going out into the 
community, it is really the start of a new life. When you have been here so long you sort of end up moving in and 
making it feel a bit home. You get to know the staff so well, you get to know the consultants so well and it is a 
massive part of your rehab, building a sort of family on the ward. Get your chin over the bar. The 34 bed centre has 
dedicated rehabilitation facilities, including a gymnasium, hydrotherapy pool, sports hall and communal area.
Load-Date: September 12, 2024
End of Document
Page 1 of 3
What I Learned When My AI Kermit Slop Went Viral
What I Learned When My AI Kermit Slop Went Viral
Atlantic Online
September 9, 2024 Monday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1491 words
Byline: Damon Beres
Body
First, I want to apologize. My Kermit the Frog post was not entirely sincere.
This particular post of mine has been viewed more than 10 million times, which is far more than I expected. But I did 
expect something. Social networks have never been the realm of good faith or authenticity; trolls and other 
engagement baiters have been able to engineer their own virality for years and years, simply by correctly predicting 
what large numbers of people will respond to. Donald Trump's TikToks don't happen by accident; nor did Kamala 
Harris's embrace of "brain rot" videos. Each campaign is constructing media that it believes can travel in algorithmic 
feeds. That's also what I did when I put together my post, which featured a couple dozen AI-generated images of 
Kermit the Frog.
Allow me to explain. Last weekend-delirious from a lack of sleep and hoping that my screaming toddler would soon 
settle down in his crib-I was tapping around on my phone in a kind of fried stupor. My mind struggled to latch on to 
anything. Each of the apps on my home screen seemed to promise only more boredom. I was the sort of trapped 
that many parents of young children might recognize: A demand for attention could come at any moment, so I 
couldn't lose myself in a book or a bike ride. But I was looking for a diversion.
[Read: What did people do before smartphones?]  
Then I had an idea. I decided that it would be fun to use Bing Image Creator, based on OpenAI's DALL-E 
technology, to help me replace each app icon on my iPhone's home screen with a thematically appropriate image of 
the world's greatest muppet. (Why? You'd have to ask my psychiatrist.) Instead of the basic Gmail icon, I contrived 
an image of Kermit buried under a massive pile of envelopes. Instead of the basic green phone icon, Kerm chatting 
on a yellow landline.
The final product was an absurd, borderline-deranged home-screen grid of 24 bespoke frogs. The creation of each 
one required a series of specific prompts from me. There was Calculator Kermit and Photos Kermit. Authenticator 
Kermit was dressed like a police officer and wielded a massive baton. My job complete, I took a screenshot and 
sent it to a friend, who replied, "Damon I truly truly fear for you." About halfway through the project, I had developed 

Page 2 of 3
What I Learned When My AI Kermit Slop Went Viral
an inkling that her message seemed to confirm: People on the internet would probably respond to this. I could use 
my Kermits to go viral.
Everyone loves Kermit, of course, and that could only help me. But just as important was the fact that I had made 
the images using generative AI, a hyper-polarizing technology with passionate boosters and passionate critics. My 
content would have to appeal to both groups in order to go as far as possible. So I tried to walk a middle path. I 
typed an ambiguously worded post that nonetheless contained a sharp opinion that people could react t "People will 
be like, ~generative AI has no practical use case,' but I did just use it to replace every app icon on my home screen 
with images of Kermit, soooo." Then I embedded the before and after images of my home screen, and published 
simultaneously on X and Threads.
The reactions were swift, and they haven't stopped. A lot of people just love the images. Others have accused me 
of destroying the environment, thanks to generative AI's water and energy use. (I suppose I'm guilty on that count; 
alas, every online action takes its toll.) Quite a few people have criticized me for leeching off Disney's intellectual 
property. (Another fair knock, given that generative AI is trained on tons of copyrighted material.) Some seem to 
view me as a tech bro or 4chan creep, perhaps because for the YouTube app, I had generated an image of Kermit 
watching Pepe the Frog-I meant it as a reference to the purportedly radicalizing content that the site has hosted, not 
as an endorsement of the symbol.
And many people have posted that I played myself, allowing the AI to do the "fun," imaginative stuff while I took on 
the rote task of changing the app icons. Those people are wrong: Writing the prompts, looking at the outputs, and 
adjusting my asks in response was like playing with atoy. By contrast, one person attempted towrite a program that 
would automate every step of the process I had undertaken. Although arguably impressive on its own merits, it 
appeared to produce bland, interchangeable, witless icons. No fun.
The truth is that the AI didn't just do everything for me. I came up with little details that some people delighted in (a 
blond-wigged Kermit snapping a selfie for the Instagram icon, Kermit climbing out of a filthy sewer for X), I tweaked 
and iterated on the prompts until the outputs were right, and I selected the options I thought looked the best. Even 
the images that some took as evidence of the uselessness of generative AI (an icon for The Washington Post app 
bearing the nonsensical headline "NEW HASPELES"; a calendar icon showing the month "EOMER") were chosen 
on purpose. It seemed funny and appropriate to include art with some glitches, given AI'swell-documented 
problems, though avoiding them would have been easy. (For the Atlantic app, of course, I made sure to choose an 
output with the correct spelling.)
[Read: Generative art is stupid]
That's not to say that I believe what I did was creative, exactly. The feeling reminded me a bit of editing a talented 
writer (albeit a nonhuman plagiarist in this case): I gave direction and received something in response, but the 
fundamental essence of the work did not emerge from my mind. As in working with a person, there was room for 
surprise-when the image generator took it upon itself, for example, to add a pair of breasts to Kermit for the 
Instagram icon. (I promise I did not ask for them.) You can nudge the program in one direction or another, but every 
press of the "Create" button is a bit like pulling a slot machine.
This is one reason generative AI is such an ideal match for the social-media era. These programs are now nested 
within X, Facebook, Instagram, and Snapchat-apps that are defined not just by endless scrolling but by the 
downward tug from the top of your screen to refresh and get something new. AI images are a confection just like 
the other algorithmically served junk people now spend so much time consuming. Having a home screen filled with 
Kermits isn't actually practical. The effort was entirely about entertaining myself and getting engagement, not 
remaking how I actually navigate my phone. (I reverted to the default app icons almost immediately, because the 
Kermits all blurred together and made the device harder to use.) It's no wonder that social-media companies are 
pushing generative AI; the technology feels like it offers both a way to melt time and a shortcut to the kind of 
numbers-go-up posting that makes these networks so compulsively usable. As my colleague Charlie Warzel wrote 
last month, that plug-and-play quality has given generative-AI images a certain utility for the MAGA set, who 
routinely embrace outrageous falsehoods for political gain. They can now illustrate and post in seconds whatever 
Page 3 of 3
What I Learned When My AI Kermit Slop Went Viral
meme they're using to rally the base on a given day. Likewise, spammers have found that it pays to flood Facebook 
with attention-grabbing AI slop.
So here is a use for generative AI: It is lubricant for broken algorithmic machinery. Pour it into a social network, and 
if you've done the alchemy right, the gears will turn and turn. This is the internet's synthetic maximalist moment, 
where fake content leads easily to superficial interaction. I soon started to notice that many of the typed responses 
to my post seemed to be following a script, that they were sent from anonymous accounts that barely followed (or 
were followed by) anyone at all. I'm certain that many were bots, interacting with a JPEG file that had also been 
made by one-albeit with my mischievous prompting.
The informational environment has become hopelessly junked up, and the way it works can be dispiriting to even 
the most cynical of the extremely online. But I have to admit that watching my Kermit post go viral was, dare I say, 
fun. I'm sure many of the actual people who responded to me felt it too. I was amused. Perhaps when we look back 
on the generative-AI revolution, we'll realize that chasing this feeling is the ultimate reason for many of these 
programs-especially as they enter social apps that are designed to prioritize engagement.
 We're a long way from Amusing Ourselves to Death, Neil Postman's famous 1985 book, which argued that 
television would lead the public to privilege spectacle over substance. But it's clear that Postman saw around the 
right corner. Many prognosticators have said quite a lot about AI's existential risks, that the technology could be 
used to construct bioweapons and God knows what else. In the meantime, aided by other sophisticated machines-
and, sometimes, an exhausted parent on an iPhone-it's a grade-A brain softener. Use with caution.
Load-Date: September 10, 2024
End of Document
Page 1 of 3
University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List
University of Chicago: Prof. Ben Zhao Named to TIME Magazine's TIME100 
AI List
Targeted News Service
September 7, 2024 Saturday 4:17 PM  EST
Copyright 2024 Targeted News Service LLC All Rights Reserved
Length: 774 words
Byline: Targeted News Service
Dateline: CHICAGO, Illinois 
Body
(TNSres) -- The University of Chicago issued the following news:
* * *
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
* * *
TIME magazine announced Sept. 5 that it has named Ben Zhao, the University of Chicago Neubauer Professor of 
Computer Science, to its TIME100 AI list.
The TIME100 AI list celebrates individuals who are shaping the future of AI, a technology that continues to 
revolutionize industries. As TIME highlights, the rapid growth of AI is driven not just by the technology itself, but by 
the people behind it--those who make critical decisions about its development, safety, and application.
Zhao's recognition on this list highlights his significant contributions and leadership, particularly in the areas of 
adversarial machine learning and security--a field that explores how machine learning models can be manipulated 
and how to defend against such attacks.
He is particularly known in the field for protective tools to mitigate harms of AI, including tools like Nightshade and 
Glaze, which artists can apply to their works to protect them from being scraped and used without consent to train 
AI models.
Innovation and impact
Zhao's research has spanned a broad range of areas, including networking, human-computer interaction, and 
security and privacy. Since 2016, he has focused on addressing security and privacy challenges in machine 

Page 2 of 3
University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List
learning and mobile systems. Most recently, his work has centered on adversarial machine learning and developing 
tools to protect human creatives from the potential harms of generative AI models.
"My experiences across different areas (but especially in human-computer interaction) has taught me the value of 
engaging with users to truly understand how research and technology impacts real people," said Zhao. "As a result, 
I am always drawn to research challenges that impact large groups of people, and projects that address those 
challenges by taking into account perspectives of the users most directly impacted."
He is particularly known in the field for tools to mitigate harms of AI. This line of work began in 2020, with Fawkes, 
an image cloaking tool designed to prevent third parties from building unauthorized facial recognition models of 
individuals based on public photos online.
Zhao's team also developed Nightshade, which proactively protects content copyright of visual artwork by making 
them toxic to AI models that train on them without consent, and Glaze, which protects individual artists against style 
mimicry.
These programs make changes to an image that are nearly imperceptible to the human eye, but significantly 
change what the AI "sees."
Since its release in January 2024, Nightshade has been downloaded nearly a million times.
As AI continues to evolve at a breakneck pace, the insights and innovations of leaders like Zhao will play a crucial 
role in shaping the technology's future.
"The recent rush towards generative AI has been spurred on by an aura of inevitability, promises of societal 
benefits, and massive profits," Zhao warned. "While many of these have yet to materialize, harms like copyright 
violation, proliferation of AI slop and deepfakes, and disruption to creative sectors are here today. These are the 
harms our lab works to mitigate through our research."
Zhao is an ACM Fellow and a recipient of the NSF CAREER award, the Internet Defense Prize, and MIT 
Technology Review's TR-35 Award, among others. His work has been featured in prominent media outlets such as 
the New York Times, Scientific American, NBC, CNN, BBC, and the Wall Street Journal, underscoring the broader 
societal impact of his research.
In addition to his research, Zhao is deeply involved in the academic community. He serves on technical program 
committees for top conferences in computer security (ACM CCS, IEEE Security & Privacy) and machine learning 
(NeurIPS). At University of Chicago, he co-directs the Security, Algorithms, Networking, and Data (SAND) Lab at 
UChicago alongside Neubauer Professor Heather Zheng and serves as the Director of Graduate Studies for the 
Department of Computer Science.
"I'm humbled by this recognition, and proud to share it with my long-term collaborator Prof. Heather Zheng, our 
wonderful students, and the many human artists, writers and other creatives working with us to build a future 
ecosystem where human creativity is valued more than technology," Zhao said.
- Adapted from an article first published by the Department of Computer Science.
* * *
Original text here: https://news.uchicago.edu/story/prof-ben-zhao-named-time-magazines-time100-ai-list
Copyright Targeted News Services
MSTRUCK-8805480 MSTRUCK
Load-Date: September 8, 2024
Page 3 of 3
University of Chicago : Prof. Ben Zhao Named to TIME Magazine's TIME100 AI List
End of Document
Page 1 of 2
PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST
PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST
States News Service
September 6, 2024 Friday
Copyright 2024 States News Service
Length: 738 words
Byline: States News Service
Dateline: CHICAGO, Illinois 
Body
The following information was released by the University of Chicago:
By Miranda Redenbaugh
Sep 6, 2024
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
TIME magazine announced Sept. 5 that it has named Ben Zhao, the University of Chicago Neubauer Professor of 
Computer Science, to its TIME100 AI list.
The TIME100 AI list celebrates individuals who are shaping the future of AI, a technology that continues to 
revolutionize industries. As TIME highlights, the rapid growth of AI is driven not just by the technology itself, but by 
the people behind itthose who make critical decisions about its development, safety, and application.
Zhao's recognition on this list highlights his significant contributions and leadership, particularly in the areas of 
adversarial machine learning and securitya field that explores how machine learning models can be manipulated 
and how to defend against such attacks.
He is particularly known in the field for protective tools to mitigate harms of AI, including tools like Nightshade and 
Glaze, which artists can apply to their works to protect them from being scraped and used without consent to train 
AI models.
Innovation and impact
Zhao's research has spanned a broad range of areas, including networking, human-computer interaction, and 
security and privacy. Since 2016, he has focused on addressing security and privacy challenges in machine 
learning and mobile systems. Most recently, his work has centered on adversarial machine learning and developing 
tools to protect human creatives from the potential harms of generative AI models.
"My experiences across different areas (but especially in human-computer interaction) has taught me the value of 
engaging with users to truly understand how research and technology impacts real people," said Zhao. "As a result, 

Page 2 of 2
PROF. BEN ZHAO NAMED TO TIME MAGAZINE'S TIME100 AI LIST
I am always drawn to research challenges that impact large groups of people, and projects that address those 
challenges by taking into account perspectives of the users most directly impacted."
He is particularly known in the field for tools to mitigate harms of AI. This line of work began in 2020, with Fawkes, 
an image cloaking tool designed to prevent third parties from building unauthorized facial recognition models of 
individuals based on public photos online.
Zhao's team also developed Nightshade, which proactively protects content copyright of visual artwork by making 
them toxic to AI models that train on them without consent, and Glaze, which protects individual artists against style 
mimicry.
These programs make changes to an image that are nearly imperceptible to the human eye, but significantly 
change what the AI "sees."
Since its release in January 2024, Nightshade has been downloaded nearly a million times.
As AI continues to evolve at a breakneck pace, the insights and innovations of leaders like Zhao will play a crucial 
role in shaping the technology's future.
"The recent rush towards generative AI has been spurred on by an aura of inevitability, promises of societal 
benefits, and massive profits," Zhao warned. "While many of these have yet to materialize, harms like copyright 
violation, proliferation of AI slop and deepfakes, and disruption to creative sectors are here today. These are the 
harms our lab works to mitigate through our research."
Zhao is an ACM Fellow and a recipient of the NSF CAREER award, the Internet Defense Prize, and MIT 
Technology Review's TR-35 Award, among others. His work has been featured in prominent media outlets such as 
the New York Times, Scientific American, NBC, CNN, BBC, and the Wall Street Journal, underscoring the broader 
societal impact of his research.
In addition to his research, Zhao is deeply involved in the academic community. He serves on technical program 
committees for top conferences in computer security (ACM CCS, IEEE Security and Privacy) and machine learning 
(NeurIPS). At University of Chicago, he co-directs the Security, Algorithms, Networking, and Data (SAND) Lab at 
UChicago alongside Neubauer Professor Heather Zheng and serves as the Director of Graduate Studies for the 
Department of Computer Science.
"I'm humbled by this recognition, and proud to share it with my long-term collaborator Prof. Heather Zheng, our 
wonderful students, and the many human artists, writers and other creatives working with us to build a future 
ecosystem where human creativity is valued more than technology," Zhao said.
Load-Date: September 6, 2024
End of Document
Page 1 of 2
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
Honor recognizes unique contributions to the field, including Glaze and 
Nightshade tools
The Pulse: Finch University of Health Sciences
September 6, 2024 Friday
University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved
Section: LATESTSTORIES; Pg. 1
Length: 719 words
Byline: Miranda Redenbaugh
Body
TIME magazine announced Sept. 5 that it has named Ben Zhao, the University of Chicago Neubauer Professor of 
Computer Science, to its TIME100 AI list.
The TIME100 AI list celebrates individuals who are shaping the future of AI, a technology that continues to 
revolutionize industries. As TIME highlights, the rapid growth of AI is driven not just by the technology itself, but by 
the people behind it-those who make critical decisions about its development, safety, and application.
Zhao's recognition on this list highlights his significant contributions and leadership, particularly in the areas of 
adversarial machine learning and security-a field that explores how machine learning models can be manipulated 
and how to defend against such attacks.
He is particularly known in the field for protective tools to mitigate harms of AI, including tools like Nightshade and 
Glaze, which artists can apply to their works to protect them from being scraped and used without consent to train 
AI models.
Innovation and impact
Zhao's research has spanned a broad range of areas, including networking, human-computer interaction, and 
security and privacy. Since 2016, he has focused on addressing security and privacy challenges in machine 
learning and mobile systems. Most recently, his work has centered on adversarial machine learning and developing 
tools to protect human creatives from the potential harms of generative AI models.
"My experiences across different areas (but especially in human-computer interaction) has taught me the value of 
engaging with users to truly understand how research and technology impacts real people," said Zhao. "As a result, 
I am always drawn to research challenges that impact large groups of people, and projects that address those 
challenges by taking into account perspectives of the users most directly impacted."

Page 2 of 2
Honor recognizes unique contributions to the field, including Glaze and Nightshade tools
He is particularly known in the field for tools to mitigate harms of AI. This line of work began in 2020, with Fawkes, 
an image cloaking tool designed to prevent third parties from building unauthorized facial recognition models of 
individuals based on public photos online.
Zhao's team also developed Nightshade, which proactively protects content copyright of visual artwork by making 
them toxic to AI models that train on them without consent, and Glaze, which protects individual artists against style 
mimicry.
These programs make changes to an image that are nearly imperceptible to the human eye, but significantly 
change what the AI "sees."
Since its release in January 2024, Nightshade has been downloaded nearly a million times.
As AI continues to evolve at a breakneck pace, the insights and innovations of leaders like Zhao will play a crucial 
role in shaping the technology's future.
"The recent rush towards generative AI has been spurred on by an aura of inevitability, promises of societal 
benefits, and massive profits," Zhao warned. "While many of these have yet to materialize, harms like copyright 
violation, proliferation of AI slop and deepfakes, and disruption to creative sectors are here today. These are the 
harms our lab works to mitigate through our research."
Zhao is an ACM Fellow and a recipient of the NSF CAREER award, the Internet Defense Prize, and MIT 
Technology Review's TR-35 Award, among others. His work has been featured in prominent media outlets such as 
the New York Times, Scientific American, NBC, CNN, BBC, and the Wall Street Journal, underscoring the broader 
societal impact of his research.
In addition to his research, Zhao is deeply involved in the academic community. He serves on technical program 
committees for top conferences in computer security (ACM CCS, IEEE Security & Privacy) and machine learning 
(NeurIPS). At University of Chicago, he co-directs the Security, Algorithms, Networking, and Data Lab at UChicago 
alongside Neubauer Professor Heather Zheng and serves as the Director of Graduate Studies for the Department 
of Computer Science.
"I'm humbled by this recognition, and proud to share it with my long-term collaborator Prof. Heather Zheng, our 
wonderful students, and the many human artists, writers and other creatives working with us to build a future 
ecosystem where human creativity is valued more than technology," Zhao said.
- Adapted from an article first published by the Department of Computer Science.
Load-Date: September 6, 2024
End of Document
Page 1 of 3
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
Rolling Stone
September 5, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 1768 words
Byline: Miles Klee
Body
The picture, posted  July 4 on the Facebook page "Love Shares 3.0" for 71,000 followers, appears to be an aerial 
view of St. Peter's Basilica in the Vatican, with people gathered in the square. Overhead, dangling from a gigantic 
black helicopter, is what can only be a massive Bible, but the lettering on the book is garbled, and the cross on the 
cover has an extra arm. It looks as if the aircraft is about to drop this tome on the crowd below, flattening them. The 
caption is pure gibberish: "Close your eyes 70% and see magic / Today's my graduation / May 2024 is Your Best 
Year." Additional hashtags identify the image as "art" and "painting." 
It is, quite clearly, AI-generated - though nobody in the comments mentions this. "Praise the lord," writes oneuser. 
Many others reply with a simple "amen." The image has close to 6,000 likes and "heart" engagements.
In the early 2010s, Facebook reshaped digital life as we know it. But in the past few years, a confluence of trends 
has left it uniquely vulnerable to click-farming pages that churn out AI-created junk. At a critical moment when 
online creators are weighing the benefits of integrating controversial AI tech into their personal brands, a shadow 
army of spam "creators" have already leveraged it to invade a platform mostly abandoned by such internet 
celebrities, eating away at whatever social value it has left. Worst of all, the very structure of Facebook appears to 
have encouraged this rot. 
One factor, of course, is the rise of text-prompt image generators like Midjourney, Stable Diffusion, and DALL-E, 
which make it profoundly easy to create "original" works at a terrific rate. Facebook, meanwhile, was investing 
billions in CEOMark Zuckerberg's "metaverse" boondoggle, and still has no real user base to show for it:Gen Z 
famouslydisdains the social network as uncool, preferringTikTok and the alsoMeta-owned Instagram, leaving 
Facebook with anaging demographic.
If the AI-reliant spam pages are any indication, many of those still scrolling Facebook can't tell or don't care when 
an image is fake, and have a particular fondness for certain comforting signifiers: Bibles, babies, American flags, 
soldiers, animals, luxurious homes, landscapes, and Jesus Christ. Then there are the images meant to evoke pity: 
patients in hospital beds, crying or endangered children, amputees, the unhoused, the starving. Sometimes the 
imagined figure is shown holding a sign asking for birthday wishes, or explaining that they're a veteran. And in 

Page 2 of 3
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
certain cases, there's no earthly explanation for what you're looking at - like this military truck that seems to be 
transporting giant carrots, but is also made out of them:
pic.twitter.com/RO99qZ5B0b
- Insane Facebook AI slop (@FacebookAIslop) September 3, 2024
Theodore, a 19-year-old who lives in Paris, has become the top curator of what he calls "Insane Facebook AI slop," 
and shares his favorite examples on a dedicatedTwitter account with more than 100,000 followers. On that site, it's 
customary to mock the content, as well as the gullible Boomers assumed to be eating it up. There's even an AI 
slop bingo card meme that followers can use to keep track of some common tropes, including the generic captions 
most often appended to the images, like: "Why don't pictures like this ever trend" and "You will never regret liking 
this photo." (Scarlett Johansson's name also shows up a lot, for some reason.)  
"I don't use Facebook a lot myself but saw plenty of screenshots of those types of posts on Twitter, and the insane 
amount of likes these had made the phenomenon funnier," Theodore tells Rolling Stone. "So I thought I might as 
well document those." At this point, he almost exclusively shares content he receives in DM submissions.
Theodore believes the success of AI slop is mostly due to the elderly and naive. "Facebook is full of old people and 
tech-illiterate people in general," he says, which is "also why the kind of posts that get the most likes are the ones 
that will target old people, using soldiers, American flags, Jesus imagery, etc." Since some themes are so 
dominant, he tries to maintain variety, lately branching out into illustrations of "third-world children doing all sorts of 
impossible crafts."
Meta has taken a rather gentle approach to AI-derived images and videos, opting to add an "AI info" label "when 
we detect industry standard AI image indicators or when people disclose that they're uploading AI-generated 
content," itsaid in a statement this summer. This label did not appear on any of the AI images shared by more than 
a dozen engagement-farming pages reviewed by Rolling Stone. As for more stringent moderation, Meta's Oversight 
Board has argued that they "unnecessarily risk restricting freedom of expression when we remove manipulated 
media that does not otherwise violate our Community Standards."
That is to say, because the typical AI slop isn't strictly misinformation (nor is it hate speech, graphic nudity, and so 
on), there's no glaring reason to delete it - unless Meta were to deem it spam. The company'spolicy states that it 
does not allow spam, which it defines as "content that is designed to be shared in deceptive and annoying ways or 
attempts to mislead users to drive engagement." The AI slop pages are certainly deceptive, repetitive, and gaming 
the system for engagement; there's also no telling how many are monetized and profiting from an abundance of 
reactions and comments.
Meta tells Rolling Stone that while "eradicating spam is a nearly impossible task," the company takes significant 
measures against it, since this type of content "detracts from people's ability to engage authentically in online 
communities." In the first quarter of 2024, it reported, Meta "removed 436 million pieces of spam content from 
Facebook," with 98.2 percent of this "actioned before it could be reported."
The question remains whether Meta would deem the AI-generated images to be spam in violation of their policy, or 
just take the engagement as a sign to feed those users more of the same. The pseudonymous data researcher and 
software developer Conspirador Norteño in June published a Substackinvestigation that suggested the latter: that 
Facebook's recommendation algorithm is favoring the AI slop over authentic content.
After logging in with a dummy account he had only ever used to shop for music gear, Conspirador simply scrolled 
through more than a thousand posts on his feed over half an hour and collected information on both the content 
and the pages that shared them. He found that less than 5 percent of the material corresponded to his past 
browsing of music equipment, 12.7 percent was sponsored ads, and the rest was "mostly a mix of AI-generated 
images and plagiarized photographs posted by content aggregator accounts with large numbers of followers." AI-
generated content accounted for 22 percent, or almost a quarter, of all the posts he viewed.
Page 3 of 3
Facebook's AI-Generated Spam Problem Is Worse Than You Realize
"I think a lot of people still operate with the expectation that images that look like photos are real photos, and don't 
notice that they're really looking at an AI image unless there are really obvious problems," Conspirador says. He 
noted the prevalence of pages such as "Log Cabin Living," "Mountain Cabins," and "Barndominium Gallery," which 
tend to feature images of lavishly appointed country mansions set in lush nature scenes - pictures that often don't 
immediately betray signs of being fake. These reliably pick up likes, comments, and subscribers. "Unusual-looking 
houses and pretty outdoor scenes tend to do well, even when an account posts dozens or hundreds that are 
basically the same," Conspirador says. A typical "Log Cabin Living" post features a preposterously large house with 
an uncanny pool that seems to blur the distinction between artificial and natural bodies of water:
People gazing with admiration at fantasy houses that don't exist is one thing, and a social media algorithm 
amplifying this stuff is another. But Conspirador was particularly surprised by "Facebook's failure to intervene in 
cases where the account [was] obviously hijacked" from an ordinary user before it began spewing AI spam. This 
was the situation with "Barndominium Gallery," a page which he foundhad previously belonged to a hair salon in 
Oklahoma. In January, the owner of the salon posted that her page had been hacked and asked friends to report it 
to Facebook, yet eight months later, no action has been taken, while the page has accrued hundreds of thousands 
of followers with its AI rubbish. Worse, whoever stole the page has begun promoting links to afake home-
construction business that charges the customer $79.99 for floor plans and cost-of-build estimates on its AI-
generated architecture.
Carissa Véliz, an associate professor of philosophy at the University of Oxford's Institute for Ethics in AI, views the 
slop takeover as the logical result of how Facebook works. "This phenomenon seems to be a secondary effect of 
social media's focus on engagement," she says. "Instead of focusing on fostering wholesome relationships, or in 
being trustworthy sources of information, social media has focused on gaining people's attention. And it turns out 
that what attracts most of our attention is akin to junk food."
"Generative AI was designed to engage people," Véliz says. "It's good at producing images that people find 
captivating." Facebook, she points out, needs that content that keeps people glued to the app, and may tolerate 
clickbait because they're concerned that "users were no longer sharing as many personal stories as before." What's 
more, Véliz proposes, companies like Meta are incentivized to create Frankenstein's monsters beyond their control, 
as the "inadequate current regulation doesn't demand of social media companies anything that can be too 
burdensome." Therefore, if you have a system running amok, but fixing it would be too difficult, "it magically 
absolves you from its effects." 
pic.twitter.com/ATksXwxEAm
- Insane Facebook AI slop (@FacebookAIslop) August 31, 2024
In the meantime, spectators like Theodore and his audience will have plenty of absurdities to laugh at, from fish with 
legs toIncredible Hulk porn to phony black-and-white "historical"photos. He's also started pulling material from 
YouTube and X/Twitter, which are hardly immune from the same trend. But perhaps not all is lost just yet. Theodore 
doesn't usually look at the comments on Facebook AI slop, since there's no need to read "amen" a hundred times 
in a row. When he does, however, he's treated to the occasional surprise: "Someone calling out the post for being 
made by an AI."   
Load-Date: September 5, 2024
End of Document
Page 1 of 9
2:00PM Water Cooler 9/4/2024
2:00PM Water Cooler 9/4/2024
Newstex Blogs 
Naked Capitalism
September 4, 2024 Wednesday 6:00 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 Naked Capitalism 
Length: 4637 words
Byline: Lambert Strether
Body
September 4th, 2024 ( Naked Capitalism  - Delivered by  Newstex )
By Lambert Strether of Corrente
This is Naked Capitalism fundraising week. 25 donors have already invested in our efforts to combat corruption and 
predatory conduct, particularly in the financial realm. Please join us and participate via our  donation page, which 
shows how to give via check, credit card, debit card, PayPal. Clover, or Wise. Read about why we're doing this 
fundraiser, what we've accomplished in the last year,, and our current goal, strengthening our IT infrastructure.
Bird Song of the Day
Gray Catbird, Heckscher SP, East Islip, Suffolk, New York, United States. 'Singing from a small wooded area near 
a marsh.'
* * *
In Case You Might Miss
Kamala's Democrat prep.
Collard greens and code switching..
Clean air in the schools? Lol no..
H5N1 reassortment in Cambodia.* * *
Politics
'So many of the social reactions that strike us as psychological are in fact a rational management of symbolic 
capital.' -Pierre Bourdieu, Classification Struggles

Page 2 of 9
2:00PM Water Cooler 9/4/2024
* * *
2024
Less than one hundred days to go!
Friday's  RCP Poll Averages:
The good news for Trump is that Kamala's post-convention 'bounce' seems to have been slight. The good news for 
Kamala is Trump's continued deterioration in North Carolina, plus taking a slight lead in Pennsylvania. Remember, 
however, that all the fluctuations - in fact, all the leads, top to bottom - are within the margin of error.
* * *
The Debate (September 10)
Kamala (D): 'Kamala Harris goes to 'debate camp': Insiders reveal where VP's preparation is already going 
'sideways' as she gets ready for primetime Trump showdown' [ Daily Mail]. 'Sources close to the Harris team 
tell NOTUS that Harris is a little rusty on the debate stage as 'strategy sessions have careened sideways' when 
Harris 'focused too narrowly on minute details, effectively trailing the sessions.' Despite her willingness to debate, 
Harris and her team are still trying to negotiate the rules of the debate with ABC News, according to a Harris 
campaign source speaking to NBC News.' Still?! More: 'Trump and his team anticipate that Harris is preparing to 
interrupt him to try and 'fact check' his statements. The former president, however, is aware of Harris and her 
propensity to get lost into so-called 'word salads' while speaking publicly. 'She has bad moments. The way she 
talks,' Trump told broadcaster Tucker Carlson in a recent interview, imitating comments the vice president made 
about school buses. 'It's weird. The whole thing is weird.'' Harris: 'Who doesn't love a yellow school bus, right? Can 
you raise your hand if you love a yellow school bus? Many of us went to school on the yellow school bus, right? It's 
part of our experience growing up. It's part of a nostalgia, a memory of the excitement and joy of going to school to 
be with your favorite teacher, to be with your best friends and to learn. The school bus takes us there.' It's true that 
'It's part of a nostalgia' isn't something a native English speaker would say, but it's the condescension of 'Raise your 
hands' that gets me. Here's the video:
https://www.youtube.com/embed/E2e2HWH5pwo?si=LfV5QXupbvfoeWOg
The audience, presumably, is adult. Also, the hand gestures.
Kamala (D): 'How Kamala Harris Plans to Lock In for Debate Prep in Pennsylvania' [ NOTUS]. 'In conversations 
with nearly a dozen people involved with or aware of the preparations, a set of goals emerged for the next week. 
The campaign is planning to tune out as much of the outside noise as possible to lock her in, aware of Harris' 
relative rust as a debater and her tendency to overprepare and fixate on the details.' And: '[S]he's once again using 
notecards as part of her prep, a second person familiar with the preparations told NOTUS, a habit they believe she 
picked up during her law school days.' I would say the habit came from college debate, in which Harris participated. 
More: 'Allies say Harris has had to defend her ideas inside the White House over the last three years, preparing her 
in some ways for this moment. But Harris is, for all intents and purposes, an out-of-practice debater with people 
who aren't her colleagues. Next week's debate will come just a month shy of four years since she debated Vice 
President Mike Pence in Utah. For that, aides holed up in a hotel in Salt Lake City days before the debate, as she 
used index cards to work through talking points - including the now-famous 'I'm speaking' line, which one person 
involved in the session said was a crowdsourced suggestion.' Hmm. She recycled ' I'm speaking,' then. That didn't 
go so well. Interestingly, in neither of these two articles to we see any suggestion that Kamala would play the 
prosecutor ('Why am I debating a felon?'). Which seems a very obvious thing for her to do. Why go to all the trouble 
of doing the lawfare if you're not going to use it in debate?* * *
Kamala (D): 'The White House wants you to know that Harris was on the call' [ Politico]. 'Name-checking Harris - or 
any vice president, for that matter - is unusual and suggests an attempt to buttress her credentials as she faces 
Page 3 of 9
2:00PM Water Cooler 9/4/2024
questions about her ability to manage international affairs and confronts an experienced opponent in former 
President Donald Trump. POLITICO's review of pool reports, readouts, transcripts of administration briefings and 
comments by the nation's top diplomats and military officials found that the administration increased its mentions of 
Harris in public statements about foreign engagements since July, when Biden announced he would drop out of the 
presidential election and endorsed his vice president.' The previous NOTUS article includes this sentence: '[T]he 
Biden administration is in what they hope to be the last stretch of a cease-fire deal between Israel and Hamas that 
might require Harris' presence in the Situation Room.' Her mere presence. I know that Harris doing debate prep 
while a ceasefire deal was being consummated would look bad, but avoiding a bad look seems to be the only 
reason for her presence.* * *
Kamala (D): 'Cooking Collard Greens The Caribbean Way' [ Caribbean Pot]. 'Collard Green or collards is not native 
to the Caribbean, so it's not something we would refer to as being traditional. However, with our love for dasheen 
bush, spinach, Jamaican callaloo (chorai), Bok Choi and just about every other green there is, it's natural that 
collards will find a loving home in my kitchen.' So, wherever Kamala learned to cook collard greens - Montreal? Her 
sorority? - it's unlikely to be a family tradition (not on her Jamaican father's side, and certainly not on her Indian 
mother's side).
Kamala (D): And code switching:
One of my favorite accounts, on Twitter since 2011. In general, very level-headed.
* * *
Trump (R): 'Donald Trump Interview' (video) [Lex Fridman,  YouTube (outside observer)]. Smart move by Trump 
campaign staff:
https://www.youtube.com/embed/qCbfTN-caFI?si=-eTHOYXIAmtN9gaK
Trump (R): 'Questions surrounding Trump's mental acuity are a real 2024 story' [ MSNBC]. 'The words below were 
taken verbatim from a campaign speech' [and they're an especially dense example of free-form riffing]. 'Trump's 
asides stack atop each other with such density that it's dizzying for even professional political observers to discern 
what he's trying to get at. Trump's speeches seem to be growing more discursive and difficult to comprehend by the 
day. Those speeches are making it hard, if not impossible, for people listening to them to understand what he wants 
to do with his power in office, and they're reportedly turning off voters. They're also raising questions over whether 
the chaos he would sow in office would be even less intentional than it was last time. Trump's deteriorating 
[asserted, not shown] ability to clearly communicate is a consequential feature of his 2024 candidacy. That 
deterioration may not have been as salient when Trump, 78, had 81-year-old President Joe Biden as an opponent. 
But it's all the more clear as he now faces off against 59-year-old Vice President Kamala Harris. Questions 
about Biden's mental acuity were rightly raised in this election cycle. Questions about Trump's mental acuity should 
be raised, too.' I doubt this will stick, though of course the Democrats are trying it. Trump did fine in debate when he 
knocked Biden out of the race. Is there any sign of 'deterioration' in the hour-long interview with Fridman? I don't 
have time to listen to it, but I'm guessing no, because otherwise the memes would already be out.* * *
MI: 'CAIR 2024 Election Survey 0f Muslim Voters' [ CAIR]. 'As the 2024 national general election approaches, 
America's estimated 2.5 million Muslim voters are positioned to once again play a crucial role in shaping the 
political landscape. With their significant presence in key swing states, Muslim voters have the potential to influence 
the outcomes of not only the presidential race but also numerous congressional, state, and local elections.' Handy 
chart:
PA: 'Taking the pulse of Pennsylvania's Trump country, from Amish region to Gettysburg' [ USA Today]. 'While the 
election may be decided in the suburbs of Philadelphia and Pittsburgh, where the majority of the state's residents 
live, central Pennsylvania plays a role. It is traditionally red, with small pockets of blue in the cities, but the votes 
that come from the small businesspeople and churchgoers of the middle of the state - often referred to derisively as 
[deplorable] 'Pennsyltucky' - could make a difference in a state where the final results could be decided by a few 
Page 4 of 9
2:00PM Water Cooler 9/4/2024
thousand votes.' Worth a read. And from the York Daily Record, so kudos to USA Today. (Pennsylvania still has a 
lot of smallish newspapers, as we saw with the reporting from Butler.)* * ** * ** * *
Syndemics
'I am in earnest - I will not equivocate - I will not excuse - I will not retreat a single inch - AND I WILL BE HEARD.' -
William Lloyd Garrison
* * *
Covid Resources, United States (National): Transmission ( CDC); Wastewater ( CDC, Biobot; includes many 
counties; Wastewater Scan, includes drilldown by zip); Variants ( CDC; Walgreens); ' Iowa COVID-19 Tracker' (in 
IA, but national data). ' Infection Control, Emergency Management, Safety, and General Thoughts' (especially on 
hospitalization by city).
Lambert here: Readers, thanks for the collective effort. To update any entry, do feel free to contact me at the 
address given with the plants. Please put 'COVID' in the subject line. Thank you!
Resources, United States (Local): AK ( dashboard); AL ( dashboard); AR ( dashboard); AZ ( dashboard); CA 
( dashboard; Marin, dashboard; Stanford, wastewater; Oakland, wastewater); CO ( dashboard; wastewater); CT 
( dashboard); DE ( dashboard); FL ( wastewater); GA ( wastewater); HI ( dashboard); IA ( wastewater reports); ID 
( dashboard, Boise; dashboard, wastewater, Central Idaho; wastewater, Coeur d'Alene; dashboard, Spokane 
County); IL ( wastewater); IN ( dashboard); KS ( dashboard; wastewater, Lawrence); KY ( dashboard, Louisville); 
LA ( dashboard); MA ( wastewater); MD ( dashboard); ME ( dashboard); MI ( wastewater; wastewater); MN 
( dashboard); MO ( wastewater); MS ( dashboard); MT ( dashboard); NC ( dashboard); ND 
( dashboard; wastewater); NE ( dashboard); NH ( wastewater); NJ ( dashboard); NM ( dashboard); NV 
( dashboard; wastewater, Southern NV); NY ( dashboard); OH ( dashboard); OK ( dashboard); OR ( dashboard); 
PA ( dashboard); RI ( dashboard); SC ( dashboard); SD ( dashboard); TN ( dashboard); TX ( dashboard); UT 
( wastewater); VA ( dashboard); VT ( dashboard); WA ( dashboard; dashboard); WI ( wastewater); WV 
( wastewater); WY ( wastewater).
Resources, Canada (National): Wastewater ( Government of Canada).
Resources, Canada (Provincial): ON ( wastewater); QC ( les eaux uses); BC ( wastewater); BC, Vancouver 
( wastewater).
Hat tips to helpful readers: Alexis, anon (2), Art_DogCT, B24S, CanCyn, ChiGal, Chuck L, Festoonic, FM, 
FreeMarketApologist (4), Gumbo, hop2it, JB, JEHR, JF, JL Joe, John, JM (10), JustAnotherVolunteer, JW, 
KatieBird, KF, LL, Michael King, KF, LaRuse, mrsyk, MT, MT_Wild, otisyves, Petal (6), RK (2), RL, RM, Rod, 
square coats (11), tennesseewaltzer, Tom B., Utah, Bob White (3).
Stay safe out there!
* * *
Airborne Transmission: Covid
'Kids Are Headed Back to School. Are They Breathing Clean Air?' [ Scientific American]. Lol no. 'Across the U.S., 
kids are headed back to their classrooms-just as COVID nears a fresh, late-summer peak. Somehow, four years 
into a viral pandemic that everyone now knows spreads through the air, most schools have done little to nothing to 
make sure their students will breathe safely. We-and especially our children-should be able to walk into a store or a 
gym or a school and assume the air is clean to breathe. Like water from the faucet, regulations should ensure our 
air is safe. 'Air is tricky. You can choose to not partake of the water or the snacks on the table, but you can't just 
abstain from breathing,' notes Gigi Gronvall, senior scholar at the Johns Hopkins Center for Health Security and an 
Page 5 of 9
2:00PM Water Cooler 9/4/2024
author of a 2021 report on the benefits of improving ventilation in schools.' Somehow. Some schools are doing just 
fine, though!
Transmission: H5N1
'Cambodia's recent H5N1 case involved novel reassortant' [ Center for Infectious Disease Research and Policy]. 
'Sequencing of the patient's virus sample at the Pasteur Institute in Cambodia found that the hemagglutinin gene 
from the 2.3.2.1c clade that has been circulating in Cambodia and Southeast Asia since 2013. The internal genes, 
however, belonged to the newer 2.3.4.4b, which is circulating globally. 'This novel reassortant influenza A(H5N1) 
virus has been detected in human cases reported in Cambodia since late 2023,' the WHO said. Cambodian health 
officials have tracked and monitored the [patient's] contacts, and no related cases have been found. The country 
has reported an uptick in human H5N1 infections since 2023, reporting 6 cases last year and 10 this year, of which 
2 were fatal. In April, animal health officials in Vietnam and the United Nations Food and Agriculture Organization 
(FAO) warned of the new reassortant circulating in chickens and muscovy ducks. The scientists said the virus has 
been circulating in the Greater Mekong subregion since 2022. Also, they noted that the reassortant had been linked 
to recent human cases and that the development shows the adaptive capacity of the virus and the risk of new, 
potentially more virulent strains.' Musical interlude.
Denial and Cope
'As COVID Surges, the High Price of Viral Denial' [ The Tyee]. Canada. 'The subject of how to respond to a slow 
burn pandemic remains taboo because most public health officials have already declared the emergency over. 
They've also stopped collecting critical data. COVID-19 deaths in Canada are not reported in a readily publicly 
accessible fashion. And most of the media pretends that an immune-destabilizing virus that can harm the 
functioning of your organs including your brain has little more import than a benign cold. As a consequence, 
authorities can't now turn around and admit to the breadth of their mistake, let alone acknowledge the growing 
disorder in public health. Nor do they dare collect critical data documenting the scale of their errors including the 
relentless march of long COVID. Here, then, is where we've arrived. We've entered a vicious cycle where more 
infections generate more COVID variants. The new variants have become more immune evasive. At the same time 
society has generally abandoned masks, testing and basic public health messages. We could slow and suppress 
the cycle by facing the challenge squarely. For example, by cleaning dirty air the way we once tackled the disease-
ridden spectre of cholera-infested water. But public health officials are afraid to talk about clean air let alone the 
obvious: avoiding infection. Beating back COVID requires hard work, communal wisdom and clear policies that 
markedly reduce the level of infection in society. To date we have chosen viral denial, dirty air and a triumphant 
reign for long COVID.' Excellent article, worth reading in full.
Elite Maleficence
'Simple measures lessen hospital-acquired COVID-19 infections' [ Burnet]. Australia. 'In a new study published in 
the Journal of Hospital Infections, Burnet researchers found simple infection control measures could save lives and 
reduce costs for hospitals. These measures include testing patients for COVID-19 on admission, requiring staff to 
wear N95 masks in clinical areas and using Rapid Antigen Tests (RAT) or Polymerase Chain Reaction (PCR) tests 
to prevent transmissions. One of the paper's lead authors, Burnet Associate Professor Nick Scott, said on average, 
15-25% of patients who tested positive for COVID-19 in hospital had contracted the virus after being admitted.' But 
HICPAC would prefer that hospitals be death traps so, no N95s. Baggy blues only, if that!* * *
TABLE 1: Daily Covid Charts
Wastewater This week[1]  CDC August 26: Last Week[2] CDC (until next week):
Variants [3]  CDC August 31 Emergency Room Visits[4] CDC August 24
Hospitalization New York[5]  New York State, data August 30: National [6] CDC August 10:
Page 6 of 9
2:00PM Water Cooler 9/4/2024
Positivity National[7]  Walgreens September 3: Ohio[8] Cleveland Clinic August 24:
Travelers Data Positivity[9]  CDC August 12: Variants[10] CDC August 12:
Deaths Weekly Deaths vs. % Positivity [11] CDC August 24: Weekly Deaths vs. ED Visits [12] CDC August 24:
LEGEND
1) for charts new today; all others are not updated.
2) For a full-size/full-resolution image, Command-click (MacOS) or right-click (Windows) on the chart thumbnail and 
'open image in new tab.'
NOTES
[1] (CDC) This week's wastewater map, with hot spots annotated. Keeps spreading.
[2] (CDC) Last week's wastewater map.
[3] (CDC Variants) KP.* very popular. XDV.1 flat.
[4] (ED) Down, but worth noting that Emergency Department use is now on a par with the first wave, in 2020.
[5] (Hospitalization: NY) Flat, that is, no longer down.
[6] (Hospitalization: CDC). The visualization suppresses what is, in percentage terms, a significant increase.
[7] (Walgreens) Big drop, but all those white states showing no change: Labor Day weekend reporting issues?
[8] (Cleveland) Dropping.
[9] (Travelers: Positivity) Down. Those sh*theads at CDC have changed the chart so that it doesn't even run back to 
1/21/23, as it used to, but now starts 1/1/24. There's also no way to adjust the time range. CDC really doesn't want 
you to be able to take a historical view of the pandemic, or compare one surge to another. In an any case, that's 
why the shape of the curve has changed.
[10] (Travelers: Variants) What the heck is LB.1?
[11] Deaths low, but positivity up. If the United States is like Canada, deaths are several undercounted:
Tara Motarity has confirmed our fears.Most provinces are only reporting about 20% of covid deaths.Maybe even 
less.Which suggests the deaths are close to 5 times to 6+ times the reported figures.Nova Scotia has reported 270 
so far this year. It's actually 1,325-1,700 so far.  pic.twitter.com/6xF6SREyKB
- Dr.Robert Strang (@DSlayer520)  September 2, 2024
[12] Deaths low, ED up.
Stats Watch
'United States Factory Orders' [ Trading Economics]. 'New orders for US manufactured goods rose by 5% from the 
previous month to $592.1 billion in July of 2024, rebounding from the 3.3% drop in the previous month, and above 
market expectations of a 4.7% increase, signaling the resilience of the US economy.'* * *
Tech: Uh oh:
Page 7 of 9
2:00PM Water Cooler 9/4/2024
Hachette v. Internet Archive is out: 2d Circuit rejects controlled digital lending theory; IA's use is not transformative; 
all four fair use factors favor the publishers; the public benefits from shutting down IA's infringement.  
#copyright https://t.co/m5mDdezoJJ
- Devlin Hartline (@devlinhartline)  September 4, 2024
Tech: 'Canva says its new AI features justify raising subscription prices by 300%' [ Fortune]. 'In the U.S., some 
Canva users will see their Teams subscription price jump in early December from $119.99 per year to $500 per 
year. The first 12 months will be discounted to $300, but it's still more than double what users currently pay. Canva 
Teams will update from $10 per month per person, with a minimum of three people required for that subscription, a 
Canva spokesperson confirmed. Canva says its price hike is attributable to new features-particularly those that are 
AI-powered.' So, lots more AI slop to justify the investment. * * *
Today's Fear & Greed Index: 54 Neutral (previous close: 65 Greed) [ CNN]. One week ago: 56 (Greed). (0 is 
Extreme Fear; 100 is Extreme Greed). Last updated Sep 4 at 1:27:54 PM ET.
Class Warfare
'Thousands of hotel workers continue nationwide strike on Labor Day, demanding higher pay' [ NBC]. 'Thousands 
of workers at 25 hotels across the country remained on strike for a second day Monday, demanding higher pay and 
the reversal of pandemic-era cuts, with members in more cities expected to join the strike. On Sunday, around 
10,000 hotel workers walked off the job, kicking off the strike during the busy Labor Day weekend at 25 hotels in 
eight cities, including San Diego, Seattle, San Francisco, Boston and Honolulu. The workers are represented by the 
UNITE HERE union and work for the Marriott, Hilton and Hyatt hotel chains.. Roughly half of those on strike, about 
5,000, are from Honolulu, The Associated Press reported. UNITE HERE says strikes have been authorized and 
could begin soon in other cities, including Baltimore; New Haven, Connecticut; Oakland, California; and Providence, 
Rhode Island. The union said similar strikes led to contracts last year for Los Angeles hotel workers and Detroit 
casino workers.'
'Our Animals, Ourselves' [ Lux Magazine]. 'Conservatives are terrified by the prospect of a society that truly values 
and decommodifies (non-fetal) life, which is why they promote an image of flesh-consuming masculinity. 
Unfortunately, it seems many socialists are not so different. Leftists rarely engage with the myriad problems of 
animal agriculture, and are often dismissive or contemptuous of those who do. In this, their views are utterly 
mainstream. A recent episode of the popular lefty podcast Citations Needed began with an analysis of 
representations of vegetarian characters in popular culture, and the result was hardly flattering - routinely played by 
women, they tend to be insufferable. Such gendered stereotyping will come as no surprise to readers of Carol 
Adam's 1990 book The Sexual Politics of Meat, which weaves accounts of 19th century radicalism and 
examinations of 20th century marketing techniques into a pathbreaking work of 'feminist vegetarian critical theory' 
(after reading Adams, you will never hear a woman say she felt treated as a 'piece of meat' in the same way). 
Today we are often told that the animal rights movement came into being in the 1970s, birthed by the white male 
philosopher Peter Singer. In the English-speaking world, many women abolitionists, suffragettes, and pacifists 
advocated for vegetarianism and made connections across movements and causes long before Singer came on the 
scene, including the courageous abolitionist sisters Sarah and Angelina Grimk, who rejected meat in part because 
they thought it would hasten the 'emancipation of woman from the toil of the kitchen.' Singer rode roughshod over 
these intellectual antecedents by distinguishing his supposedly rational arguments from all the emotional - that is, 
feminine - advocacy that came before it. In the 1800s, there was even a diagnosis, zoophilpsychosis, for the 
affliction of being overly concerned for animals, from which women were believed to disproportionately suffer.' 
Zoophilpsychosis
News of the Wired
I am not feeling wired today.
* * *
Page 8 of 9
2:00PM Water Cooler 9/4/2024
Contact information for plants: Readers, feel free to contact me at lambert [UNDERSCORE] strether [DOT] corrente 
[AT] yahoo [DOT] com, to (a) find out how to send me a check if you are allergic to PayPal and (b) to find out how to 
send me images of plants. Vegetables are fine! Fungi, lichen, and coral are deemed to be honorary plants! If you 
want your handle to appear as a credit, please place it at the start of your mail in parentheses: (thus). Otherwise, I 
will anonymize by using your initials. See the previous Water Cooler (with plant)  here. From artinnature:
artinnature writes: 'Bumblebees on Oxydendrum arboreum (Sourwood).'
* * *
Readers: Water Cooler is a standalone entity not covered by the annual NC fundraiser. Material here is Lambert's, 
and does not express the views of the Naked Capitalism site. If you see a link you especially like, or an item you 
wouldn't see anywhere else, please do not hesitate to express your appreciation in tangible form. Remember, a tip 
jar is for tipping! Regular positive feedback both makes me feel good and lets me know I'm on the right track with 
coverage. When I get no donations for three or four days I get worried. More tangibly, a constant trickle of donations 
helps me with expenses, and I factor in that trickle when setting fundraising goals:
Here is the screen that will appear, which I have helpfully annotated:
If you hate PayPal, you can email me at lambert [UNDERSCORE] strether [DOT] corrente [AT] yahoo [DOT] com, 
and I will give you directions on how to send a check. Thank you!
This entry was posted in
Water Cooler on September 4, 2024 by Lambert Strether.
About Lambert Strether
Readers, I have had a correspondent characterize my views as realistic cynical. Let me briefly explain them. I 
believe in universal programs that provide concrete material benefits, especially to the working class. Medicare for 
All is the prime example, but tuition-free college and a Post Office Bank also fall under this heading. So do a Jobs 
Guarantee and a Debt Jubilee. Clearly, neither liberal Democrats nor conservative Republicans can deliver on such 
programs, because the two are different flavors of neoliberalism ('Because markets'). I don't much care about the 
'ism' that delivers the benefits, although whichever one does have to put common humanity first, as opposed to 
markets. Could be a second FDR saving capitalism, democratic socialism leashing and collaring it, or communism 
razing it. I don't much care, as long as the benefits are delivered.To me, the key issue - and this is why Medicare for 
All is always first with me - is the tens of thousands of excess 'deaths from despair,' as described by the Case-
Deaton study, and other recent studies. That enormous body count makes Medicare for All, at the very least, a 
moral and strategic imperative. And that level of suffering and organic damage makes the concerns of identity 
politics - even the worthy fight to help the refugees Bush, Obama, and Clinton's wars created - bright shiny objects 
by comparison. Hence my frustration with the news flow - currently in my view the swirling intersection of two, 
separate Shock Doctrine campaigns, one by the Administration, and the other by out-of-power liberals and their 
allies in the State and in the press - a news flow that constantly forces me to focus on matters that I regard as of 
secondary importance to the excess deaths. What kind of political economy is it that halts or even reverses the 
increases in life expectancy that civilized societies have achieved? I am also very hopeful that the continuing 
destruction of both party establishments will open the space for voices supporting programs similar to those I have 
listed; let's call such voices 'the left.' Volatility creates opportunity, especially if the Democrat establishment, which 
puts markets first and opposes all such programs, isn't allowed to get back into the saddle. Eyes on the prize! I love 
the tactical level, and secretly love even the horse race, since I've been blogging about it daily for fourteen years, 
but everything I write has this perspective at the back of it.
Link to the original story.
Page 9 of 9
2:00PM Water Cooler 9/4/2024
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 4, 2024
End of Document
Page 1 of 4
It's not just you. More weird spam is popping up on Facebook
It's not just you. More weird spam is popping up on Facebook
CNN Wire
September 3, 2024 Tuesday 10:00 AM GMT
Copyright 2024 Cable News Network All Rights Reserved
Length: 1745 words
Byline: By Clare Duffy, CNN
Dateline: (CNN) 
Body
             New York (CNN) - If a strange photo has recently stopped you in your tracks while scrolling your Facebook 
feed, you're not alone.
Users who once came to Facebook to connect with friends and family are increasingly complaining of random, 
spammy, junk content - much of it apparently generated by artificial intelligence - showing up in their feeds.
Sometimes it's obviously fake, AI-generated images, like the now-infamous "Shrimp Jesus." Other times, it's old 
posts from real creators that look like they're being reshared by bot accounts for engagement. In some cases, it's 
pages sharing streams of seemingly benign but random content - memes or movie clips, shared every few hours.
But the spam is more than just an annoyance; it can also be weaponized. Some spam pages appear designed to 
scam other users. In extreme cases, spam pages that gain a following can eventually be used, for example, by 
foreign actors seeking to sow discord ahead of elections, according to experts who study inauthentic behavior 
online.
The surge coincides with an intentional strategy shift at Facebook in the past few years. The company de-
emphasized current eventsand politics in the wake of claims it had contributed to election manipulation and real-
world violence. Feeling the heat from the rise of TikTok and its emphasis on entertainment over social connections, 
Facebook re-designed users' home feeds into a "discovery engine" in the hopes that people would engage with 
content they might not otherwise see.
But the push for more "discoverable" content has led to an algorithm that regularly pushes vapid, often misleading, 
computer-generated content.
The change has been palpable. AI-generated or recycled meme content has appeared on Facebook's quarterly 
most viewed content list. Posts with obviously AI-generated images and confusing captions sometimes receive 
thousands of likes and hundreds of comments and shares.

Page 2 of 4
It's not just you. More weird spam is popping up on Facebook
Bad actors and engagement farmers are only too happy to fulfill Facebook's demand for new content, experts say. 
And the proliferation of AI tools has made it far easier for them to quickly crank out huge volumes of fake images 
and text.
"It's a really interesting thing that a lot more people are starting to talk about because it's this random, kind of vanilla 
problem now, but obviously there are theoretical, long-term concerns," said Ben Decker, CEO of online threat 
analysis firm Memetica.
Facebook parent company Meta, for its part, works "to remove and reduce the spread of spammy content to ensure 
a positive user experience, offering users controls over their feed and encouraging creators to use AI tools to 
produce high-quality content that meets our Community Standards," spokesperson Erin Logan said in a statement. 
"We also take action against those who attempt to manipulate traffic through inauthentic engagement, regardless of 
whether they use AI or not."
Adventures in the AI swamp
Before I started reporting this story in July, my Facebook feed felt pretty normal, featuring baby photos from college 
friends and listings from Facebook Marketplace.
But, curious about the complaints, I started clicking on whatever content I did see that seemed odd, and the 
algorithm kicked in. Now, weeks later, nearly every third post on my feed appears to be so-called "AI slop."
One recent example: a black-and-white image showing a shack in the woods with a family sitting out front, shared 
by a page called "History for Everyone."
At first glance, the post looks like something you might find in a history book. But upon closer inspection, the people 
in the image have blurred, undefined facial features, and the children's hands and feet seem to disappear into the 
landscape around them - hallmarks of AI-generated images.
The post's caption claims the image was taken in 1910 in New Jersey at a "small shack on Forsythe's Bog, 
occupied by De Marco family, 10 in the family living in this one room," by National Child Labor Committee 
photographer Lewis Hine. Curious, I copied the full caption into Google, which pointed me to the real caption of an 
entirely different photo that had been published by the Library of Congress.
I plugged the Facebook image into a Google reverse image search, and the only other places it appeared online 
were two other, similar Facebook groups called "Past Memories" and "History Pictures."
It's impossible to say definitively how the image was created, but CNN's photo team ran it through AI-detection 
software - which is still in early testing - and found "substantial evidence" it had been manipulated. Hany Farid, a 
digital forensics expert and UC Berkeley professor who has studied AI, added that the image appeared to be AI-
generated and may have been created by using the caption of the real, historical image as the AI prompt, 
potentially to avoid copyright infringement.
The group that shared the post, "History for Everyone," is managed by a page by the same name, which was 
created in 2022 and previously changed its name from "Cubs" and "Chikn.Nuggit." The page did not respond to a 
direct message.
The History for Everyone post is illustrative of a lot of the content that's come across my feed - uncanny, bizarre, 
but also seemingly benign.
Other examples include a page called "Amy Couch" that also shares "historical" photos, with an apparently AI-
generated profile photo that shows a woman with one giant tooth where her two front teeth should be. Or an art and 
history page for an "artist" called "Kris Artist" whose profile photo I traced back to a real social media influencer who 
told me over email: "That is definitely not my account but they are using my picture."
Page 3 of 4
It's not just you. More weird spam is popping up on Facebook
When I messaged the "Kris Artist" page, I received what appeared to be an automated response: "Hi, thanks for 
contacting us. We've received your message and appreciate you reaching out. Please Join our Group."
After I flagged the History for Everyone post, as well as the Amy Couch and Kris Artist pages, to Meta, it removed 
them for violating its spam policy.
Behind the AI slop
It's not clear exactly how much of this content exists on Facebook. But there may be lots of people seeing it. The 
"History for Everyone" page has more than 40,000 followers, although individual posts often receive just a handful 
of interactions.
Researchers from Stanford and Georgetown earlier this year tracked 120 Facebook pages that frequently posted 
AI-generated images - and found the images collectively received "hundreds of millions of engagements and 
exposures," according to a paper released in March, which has not yet been peer-reviewed.
"The Facebook Feed ... at times shows users AI-generated images even when they do not follow the Pages posting 
those images. We suspect that AI-generated images appear on users' Feeds because the Facebook Feed ranking 
algorithm promotes content that is likely to generate engagement," researchers Renee DiResta and Josh Goldstein 
wrote in the paper. They added that often the users engaging with that content didn't seem to realize it was AI.
Experts who track this kind of online behavior say there are likely several different kinds of actors behind the 
Facebook spam, with varying motives.
Some just want to make money, for example through bonus payments that Facebook pays out to creators posting 
public content. There are dozens of YouTube videos teaching people how to get paid for posting AI content on 
Facebook - as tech news site 404 Media reported earlier this month - with some claiming they make thousands of 
dollars each month using the tactic.
"Even in the realm of the political, the tactics of manipulators have long been previewed by those with a different 
motivation: making money. Spammers and scammers are often early adopters of new technologies," the Stanford 
researchers wrote.
On other pages, scammers use the comments as a place to hawk sham products or collect users' personal 
information.
In some cases, what looks like a harmless account sharing mostly random content will slip in occasional 
misinformation or offensive memes, as a way of evading Facebook's enforcement mechanisms. "If something looks 
just like a run-of-the-mill spam campaign, it might not trigger the company's top investigators ... and so it might go 
undetected for longer," said David Evan Harris, an AI researcher who previously worked on responsible AI at Meta.
Harris added that there is also an online market for "aged" Facebook accounts, because older accounts are more 
likely to appear human and evade the platform's spam filters.
"It's like a black market, basically, you can sell someone 1,000 of these accounts that are all five years or older, and 
then they can turn those into a scam or an influence operation," Harris said. "This is something you see in elections: 
Someone might make a Facebook group that's like, 'everybody loves cheeseburgers,' and the group posts images 
of the best cheeseburgers every day for two years, and then all of a sudden, a month before an election ... it 
becomes a 'vote for (former Brazilian President Jair) Bolsonaro' group."
What to do with AI spam?
With AI tools, bad actors no longer need lots of people to rapidly produce reams of fake content - the technology 
can do it for them.
Page 4 of 4
It's not just you. More weird spam is popping up on Facebook
For Facebook to identify all of the AI-generated images getting uploaded each day without making mistakes would 
be challenging, "particularly at a time when this technology is moving so incredibly fast," Farid said. Even if it could, 
"that doesn't mean you should ban all AI generated content, right? ... It's a very subtle question on policy," he said.
Earlier this year, Meta said it would add "AI info" tags to content created by certain third-party generators that use 
metadata to let other sites know AI was involved. Meta also automatically labels AI-generated images created with 
its own tools.
However, there are still ways for users to strip out that metadata (or create AI images without it) to evade detection.
Meta may also be hampered by a smaller team dedicated to addressing fake content, after it - like other tech giants 
- trimmed its trust and safety staff last year, meaning it must rely more on automated moderation systems that can 
be gamed.
"Digitally savvy social media communities have always been one and a half steps ahead of trust and safety efforts 
at all platforms ... it's almost a cat and mouse game that never really ends," Harris said.         
             By Clare Duffy, CNN         
TM & © 2024 Cable News Network, Inc., a Time Warner Company. All rights reserved.
Load-Date: September 3, 2024
End of Document
Page 1 of 2
Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more views
Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more 
views
Newstex Blogs 
Tubefilter
September 3, 2024 Tuesday 6:31 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 Tubefilter
Length: 713 words
Body
September 3rd, 2024 (Tubefilter — Delivered by Newstex)
Artificial intelligence is a contentious topic these days-and a trendy one, with every major tech company and former 
crypto/NFT brand jumping on what they see as the latest moneymaking bandwagon. We've written before about the 
issues creators face with AI, including the lack of control over whether their content is scraped for use in large 
language models, and we've also written about a small handful of companies who are  trying to make AI work for 
creators, with their consent.
Joining that handful is Spotter, which today announced Spotter Studio, an AI-based tool that's meant to serve as 'a 
brainstorm partner, project planner, and research copilot,' the company says. Once a creator signs up for Spotter 
Studio, the program looks at their entire channel, and, based on that information, can do everything from cold-
suggesting new video topics to drafting thumbnails.
Spotter, which was founded in 2019, used to focus on catalog licensing, where it would pay creators a lump sum for 
the rights to their old content. But, over the last couple of years, it noticed a changing tide in our industry: artificial 
intelligence wasn't going away, and creators were simultaneously becoming more interested in and more leery of 
AI. It decided to shift its business model. Paul Bakaus, Spotter's EVP of Product and Creator Tools, tells Tubefilter 
the company figured it could use AI to bolster creators' workflows, and wanted to help them 'get ahead' of the 
deluge of generative AI slop it knew would soon fill YouTube, TikTok, and other platforms.
Spotter began hiring executives from Adobe, Amazon, Google, Headspace, Linktree, and Spotify to help it build AI 
tools, and consulted consulted YouTubers like Colin & Samir about what creators really wanted from AI. Its first AI 
tool, Title Exploder, rolled out in late 2023.
Spotter Studio (which wraps Title Exploder into its suite) was also born from creator input. MrBeast, Dude Perfect, 
Kinigra Deon, Rebecca Zamolo, Jordan Matter, Jay Alto, Hayden Hillier-Smith, and Colin & Samir all participated in 
the tool's beta period.

Page 2 of 2
Spotter's new AI-driven 'brainstorm partner' is getting creators 49% more views
And, Spotter says, these creators found that videos made with Spotter Studio got 49% more views in their first 
seven days than videos made without it. So far, videos made using Spotter Studio as part of the development 
process have collectively netted 844 million views.
'Spotter's mission has always been to empower Creators and provide the resources and opportunities that enable 
them to thrive,' Aaron DeBevoise, CEO and Founder of Spotter, said in a statement. 'As the industry evolves, so do 
we, continually adapting to meet the needs of Creators by working directly with them. What makes Spotter Studio 
so special is that it was not only designed for Creators, but with them.'
The tool starts broad. Creators begin with its Brainstorm function, where Spotter Studio generates video ideas 
based on their channel's content. If the creator likes an idea, they can pin it for future use. If they like a suggestion's 
core conceit but want to tweak something about the execution, they can ask the Studio to change that aspect. (Like, 
if a video idea requires winter gear but it's summer, they can say, Change this video to being filmed on the beach.) 
They can revise multiple ideas over and over until they've narrowed it down to something they want to make.
Then Spotter Studio offers finishing flair like title suggestions and thumbnail drafts (which Bakaus says are not 
meant to serve as true thumbnail art; they're purposefully kind of cartoony and lo-fi so creators still have to make 
their own 'nails for the upload).
While AI is the core of Spotter Studio, the tool also just plain offers a centralized place to plan, Dude Perfect's Coby 
Cotton said. 'Ideas that used to be scattered across phones, whiteboards, and sticky notes are now organized in 
one place, accessible to the entire DP team from ideation through post-production. Spotter Studio is our new home 
base,' he said.
Spotter Studio is being officially announced at VidSummit this week, but it's available now for $49/month or 
$299/year (temporary discount) to creators in the U.S., Canada, the U.K., and Australia.
Spotter is a Tubefilter partner.
Visit Tubefilter for more great stories.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 3, 2024
End of Document
Page 1 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
National Novel Writing Month's AI-neutral stance criticized by bestselling 
authors
Newstex Blogs 
VentureBeat
September 3, 2024 Tuesday 3:27 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 VentureBeat 
Length: 1234 words
Byline: Carl Franzen
Body
September 3rd, 2024 ( VentureBeat  - Delivered by  Newstex )
Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage.  
Learn More
National Novel Writing Month (NaNoWriMo), the 25-year-old nonprofit organization that encourages anyone and 
everyone who has interest to draft a novel each year during the month of November, recently stirred significant 
debate by announcing it will accept the use of artificial intelligence (AI) as a tool in the writing process.
The decision, rooted in the belief that opposition to AI can be classist and ableist, has received mixed reactions, 
drawing both  support and lots of criticism - including from bestselling established authors and former NaNoWriMo 
board members.
Yesterday, the  organization published a statement on its website noting that it neither condemns nor exclusively 
endorses the technology. Instead, NaNoWriMo champions the freedom for writers to choose their own methods, 
whether they involve traditional approaches or AI tools.
'NaNoWriMo does not explicitly support any specific approach to writing, nor does it explicitly condemn any 
approach, including the use of AI,' the statement reads, later adding, 'We believe that to categorically condemn AI 
would be to ignore classist and ableist issues surrounding the use of the technology, and that questions around the 
use of AI tie to questions around privilege.'
Disclaimer: VentureBeat uses AI tools to generate imagery, copy and other material for use in our publishing and 
promotion.
Why NaNoWriMo supports AI for use in writing in some cases

Page 2 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
The organization's official statement highlights the complexity of AI as a broad technological category, making it 
difficult to entirely endorse or reject. It also underscores the social implications of AI use, suggesting that to oppose 
AI outright ignores the realities of class and ability disparities.
According to NaNoWriMo, some writers may turn to AI for practical reasons, such as financial constraints or 
cognitive challenges that make traditional writing methods less accessible.
As NaNoWriMo's statement explains: 'Not all writers have the financial ability to hire humans to help at certain 
phases of their writing. For some writers, the decision to use AI is a practical, not an ideological, one. The financial 
ability to engage a human for feedback and review assumes a level of privilege that not all community members 
possess.'
The organization also points out that underrepresented minorities are less likely to secure traditional publishing 
deals, which forces many into the indie author space where upfront costs can be prohibitive. AI tools, in these 
cases, might provide essential support that enables them to pursue their writing goals.
Bestselling authors lash out
However, the endorsement of AI has not been without controversy. Prominent voices in the writing community have 
expressed their displeasure with NaNoWriMo's stance.
Urban fantasy author Daniel Jos Older, a former member of NaNoWriMo's Writers Board, announced his 
resignation from the board in response to the organization's pro-AI position.
'Never use my name in your promo again,' Older declared on social media, urging other writers to follow his lead.
Hello  @NaNoWriMo this is me DJO officially stepping down from your Writers Board and urging every writer I know 
to do the same. Never use my name in your promo again in fact never say my name at all and never email me 
again. Thanks! https://t.co/KDKZ0zVx3H- Daniel Jos Older (@djolder)
September 2, 2024
Maureen Johnson, a #1 New York Times and USA Today bestselling author of young adult (YA) novels, also 
resigned from NaNoWriMo's Writers' Board of the Young Writers Program, citing concerns over how the 
organization might use writers' work to train AI systems.
To  @NaNoWriMo: please remove me from the Writers' Board of the Young Writers Program. I want nothing to do 
with your organization from this point forward. I would also encourage writers to beware-your work on their platform 
is almost certainly going to be used to train AI. https://t.co/FJo2WxXq73- Maureen Johnson (@maureenjohnson)
September 3, 2024
Other authors, including  Adam Christopher and Bryan Young, criticized NaNoWriMo for what they perceive as an 
anti-art and anti-creativity stance, accusing the organization of promoting meaningless AI-generated content.
To be clear,  @NaNoWriMo are anti-writing, anti-art, anti-creativity, anti-craft. They fully support generating 50,000 
words of meaningless AI slop and uploading it to complete the challenge, and if you disagree you are the 
enemy. https://t.co/1vN0UFfGim- Adam Christopher (@ghostfinder)
September 2, 2024
The backlash was further fueled by revelations that  NaNoWriMo's recent sponsors include companies offering AI 
software and writing tools, such as ProWritingAid.
Page 3 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
ProWritingAid provides a suite of AI-powered tools designed to enhance writing, including grammar checking, 
sentence rephrasing, and a variety of writing reports. Its 'AI Sparks' feature assists writers in overcoming writer's 
block by generating text and adding sensory details or dialogue.
This sponsorship has led to suspicions and criticism from those who view the endorsement as influenced by 
financial incentives rather than a purely ethical stance.
NaNoWriMo also collaborates with writing software like Scrivener, which integrates AI tools like ProWritingAid to 
help users access AI writing and editing features within their environment. Other platforms like Dabble, Storyist, and 
Ninja Writers, while not inherently AI-focused, support the integration of AI tools, allowing writers to enhance their 
work using external AI services.
In contrast, another sponsor, Freewrite remains focused on providing distraction-free writing devices, emphasizing 
traditional writing processes without AI integration.
In response to the criticism, NaNoWriMo acknowledged the existence of unethical practices within the AI space but 
maintained that its stance is driven by a desire to support all writers, regardless of their chosen methods. The 
organization reiterated its commitment to providing resources and information about AI to its community, noting that 
events related to AI have been well-attended, indicating strong interest among participants.
As AI continues to evolve and its role in creative processes becomes more prominent, NaNoWriMo's position could 
serve as a bellwether for how other organizations and individuals approach the integration of AI into creative fields. 
For enterprise decision-makers, especially those in publishing and creative industries, NaNoWriMo's stance might 
offer valuable insights as they navigate the ethical and practical implications of AI in their own operations.
NaNoWriMo's position ultimately reflects a broader debate within the writing community-is AI a tool on the order of 
a word processor or search engine, one primarily directed by humans, or is it a morally and ethically compromised 
technology built from copyrighted works without permission, which critics equate with theft? For now, it seems, 
leading authors are coalescing around the latter position.
VB Daily
Stay in the know! Get the latest news in your inbox daily
vb_dailyroundup 5de2efbc19/river-full Subscribe
By subscribing, you agree to VentureBeat's  Terms of Service.
Thanks for subscribing. Check out more  VB newsletters here.
An error occured.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
Page 4 of 4
National Novel Writing Month's AI-neutral stance criticized by bestselling authors
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: September 3, 2024
End of Document
Page 1 of 3
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images frenzy
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated 
images frenzy
The Independent (United Kingdom)
September 3, 2024 Tuesday 4:01 PM EST
Copyright 2024 Independent Print Ltd  All Rights Reserved
Length: 872 words
Byline: Mike Bedigan
Body
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate's latest obsession.
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a Second World War soldier, a cowboy and even the muscle-bound body of Rambo - earnestly 
and unironically. 
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks. 
Notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Program at Columbia University, suggests one simple reason 
for this: Trump is just trying to stay relevant.
"In 2016, whatever Trump posted actually blew into the liberal media," Cross tells The Independent. "People would 
be reacting like 'can you believe this outrageous thing he said today?' I'm not sure if that's happening this time 
around, because Kamala has proven herself as adept at using social media as Trump was. She's just better at 
coming up with memes."
Link to Image
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "kamala is brat" - a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum. 

Page 2 of 3
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images frenzy
Cross suggests that Trump's over-posting of AI images is, as the younger generation might say, an attempt to "clap 
back" at the Harris campaign in whatever way he can. "It's almost like throwing spitballs on the wall and seeing 
what will stick," she tells The Independent.
But Trump's online posting - unlike that of his political rivals - is, and always has been, much more sincere. 
From his first presidential campaign in 2016, Trump has attempted to project an image of himself as a strong 
leader, capable of uniting America in the face of great evil. Now, thanks to AI, he and the Republicans have a tool 
that allows them to visualise the hypothetical realities they are peddling to their supporters, who seem receptive to 
the visual hyperbole of AI slop that now dominates right-wing social media platforms and accounts.
"Things like him on the lion or lying about Taylor Swift, it's aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else," Cross says. "And there's a whole army of people, of Trump supporters 
out there who get their news from social media... They don't trust any of the mainstream outlets."
pic.twitter.com/H0ExcNXBdl
- Donald J. Trump (@realDonaldTrump)
August 18, 2024
Social commentator and activist Patrick Jones - known online as Mr Jones X - agrees. The integration of AI images 
into Trump's campaign is about strengthening his support base, not expanding it, he says.
"He understands that these visual images have the ability to sway a specific demographic of people, because if 
they see a thing, especially if it's coming from him on X or Truth Social, they're going to believe it," Jones tells The 
Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president's mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Harris emerging as the Democratic party's presidential candidate, this seems 
to have been forgotten.
"It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign - essentially, they had to throw it out," Jones says. The momentum of the Harris-Walz 
campaign is "hard to combat", he adds. "So now you have to come up with the most absurd talking points, the most 
absurd arguments." 
The former president's recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election - though there are currently few if 
any federal laws or regulations.
Link to Image
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads. 
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the Senate floor in July and are still waiting for 
another go at a full Senate vote. But these images can have a bigger impact than a funny social media post.
"It's definitely potentially dangerous," says Cross. "What they did in 2016 was actually dissuade people from going 
to the polls. And you've got states where the margins are anywhere from 7,000 to 20,000 votes. 
Page 3 of 3
'Trump is just trying to stay relevant': Inside the ex-president's AI-generated images frenzy
"So if you can get those people to stay home, or get those people to switch votes a tiny number of them, or even 
not vote, that would be significant in the seven swing states that we're looking at right now."
Load-Date: September 4, 2024
End of Document
Page 1 of 3
Bigger picture of Trump's weird AI images obsession The Republican party and its presidential nominee now 
have a tool that allows them to visualise the hypothet....
Bigger picture of Trump's weird AI images obsession; The Republican party 
and its presidential nominee now have a tool that allows them to visualise 
the hypothetical realities they are peddling to their supporters, writes Mike 
Bedigan
The Independent - Daily Edition
September 2, 2024 Monday
First Edition
Copyright 2024 Independent Print Ltd All Rights Reserved
Section: WORLD; Pg. 17
Length: 862 words
Byline: MIKE BEDIGAN
Body
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merchandise. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI 
images were the Republican candidate's latest obsession.
The former president has been sharing such images since March 2023, with his face photoshopped onto images 
including a Second World War soldier, a cowboy, and even the muscle-bound body of Rambo - earnestly and 
without irony.
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks. 
Notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Programme at Columbia University, suggests one simple 
reason for this: Mr Trump is just trying to stay relevant.
"In 2016, whatever Trump posted actually blew into the liberal media," Ms Cross tells The Independent. "People 
would be reacting like 'can you believe this outrageous thing he said today?' I'm not sure if that's happening this 
time around, because Kamala has proven herself as adept at using social media as Trump was. She's just better at 
coming up with memes."

Page 2 of 3
Bigger picture of Trump's weird AI images obsession The Republican party and its presidential nominee now 
have a tool that allows them to visualise the hypothet....
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "kamala is brat" - a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum.
Ms Cross suggests that Mr Trump's over-posting of AI images is, as the younger generation might say, an attempt 
to "clap back" at the Harris campaign in whatever way he can. "It's almost like throwing spitballs on the wall and 
seeing what will stick," she tells The Independent.
But Mr Trump's online posting - unlike that of his political rivals - is, and always has been, much more sincere. From 
his first presidential campaign in 2016, Mr Trump has attempted to project an image of himself as a strong leader, 
capable of uniting America in the face of great evil. Now, thanks to AI, he and the Republicans have a tool that 
allows them to visualise the hypothetical realities they are peddling to their supporters, who seem receptive to the 
visual hyperbole of AI slop that now dominates right-wing social media platforms and accounts.
"Things like him on the lion or lying about Taylor Swift, it's aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else," Ms Cross says. "And there's a whole army of people, of Trump 
supporters out there who get their news from social media... They don't trust any of the mainstream outlets."
Social commentator and activist Patrick Jones - known online as Mr Jones X - agrees. The integration of AI images 
into Mr Trump's campaign is about strengthening his support base, not expanding it, he says.
"He understands that these visual images have the ability to sway a specific demographic of people, because if 
they see a thing, especially if it's coming from him on X or Truth Social, they're going to believe it," Mr Jones tells 
The Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president's mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Ms Harris emerging as the Democratic party's presidential candidate, this 
seems to have been forgotten.
"It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign - essentially, they had to throw it out," Mr Jones says. The momentum of the Harris-
Walz campaign is "hard to combat", he adds. "So now you have to come up with the most absurd talking points, 
[and] the most absurd arguments."
The former president's recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election - though there are currently few if 
any federal laws or regulations.
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads.
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the Senate floor in July and are still waiting for 
another go at a full Senate vote. But these images can have a bigger impact than a funny social media post.
"It's definitely potentially dangerous," says Ms Cross. "What they did in 2016 was actually dissuade people from 
going to the polls. And you've got states where the margins are anywhere from 7,000 to 20,000 votes. So if you can 
get those people to stay home, or get those people to switch votes - a tiny number of them - or even not vote, that 
would be significant in the seven swing states that we're looking at right now."
Load-Date: September 1, 2024
Page 3 of 3
Bigger picture of Trump's weird AI images obsession The Republican party and its presidential nominee now 
have a tool that allows them to visualise the hypothet....
End of Document
Page 1 of 3
Inside Trump's weird new obsession with AI-generated images
Inside Trump's weird new obsession with AI-generated images
Irish Independent
September 2, 2024 Monday
Edition 1, National Edition
Copyright 2024 Independent Newspapers Ireland Limited All Rights Reserved
Section: NEWS; Pg. 18,19
Length: 882 words
Byline: MIKE BEDIGAN
Body
Republicans using new tech to create 'visual hyperbole' to peddle to their supporters online
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate's latest obsession.
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a WW2 soldier, a cowboy and even the muscle-bound body of Rambo - earnestly and unironically.
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks, 
notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Programme at Columbia University, suggests one simple 
reason for this: Trump is just trying to stay relevant.
"In 2016, whatever Trump posted actually blew into the liberal media," Cross said.
"People would be reacting like 'can you believe this outrageous thing he said today?' I'm not sure if that's happening 
this time around, because Kamala has proven herself as adept at using social media as Trump was.
She's just better at coming up with memes."
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "Kamala is brat" - a reference to her wildly popular new album.

Page 2 of 3
Inside Trump's weird new obsession with AI-generated images
The addition of Tim Walz, already familiar with viral videos, thanks to his daughter Hope, has only built momentum.
Cross suggests that Trump's over-posting of AI-images is, as the younger generation might say, an attempt to "clap 
back" at the Harris campaign in whatever way he can.
"It's almost like throwing spitballs on the wall and seeing what will stick," she said.
But Trump's online posting - unlike that of his political rivals - is, and always has been, much more sincere.
From his first presidential campaign in 2016, Trump has attempted to project an image of himself as a strong 
leader, capable of uniting America in the face of great evil.
Now, thanks to AI, he and the Republicans have a tool that allows them to visualise the hypothetical realities they 
are peddling to their supporters, who seem receptive to the visual hyperbole of AI slop that now dominates right-
wing social media platforms and accounts.
"Things like him on the lion or lying about Taylor Swift, it's aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else," Cross says.
"And there's a whole army of people, of Trump supporters out there who get their news from social media... They 
don't trust any of the mainstream outlets."
Social commentator and activist Patrick Jones - known online as Mr Jones X - agrees. The integration of AI images 
into Trump's campaign is about strengthening his support base, not expanding it, he says.
"He understands that these visual images have the ability to sway a specific demographic of people, because if 
they see a thing, especially if it's coming from him on X or Truth Social, they're going to believe it,"
Jones told The Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president's mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Harris emerging as the Democratic party's presidential candidate, this seems 
to have been forgotten.
"It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign - essentially, they had to throw it out," Jones says.
The momentum of the Harris-Walz campaign is "hard to combat", he adds. "So now you have to come up with the 
most absurd talking points, the most absurd arguments."
The former president's recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election - though there are currently few if 
any federal laws or regulations.
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads.
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the senate floor in July and are still waiting for 
another go at a full senate vote. But these images can have a bigger impact than a funny social media post.
"It's definitely potentially dangerous," says Cross.
"What they did in 2016 was actually dissuade people from going to the polls. And you've got states where the 
margins are anywhere from 7,000 to 20,000 votes.
Page 3 of 3
Inside Trump's weird new obsession with AI-generated images
"So if you can get those people to stay home, or get those people to switch votes a tiny number of them, or even 
not vote, that would be significant in the seven swing states that we're looking at right now." (© The Independent)
"There's an army of people out there who get their news from social media... they don't trust the mainstream"
Graphic
 
Donald Trump dances onstage with Moms for Liberty co-founder Tiffany Justice at an event in Washington on 
Friday night. Photo: ReutersLeft, a fake AI-generated of Kamala Harris holding a communist rally; above, an AI 
image saying Taylor Swift is backing Trump; and, below, an AI image of Trump riding a lion. Images: Twitter
Load-Date: September 2, 2024
End of Document
Page 1 of 3
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images frenzy
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated 
images frenzy
The Independent (United Kingdom)
September 1, 2024 Sunday 12:30 PM GMT
Copyright 2024 Independent Digital News and Media Limited All Rights Reserved
Section: US POLITICS,AMERICAS,WORLD; Version:3
Length: 873 words
Byline: Mike Bedigan
Highlight: The Republican party and its presidential nominee now have a tool that allows them to visualise the 
hypothetical realities that they are peddling to their supporters, who are receptive to such visual hyperbole – so-
called ‘AI slop’, writes Mike Bedigan
Body
First appeared “Comrade Kamala” with a hammer and sickle. Then, a line of blonde women wearing “Swifties for 
Trump ” merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate’s latest obsession. 
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a Second World War soldier, a cowboy and even the muscle-bound body of Rambo – earnestly 
and unironically. 
Yet the frequency of Trump’s sharing of such fantastical images has ramped up considerably in recent weeks. 
Notably, it seems, following the ascension of Kamala Harris  to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Program at Columbia University, suggests one simple reason 
for this: Trump is just trying to stay relevant.
“In 2016, whatever Trump posted actually blew into the liberal media,” Cross tells The Independent. “People would 
be reacting like ‘can you believe this outrageous thing he said today?’ I’m not sure if that’s happening this time 
around, because Kamala has proven herself as adept at using social media as Trump was. She’s just better at 
coming up with memes.”

Page 2 of 3
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images frenzy
The Harris campaign has quickly excelled in the online sphere , ever since British pop singer Charli XCX declared 
that “kamala is brat” – a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum. 
Cross suggests that Trump’s over-posting of AI images is, as the younger generation might say, an attempt to “clap 
back” at the Harris campaign in whatever way he can. “It’s almost like throwing spitballs on the wall and seeing 
what will stick,” she tells The Independent.
But Trump’s online posting – unlike that of his political rivals – is, and always has been, much more sincere. 
From his first presidential campaign in 2016, Trump has attempted to project an image of himself as a strong 
leader, capable of uniting America in the face of great evil. Now, thanks to AI, he and the Republicans have a tool 
that allows them to visualise the hypothetical realities they are peddling to their supporters, who seem receptive to 
the visual hyperbole of AI slop that now dominates right-wing social media platforms and accounts.
“Things like him on the lion or lying about Taylor Swift, it’s aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else,” Cross says. “And there’s a whole army of people, of Trump supporters 
out there who get their news from social media... They don’t trust any of the mainstream outlets.”
pic.twitter.com/hlExcNXBdl                        — Donald J. Trump (@realDonaldTrump) August 18, 2024
Social commentator and activist Patrick Jones – known online as Mr Jones X – agrees. The integration of AI 
images into Trump’s campaign is about strengthening his support base, not expanding it, he says.
“He understands that these visual images have the ability to sway a specific demographic of people, because if they 
see a thing, especially if it’s coming from him on X or Truth Social, they’re going to believe it,” Jones tells The 
Independent.
The Trump campaign is already in possession of some of the most powerful political imagery of the past decade: 
the president’s mugshot, and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Harris emerging as the Democratic party’s presidential candidate, this seems 
to have been forgotten.
“It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign – essentially, they had to throw it out,” Jones says. The momentum of the Harris-Walz 
campaign is “hard to combat”, he adds. “So now you have to come up with the most absurd talking points, the most 
absurd arguments.” 
The former president’s recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election – though there are currently few if 
any federal laws or regulations.
In March, Democratic senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads. 
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the Senate floor in July and are still waiting for 
another go at a full Senate vote. But these images can have a bigger impact than a funny social media post.
“It's definitely potentially dangerous,” says Cross. “What they did in 2016 was actually dissuade people from going 
to the polls. And you've got states where the margins are anywhere from 7,000 to 20,000 votes. 
“So if you can get those people to stay home, or get those people to switch votes a tiny number of them, or even 
not vote, that would be significant in the seven swing states that we're looking at right now.”
Page 3 of 3
‘Trump is just trying to stay relevant’: Inside the ex-president’s AI-generated images frenzy
Load-Date: September 3, 2024
End of Document
Page 1 of 3
Inside Trump's weird new obsession with AI-generated images
Inside Trump's weird new obsession with AI-generated images
The Independent (United Kingdom)
September 1, 2024 Sunday 12:30 PM EST
Copyright 2024 Independent Print Ltd  All Rights Reserved
Length: 870 words
Byline: Mike Bedigan
Body
First appeared "Comrade Kamala" with a hammer and sickle. Then, a line of blonde women wearing "Swifties for 
Trump" merch. By the time Donald Trump himself appeared riding a lion, it was clear: fan-generated AI images 
were the Republican candidate's latest obsession.
The former president has been sharing such images as far back as March 2023, with his face photoshopped onto 
images including a WW2 soldier, a cowboy and even the muscle-bound body of Rambo - earnestly and unironically. 
Yet the frequency of Trump's sharing of such fantastical images has ramped up considerably in recent weeks, 
notably, it seems, following the ascension of Kamala Harris to become the Democratic nominee and the online 
success of her own campaign.
June Cross, director of the Documentary Journalism Program at Columbia University, suggests one simple reason 
for this: Trump is just trying to stay relevant.
"In 2016, whatever Trump posted actually blew into the liberal media," Cross tells The Independent. "People would 
be reacting like 'can you believe this outrageous thing he said today?' I'm not sure if that's happening this time 
around, because Kamala has proven herself as adept at using social media as Trump was. She's just better at 
coming up with memes."
Link to Image
The Harris campaign has quickly excelled in the online sphere, ever since British pop singer Charli XCX declared 
that "kamala is brat" - a reference to her wildly popular new album. The addition of Tim Walz, already familiar with 
viral videos, thanks to his daughter Hope, has only built momentum. 
Cross suggests that Trump's over-posting of AI-images is, as the younger generation might say, an attempt to "clap 
back" at the Harris campaign in whatever way he can. "It's almost like throwing spitballs on the wall and seeing 
what will stick," she tells The Independent.

Page 2 of 3
Inside Trump's weird new obsession with AI-generated images
But Trump's online posting - unlike that of his political rivals - is, and always has been, much more sincere. 
From his first presidential campaign in 2016, Trump has attempted to project an image of himself as a strong 
leader, capable of uniting America in the face of great evil. Now, thanks to AI, he and the Republicans have a tool 
that allows them to visualise the hypothetical realities they are peddling to their supporters, who seem receptive to 
the visual hyperbole of AI slop that now dominates right-wing social media platforms and accounts.
"Things like him on the lion or lying about Taylor Swift, it's aimed at trying to boost the morale of his supporters who 
do not get their news from anywhere else," Cross says. "And there's a whole army of people, of Trump supporters 
out there who get their news from social media... They don't trust any of the mainstream outlets."
pic.twitter.com/H0ExcNXBdl
- Donald J. Trump (@realDonaldTrump)
August 18, 2024
Social commentator and activist Patrick Jones - known online as Mr Jones X - agrees. The integration of AI images 
into Trump's campaign is about strengthening his support base, not expanding it, he says.
"He understands that these visual images have the ability to sway a specific demographic of people, because if 
they see a thing, especially if it's coming from him on X or Truth Social, they're going to believe it," Jones tells The 
Independent.
The Trump campaign is already in possesssion of some of the most powerful political imagery of the past decade: 
the president's mugshot,and defiant, fist-raised stance following the attempt on his life being just two. But in the 
wake of Joe Biden stepping down and Harris emerging as the Democratic party's presidential candidate, this seems 
to have been forgotten.
"It was absolute panic, because now none of those talking points were going to work any longer. The whole 
framework of their campaign - essentially, they had to throw it out," Jones says. The momentum of the Harris-Walz 
campaign is "hard to combat," he adds. "So now you have to come up with the most absurd talking points, the most 
absurd arguments." 
The former president's recent fixation on AI-generated promotions comes at a time in which serious concerns are 
being raised in Congress about the use of such content in the upcoming election - though there are currently few if 
any federal laws or regulations.
Link to Image
In March, Democratic Senator Amy Klobuchar, of Minnesota, introduced two bills to address voter-facing AI-
generation election content; one to ban deep-fakes of candidates, and the other to require disclosures on AI-
manipulated political ads. 
Republicans on the Senate Rules Committee voted against both, but a Democratic majority advanced the bills out 
of committee in May. They then failed a unanimous consent vote on the Senate floor in July and are still waiting for 
another go at a full Senate vote. But these images can have a bigger impact than a funny social media post.
"It's definitely potentially dangerous," says Cross. "What they did in 2016 was actually dissuade people from going 
to the polls. And you've got states where the margins are anywhere from 7,000 to 20,000 votes. 
"So if you can get those people to stay home, or get those people to switch votes a tiny number of them, or even 
not vote, that would be significant in the seven swing states that we're looking at right now."
Load-Date: September 1, 2024
Page 3 of 3
Inside Trump's weird new obsession with AI-generated images
End of Document
Page 1 of 3
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
Forbes.com
August 27, 2024 Tuesday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1209 words
Byline: Rashi Shrivastava, Forbes Staff
Highlight: Plus: Major AI regulation up for a vote in California.
Body
The Prompt is a weekly rundown of AI s buzziest startups, biggest breakthroughs, and business deals. To 
get it in your inbox, .
Welcome back to The Prompt.
<figure>
<figcaption>
With the arrival of AI, some businesses have been overwhelmed with applications from suspected North Korean 
operatives.
Getty
</figcaption></figure>
AI tools are helping North Koreans covertly apply for thousands of remote IT jobs in the US,reported. Companies 
large and small are being flooded with job applications from thousands of suspected North Korean operatives, who 
earn hundreds of millions of dollars and send the money back to the regime, where the U.S. government believes it 
s used to fund its weapons of mass destruction program. With the help of AI tools, these workers are able to run 
multiple job profiles and apply for hundreds of jobs at once.
Now let s get into the headlines.
REGULATION
This week,California legislators will vote on , a controversial bill that seeks to regulate the most advanced and 
powerful AI models. If passed, the bill would require the developers of AI models whose training either cost more 
than $100 million, or required a specified amount of computing power, to implement safeguardsand allowthird-
party audits of safety practices.

Page 2 of 3
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
It also requires AI companies to outline methods for shutting down the AI model and effectively implement a  kill 
switch for the technology if needed. The legislation would allow the state attorney general to take action against a 
developer if its AI model causes severe harm such as mass casualties or more than $500 million in damages.
Silicon Valley leaders are deeply  on their positions regarding the bill: xAI and Tesla founderElon 
MuskandAnthropicCEO Dario Amodei have come out in support of the bill, while leaders fromOpenAI, Meta and 
Google have voiced concerns that the bill would stifle innovation.
TALENT RESHUFFLE 
Three of the five cofounders of French AI startup H have left the company after operational and business 
disagreements, according to. The departure comes just a few months after the startup raised awhopping  seed 
roundfrom billionaires like Eric Schmidt and Bernard Arnault to build AI agents for multi-step tasks.
AI DEAL OF THE WEEK
Coding automation startup Cursor AI raised$60 million in Series A funding at a $400 million valuation, CEO 
Michael Truell told. The company s AI tools are popular among developers at leading AI startups like OpenAI and 
Midjourney, where they areused to write, edit and predict parts of code.But Cursor isn t short on competition  the 
market is flooded with similar AI coding assistants likeCodeium, which launched an engine capable of digesting 100 
million lines of code, and Cognition Labs, which is valued at $2 billion and created an AI software engineer called 
Devin. Tech giants are also developing their own AI programming tools in-house;Amazon CEO Andy Jassysaid 
that its AI assistant, called Q has helped save the company$260 million and  yearsworth of time in terms of 
software development.
DEEP DIVE
The idea of America is big business on Facebook. The social network has hosted more than a hundred pages that 
have adopted American patriotism as a theme, boasting names like Proud American, Proud To Be An American, 
American Story, and We Are America.
But a large swath of those pages   despite their names  aren t American at all.Instead, they re run by foreign click 
farmers, many of whom are based in Macedonia, who useAI to pump out a near-endless ocean of clickbaity 
soup. Posts sharing prayers for American soldiers, rewritten tweets, memes and pictures of old Hollywood pin-up 
girls link out toAI-generated articles, against which the click farmers can sell advertising.
Headlines like  A Father s Heroism: The Tragic Story of Phil Dellegrazie And His Son Anthony  tease short, 
uninformative articles on websites plastered with often sexual advertisements. The pages promoting them fake 
Americanness because they get paid every time someone clicks on one of their links, and in the advertising world, 
American clicks are some of the most valuable.
AForbesreview identified 67 Facebook pages   now taken down   that identified themselves as champions of 
American news, culture or identity, but were actually based overseas. As of August 20, they hadmore than 9 
million followers combined  more than the Facebook pages of the Wall Street Journal or the Washington Post. 
Thirty-three of them were run fromMacedonia,with others spread out across 23 different countries, including 
Canada, France, Morocco, Venezuela and Vietnam.
Click farmers, especially those from Macedonia, have a long history on Facebook. During the 2016 presidential 
election, teenagers in the small Eastern European countrypushedfake news to millions of Americans on Facebook, 
makingtens of thousandsof dollars in ad revenue. In 2019, similar Eastern European pagesran the same playbook  
this time, reaching nearly half of all Americans on the platform.
Now, AI has given those same operations the capacity to producenear-infinite volumes of low-quality (or 
outright fake) news  and in at least some cases, this AI-produced slop is breaking through. The pages have 
begun using generic AI-generated imagery (bald eagles, stars and stripes, camo soldiers and the occasional 
Page 3 of 3
The Prompt: North Korean Operatives Are Using AI To Get Remote IT Jobs
Statue of Liberty) to appeal to American Facebook users   and in at least some cases, it s working. Onepostmade 
last week by the Canada-based page American Patriots featured an AI-generated photo of an American soldier 
and his children,and received more than 100,000 likes and 35,000 comments. The American Patriots page, like 
most of the others, directed people from Facebook to click farms featuring low-quality articles.
Read the full story onForbes.
WEEKLY DEMO 
Do you want to practice a tough workplace conversation or get tips on how to negotiate a raise? Companies are 
increasingly deploying AI-powered career coaches as an alternative toexpensive human counselorsthat can 
cost up to $240 an hour,reported. But people who have interacted with these AI-based career counselors note that 
these chatbotsoften lack nuance and can sometimes offer confusing advice.  I m already confused about my 
career. AI [only] throws me in a bigger loop,  one third-year law student said.
AI INDEX
Two years ago, the Biden administration passed the CHIPS Act to incentivize the development of semiconductors 
and chips within the United States, as the country battled with China on developing AI models. Butred tape and a 
grueling application process has largely kept funds out of reach from smaller firms that need it most,reported.
Less than 7% 
Applicants that received funding from the 380 firms that submitted applications.
9 out of 23 
Semiconductor manufacturers who were approved for the funding were smaller companies.
$4 billion out of $134 billion 
Amount of grants and loans awarded to smaller companies; the rest went to chip giants like Intel, TSMC and 
Samsung.
MODEL BEHAVIOR
American rapper and singer Will.i.am is launching anAI-powered radio station called Raidio.FYI, which will allow 
listeners to listen to songs and news and ask questions to the host through a chatbot app built on OpenAI s large 
language models, according toThe Sunday Times. The rapper is reportedly an investor in OpenAI and Anthropic.
Load-Date: August 28, 2024
End of Document
Page 1 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
The Foreign Pro-Trump Fake News Industry Has Pivoted To American 
Patriotism
Forbes.com
August 26, 2024 Monday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1905 words
Byline: Emily Baker-White, Forbes Staff
Highlight: It s been more than eight years since content farms overseas started  American  fake news pages on 
Facebook. Their business, now fueled by AI, is still going strong.
Body
It s been more than eight years since content farms overseas started  American  fake news pages on 
Facebook. Their business, now fueled by AI, is still going strong.
By Emily Baker-White, Forbes Staff
The idea of America is big business on Facebook. The social network has hosted more than a hundred pages that 
have adopted American patriotism as a theme, boasting names like Proud American, Proud To Be An American, 
American Story, and We Are America.
But a large swath of those pages   despite their names   aren t American at all. Instead, they re run by foreign click 
farmers, many of whom are based in Macedonia, who use AI to pump out a near-endless ocean of clickbaity soup. 
Posts sharing prayers for American soldiers, rewritten tweets, memes and pictures of old Hollywood pin-up girls link 
out to AI-generated articles, against which the click farmers can sell advertising. Headlines like  Dedicated 
Firefighters Risk Their Lives To Save Others  and  A Father s Heroism: The Tragic Story of Phil Dellegrazie And His 
Son Anthony  tease short, uninformative articles on websites plastered with often sexual advertisements. The 
pages promoting them fake Americanness because they get paid every time someone clicks on one of their links, 
and in the advertising world, American clicks are some of the most valuable.
AForbesreview identified 67 Facebook pages   now taken down   that identified themselves as champions of 
American news, culture or identity, but were actually based overseas. As of August 20, they had more than 9 million 
followers combined   more than the Facebook pages of the Wall Street Journal or the Washington Post. Thirty-three 
of them were run from Macedonia, with others spread out across 23 different countries, including Canada, France, 
Morocco, Venezuela and Vietnam.
Click farmers, especially those from Macedonia, have a long history on Facebook. During the 2016 presidential 
election, teenagers in the small Eastern European countrypushedfake news to millions of Americans on Facebook, 
makingtens of thousandsof dollars in ad revenue. In 2019, similar Eastern European pagesran the same playbook  
this time, reaching nearly half of all Americans on the platform.

Page 2 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
Now, AI has given those same operations the capacity to produce near-infinite volumes of low-quality (or outright 
fake) news   and in at least some cases, this AI-produced slop is breaking through. The pages have begun using 
generic AI-generated imagery (bald eagles, stars and stripes, camo soldiers and the occasional Statue of Liberty) to 
appeal to American Facebook users   and in at least some cases, it s working. Onepostmade last week by the 
Canada-based page American Patriots featured an AI-generated photo of an American soldier and his children, and 
received more than 100,000 likes and 35,000 comments. The American Patriots page, like most of the others, 
directed people from Facebook to click farms featuring low-quality articles.
<figure>
<figcaption>
Pages like We Are America, American Patriots and USA Army Is Love post a mix of real and AI-generated 
photography and memes.
Facebook
</figcaption></figure>
Forbesfed three of the American Patriots articles through an AI text detector called GPT-Zero, which found that 
they were 79%, 85%, and 100% likely to have been generated by AI. The detector also found that stories linked 
from We Love America, a page from Spain, and American Story, a Macedonian page, had a 100% likelihood of 
being generated by AI.(Disclosure: In a previous life, I held content policy positions at Facebook and 
Spotify.)
 Every platform has incentives   and they provide a window into what is at the heart of Facebook, what makes it 
tick," said Jeff Allen, co-founder of the Integrity Institute and a former Facebook data scientist who tracked networks 
of spammy page administrators from the inside. To him, click farmers are a  great magnifying glass   into the more 
reptilian parts of our brain. 
Meta spokesperson Margarita Franklin toldForbesthat all 67 pages violated Meta s rules on inauthentic behavior, 
because they misrepresented where they were based; all were taken down. It s not necessarily a violation of Meta s 
rules to make a page about one country while based in another, but the pages cross a line when they deceive 
people about where they re from. Franklin said the pages had only been active for a little more than a week 
whenForbesflagged them.
Franklin also said that while AI does make content generation easier for spammers and scammers, their primary 
challenge has always been getting eyeballs on their pages, whether they re made with AI or not. A recent Meta 
Threat Report found that generative AI has  provide[d] only incremental productivity and content-generation gains  
to  threat actors,  because the cost of creating low-quality clickbait articles has always been pretty low.
When Macedonian content farms first became big on Facebook in 2016, they leaned hard into hyper-partisan rage 
bait focused on divisive issues like immigration, trans rights, race and policing. The theory was simple   write about 
what people were most likely to engage with. And at the time, posts about those issuesoften topped the chartsof 
Facebook engagement.
But Facebook s algorithm has shifted away from politics in the eight years since then. The company began 
aggressively demoting political posts after the January 6, 2021 capitol riots, which wereorganized in parton Meta 
platforms.
Some of the American patriotic pages still featured political topics, with recent posts on topics including critical race 
theory and trans rights. In the aggregate, though, the pages didn t focus on politics. More often, they featured 
formulaic tabloid stories, like tales of cheating spouses ( You won t believe what he did next! ) or disrespected blue 
collar workers who get revenge on the elitists who snubbed them. Oddly, ever-present across the pages were 
memes featuring the television personality and America s Got Talent judge Simon Cowell. Along with changing their 
content to echo the Facebook algorithm s shift away from politics, the pages also showed other telltale signs of 
Page 3 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
adapting to the platform s ever-changing rules and incentives. For instance, Facebook has reduced the reach of  
spammy  links but prioritizes a page admin s comments on their own posts; as a result, these pages often posted a 
meme or other image that summarizes the gist of an article, and then posted the link as a comment.
<figure>
<figcaption>
Patriotic Warriors, a Facebook page that had 141,000 followers before it was taken down, is run out of Macedonia.
Facebook
</figcaption></figure>
Some of the pages also used other engagement-juicing tricks that have long been popular. One page based in 
Kosovo, called Animals News America, featured clickbait posts similar (and in some cases, identical) to those on 
other, non-animal themed pages. But it also posted a regular stream of kittens and puppies, using a strategy 
previouslyemployedby notorious misinformation spreaders like the COVID- denying doctor Joseph Mercola and 
NTD News, a Falun Gong-affiliated sister brand of the Epoch Times.
AfterForbesreached out for comment, Meta removed every page.
Even if these pages weren t intentionally being used to shape people s political views, click-farmers will sometimes 
shift their pages into deliberate geopolitical influence operations, Allen said. While still at Facebook, he observed 
one Thailand-based operation that targeted pages about politics to audiences in Myanmar. They would "pop in and 
out of being guns for hire for political campaigns," he said. "But when it wasn't political campaign season, they'd run 
the exact same operations, just making the money themselves."
That makes these pages less innocuous than they might seem.  I bet there are plenty of foreign influence 
operations that would like to buy these Pages when the time is right. So, there are times when  click farms  can 
become much more nefarious," Allen said. After the original Macedonian click farmers were exposed, 
Facebooklaunched a featureto enable users to find out which country a page is run from, if it has at least 5,000 
followers or has run political ads. But the country of a page administrator s origins is often hidden in an obscure 
panel called Page Transparency, and comments on the foreign America-themed pages  posts suggest that many 
people engaging with those posts did not know that the pages are run by foreigners.
The America-themed pages themselves were also deliberately misleading.One postmade last week by a page 
called America Today reads:  Not another cent to nations that disrespect our flag and values!     The page was 
managed from Macedonia.
Franklin noted that in certain cases, Meta now displays the location of certain pages  page managers directly in the 
Facebook News Feed.
Accounts that pretend to be American when they re not may be a widespread issue on social media. Facebook, to 
its credit, is the only major social media platform reveals the country from which its large pages are managed. Other 
platforms, including YouTube and TikTok, allow users to self-declare a location if they want to, making it harder to 
detect accounts that are pretending to be American when they re not. The incentives, however, are the same. 
Parveen Kumar Shah, who makes his living advising people about how to build audiences on YouTube and 
Instagram through his channelTubeSensei,recently suggested other page creators seeking to build an audience 
should pretend to be American. Why? You ll make more money that way, he advised.
AI makes that even easier. In an interview, he toldForbesthat now,  if you don t want to show your face, everything 
can be done through AI.  On YouTube, Shahshowed his followershow to make masculinity-themed pages for 
American teens with titles like Far From Weak and Sigma Male. He toldForbes:  Targeting that type of audience is 
very easy because a teenager s brain is very easy to mold. 
Page 4 of 4
The Foreign Pro-Trump Fake News Industry Has Pivoted To American Patriotism
There aremany videoson YouTube that explain how to hide or spoof your country of residence on the platform, to 
make it look like your channel is based in another part of the world. For Shah, this is a simple economic calculus: 
YouTube pays channel managers based on the ads that run on their channel, and advertisers spend far more in 
Western markets than they do in India. On the TubeSensei channel, he explained:  Our channel is going to be for a 
U.S. audience, and as soon as they come to know that this is an Indian channel, or there is an Indian creator 
behind it, they stop watching the channel. 
YouTube did not respond to a request for comment.
Allen, the former Facebook data scientist, characterized engagement farming as a problem for platforms to fix   one 
that if they don t address, regulators might eventually penalize them for. He compared the prevalence of inauthentic 
pages to defective tires on a car: "Your tires have been popping on the highways for the past ten years. At a certain 
point, there's going to be some regulatory teeth."
As long as the click farmers  crimes don t go beyond the proliferation of stale, low-quality memes, though, Allen 
doesn't think removing pages is the solution. Instead, he said, Facebook should move away from an algorithm that 
incentivizes people to post sensationalist slop in the first place.
"If a click farmer tries to farm on your platform, but doesn't get any clicks   does he do any farming?"
Rashi Shrivastava contributed reporting.
MORE FROM FORBES
Load-Date: August 27, 2024
End of Document
Page 1 of 3
How did Donald Trump end up posting Taylor Swift deepfakes?
How did Donald Trump end up posting Taylor Swift deepfakes?
The Guardian (London)
August 24, 2024 Saturday 5:00 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:3
Length: 1114 words
Byline: Nick Robins-Early
Highlight: AI images posted to Truth Social bore the watermark of a tiny Texas non-profit looking to bankroll X 
users
Body
When Donald Trump  shared a slew of AI-generated images  this week that falsely depicted Taylor Swift  and her 
fans endorsing his campaign for president, the former US president was amplifying the work of a murky non-profit 
with aspirations to bankroll rightwing media influencers and a history of spreading misinformation.
Several of the images Trump posted on his Truth Social platform, which showed digitally rendered young women in 
“Swifties for Trump” T-shirts, were the products of the John Milton Freedom Foundation. Launched last year, the 
Texas-based non-profit organization frames itself as a press freedom group with the goal of “empowering 
independent journalists” and “fortifying the bedrock of democracy”.
The group’s day-to-day operations appear to revolve around sharing engagement bait on X and seeking millions 
from donors for a “fellowship program” chaired by a high school sophomore that would award $100,000 to Twitter 
personalities such as Glenn Greenwald, Andy Ngo and Lara Logan, according to a review of the group’s tax 
records, investor documents and social media output. The John Milton Freedom Foundation did not respond to a 
request for comment to a set of questions about its operations and fellowship program.
After months of retweeting conservative media influencers and echoing Elon Musk  ’s claims that freedom of 
speech is under attack from leftwing forces, one of the organization’s messages found its way to Trump and then 
his millions of supporters.
Trump distanced himself from the images in an interview with Fox Business on Wednesday, saying: “I don’t know 
anything about them other than someone else generated them. I didn’t generate them.”
Disinformation researchers have long warned that generative AI  has the ability to lower the bar for creating 
misleading content and threaten information around elections. After Musk’s xAI company released its largely 

Page 2 of 3
How did Donald Trump end up posting Taylor Swift deepfakes?
unregulated Grok image generator last week, there has been a surge of AI content that has included depictions of 
Trump, Kamala Harris and other political figures. The Milton Freedom Foundation is one of many small groups 
flooding social media with so-called AI slop. 
                   A niche non-profit’s AI slop makes its way to Trump                   
During the spike in AI images on X, the conservative @amuse account posted the images  of AI-generated Swift 
fans to more than 300,000 followers. On the text of the post, which was labeled “satire”, was a watermark that 
stated it was “sponsored by the John Milton Freedom Foundation”. Trump posted a screenshot of @amuse’s tweet 
on Truth Social.
The @amuse account has considerable reach itself, with about 390,000 followers on X and dozens of daily posts. 
Running @amuse appears to be Alexander Muse, listed as a consultant in the investor prospectus of the Milton 
Foundation, who also writes a rightwing commentary Substack that includes posts exploring election conspiracy 
theories. The @amuse account has numerous connections with Muse. The X account is connected to a Substack 
posting the same articles that Muse publishes on his LinkedIn page, which also has the username “amuse”, 
reflecting his first initial and last name. Muse’s book on how to secure startup funding, which includes examples of 
him asking ChatGPT  to pretend it’s Musk and offer business advice, lists that same Substack account as its 
publisher.
Prominent accounts including Musk have shared and replied to @amuse’s posts, which recently have included AI 
depictions of Trump fighting Darth Vader and sexualized imagery of Harris. Its banner picture is currently an AI-
generated photo of Trump surrounded by women in “Swifties” shirts. The account posts misleading, pro-Trump 
headlines such as claiming Harris turned hundreds of thousands of children over to human traffickers as “border 
czar”. The headlines, like the AI-generated Swifties for Trump images, come with the watermark “sponsored by the 
John Milton Freedom Foundation”.
The John Milton Freedom Foundation, named after the 17th-century British poet and essayist, has a small online 
footprint: a website, an investor prospectus and an X account with fewer than 500 followers. The team behind it, 
according to its own documents, consists of five people based in the Dallas-Fort Worth area with varying degrees of 
experience in Republican politics. Muse’s daughter, described as a 10th grade honor student on the non-profit’s 
site, serves as the Milton Foundation’s “fellowship chair”.
The foundation’s stated goal is to raise $2m from major donors to award $100,000 grants to a list of “fellows” made 
up of rightwing media influencers. These include people like the former CBS journalist turned far-right star Lara 
Logan, who was cut from Newsmax  in recent years for going on a QAnon-inspired rant that claimed world leaders 
drink children’s blood, as well as the author of an anti-trans children’s book. The organization believes that this 
money would allow these already established influencers to “increase their reach by more than 10x in less than a 
year”, according to its investor prospectus.
While only one of the fellows listed on the foundation’s site mentions the organization on their X profiles and none 
follow its account, the @amuse account has a prominent link to the group’s community page and the foundation 
often engages with its posts.
It is not clear that the foundation has any money to give and if all the media influencers listed as its 2024 fellowship 
class know about the organization. One Texas-based account that posts anti-vaccine content lists itself as a “JMFF” 
fellow in their bio, but none of the others advertise any connection. The most recent tax records for the Freedom 
Foundation place it in the category of non-profits whose gross receipts, or total funds received from all sources, 
range from $0 to $50,000 – far below the millions it is seeking.
The organization’s board includes its chair, Brad Merritt, who is touted as an experienced Republican organizer with 
claims to have raised $300m for various non-profits; its director, Shiree Sanchez, who served as assistant director 
of the Republican party of Texas between 1985 and 1986; and Mark Karaffa, a retired healthcare industry 
executive.
Page 3 of 3
How did Donald Trump end up posting Taylor Swift deepfakes?
Muse’s experience in digital media appears to be far more extensive than the non-profit’s other members. In 
addition to his blog, he claims to have worked with James O’Keefe, the former CEO of the rightwing organization 
Project Veritas , who was known for hidden camera stings until he was ousted last year  over allegations of 
misplaced funds. Muse, who is described in the prospectus as a “serial entrepreneur”, also blogs about how to 
make money from generative AI.
Load-Date: August 26, 2024
End of Document
Page 1 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the 
internet is ‘flooded with garbage’
The Guardian (London)
August 24, 2024 Saturday 9:00 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: AUSTRALIA NEWS; Version:2
Length: 1582 words
Byline: Ariel Bogle
Highlight: Australian Barbara O’Neill’s ‘natural self-healing’ remedies found a certain audience through her own 
efforts. But her image has run wild thanks to unaffiliated groups exploiting her name on social mediaFollow our 
Australia news live blog for latest updatesGet our morning and afternoon news emails, free app or daily news 
podcast
Body
Five years ago, Barbara O’Neill was permanently banned from providing any health services in New South Wales 
or other Australian states. 
O’Neill, whose website describes her as “an international speaker on natural healing”, was found by the NSW 
Health Care Complaints Commission (HCCC)  in 2019 to have given highly risky health advice to vulnerable 
people, including the use of bicarbonate soda as a cancer treatment.
Since then her views have found a much larger audience overseas and online, supported by elements of the 
Seventh-day Adventist (SDA) church and media networks in the US. So far this year O’Neill has spoken in the US, 
the UK and Ireland and advertised retreats in Thailand for thousands of dollars. A Facebook page managed in her 
name is promoting plans for O’Neill to tour Australia later this year, despite the commission’s ruling.
Sign up for Guardian Australia’s free morning and afternoon email newsletters for your daily news roundup
But O’Neill’s story reveals not only the limits of a state health regulator. Beyond her own promotional efforts, a vast 
scam economy has grown up that profits from her notoriety without her authorisation.
Clips of O’Neill’s health teachings, often dating as far back as 2012, now feed a voracious economy of unaffiliated 
Facebook pages and groups – more than 180 at one point – that are branded with her name and share lecture clips 
and recipes but are outside the control of O’Neill. Many are controlled by accounts based in Morocco, but attempts 
to contact administrators went unanswered.

Page 2 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
Old clips of O’Neill are being used to sell herbal teas, Celtic salt and castor oil on TikTok, as Vox found.  AI-
generated content of O’Neill on the app now goes even further, making up entirely new claims about her and her 
health advice.
Accounts on the app share generative AI images that falsely claim she “disappeared” after revealing that a certain 
mineral that will help people live for 100 years, or that show O’Neill being “arrested” for sharing apparent methods 
of natural healing such as black seed oil. The videos typically link to online stores or even Amazon where, naturally, 
the product referred to is for sale. Questions to account owners went unanswered.
It’s part of an emerging online ecosystem in which would-be digital creators in search of easy money follow trending 
topics such as O’Neill’s health claims, and use generative AI to create eye-catching and often bizarre images on 
social media – often sending viewers to online stores.
Jason Koebler, cofounder of 404 Media, has explored the “AI slop” economy  on Facebook. He suggests creators 
around the world are essentially “penetration testing” social media platforms to circumvent moderation policies and 
make money in new ways, building off content they know will capture attention. So-called “wellness secrets” fit the 
bill.
“That’s been the biggest effect of the generative AI boom,” he says. “The entire internet and social media platforms 
have been flooded with garbage.”
                   ‘Genuine’ O’Neill content finds an audience                   
For years, O’Neill and her husband, Michael O’Neill – the founder of the Informed Medical Options party (now the 
Heart party), which opposes water fluoridation and “No jab, no pay” immunisation requirements  – worked at the 
Misty Mountain health retreat in northern New South Wales.
She crisscrossed Australia giving health lectures, often in regional cities and outer suburbs such as Dandenong, 
SDA publications from the 2010s show. “Do you want better health?”, one ad from 2012 asked, indicating O’Neill 
would discuss high blood pressure and “overcoming depression”.
After a series of complaints in 2018 and 2019, the HCCC investigated some of her claims. The commission found  
that among her many claims was that cancer was caused by fungus and that it could be treated by “sodium 
bicarbonate wraps”.
Her comments about infant nutrition, antibiotics for pregnant women and vaccinations were also not based on 
evidence, the HCCC found, and she had “limited qualifications in the area of nutrition and dietetics”.
“Mrs O’Neill does not recognise that she is misleading vulnerable people (including mothers and cancer sufferers) 
by providing very selective information,” it concluded, and banned her permanently from providing any health 
services. The ban is enforceable in New South Wales, the ACT, Queensland and Victoria.
Misty Mountain lost its charity status  in 2021. Yet despite the restrictions she faces in Australia, O’Neill maintains a 
rigorous international touring schedule. In May, she hosted an eight-day retreat in Phuket, Thailand that was 
advertised as costing between US$2,979.80 (about A$4,500) and US$7,070.90.
A June event about childhood vaccinations run by an Australian anti-vaccine group advertised a “bonus zoom live 
with Barbara O’Neill” for about $180.
“I believe it is our role to get this message out to as many as possible,” O’Neill said in a recent online interview. 
“The ban has actually freed me. It freed me to go places I don’t think I ever would have gone.”
Seventh-day Adventist networks have helped O’Neill continue to share her message. She has spoken at retreats 
and conferences organised by SDA institutes and colleges, though not all are affiliated with official church 
leadership.
Page 3 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
A flyer for a multi-day event in September 2023 organised by the Mountaintop SDA church in Maryland, seen by 
Guardian Australia, said O’Neill would lecture on topics including “Cancer: Causes and Treatments” and 
“Safeguarding Against Depression”.
She has featured prominently  on media published by Amazing Discoveries, a channel that broadcasts messages 
on “health, creation-evolution, media, current events, Bible prophecy, history, and Christian living”.
“I do believe that Amazing Discoveries has certainly contributed to Barbara’s fame but we are definitely not solely 
responsible,” the executive director at Amazing Discoveries, Wendy Goubej, says. “The recent TikTok videos are I 
think what really catapulted her to prominence. It’s sad to see that there are people who are misquoting her and 
misusing her information for personal gain.”
The US General Conference of Seventh-day Adventists did not respond to a request for comment. A spokesperson 
for the church in Australia said O’Neill was not an employee and that the church had no involvement in her 
speaking engagements.
“In matters concerning health, the Seventh-day Adventist Church advises people to seek information and guidance 
from qualified and accredited healthcare professionals,” they said.
                   Fake posts take up the message                   
But publicity genuinely affiliated with O’Neill is dwarfed by the avalanche of scam posts on almost every major 
social media platform. Even as videos are taken down, new accounts and claims emerge.
In July, a Facebook ad used faked Channel Nine news footage to claim that O’Neill, an “Australian health coach”, 
had revealed a medicine that would heal “joint diseases” in three weeks. The page’s operator, with a Democratic 
Republic of Congo phone number, said over WhatsApp they had no idea where the video came from and they 
believed their page had been hacked. 
Other Facebook ads claim she has recommended everything from particular herbal salves to supplements that help 
men with impotence. An ad linked to a Dubai pharmacy claims she is “considered one of the best urologists in the 
world”.
One particularly unconvincing video merges faked video and audio of the former Fox News personality Tucker 
Carlson and O’Neill to promote eyedrops.
In late 2023, O’Neill’s team shared a video on her verified Instagram account addressing the deluge of fakes online. 
The post said that while she was grateful for fan pages that “faithfully share” her teachings, “it is important to clear 
up some misconceptions as people have been impersonating Barbara on social media and selling consultations 
and ‘cures’.” 
In August, her Facebook page again posted about the scams. “So many people still being tricked,” it read. “We are 
tagged in stories of people excited about purchasing fake items or products sold off fake AI videos.”
Tara Kirk Sell, a senior scholar at the Johns Hopkins Center for Health Security, says the phenomenon around 
O’Neill “shows the limit of regulatory powers”.
“I think that a lot of people are looking for easy solutions in this space: ‘if only we could take all this content off 
social media … the problem would be solved’.
“Well, it’s not that easy, right?”
A Meta spokesperson said the company was reviewing the Facebook ads flagged by Guardian Australia. “Meta 
adopts a multi-faceted approach to tackle scams,” he said. “We use both technology, such as new machine learning 
techniques, and specially trained reviewers to identify and action content and accounts that violate our policies.”
Page 4 of 4
A banned promoter of cancer ‘cures’ was hijacked by genAI. Now the internet is ‘flooded with garbage’
A TikTok spokesperson said the platform did not allow impersonation accounts “or attempts to defraud or scam 
members”, and removed an account sharing generative AI images of O’Neill identified by the Guardian. “In 
Australia, between January and March 2024, we removed over 73,000 videos for violating our Frauds and Scams 
Policy, with 98% of these taken down proactively before anyone reported them,” they said.
An HCCC spokesperson said it could not comment on specific cases or speculate on potential complaints. “The 
global spread of health misinformation through social media is an ongoing concern for the commission,” he said.
O’Neill did not respond to requests for comment.
Load-Date: August 25, 2024
End of Document
Page 1 of 2
Donald Trump, AI Artist
Donald Trump, AI Artist
Atlantic Online
August 23, 2024 Friday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 622 words
Byline: Damon Beres
Body
This is Atlantic Intelligence, a newsletter in which our writers help you wrap your mind around artificial intelligence 
and a new machine age. Sign up here.
The era of generative-AI propaganda is upon us. In the past week, Donald Trump has published fabricated images 
on his social-media accounts showing Kamala Harris speaking to a crowd of uniformed communists under the 
hammer and sickle, Taylor Swift in an Uncle Sam outfit, and young women in "Swifties for Trump" T-shirts. Other 
far-right influencers have published their own AI slop depicting Harris in degrading sexual contexts or glorifying 
Trump.
As my colleague Charlie Warzel writes for The Atlantic, "Although no one ideology has a monopoly on AI art, the 
high-resolution, low-budget look of generative-AI images appears to be fusing with the meme-loving aesthetic of the 
MAGA movement. At least in the fever swamps of social media, AI art is becoming MAGA-coded."
Such images are, in effect, an evolution of the memes that have long fueled the far right. But now even elementary 
Photoshop skills are no longer required: Simply plug a prompt into an image generator and within seconds, you'll 
have a reasonably lifelike JPEG for your posting pleasure.
"That these tools should end up as the medium of choice for Trump's political movement makes sense," Charlie 
writes. "It stands to reason that a politician who, for many years, has spun an unending series of lies into a 
patchwork alternate reality would gravitate toward a technology that allows one to, with a brief prompt, rewrite 
history so that it flatters him."
The MAGA Aesthetic Is AI Slop
By Charlie Warzel
Taylor Swift fans are not endorsing Donald Trump en masse. Kamala Harris did not give a speech at the 
Democratic National Convention to a sea of communists while standing in front of the hammer and sickle. Hillary 
Clinton was not recently seen walking around Chicago in a MAGA hat. But images of all these things exist.

Page 2 of 2
Donald Trump, AI Artist
In recent weeks, far-right corners of social media have been clogged with such depictions, created with generative-
AI tools 
This AI slop doesn't just exist in a vacuum of a particular social network: It leaves an ecological footprint of sorts on 
the web. The images are created, copied, shared, and embedded into websites; they are indexed into search 
engines. It's possible that, later on, AI-art tools will train on these distorted depictions, creating warped, digitally 
inbred representations of historical figures. The very existence of so much quickly produced fake imagery adds a 
layer of unreality to the internet.
Read the full article.
What to Read Next
  
• Silicon Valley is coming out in force against an AI-safety bill: This week, my colleague Caroline Mimbs 
Nyce spoke with California State Senator Scott Wiener, whose attempts to impose regulations on 
advanced AI models have been met with severe pushback-not just from tech companies, but from other 
Democrats, including Nancy Pelosi. "The opposition claims that the bill is focused on ~science-fiction 
risks,'" Wiener said. "They're trying to say that anyone who supports this bill is a doomer and is crazy. This 
bill is not about the Terminator risk. This bill is about huge harms that are quite tangible."
P.S.
Speaking of science fiction, I'm off to see Alien: Romulus tonight. Writing for The Atlantic about this film and the 
greater franchise to which it belongs, the journalist Fran Hoepfner noted, "The Alien films have always touched on 
heady, pessimistic visions of a future overrun by capitalism and genetic experimentation, but they're also movies 
about a human beating a monster-shooting it, setting it on fire, throwing it out of an air-locked door into the void of 
space." Sounds like a good Friday night to me.
- Damon
Load-Date: August 24, 2024
End of Document
Page 1 of 3
The MAGA Aesthetic Is AI Slop
The MAGA Aesthetic Is AI Slop
Atlantic Online
August 21, 2024 Wednesday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1298 words
Byline: Charlie Warzel
Body
Taylor Swift fans are not endorsing Donald Trump en masse. Kamala Harris did not give a speech at the 
Democratic National Convention to a sea of communists while standing in front of the hammer and sickle. Hillary 
Clinton was not recently seen walking around Chicago in a MAGA hat. But images of all these things exist.
In recent weeks, far-right corners of social media have been clogged with such depictions, created with generative-
AI tools. You can spot them right away, as they bear the technology's distinct image style: not-quite-but-almost 
photorealistic, frequently outrageous, not so dissimilar from a tabloid illustration. Donald Trump-or at least whoever 
controls his social-media accounts-posted the AI-generated photo of Harris with the hammer and sickle, as well as 
a series of fake images depicting Taylor Swift dressed as Uncle Sam and young women marching in Swifties for 
Trump shirts. (This after he falsely claimed that Harris had posted an image that had been "A.I.'d"-a tidy bit of 
projection.)
[Read: Why does AI art look like that?]
Trump himself has been the subject of generative-AI art and has shared depictions of himself going back to March 
2023. He's often dressed up as a gun-toting cowboy or in World War II fatigues, storming a beach. Yet these are 
anodyne compared with much of the material created and shared by far-right influencers and shitposters. There are 
plenty of mocking or degrading images of Harris and other female Democratic politicians, such as Alexandria 
Ocasio-Cortez. On X, one post that included a fake image in which Harris is implied to be a sex worker has been 
viewed more than 3.5 million times; on Facebook, that same post has been shared more than 87,000 times. One 
pro-Trump, Elon-Musk-fanboy account recently shared a suggestive image depicting a scantily clad Harris 
surrounded by multiple clones of Donald Trump; it's been viewed 1.6 million times. There are images and videos of 
Harris and Trump holding hands on a beach and Harris wearing a crown that reads Inflation Queen. On the first 
night of the DNC, MAGA influencers such as Catturd2 and Jack Posobiec supplemented their rage tweets about 
Democrats with stylized AI images of Tim Walz and Joe Biden looking enraged.

Page 2 of 3
The MAGA Aesthetic Is AI Slop
Although no one ideology has a monopoly on AI art, the high-resolution, low-budget look of generative-AI images 
appears to be fusing with the meme-loving aesthetic of the MAGA movement. At least in the fever swamps of social 
media, AI art is becoming MAGA-coded. The GOP is becoming the party of AI slop.
AI slop isn't, by nature, political. It is most prevalent on platforms such as Facebook, where click farmers and 
spammers create elaborate networks to flood pages and groups with cheap, fake images of starving children and 
Shrimp Jesus in the hopes of going viral, getting likes, and picking up "creator bonuses" for online engagement. 
Jason Koebler, a technology reporter who has spent the past year investigating Facebook's AI-slop economy, has 
described the deluge of artificial imagery as part of a "zombie internet" and "the end of a shared reality," where "a 
mix of bots, humans, and accounts that were once humans but aren't anymore interact to form a disastrous website 
where there is little social connection at all."
What's going on across the MAGA internet isn't exactly the same as Facebook's spam situation, although the vibe 
is similar. MAGA influencers may be shitposting AI photos for fun, but they're also engagement farming, especially 
on X, where premium subscribers can opt in to the platform's revenue-sharing program. Right-wing influencers 
have been vocal about these bonuses, which are handed out based on how many times a creator's content is seen 
in a given month. "Payout was huge. They've been getting bigger," Catturd2 posted this March, while praising 
Musk.
Although many of these influencers already have sizable followings, AI-image generators offer an inveterate poster 
the thing they need most: cheap, fast, on-demand fodder for content. Rather than peck out a few sentences 
complaining about Biden's age or ridiculing Harris's economic policies, far-right posters can illustrate their attacks 
and garner more attention. And it's only getting easier to do this: Last week, X incorporated the newest iteration of 
the generative-AI engine Grok, which operates with fewer guardrails than some competing models and has already 
conjured up untold illustrations of celebrities and politicians in compromising situations.  
[Read: Hot AI Jesus is huge on Facebook]
It's helpful to think of these photos and illustrations not as nefarious deepfakes or even hyper-persuasive 
propaganda, but as digital chum-Shrimp Jesus on the campaign trail. For now, little (if any) of what's being 
generated is convincing enough to fool voters, and most of it is being used to confirm the priors of true believers. 
Still, the glut of AI-created political imagery is a pollutant in a broader online information ecosystem. This AI slop 
doesn't just exist in a vacuum of a particular social network: It leaves an ecological footprint of sorts on the web. 
The images are created, copied, shared, and embedded into websites; they are indexed into search engines. It's 
possible that, later on, AI-art tools will train on these distorted depictions, creating warped, digitally inbred 
representations of historical figures. The very existence of so much quickly produced fake imagery adds a layer of 
unreality to the internet. You and I, like voters everywhere, must wade through this layer of junk, wearily separating 
out what's patently fake, what's real, and what exists in the murky middle.
In many ways, political slop is a logical end point for these image generators, which seem most useful for people 
trying to make a quick buck. Photography, illustration, and graphic design previously required skill or, at the very 
least, time to create something interesting enough to attract attention, which, online, can be converted into real 
money. Now free or easily affordable tools have flooded the market. What once took expert labor is now spam, 
powered by tools trained on the output of real artists and photographers. Spam is annoying, but ultimately easy to 
ignore-that is, until it collides with the negative incentives of social-media platforms, where it's used by political 
shitposters and hucksters. Then the images become something else. In the hands of Trump, they create small 
news cycles and narratives to be debunked. In the hands of influencers, they are fired at our timelines in a 
scattershot approach to attract a morsel of attention. As with the Facebook AI-slop farms, social media shock jocks 
churning out obviously fake, low-quality images don't care whether they're riling up real people, boring them, or 
creating fodder for bots and other spammers. It is engagement for engagement's sake. Mindlessly generated 
information chokes our information pathways, forcing consumers to do the work of discarding it.
That these tools should end up as the medium of choice for Trump's political movement makes sense, too. It stands 
to reason that a politician who, for many years, has spun an unending series of lies into a patchwork alternate 
Page 3 of 3
The MAGA Aesthetic Is AI Slop
reality would gravitate toward a technology that allows one to, with a brief prompt, rewrite history so that it flatters 
him. Just as it seems obvious that Trump's devoted followers-an extremely online group that has so fully embraced 
conspiracy theorizing and election denial that some of its members stormed the Capitol building-would delight in the 
bespoke memes and crude depictions of AI art. The MAGA movement has spent nine years building a coalition of 
conspiratorial hyper-partisans dedicated to creating a fictional information universe to cocoon themselves in. Now 
they can illustrate it.
Load-Date: August 22, 2024
End of Document
Page 1 of 2
Why the Popular Software Company Procreate Is Swearing Off Generative AI
Why the Popular Software Company Procreate Is Swearing Off Generative AI
Inc.com
August 19, 2024 Monday 15:57 PM EST
Copyright 2024 Mansueto Ventures, LLC All Rights Reserved
Length: 381 words
Byline: Ben Sherry
Body
Art and design company Procreate said artificial intelligence is 'ripping the humanity out of things.'
While technology firms scramble to take advantage of generative AI, one artist-friendly company is pushing in a 
decidedly different direction. Procreate, the company behind the popular art and design iPad app of the same 
name, has vowed to never introduce generative AI-powered features to its platform, writing in a statement that the 
technology is "ripping the humanity out of things."
In a video titled "we're never going there," posted to the Australia-based company's social channels, Procreate co-
founder and CEO James Cuda responded to questions about potential plans to implement generative AI features or 
use customers' work to train AI models. Adobe, one of Procreate's main competitors, recently announced plans to 
do both. Cuda, who started the company in 2011 with wife Alanna, said "I really f*cking hate generative AI," and 
announced that Procreate will not use the tech at all. 
"I don't like what's happening in the industry and I don't like what it's doing to artists," said Cuda, adding that "our 
products are always designed and developed with the idea that a human will be creating something."
In a statement shared to Procreate's website, the company wrote that generative AI is built on a foundation of theft. 
The company specified that it sees machine learning as a "compelling technology with a lot of merit, but the path 
generative AI is on is wrong for us." 
The company acknowledged that the decision "might make us an exception or seem at risk of being left behind," 
but affirmed their chosen path as being "the more exciting and fruitful one for our community." Procreate, which 
costs $13, has been one of the most popular digital art platforms on the iPad for over a decade, and has 
consistently been the top paid app on the iPad app store for more than seven years. 
On X, Ed Newton-Rex, CEO of genAI certification company Fairly Trained, wrote that he suspects more companies 
will come out against generative AI, "not just for legal/ethical reasons (though those are big)," he said, "but also 
because rejecting gen AI will be a signal of premium quality. In a world of AI-generated slop, platforms that keep 
themselves slop-free will stand out."
Link to Image

Page 2 of 2
Why the Popular Software Company Procreate Is Swearing Off Generative AI
Graphic
 
Photo: Getty Images
Load-Date: August 19, 2024
End of Document
Page 1 of 2
Ripple CTO highlights AI controversy over dangerous Mushroom identification book
Ripple CTO highlights AI controversy over dangerous Mushroom 
identification book
Newstex Blogs 
Cryptopolitan
August 18, 2024 Sunday 8:30 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 Cryptopolitan
Length: 431 words
Body
August 18th, 2024 (Cryptopolitan — Delivered by Newstex)
David Schwartz, Ripple's Chief Technology Officer, recently posted a viral Reddit post on his social media account, 
which tells the story of a family who was admitted to the hospital after consuming poisonous mushrooms, which 
they identified using an AI-generated book.
If this report is true, it's history repeating itself.https://t.co/UEVENXO72E  https://t.co/sjQgkATFqz— David 
"JoelKatz" Schwartz (@JoelKatz) 
August 17, 2024
According to the Reddit post, the family used a mushroom identification book they bought from a popular store. The 
post stated that the book provided images and text created by AI to identify the mushrooms, but all of them were 
poisonous. The family consumed the mushrooms with the help of the book written by the AI, and all of them were 
admitted to the hospital, which is a big question mark on the AI content. 
Ripple CTO draws parallels to historical lawsuit
The post also stated that not only there are AI pictures in the book but also Chatbot replies in the text of the book 
suggesting that no human had a hand in it. Even though the retailer has apparently provided a refund for the book, 
the issue has made people question whether there could be more low-quality books written by AI for sale. 
In his social media post, Schwartz compared this event to a well-known lawsuit that occurred at the beginning of the 
1990s. The Ripple executive cited Winter v. G.P. Putnam's Sons, a 1991 Court of Appeals case. The case points to 
two young adults who decided to purchase a book they named 'The Encyclopedia of Mushrooms' to act as a 
reference.
The couple was forced to seek legal intervention against P. Putnam's Sons for product liability, negligence, and 
false representation. Although the two mushroom hunters almost lost their lives because of the wrong information 
provided by the book, the court ruled in favor of the publisher. 

Page 2 of 2
Ripple CTO highlights AI controversy over dangerous Mushroom identification book
Identification guides face scrutiny over AI use
Schwartz's use of this case demonstrates how the use of AI in content creation is not a positive thing and has legal 
ramifications. Whether books generated by AI can be subjected to similar legal procedures as more and more 
content is being produced with the help of AI is still up for debate. 
Schwartz wrote an X post concerning Quora, a popular question-and-answer website. This is not the first time that 
the Ripple CTO has criticized this website and how AI is being used on it. In his post, Schwartz highlighted some of 
the issues with the questions that Quora's AI-generated, which he referred to as 'AI-generated slop.' 
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: August 18, 2024
End of Document
Page 1 of 2
In a word: This week's column: 'the ick' or a 'boop'?
In a word: This week's column: 'the ick' or a 'boop'?
Sunjournal.com 
August 18, 2024 Sunday
Copyright 2024 Lewiston Sun Journal  All Rights Reserved
Length: 625 words
Byline: By Jim Witherell Special to the Sun Journal
Body
Recently the lexicographers at the Cambridge Dictionary added 3,236 new words and phrases to their list of 
searchable words (as well as myriad new meanings of existing words). This news should be enough to excite word 
lovers everywhere or at least be enough to keep them interested in reading the next few hundred words, I hope - so 
let's jump right in.
Let's start by looking at how new words are selected for inclusion in the tome. According to Cambridge Dictionary 
Publishing Manager Wendalyn Nichols, "Some new terms are added very quickly and others can take some time. 
We try to identify words and uses that have proven staying power, rather than adding ones that might be short-
lived."
Here are a few of the words that made the cut this time, beginning with "the ick," which is defined as "a sudden 
feeling that you dislike someone or something or are no longer attracted to someone because of something they 
do."
On the other hand, a "boop" is one way of showing someone that you like them, and is accomplished by simply 
touching that person - or thing - gently on the head with your finger.
Another way of showing affection is by "pebbling," which is the act of showing appreciation for someone by sending 
them small gifts, such as memes, videos, or links, that they think the other person would enjoy. The term, it's said, 
comes from gentoo penguins, which give pebbles to potential mates as part of their courtship rituals.
One way to tell if your pebbles were well received is to wait for the recipient to give you a "chef's kiss," which is a 
movement in which they put their fingers and thumb together, kiss them, then pull their hand away from their lips.

Page 2 of 2
In a word: This week's column: 'the ick' or a 'boop'?
If no chef's kiss is forthcoming, you might want to study their "face journey," defined as "a series of expressions that 
appear on someone's face showing different emotions that they are experiencing as a reaction to something."
"We also collect evidence of new words that have only appeared in English very recently," said Nichols. But exactly 
how do the Cambridge editors know which newer words are worthy of being included in the dictionary? It turns out 
that they make use of a blog called "About words" that helps them decide.
On the blog, visitors are asked for their opinions on whether or not certain words and phrases are worthy of being 
included in the Cambridge Dictionary. The three choices people have are: "Yes! I've heard/read this a lot," 
"Definitely not!" and "Let's wait and see. Maybe people will start using it."
One candidate for inclusion is the phrase "Generation T," which is a way of referring to "a group of people who were 
born in the early 2000s and who spend a lot of their free time traveling." Another hopeful is a new definition of 
"slop" -  "AI-generated content that is unwanted and is of poor quality."
If you work in an office, have you ever been guilty of "mouse jiggling," which is another candidate. It's "the activity of 
making one's computer mouse move at regular intervals . . . in order to make your employer think you are working."
And if there's a good reason for that mouse jiggling that you're doing, it might be because your boss has burdened 
you with too many "vampire tasks," which are all those "routine but necessary administrative tasks" that take time 
away from doing the important stuff.
"Lexicographers," explained Nichols, "use the Cambridge English Corpus, a collection of more than 2 billion written 
and spoken English words, to gather evidence for how a new word is used by different people and in a variety of 
situations." That's a lot of words!
Jim Witherell of Lewiston is a writer and lover of words whose work includes "L.L. Bean: The Man and His 
Company" and "Ed Muskie: Made in Maine." He can be reached at jlwitherell19@gmail.com
Load-Date: October 8, 2024
End of Document
Page 1 of 3
Why Does AI Art Look Like That?
Why Does AI Art Look Like That?
Atlantic Online
August 16, 2024 Friday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1530 words
Byline: Caroline Mimbs Nyce
Body
This week, X launched an AI-image generator, allowing paying subscribers of Elon Musk's social platform to make 
their own art. So-naturally-some users appear to have immediately made images of Donald Trump flying a plane 
toward the World Trade Center; Mickey Mouse wielding an assault rifle, and another of him enjoying a cigarette and 
some beer on the beach; and so on. Some of the images that people have created using the tool are deeply 
unsettling; others are just strange, or even kind of funny. They depict wildly different scenarios and characters. But 
somehow they all kind of look alike, bearing unmistakable hallmarks of AI art that have cropped up in recent years 
thanks to products such as Midjourney and DALL-E.  
Two years into the generative-AI boom, these programs' creations seem more technically advanced-the Trump 
image looks better than, say, a similarly distasteful one of SpongeBob SquarePants that Microsoft's Bing Image 
Creator generated last October-but they are stuck with a distinct aesthetic. The colors are bright and saturated, the 
people are beautiful, and the lighting is dramatic. Much of the imagery appears blurred or airbrushed, carefully 
smoothed like frosting on a wedding cake. At times, the visuals look exaggerated. (And yes, there are frequently 
errors, such as extra fingers.) A user can get around this algorithmic monotony by using more specific prompts-for 
example, by typing a picture of a dog riding a horse in the style of Andy Warhol rather than just a picture of a dog 
riding a horse. But when a person fails to specify, these tools seem to default to an odd blend of cartoon and 
dreamscape.
These programs are becoming more common. Google just announced a new AI-image-making app called Pixel 
Studio that will allow people to make such art on their Pixel phone. The app will come preinstalled on all of the 
company's latest devices. Apple will launch Image Playground as part of its Apple Intelligence suite of AI tools later 
this year. OpenAI now allows ChatGPT users to generate two free images a day from DALL-E 3, its newest text-to-
image model. (Previously, a user needed a paid premium plan to access the tool.) And so I wanted to understand: 
Why does so much AI art look the same?
[Read: AI has a hotness problem]

Page 2 of 3
Why Does AI Art Look Like That?
The AI companies themselves aren't particularly forthcoming. X sent back a form email in response to a request for 
comment about its new product and the images its users are creating. Four firms behind popular image generators-
OpenAI, Google, Stability AI, and Midjourney-either did not respond or did not provide comment. A Microsoft 
spokesperson directed me toward some of its prompting guides and referred any technical questions to OpenAI, 
because Microsoft uses a version of DALL-E in products such as Bing Image Creator.
So I turned to outside experts, who gave me four possible explanations. The first focuses on the data that models 
are trained on. Text-to-image generators rely on extensive libraries of photos paired with text descriptions, which 
they then use to create their own original imagery. The tools may inadvertently pick up on any biases in their data 
sets-whether that's racial or gender bias, or something as simple as bright colors and good lighting. The internet is 
filled with decades of filtered and artificially brightened photos, as well as a ton of ethereal illustrations. "We see a 
lot of fantasy-style art and stock photography, which then trickles into the models themselves," Zivvy Epstein, a 
scientist at the Stanford Institute for Human-Centered AI, told me. There are also only so many good data sets 
available for people to use to build image models, Phillip Isola, a professor at the MIT Computer Science &amp; 
Artificial Intelligence Laboratory, told me, meaning the models might overlap in what they're trained on. (One 
popular one, CelebA, features 200,000 labeled photos of celebrities. Another, LAION 5B, is an open-source option 
featuring 5.8 billion pairs of photos and text.)
The second explanation has to do with the technology itself. Most modern models use a technique called diffusion: 
During training, models are taught to add "noise" to existing images, which are paired with text descriptions. "Think 
of it as TV static," Apolin¡rio Passos, a machine-learning art engineer at Hugging Face, a company that makes its 
own open-source models, told me. The model then is trained to remove this noise, over and over, for tens of 
thousands, if not millions, of images. The process repeats itself, and the model learns how to de-noise an image. 
Eventually, it's able to take this static and create an original image from it. All it needs is a text prompt.
[Read: Generative art is stupid]
Many companies use this technique. "These models are, I think, all technically quite alike," Isola said, noting that 
recent tools are based on the transformer model. Perhaps this technology is biased toward a specific look. Take an 
example from the not-so-distant past: Five years ago, he explained, image generators tended to create really blurry 
outputs. Researchers realized that it was the result of a mathematical fluke; the models were essentially averaging 
all the images they were trained on. Averaging, it turns out, "looks like blur." It's possible that, today, something 
similarly technical is happening with this generation of image models that leads them to plop out the same kind of 
dramatic, highly stylized imagery-but researchers haven't quite figured it out yet. Additionally, "most models have an 
~aesthetic' filter on both the input and output that reject images that don't meet a certain aesthetic criteria," Hany 
Farid,  a professor at the UC Berkeley School of Information, told me over email. "This type of filtering on the input 
and output is almost certainly a big part of why AI-generated images all have a certain ethereal quality."
The third theory revolves around the humans who use these tools. Some of these sophisticated models incorporate 
human feedback; they learn as they go. This could be by taking in a signal, such as which photos are downloaded. 
Others, Isola explained, have trainers manually rate which photos they like and which ones they don't. Perhaps this 
feedback is making its way into the model. If people are downloading art that tends to have really dramatic sunsets 
and absurdly beautiful oceanscapes, then the tools might be learning that that's what humans want, and then giving 
them more of that. Alexandru Costin, a vice president of generative AI at Adobe, and Zeke Koch, a vice president of 
product management for Adobe Firefly (the company's AI-image tool) told me in an email that user feedback can 
indeed be a factor for some AI models-a process called "reinforcement learning from human feedback," or RLHF. 
They also pointed to training data as well as assessments performed by human evaluators as influencing factors. 
"Art generated by AI models sometimes have a distinct look (especially when created using simple prompts)," they 
said in a statement. "That's generally caused by a combination of the images used to train the image output and the 
tastes of those who train or evaluate the images."
The fourth theory has to do with the creators of these tools. Although representatives for Adobe told me that their 
company does not do anything to encourage a specific aesthetic, it is possible that other AI makers have picked up 
on human preference and coded that in-essentially putting their thumb on the scale, telling the models to make 
Page 3 of 3
Why Does AI Art Look Like That?
more dreamy beach scenes and fairylike women. This could be intentional: If such imagery has a market, maybe 
companies would begin to converge around it. Or it could be unintentional; companies do lots of manual work in 
their models to combat bias, for example, and various tweaks favoring one kind of imagery over another could 
inadvertently result in a particular look.
More than one of these explanations could be true. In fact, that's probably what's happening: Experts told me that, 
most likely, the style we see is caused by multiple factors at once. Ironically, all of these explanations suggest that 
the uncanny scenes we associate with AI-generated imagery are actually a reflection of our own human 
preferences, taken to an extreme. No surprise, then, that Facebook is filled with AI-generated slop imagery that 
earns creators money, that Etsy recently asked users to label products made with AI following a surge of junk 
listings, and that the arts-and-craft store Michaels recently got caught selling a canvas featuring an image that was 
partially generated by AI (the company pulled the product, calling this an "unacceptable error.").
[Read: AI-generated junk is flooding Etsy]
AI imagery is poised to seep even further into everyday life. For now, such art is usually visually distinct enough that 
people can tell it was made by a machine. But that may change. The technology could get better. Passos told me 
he sees "an attempt to diverge from" the current aesthetic "on newer models." Indeed, someday computer-
generated art may shed its weird, cartoonish look, and start to slip past us unnoticed. Perhaps then we'll miss the 
corny style that was once a dead giveaway.
Load-Date: August 17, 2024
End of Document
Page 1 of 2
Twitter page gains thousands of followers for making fun of Facebook posts
Twitter page gains thousands of followers for making fun of Facebook posts
CE Noticias Financieras English
August 14, 2024 Wednesday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 CE Noticias Financieras All Rights Reserved
Length: 372 words
Body
Anyone who has an account on a social network knows that each platform has its own particularities, which means 
that its audience is also unique. In a "crossover", a profile on X (old) has been successful for making fun of bizarre 
posts made using images generated by artificial intelligence.
Théodore Cazals, 19, is a French student living in Paris and the creator of the profile "Insane Facebook AI slop" 
(low-quality madness made by artificial intelligence on Facebook, in free translation), which already has more than 
100,000 followers since its creation in April.
The images published on Mark Zuckerberg's network are generally appealing and stir users' empathy and 
superstition because they portray sad situations, despite being unrealistic. They are also accompanied by phrases 
that encourage user engagement. Prints of these posts ended up on X as a joke.
The page came about when Théodore Cazals realized that this type of post generated a lot of engagement on X. 
Although he is the only one behind the profile, there is collaboration from followers, who send suggestions by 
private message.
According to Cazals, the aim of the page is to show a side of Facebook that many X users don't know about. In 
addition, the young Frenchman suggests that the content helps his followers to know what less tech-savvy relatives 
are consuming - and believing - on the social network.
The Frenchman says that the page didn't gain many followers in its first month, but has grown a lot recently. "The 
ridiculous aspect of the images and the fact that they mock less technologically literate people is what makes it so 
successful," he says.
Cazals has come to see the page as a product that could be worth something in the future. He explains that if this 
type of content no longer engages, he intends to change the name and subject matter in order to make the most of 
the space with the followers he has already gained.
Here are the main posts from X's @FacebookAIslop page, formerly Twitter:
"I'm poor. Who loves me?"
"The biggest fish in the whole world"
"Incredible photo of a truck full of babies"
"Why do images like this never go viral?"
"When Peter Griffin visited Africa to donate food"
"Today is my birthday"
"Nobody loves me because I'm poor"

Page 2 of 2
Twitter page gains thousands of followers for making fun of Facebook posts
Load-Date: August 15, 2024
End of Document
Page 1 of 2
Generative AI's Slop Era
Generative AI's Slop Era
Atlantic Online
August 9, 2024 Friday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 563 words
Byline: Damon Beres
Body
This is Atlantic Intelligence, a newsletter in which our writers help you wrap your mind around artificial intelligence 
and a new machine age. Sign up here.
Tech companies believe that generative AI can transform how we find information online, replacing traditional 
search engines with bots that synthesize knowledge into a more interactive format. Rather than clicking a series of 
links, reading a variety of sources, and then determining an answer for yourself, you might instead have a 
conversation with a search bot that has effectively done the reading for you. Companies such as OpenAI, 
Perplexity, and Google are bringing such tools to market: As my colleague Matteo Wong wrote in a recent story for 
The Atlantic, "The generative-AI search wars are in full swing."
As part of his reporting, Matteo spoke with Dmitry Shevelenko, Perplexity's chief business officer. In particular, the 
two discussed the media partnerships that have been signed by Perplexity and other AI firms to support their 
search projects. These deals give media companies compensation for allowing their material to be used by 
generative-AI tools; The Atlantic, for example, has signed a contract with OpenAI that may, among other things, 
show our articles to users of the new SearchGPT tool. (The editorial division of The Atlantic operates independently 
from the business division, which announced its corporate partnership with OpenAI in May.)
I found two of Shevelenko's quotes especially striking. First: "One of the key ingredients for our long-term success 
is that we need web publishers to keep creating great journalism that is loaded up with facts, because you can't 
answer questions well if you don't have accurate source material." And second: "Journalists' content is rich in facts, 
verified knowledge, and that is the utility function it plays to an AI answer engine." Each statement seemed to 
betray an attitude that the creative output of humanity amounts to little more than fodder-which seems particularly 
grim in light of what we know about how AI is trained on tremendous amounts of copyrighted material without 
consent, and how these tools have a tendency to present users with false information. Or as I put it last year: "At its 
core, generative AI cannot distinguish original journalism from any other bit of writing; to the machine, it's all slop 
pushed through the pipes and splattered out the other end."
The AI Search War Has Begun

Page 2 of 2
Generative AI's Slop Era
By Matteo Wong
Every second of every day, people across the world type tens of thousands of queries into Google, adding up to 
trillions of searches a year. Google and a few other search engines are the portal through which several billion 
people navigate the internet. Many of the world's most powerful tech companies, including Google, Microsoft, and 
OpenAI, have recently spotted an opportunity to remake that gateway with generative AI, and they are racing to 
seize it. And as of this week, the generative-AI search wars are in full swing.
Read the full article.
What to Read Next
  
• Bing is a trap: "Tech companies say AI will expand the possibilities of searching the internet. So far, the 
opposite seems to be true," I wrote last year.
P.S.
The future of search bots may depend on recent copyright lawsuits against generative-AI companies. Earlier this 
year, Alex Reisner wrote a great article for The Atlantic exploring what's at stake.
- Damon
Load-Date: August 10, 2024
End of Document
Page 1 of 2
FTAV’s further reading
FTAV’s further reading
 
FT.com
August 8, 2024 Thursday
Copyright 2024 The Financial Times Ltd. All Rights Reserved Please do not cut and paste FT articles and redistribute by email or post to the 
web.
Length: 90 words
Byline: Bryce Elder
Body
Elsewhere on Thursday . . . 
—  The banker has no clothes, part three (Rupak Ghose)
— Sahm: My recession rule was meant to be broken (Bloomberg  $)
—  Intel, the weak link in the chip strategy of Bidenomics (Chartbook) 
—  America’s deficit attention disorder (Project Syndicate)
—  Where Facebook’s AI slop comes from (404 Media)
—  The empathy punishment (Grub Street, New York  $)
—  Artists and Activists Both Have a Role. But Not the Same One (New York Times  $)
—  The bizarre secrets I found investigating corrupt Winamp skins (Jordan Eldredge)
Load-Date: August 8, 2024

Page 2 of 2
FTAV’s further reading
End of Document
Page 1 of 1
FTAV’s further reading
FTAV’s further reading
FT.com Headlines
FT.com Headlines
https://www.ft.com/content/267e8469-bb77-45c6-8dab-b62c6600b4e6
August 8, 2024 Thursday
Length: 99 words
Body
Elsewhere on Thursday . . . — The banker has no cloth...
End of Document

Page 1 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
‘Hold on to your seats’: how much will AI affect the art of film-making?
The Guardian (London)
July 27, 2024 Saturday 10:07 AM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: FILM; Version:1
Length: 2214 words
Byline: Adrian Horton
Highlight: The future is here, whether some like it or not, and artificial intelligence is already impacting the film 
industry. But just how far can, and should, it go?
Body
Last year, Rachel Antell, an archival producer for documentary films, started noticing AI-generated images mixed in 
with authentic photos. There are always holes or limitations in an archive; in one case, film-makers got around a 
shortage of images for a barely photographed 19th-century woman by using AI to generate what looked like old 
photos. Which brought up the question: should they? And if they did, what sort of transparency is required? The 
capability and availability of generative AI – the type that can produce text, images and video – have changed so 
rapidly, and the conversations around it have been so fraught, that film-makers’ ability to use it far outpaces any 
consensus on how.
“We realized it was kind of the wild west, and film-makers without any mal-intent were getting themselves into 
situations where they could be misleading to an audience,” said Antell. “And we thought, what’s needed here is 
some real guidance.”
So Antell and several colleagues formed the Archival Producers Alliance (APA), a volunteer group of about 300 
documentary producers and researchers dedicated to, in part, developing best practices for use of generative AI in 
factual storytelling. “Instead of being, ‘the house is burning, we’ll never have jobs,’ it’s much more based around an 
affirmation of why we got into this in the first place,” said Stephanie Jenkins, a founding APA member. Experienced 
documentary film-makers have “really been wrestling with this”, in part because “there is so much out there about 
AI that is so confusing and so devastating or, alternatively, a lot of snake oil.”
The group, which published an open letter  warning against “forever muddying the historical record” through 
generative AI and released a draft set of guidelines  this spring, is one of the more organized efforts in Hollywood to 
grapple with the ethics of a technology that, for all the bullish or doomsday prophesying, is already here and 
shaping the industry. Short of regulation or relevant union agreements, it has come down to film-makers – directors, 
producers, writers, visual effects and VFX artists and more – to figure out how to use it, where to draw the line and 

Page 2 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
how to adapt. “It’s a project by project basis” for “use cases and the ethical implications of AI”, said Jim Geduldick, a 
VFX supervisor and cinematographer who has worked on Masters of the Air, Disney’s live-action Pinocchio and the 
upcoming Robert Zemeckis film Here , which uses AI to de-age  its stars Tom Hanks and Robin Wright. 
“Everybody’s using it. Everybody’s playing with it.”
Some of the industry’s adoption of AI has been quiet – for years, studios and tech companies with entertainment 
arms have already engaged in a tacit machine learning arms race.  Others have embraced the technology 
enthusiastically and optimistically; Runway, an AI research company , hosted its second annual AI Film Festival  in 
New York and Los Angeles this spring, with presenting partners in the Television Academy and the Tribeca 
Festival. The latter featured five short films made by OpenAI’s Sora , the text-to-video model yet to be released to 
the public that prompted the film mogul Tyler Perry to halt an $800m expansion of his studios  in Atlanta because 
“jobs are going to be lost”.
The industry’s embrace has engendered plenty of pushback. Last month, in response to Tribeca and other nascent 
AI film festivals, the director of Violet, Justine Bateman, announced  a “raw and real”, no-AI-allowed film festival for 
spring 2025, which “creates a tunnel for human artists through the theft-based, job-replacing AI destruction”. And in 
the year since the dual actors and writers’ strikes secured landmark protections against the use of generative AI to 
replace jobs or steal likenesses, numerous non-protected instances of AI have drawn attention and scorn online. 
Concerns about job and quality loss surrounded AI-generated images in A24 promotional posters for the film Civil 
War , interstitials in the horror film Late Night with the Devil  and a fake band poster in True Detective: Night 
Country.  The alleged use of AI-generated archival photos in the Netflix documentary What Jennifer Did  reignited 
discussions about documentary ethics first sparked by similar outcry  over three lines of AI-generated narration  to 
mimic Anthony Bourdain in the 2021 film Roadrunner. And that’s not to mention all of the bemoaning of disposable 
AI filler content  – or “ slop  ”, as the parlance goes – clogging up our social media feeds.
Taken together, the burgeoning use of generative AI in media can feel overwhelming – before the ink is dry on any 
new proclamation about it, the ground has shifted again. On an individual level, film artists are figuring out whether 
to embrace the technology now, how to use it and where their craft is headed. It has already rendered dubbing and 
translation work nearly obsolete.  Visual effects artists, perennially on the bleeding edge of new technology for 
Hollywood, are already working with machine learning and some generative AI, particularly for pre-production 
visualizations and workflows. “From an artist’s perspective, we’re all trying to get ahead of the game and play with 
open source tools that are available,” said Kathryn Brillhart, a cinematographer and director whose credits include 
The Mandalorian, Black Adam and Fallout.
Both Geduldick and Brillhart noted numerous limitations on the use of generative AI in film projects at this point – 
for one, the security of these platforms, especially for big studios worried about leaks or hacks. There’s the legal 
liability and ethics of the current generative AI models, which to date have trained on scraped data. “Some studios 
are like, ‘We don’t even feel comfortable using gen AI in storyboards and concept art, because we don’t want a hint 
of any theft or licensing issues to come through in the final,’” said Brillhart. Studio films that do employ AI have 
limited uses and a clear data trail – in the case of Zemeckis’s Here, the new de-aging and face replacement tech, 
designed by the AI firm Metaphysic and the Hollywood agency CAA, uses the faces of Hanks and Wright, famous 
actors who have signed on to the roles, to play characters over the course of 50 years.  “I’ve always been attracted 
to technology that helps me to tell a story,” Zemeckis said  in 2023 of his decision to use Metaphysic. “With Here, 
the film simply wouldn’t work without our actors seamlessly transforming into younger versions of themselves. 
Metaphysic’s AI tools do exactly that, in ways that were previously impossible!”
And then there’s the output of generative AI, which often plunges deep into the uncanny valley and leaves much to 
be desired. (Or, in the words  of the AI skeptic David Fincher, “it always looks like sort of a low-rent version of 
Roger Deakins”). Geduldick, who has integrated AI into his workflow, sees current generative AI models as more 
“assistive” than truly imitative of human art. “Are they implementing generative models that are going to speed up 
both the business and the creative side of what we’re doing? Yes,” he said. “But I think that there is no generative 
model out there today that doesn’t get touched by artistic hands to get it to the next level. That is for the foreseeable 
future.”
Page 3 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
Still, like the digital revolution before it, the one certainty about generative AI is that it will change the field of visual 
effects – making pre-visualization cheaper and more efficient, streamlining tedious processes, shaping storyboard 
design. As the work shifts, “I think everybody needs to pivot,” said Geduldick.
“The craft has gone from hand-making models to using a mouse to now using text and using your brain in different 
ways,” said Brillhart. “What’s going to happen is more of a forced learning curve,” she added. “I think there’s going 
to be growing pains, for sure.”
On the documentary side, generative AI opens new opportunities for nonfiction storytelling, though also threatens 
trust. “All technology has a kind of a dual moral purpose. And it’s up to us to interrogate the technology to find the 
way to use it for good,” said David France, an investigative journalist and film-maker whose 2020 documentary 
Welcome to Chechnya  is one of a handful in recent years to employ generative AI as an anonymization device. 
The film, which follows the state-sanctioned persecution of LGBTQ+ people in the Russian republic, used AI to map 
actors’ faces over real subjects who faced harrowing violence. France and his team tried several different methods 
to get around risking exposure; nothing worked cinematically, until trying the equivalent of deepfake technology, 
though with multi-step processes of consent and clear limitations. “We realized that we had an opportunity to really 
empower the people whose stories we were telling, to tell their stories directly to the audience and be faithful in their 
kind of emotional presentation,” said France.
The film-makers Reuben Hamlyn and Sophie Compton employed a similar technique for the subjects of their film 
Another Body , who were the victims of nonconsensual, deepfake pornography. Their main subject, “Taylor”, 
communicates through a digital veil – like deepfakes, an AI-generated face that interprets her real expressions 
through different features.
Along with demonstrating the convincing, uncanny power of the technology that someone used to target Taylor, the 
AI translated “every minute facial gesture”, said Hamlyn. “That emotional truth is retained in a way that is impossible 
even with silhouetting.”
“It’s such an important tool in empowering people to share their story,” he added.
Crucially, both Welcome to Chechnya and Another Body clue their audiences to the technology through implicit or 
explicit tells. That’s in line with the best practices put forth by the Archival Producers Alliance, to avoid what has 
landed other films in hot water – namely Roadrunner , whose use of AI was revealed in the New Yorker  after the 
film’s release. The group also encourages documentary film-makers to rely on primary sources whenever possible; 
to think through algorithmic biases produced by the model’s training data; to be as intentional with generative AI as 
they would with re-enactments; and consider how synthetic material, released in the world, could cloud the 
historical record.
“We never say don’t do it,” said Jenkins, the APA member, but instead “think about what you’re saying when you 
use this new material and how it will come across to your audience. There is something really special about the 
human voice and the human face, and you want to engage with [generative AI] in a way that is intentional and 
doesn’t fall into some sort of manipulation.”
That line between human and machine is perhaps the most fraught one in Hollywood at the moment, in flux and 
uncertain. Compton, the co-director of Another Body, sees the emotionally loaded debates around AI as a series of 
smaller, more manageable questions involving pre-existing industry issues. “There are genuinely existential aspects 
of this discussion, but in terms of film and AI, we’re not really talking about those things,” she said. “We’re not 
talking about killer robots. What we are talking about is consent, and what is the dataset that’s being used, and 
whose jobs are on the line if this is adopted massively.”
Geduldick, an optimist on the assistive uses of generative AI, nevertheless sees a gap between its day-to-day 
applications, tech companies’ lofty rhetoric, and “soulless” AI content produced for content’s sake. Companies such 
as OpenAI – whose chief technology officer recently said  generative AI might eliminate some creative jobs, “but 
maybe they shouldn’t have been there in the first place” – have “repeatedly shown in their public-facing interviews 
or marketing that there’s a disconnect [in] understanding what creatives actually do,” he said. “Film-making is a 
Page 4 of 4
‘Hold on to your seats’: how much will AI affect the art of film-making?
collaborative thing. You are hiring loads of talented artists, technicians, craftspeople to come together and create 
this vision that the writers, director, showrunners and producers have thought up.”
For now, according to Geduldick, the “hype outweighs the practical applications” of generative AI, but that does not 
obviate the need for regulation from the top, or for guidelines for those already using it. “The potential for it to be 
cinematic is really great,” said France. “I don’t know yet that we’ve seen anybody solve the ethical problem of how 
to use it.”
In the meantime, film-making, both feature and nonfiction, is at a fluid, amorphous crossroads. Generative AI is 
here – part potential, part application, part daunting, part exciting and, to many, a tool. There will likely be more AI 
film festivals, more backlash, more and more AI content creation – for better or for worse. There are already whole 
AI-generated streaming services , should you choose to generate your own content. How the human element will 
fare remains an open question – according to a recent Deloitte study , a surprising 22% of Americans thought 
generative AI could write more interesting TV shows or movies than people.
The only certainty, at this point, is that AI will be used, and the industry will change as a result. “This will be in films 
that are coming out,” said Jenkins. “So hold on to your seats.”
Load-Date: July 27, 2024
End of Document
Page 1 of 3
AI's Real Hallucination Problem
AI's Real Hallucination Problem
Atlantic Online
July 24, 2024 Wednesday
Copyright 2024 Atlantic Monthly Group, Inc. All Rights Reserved
Length: 1703 words
Byline: Charlie Warzel
Body
Two years ago, OpenAI released the public beta of DALL-E 2, an image-generation tool that immediately signified 
that we'd entered a new technological era. Trained off a huge body of data, DALL-E 2 produced unsettlingly good, 
delightful, and frequently unexpected outputs; my Twitter feed filled up with images derived from prompts such as 
close-up photo of brushing teeth with toothbrush covered with nacho cheese. Suddenly, it seemed as though 
machines could create just about anything in response to simple prompts.
You likely know the story from there: A few months later, ChatGPT arrived, millions of people started using it, the 
student essay was pronounced dead, Web3 entrepreneurs nearly broke their ankles scrambling to pivot their 
companies to AI, and the technology industry was consumed by hype. The generative-AI revolution began in 
earnest.
Where has it gotten us? Although enthusiasts eagerly use the technology to boost productivity and automate 
busywork, the drawbacks are also impossible to ignore. Social networks such as Facebook have been flooded with 
bizarre AI-generated slop images; search engines are floundering, trying to index an internet awash in hastily 
assembled, chatbot-written articles. Generative AI, we know for sure now, has been trained without permission on 
copyrighted media, which makes it all the more galling that the technology is competing against creative people for 
jobs and online attention; a backlash against AI companies scraping the internet for training data is in full swing.
Yet these companies, emboldened by the success of their products and the war chests of investor capital, have 
brushed these problems aside and unapologetically embraced a manifest-destiny attitude toward their technologies. 
Some of these firms are, in no uncertain terms, trying to rewrite the rules of society by doing whatever they can to 
create a godlike superintelligence (also known as artificial general intelligence, or AGI). Others seem more 
interested in using generative AI to build tools that repurpose others' creative work with little to no citation. In recent 
months, leaders within the AI industry are more brazenly expressing a paternalistic attitude about how the future will 
look-including who will win (those who embrace their technology) and who will be left behind (those who do not). 

Page 2 of 3
AI's Real Hallucination Problem
They're not asking us; they're telling us. As the journalist Joss Fong commented recently, "There's an audacity 
crisis happening in California."
There are material concerns to contend with here. It is audacious to massively jeopardize your net-zero climate 
commitment in favor of advancing a technology that has told people to eat rocks, yet Google appears to have done 
just that, according to its latest environmental report. (In an emailed statement, a Google spokesperson, Corina 
Standiford, said that the company remains "dedicated to the sustainability goals we've set," including reaching net-
zero emissions by 2030. According to the report, its emissions grew 13 percent in 2023, in large part because of the 
energy demands of generative AI.) And it is certainly audacious for companies such as Perplexity to use third-party 
tools to harvest information while ignoring long-standing online protocols that prevent websites from being scraped 
and having their content stolen.
But I've found the rhetoric from AI leaders to be especially exasperating. This month, I spoke with OpenAI CEO 
Sam Altman and Thrive Global CEO Arianna Huffington after they announced their intention to build an AI health 
coach. The pair explicitly compared their nonexistent product to the New Deal. (They suggested that their product-
so theoretical, they could not tell me whether it would be an app or not-could quickly become part of the health-care 
system's critical infrastructure.) But this audacity is about more than just grandiose press releases. In an interview 
at Dartmouth College last month, OpenAI's chief technology officer, Mira Murati, discussed AI's effects on labor, 
saying that, as a result of generative AI, "some creative jobs maybe will go away, but maybe they shouldn't have 
been there in the first place." She added later that "strictly repetitive" jobs are also likely on the chopping block. Her 
candor appears emblematic of OpenAI's very mission, which straightforwardly seeks to develop an intelligence 
capable of "turbocharging the global economy." Jobs that can be replaced, her words suggested, aren't just 
unworthy: They should never have existed. In the long arc of technological change, this may be true-human 
operators of elevators, traffic signals, and telephones eventually gave way to automation-but that doesn't mean that 
catastrophic job loss across several industries simultaneously is economically or morally acceptable.
[Read: AI has become a technology of faith]
Along these lines, Altman has said that generative AI will "create entirely new jobs." Other tech boosters have said 
the same. But if you listen closely, their language is cold and unsettling, offering insight into the kinds of labor that 
these people value-and, by extension, the kinds that they don't. Altman has spoken of AGI possibly replacing the 
"the median human" worker's labor-giving the impression that the least exceptional among us might be sacrificed in 
the name of progress.
Even some inside the industry have expressed alarm at those in charge of this technology's future. Last month, 
Leopold Aschenbrenner, a former OpenAI employee, wrote a 165-page essay series warning readers about what's 
being built in San Francisco. "Few have the faintest glimmer of what is about to hit them," Aschenbrenner, who was 
reportedly fired this year for leaking company information, wrote. In Aschenbrenner's reckoning, he and "perhaps a 
few hundred people, most of them in San Francisco and the AI labs," have the "situational awareness" to anticipate 
the future, which will be marked by the arrival of AGI, geopolitical struggle, and radical cultural and economic 
change.
Aschenbrenner's manifesto is a useful document in that it articulates how the architects of this technology see 
themselves: a small group of people bound together by their intellect, skill sets, and fate to help decide the shape of 
the future. Yet to read his treatise is to feel not FOMO, but alienation. The civilizational struggle he depicts bears 
little resemblance to the AI that the rest of us can see. "The fate of the world rests on these people," he writes of the 
Silicon Valley cohort building AI systems. This is not a call to action or a proposal for input; it's a statement of who 
is in charge.
Unlike me, Aschenbrenner believes that a superintelligence is coming, and coming soon. His treatise contains quite 
a bit of grand speculation about the potential for AI models to drastically improve from here. (Skeptics have strongly 
pushed back on this assessment.) But his primary concern is that too few people wield too much power. "I don't 
think it can just be a small clique building this technology," he told me recently when I asked why he wrote the 
treatise.
Page 3 of 3
AI's Real Hallucination Problem
"I felt a sense of responsibility, by having ended up a part of this group, to tell people what they're thinking," he said, 
referring to the leaders at AI companies who believe they're on the cusp of achieving AGI. "And again, they might 
be right or they might be wrong, but people deserve to hear it." In our conversation, I found an unexpected overlap 
between us: Whether you believe that AI executives are delusional or genuinely on the verge of constructing a 
superintelligence, you should be concerned about how much power they've amassed.
Having a class of builders with deep ambitions is part of a healthy, progressive society. Great technologists are, by 
nature, imbued with an audacious spirit to push the bounds of what is possible-and that can be a very good thing for 
humanity indeed. None of this is to say that the technology is useless: AI undoubtedly has transformative potential 
(predicting how proteins foldis a genuine revelation, for example). But audacity can quickly turn into a liability when 
builders become untethered from reality, or when their hubris leads them to believe that it is their right to impose 
their values on the rest of us, in return for building God.
[Read: This is what it looks like when AI eats the world]
An industry is what it produces, and in 2024, these executive pronouncements and brazen actions, taken together, 
are the actual state of the artificial-intelligence industry two years into its latest revolution. The apocalyptic visions, 
the looming nature of superintelligence, and the struggle for the future of humanity-all of these narratives are not 
facts but hypotheticals, however exciting, scary, or plausible.
When you strip all of that away and focus on what's really there and what's really being said, the message is clear: 
These companies wish to be left alone to "scale in peace," a phrase that SSI, a new AI company co-founded by Ilya 
Sutskever, formerly OpenAI's chief scientist, used with no trace of self-awareness in announcing his company's 
mission. ("SSI" stands for "safe superintelligence," of course.) To do that, they'll need to commandeer all creative 
resources-to eminent-domain the entire internet. The stakes demand it. We're to trust that they will build these tools 
safely, implement them responsibly, and share the wealth of their creations. We're to trust their values-about the 
labor that's valuable and the creative pursuits that ought to exist-as they remake the world in their image. We're to 
trust them because they are smart. We're to trust them as they achieve global scale with a technology that they say 
will be among the most disruptive in all of human history. Because they have seen the future, and because history 
has delivered them to this societal hinge point, marrying ambition and talent with just enough raw computing power 
to create God. To deny them this right is reckless, but also futile.
It's possible, then, that generative AI's chief export is not image slop, voice clones, or lorem ipsum chatbot bullshit 
but instead unearned, entitled audacity. Yet another example of AI producing hallucinations-not in the machines, 
but in the people who build them.
Load-Date: July 25, 2024
End of Document
Page 1 of 2
No One Can Believe What Comes Up When You Google Beethoven: 'I'm So Done'
No One Can Believe What Comes Up When You Google Beethoven: 'I'm So 
Done'
Newsweek.com
July 18, 2024 Thursday 11:53 AM EST
Copyright © 2024 Newsweek Inc. All Rights Reserved
Length: 584 words
Byline: Rachael O'Connor
Highlight: One user labeled it "disgusting".
Body
The discovery of what comes up when you Google the composer Ludwig van Beethoven has sparked a huge 
discussion online as people debate the rise of artificial intelligence.
German composer Beethoven died in 1827, but his works, which include Moonlight Sonata, The Emperor Piano 
Concerto, and Für Elise, means he remains one of the most recognizable names in history.
This legendary status is likely contributing to anger around what comes up when you Google his name: rather than 
the famous Joseph Karl Stieler portrait, or any other recognizable portrait of the composer, the image 
accompanying his name is made by artificial intelligence (AI).
The Google discovery was pointed out in a viral post on Reddit by user u/PeopleAreBozos, with the image bearing 
the tell-tale smoothness of AI art, and it racked up 35,000 upvotes as commenters let their frustration be known.
Newsweek ran the image through multiple AI checkers, all of which gave a probability of between 93 to 98 percent 
chance of having been generated by AI.
One user shared the iconic Stieler portrait in the comments of the r/mildlyinfuriating post, asking: "Why on earth 
would anyone need that picture to exist when you have this in public domain?"
"I'm so done with finding AI images when I just want an actual, real image. Especially when having it in AI brings 
absolutely nothing, it's justa slightly worse version of the portrait we already have," another complained.
One simply labeled it "disgusting", and another said "I hate it so much how AI ruined Google images. I can't even 
look at it anymore."

Page 2 of 2
No One Can Believe What Comes Up When You Google Beethoven: 'I'm So Done'
The image also made it to the popular X account Insane Facebook AI Slop, racking up close to 7,000 likes of its 
own, where one commenter despaired, "the internet is actually dying".
It appears the image was originally posted on the website LVBeethoven.com, which describes itself as a "resource 
for everything Beethoven" and features multiple AI-generated images.
It is not an official site for the composer: Beethoven.de is the official site for the Beethoven-Haus museum and 
cultural institution based in Bonn, Germany, where he was born.
Newsweek reached out to LVBeethoven.com for comment.
The controversy of AI-generated art is well-publicized: Shawn Simpson, visiting lecturer in the Department of 
Philosophy at the University of Pittsburgh, wrote in a recent opinion piece forNewsweekthat "AI art is a real 
problem, and we need to make an effort to address it."
He shared the story of a visual artist who had lost a commission after the company generated images themselves 
through the AI program Dall-E, and told the artist they no longer needed their services.
"If we care about keeping human artists employed and producing great works of art, something must be done," he 
wrote, suggesting a ban on at least some AI art or supporting artists through public grants could be an option to 
protect creatives in the future.
Media artist Boris Eldagsen also wrote in an opinion piece for Newsweek where he described how he won a prize in 
a photography competition, using Dall-Eto generate an image.
He stated he came clean to the organizers but was told he could keep the prize. Eldagsen refused to accept the 
award, stating photography and AI should not compete with one another as they are separate entities.
Newsweek has contacted u/PeopleAreBozos on Reddit for comment.
Do you have funny and adorable videos or pictures you want to share? Send them to life@newsweek.com 
with some extra details, and they could appear on our website.
Link to Image
Graphic
 
Beethoven
Getty/ brandstaetter images
The iconic portrait of Ludwig van Beethoven, created in 1820 by German artist Joseph Karl Stieler. It is on display 
at the Beethoven-Haus museum in Bonn, Germany.
Load-Date: July 18, 2024
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 24, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: August 1, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 31, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 876 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his shed more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 18, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 876 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his shed more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 19, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: August 2, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 25, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 22, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 29, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 26, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 30, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 3
We want YOUR gossip!
We want YOUR gossip!
Crikey
July 18, 2024 Thursday 10:11:43 GMT
Copyright 2024 First Digital Media All Rights Reserved
Length: 877 words
Byline: Crikey
Body
ABSTRACT
Crikey is animated by our readership.
FULL TEXT
Crikey has always been in the business of tip-offs, from salacious snippets to serious snipes. Ever since the 
publication's founder Stephen Mayne started Crikey out of his bedroom more than two decades ago, we've been a 
home to important leaks, whether from a serving politician or something overheard down the pub by one of our 
readers.   I’ve long been of the view that the role of Tips and Murmurs editor, which I took up mid-2020, might just 
be the best gig at Crikey. It is a place for small things that point to bigger things, from covering the figures and 
motivations behind the scenes of big stories or political moves, to providing a corrective to lazy political rhetoric, 
illustrating hypocrisy or falsehoods from the people who control the conversation in Australia, or just good old 
fashioned gossip.   The column format allows me access to the planet-sized knowledge of not only my wonderful 
colleagues but also our readership. This allows Tips at its best to be a concentrated version of my favourite parts of 
Crikey -- our willingness to point out what others won't, our long memories, and our preference for acerbic humour 
over solemn earnestness.  As Cam Wilson wrote when detailing our decision to ban AI slop, “From our inception, 
we have been so very Crikey. There are a lot of things that make up Crikeyness, but central is its humanness.” A 
key part of that humanness has always been our readers, the rigour and scepticism they demand of us, and what 
they use their insights and first-hand knowledge to direct our attention to.   In my time writing for Tips and Murmurs, 
readers have alerted us to some of my favourite things we’ve covered, including: 
• David Marr, the ABC's new host of Late Night Live, calling Bundjalung woman and renowned author 
Melissa Lucashenko "f**king rude" backstage at a Sydney Writers' Festival event
• Plumbers at Holt St messing with Daily Telegraph editor in chief Col Allan, who had been pissing in his 
office sink

Page 2 of 3
We want YOUR gossip!
•The Australian's Gerard Henderson offering Crikey a very lengthy response to one of our questions that 
we deemed it fine enough to eat off of
• The documents revealing the early meetings between then PM Scott Morrison and then US secretary of 
state Mike Pompeo;
• The incredible amount of “woke” money that was helping fund the campaign against an Indigenous Voice 
to Parliament;
• The strange case of the bag of weed someone tried to send Scott Morrison shortly after he lost the 
election;
• The early poetry of Andrew Bolt;
• Then energy minister Angus Taylor barricading himself in the ironically named “media room” to avoid 
questions after his first speech in that portfolio;
• The most cringe-inducingly awful International Women’s Day events, a tradition we’ve returned to several 
times, along with the general trend of corporations' tone-deaf attempts to profit from social justice 
movements;
• The fact that trucking billionaire Lindsay Fox, who had just thrown a men-only birthday bash, was hiring a 
diversity officer;
• The multi-volume "spiv-tionary", where readers helped us decode the euphemist language of "high-level 
dodginess";
• The extremely bipartisan tendency of government departments to advertise government policy; 
 And so much more.   Put in proper context, these items, whether what they reveal is funny or absurd or infuriating, 
tell us something about how power is exercised in Australian politics, business and media. Crikey is always aiming 
to do that, and Tips is where we get to have the most fun doing it (after all, in what other role would I be allowed to 
describe an elected official as “a man who calls to mind a kind of Freaky Friday body switch between a small town 
mayor and a Year 12 student who wears a blazer on free dress days”?)   We love this stuff, and we want more of it.  
Crikey’s readers are our greatest resource -- you’re literally why we get up in the morning, why we do what we do, 
how we do it. All publications are ultimately animated by their readership, and your bullshit- detectors, irreverence 
and interest in context have sculpted us over the years as surely as a river shapes a stone.  So if you’ve noticed 
something -- something dodgy-seeming, something hilarious or deeply ironic, something which you suspect 
someone in power would rather not be pointed out -- please, let us know, either via boss@crikey.com.au or via our 
anonymous Tips inbox. We can't wait to hear from you.  Please note, when contacting us, we recommend that you: 
• Use a secure computer to communicate with us — one that is not managed by your employer and does not 
have any malware that might be used to record your activities;
• Make sure the computer you use is not in front of any public surveillance cameras;
• When using a computer, use an operating system and browser that helps preserve your privacy and 
anonymity;
• Delete trails of communication that you store on your computer, such as copies of messages;
• Run any files you send to us through a metadata-scrubbing tool to minimise the risk of unintentionally 
sending us information embedded in the documents, such as an author’s name.
Got a tip?Crikey’s readers are our greatest resource. If you know something, you can contact us anonymously 
and securely by clicking here. 
Load-Date: July 23, 2024
Page 3 of 3
We want YOUR gossip!
End of Document
Page 1 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
Newstex Blogs 
JD Supra
July 12, 2024 Friday 10:27 AM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 JD Supra 
Length: 2155 words
Byline: EDRM - Electronic Discovery Reference ModelSheila Grela
Body
July 12th, 2024 ( JD Supra  - Delivered by  Newstex )
Image: Sheila Grela with AI.
Introduction
As the granddaughter of two Alabama farmers, the word 'slop' evokes images of something with little value. In 
today's digital landscape, avoiding AI-generated content is nearly impossible, akin to dodging spoilers online. From 
AI-enhanced Google searches to AI-written articles and AI-composed music, artificial intelligence permeates every 
corner of the internet. This surge in AI content echoes the Dead Internet Theory, which posits that a significant 
portion of online activity is generated by bots rather than humans. The concern is that the internet may become a 
digital trough filled with 'slop,' where valuable content is lost amid low-quality AI-generated material.
Meet 'Slop'
'Slop' is the term for AI-generated content created primarily for profit. Similar to spam, slop is low-quality material 
that floods the web to generate ad revenue. Like spam and trolls, slop is another time-waster clogging digital feeds 
with irrelevant, unhelpful content. Examples include clickbait articles with misleading titles leading to shallow 
content filled with ads or poorly written blog posts stuffed with keywords to manipulate search engine rankings. 
These are classic examples of 'slop.'
'Slop' is the term for AI-generated content created primarily for profit. Similar to spam, slop is low-quality material 
that floods the web to generate ad revenue. Like spam and trolls, slop is another time-waster clogging digital feeds 
with irrelevant, unhelpful content.
Sheila Grela.
What is AI-Generated Slop?

Page 2 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
'Slop' encompasses various AI-generated content-text and images-designed to flood the internet with low-quality 
material. This content aims to pull in ad revenue and manipulate search engine rankings. Unlike the interactive 
nature of chatbots, slop is static, often misleading, and essentially digital clutter. It is cheap to produce, and even 
minimal clicks can make it profitable. However, not all promotional content is spam, and not all AI-generated 
content is slop. Thoughtlessly produced content imposed on unsuspecting users can be aptly described as 'slop.' 
For instance, automated news articles that repeat the same information with little context or analysis fall into this 
category.
How to Discern High-Quality Content from 'Slop'
Navigating the vast ocean of online content can be challenging, especially with the rise of AI-generated 'slop.' Here 
are some tips to help you distinguish high-quality content from digital clutter:
Check the Source
Reputable Publishers: Look for content from well-known, reputable sources such as established news outlets, 
academic journals, and official organizational websites. For example, articles from The New York Times or studies 
published in The Lancet are more likely to be reliable.
Author Credentials: Verify the credentials of the author. Are they an expert in the field? Do they have a history of 
reliable publications? Checking the author's LinkedIn profile or previous work can provide insights into their 
expertise.
Look for Detailed References and Citations
Citations: High-quality content typically includes references and citations to support its claims. Check if the article 
links to credible sources or provides a bibliography.
External Links: Follow the links to see if they lead to reputable websites or primary sources. For instance, an article 
on health should link to studies from medical journals or government health websites, not random blogs.
Evaluate the Writing Quality
Grammar and Style: Poor grammar, awkward phrasing, and inconsistent style can indicate low-quality, hastily 
generated content. High-quality articles are typically well-edited and free of such errors.
Depth of Analysis: Good content provides in-depth analysis, context, and multiple perspectives rather than 
superficial information. Look for detailed explanations and balanced viewpoints.
Analyze the Purpose and Tone
Objective vs. Promotional: Determine whether the content aims to inform or has a hidden agenda, such as selling a 
product or service. For example, an objective article will present facts and research, while a promotional piece 
might overly praise a product without much evidence.
Neutral Tone: High-quality content maintains a neutral, objective tone and avoids sensationalism. Watch out for 
exaggerated claims or emotional language that can indicate bias.
Cross-Check Information
Multiple Sources: Verify the information by checking multiple sources. Consistency across reputable sources can 
indicate reliability. If several trustworthy websites report the same facts, the information is likely accurate.
Fact-Checking Websites: Use fact-checking websites like Snopes, FactCheck.org, or PolitiFact to verify 
controversial claims. These sites often debunk false information and provide reliable facts.
Check for AI Hallmarks
Page 3 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
Repetition and Redundancy: AI-generated content often contains repetitive phrases and redundant information. If 
an article keeps repeating the same points, it might be AI-generated.
Lack of Depth: AI content may provide general information but lack the depth and nuance found in expert human 
writing. Look for detailed analysis and insights.
Static Content: Unlike interactive and responsive human-written content, AI-generated 'slop' tends to be static and 
non-engaging. High-quality articles often invite reader interaction through comments or discussion.
Look for Visual and Structural Clues
Layout and Design: Professionally designed content usually features a good layout; and proper use of headings, 
images, and other multimedia elements. Slop often lacks these features and may appear cluttered or poorly 
formatted.
Advertisements: Excessive ads and pop-ups can indicate that the primary goal of the content is monetization rather 
than providing valuable information. High-quality sites typically have fewer ads and more focus on content.
Test for Engagement and Interactivity
Comments and Discussions: High-quality content often sparks discussions and thoughtful comments from readers. 
Look for active engagement and meaningful exchanges. A lively comment section can indicate that the content is 
resonating with readers.
Updates: Reliable sources frequently update their content to reflect new information and developments. Check if the 
article has been updated recently to include the latest data.
By being vigilant and applying these strategies, you can better navigate the digital landscape and avoid falling for 
AI-generated 'slop.' Always prioritize confirmed human information and critical thinking to ensure your digital 
interactions are based on accurate, reliable, and valuable content.
Why Confirmed Human Information Needs to Take Precedence
As a paralegal, I can attest that confirmed human information must take precedence. Douglas Adams aptly said, 
'We are stuck with technology when what we really want is just stuff that works.' While AI can generate content 
quickly, it lacks the nuance, empathy, and critical thinking that only humans can provide. Human input ensures that 
information is accurate, reliable, and meaningful.
AI-generated content, with its potential for errors and lack of accountability, can mislead us. This is particularly 
dangerous in critical areas like legal advice, medical information, and financial guidance. Human expertise comes 
with a responsibility and a level of scrutiny that AI cannot match.
As a paralegal, I can attest that confirmed human information must take precedence. Douglas Adams aptly said, 
'We are stuck with technology when what we really want is just stuff that works.' While AI can generate content 
quickly, it lacks the nuance, empathy, and critical thinking that only humans can provide. Human input ensures that 
information is accurate, reliable, and meaningful.
Sheila Grela.
Real-World Examples and Potential Risks
Misleading Legal Advice
Legal advice and strategy are inherently complex and require the expertise of a competent attorney. AI-generated 
legal advice websites can provide misleading or incorrect guidance on critical legal matters, such as filing deadlines 
and legal procedures. This misinformation can lead to missed court dates and adverse legal outcomes, potentially 
Page 4 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
causing significant harm. For example, an AI tool might incorrectly calculate a filing deadline, leading to missed 
opportunities for legal action. Consulting a qualified human attorney for legal matters is essential.
Health Risks from AI Content
AI-powered apps offering lifestyle and health recommendations can sometimes provide dangerous advice. For 
instance, an AI might suggest unsafe exercise routines or dietary changes without considering individual health 
conditions, leading to potential injuries or health issues. This lack of personalized context and understanding poses 
serious risks to users.
Financial Misinformation
AI-generated articles and financial reports can cause significant monetary losses. For example, an AI-authored 
article might provide inaccurate stock information, recommending investments in companies with poor financial 
health. Investors following this advice could suffer substantial financial losses, underscoring the dangers of relying 
on AI for critical financial decisions. In one notable case, AI-generated stock analysis led to a surge in investments 
in a failing company, causing widespread financial losses.
Statistics Highlighting the Issue
Content Volume: According to a 2023 study by the University of California, 40% of web content is now generated by 
AI. This influx of AI-generated material contributes to the digital clutter we experience today.
User Trust: A 2022 survey by Pew Research found that 60% of internet users have encountered misleading or false 
information online. Of these, 45% reported that the misleading information was AI-generated.
Economic Impact: The economic model behind AI-generated slop is straightforward: a study by the Digital 
Marketing Institute found that producing AI content costs up to 80% less than human-generated content, making it 
an attractive option for content farms and low-budget operations.
Why Human-Confirmed Information Matters
When we need genuine insights, thoughtful analysis, or reliable data, turning to humans is essential. Confirmed 
human information brings wisdom, context, and integrity-qualities that are crucial for making informed decisions and 
maintaining trust in the digital age. No AI can replace the accuracy and depth that comes from human experience 
and knowledge. The lack of wit, humor, and empathy can make facts boring and forgettable.
As William Pollard wisely noted, 'Information is a source of learning. But unless it is organized, processed, and 
available to the right people in a format for decision making, it is a burden, not a benefit.'
This emphasizes the importance of confirmed, reliable information over sheer volume.
Similarly, Atul Gawande pointed out, 'Better is possible. It does not take genius. It takes diligence. It takes moral 
clarity. It takes ingenuity. And above all, it takes a willingness to try.'
This rings true when considering the need for high-quality, human-verified information.
Garry Kasparov observed, 'AI may be able to process vast amounts of data, but it lacks the ability to make 
judgments and decisions with the same depth and ethical considerations as humans.'
This highlights the critical need for human oversight in evaluating and using information.
Neil Gaiman hit the nail on the head: 'Google can bring you back 100,000 answers. A librarian can bring you back 
the right one.'
Prioritizing confirmed human information is more important than ever. It is the key to ensuring that our digital 
interactions remain trustworthy, insightful, and truly beneficial.
Page 5 of 5
The New Term 'Slop' Joins 'Spam' in Our Vocabulary
Conclusion
While AI-generated slop might flood the digital landscape, the value of human input remains irreplaceable. As we 
navigate through this AI-driven world, let us remember to prioritize the wisdom and reliability that only human minds 
can offer. By doing so, we can ensure that our digital interactions are based on accurate, reliable, and valuable 
content, keeping the essence of human touch alive in the age of artificial intelligence.
Searching through the vast sea of data on the internet can feel like trying to find a needle in a haystack-while 
blindfolded. Even with the advent of generative AI, distinguishing valuable information from the irrelevant noise 
remains a significant challenge. In this sprawling digital landscape, we need strategies that make navigating the 
vast ocean of information more manageable and insightful. Moreover, there is a pressing need for innovative 
solutions to filter out low-quality content, akin to how we handle spam.
Can generative AI offer any bright ideas on how to clean up the digital clutter it helps generate? From advanced 
algorithms to smarter filters, exploring these possibilities could revolutionize how we access and utilize online 
information.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: July 12, 2024
End of Document
Page 1 of 2
Spam evolves with AI: What is "Slop"?
Spam evolves with AI: What is "Slop"?
CE Noticias Financieras English
July 11, 2024 Thursday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 CE Noticias Financieras All Rights Reserved
Length: 601 words
Body
Headless articles that only create disinformation, memes and meaningless images that flood social networks, eye-
catching headlines, but without reliable content that fill the "timelines" of cybernauts. Artificial intelligence has 
opened the door to a new era of creativity and automation, but also to a new type of digital garbage, the "Slop", the 
evolution of "Spam", one of the evils that appeared with the rise of the Internet.
The "Slop" can be translated as garbage or 'slop' and refers to the content created automatically by generative AI 
tools in an automated way, without human labor or supervision, which only aims to monetize in some way.
As with Spam , these undesirable contents are programmed and created for the simple purpose of generating traffic 
or being monetized, which encourages their mass production with the help of generative AI, which facilitates the 
task of generating texts or images on an industrial scale, although their quality and usefulness are null.
Specialized technology media cite some examples, such as tourist articles that recommend visiting slums or 
unimportant sites in cities, books published in Amazon of zero quality or meaningless viral memes on Facebook or 
X.
These contents are often ridiculous and harmless, although annoying because of their persistence, generating 
waste of time and frustration among cybernauts, since they force them to navigate among dozens of useless pages 
and reduce trust in legitimate contents.
Simon Willison, a developer credited with being one of the first to use the word "slop" indicates that it is crucial to 
recognize and label this threat. "The term spam helped to understand and combat spam. Defining slop can raise 
awareness of the dangers of unsupervised AI," he warns.
The expert warns that, today, there are not too many tools to detect this type of articles. However, he believes that, 
over time, it will be possible to put a stop to it in the same way as spam.
However, while AI has the potential to change the lives of mankind, there are also those who seek to exploit it for 
illicit purposes. In fact, it is becoming increasingly common to find news of deepfakes circulating on the networks. It 
is even used to perfect the wording of phishing emails and to spread hoaxes.
Marcelo Pacheco, director of the Systems Engineering program at the Franz Tamayo University, Unifranz, says 
that, as with any technological tool, AI can be used for both good and evil, i.e. its uses can be beneficial for 
humanity, but also harmful.

Page 2 of 2
Spam evolves with AI: What is "Slop"?
 Unifranz 
"It is possible to use artificial intelligence for a multitude of things, from making our lives easier to extortion, because 
AI is not inherently good or bad, it is what we do with it," he says.
For his part, systems engineer Sergio Valenzuela, professor of systems engineering at Unifranz, says it is important 
to understand the duality of the human being, who can be capable of great good as well as great evil, so ethics 
must always go hand in hand with advances, as this way risks can be reduced.
"AI is not inherently good or bad, however, it is important that its development is guided by ethical principles and 
that it avoids harming society through its use," he notes.
Given this reality, experts invite cybernauts to contrast the information they are reading if there is the slightest 
suspicion that it has been generated with AI. They also point out that the only viable solution is to force the labeling 
of content produced by this technology so that users know the truth. A system that Meta is trying to implement on 
Facebook and Instagram, although without the expected success.
?       
Load-Date: July 12, 2024
End of Document
Page 1 of 2
Dead tech blog now publishing using AI with old bylines
Dead tech blog now publishing using AI with old bylines
Newstex Blogs 
Talking Biz News
July 11, 2024 Thursday 8:51 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 Talking Biz News
Length: 248 words
Body
July 11th, 2024 (Talking Biz News — Delivered by Newstex)
The Unofficial Apple Weblog, a legendary and long-dead Apple-centric tech news blog, is publishing new content 
using artificial intelligence and the bylines of former journalists, reports Jason Koebler of 404 Media.
Koebler reports, 'This month, 'Christina Warren' started blogging again for The Unofficial Apple Weblog (TUAW), a 
legendary and long-dead Apple-centric tech news blog that she worked at more than a decade ago. Warren was for 
years a well-known and very good tech journalist, before she went on to work for Microsoft and GitHub. The real 
Christina Warren hasn't been writing these new posts on the zombie TUAW, however. The site's new owners have 
stolen her identity, replaced her photo with an AI-generated one, and have been publishing what appear to be AI-
generated articles under her byline.
'Worse, the new version of TUAW has 'recreated' the archives of the site by running old, real articles through a 
summarization tool and then republishing new, 'bastardized versions' of the old articles under the bylines of real 
writers who didn't actually write them, Warren said. The names and bios of dozens of real journalists who actually 
worked for TUAW a decade ago are listed on the website, and all of them have had their real images replaced with 
AI-generated ones, and their old work misattributed to other people and turned into AI slop by a summarization tool 
that has destroyed their original work.'
Read more here.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 

Page 2 of 2
Dead tech blog now publishing using AI with old bylines
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: July 12, 2024
End of Document
Page 1 of 2
TUAW makes a sad return as an AI-powered stolen content farm
TUAW makes a sad return as an AI-powered stolen content farm
Newstex Blogs 
9to5Mac
July 10, 2024 Wednesday 12:04 PM EST
Delivered by Newstex LLC. All Rights Reserved
Copyright 2024 9to5Mac
Length: 377 words
Body
July 10th, 2024 (9to5Mac — Delivered by Newstex)
The Unofficial Apple Weblog, more commonly referred to as TUAW, has made a return from the dead, almost a 
decade after it was closed down. Unfortunately, that's not a good thing 
TUAW launched in 2004, and was once a popular source of Apple content. It was owned by AOL, and closed down 
in 2015 when the corporation decided to pull resources from its smaller web publications to focus on the bigger 
ones. The  archives were  folded into Engadget.
The domain was acquired by Yahoo, which recently sold it - without any rights to the content - to a company called 
Web Orange Limited (WOL). This is when things get messy.
Former contributor Christina Warren found that the company had seemingly come up with a cheap plan to 
repopulate it with content: just get an AI to rewrite some junk, and steal the identities of the original writers.
So someone bought the TUAW domain, populated it with AI-generated slop, and then reused my name from a job I 
had when I was 21 years old to try to pull some SEO scam that won't even work in 2024 because Google changed 
its algo. Assholes! H/t @gruber  pic.twitter.com/1JQeNljarT— Christina Warren (@film_girl) 
July 9, 2024
Some of the content was stolen from the TUAW archives, and some from current Apple sites.
Having been called out by Warren, the company simply changed her name.
Engadget reports that WOL seems to think all this is just fine.
'With a commitment to revitalize its legacy, the new team at Web Orange Limited meticulously rewrote the content 
from archived versions available on archive.org, ensuring the preservation of TUAW's rich history while updating it 
to meet modern standards and relevance,' the site's about page states.

Page 2 of 2
TUAW makes a sad return as an AI-powered stolen content farm
TUAW doesn't say if AI was used in those 'rewrites,' but a comparison between the original archive on Engadget 
and the 'rewritten' content on TUAW suggests that Web Orange Limited put little effort into the task. 'The article 
'rewrites' aren't even assigned to the correct names,' Warren tells Engadget, 'It has stuff for me going back to 2004. 
I didn't start writing for the site until 2007.'
The company didn't respond to a request for a comment.
Photo by Andrea De Santis on  Unsplash 
FTC: We use income earning auto affiliate links. More.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: July 10, 2024
End of Document
Page 1 of 2
Google Searches Prefer AI Spam to Real Content
Google Searches Prefer AI Spam to Real Content
Inc.com
July 3, 2024 Wednesday 12:38 PM EST
Copyright 2024 Mansueto Ventures, LLC All Rights Reserved
Length: 709 words
Byline: Kit Eaton
Body
Search engine optimization is the holy grail to boost traffic to websites--but in the AI era, even Google's much-
scrutinized search algorithm shows a preference for ripped-off, AI-generated material over original content.
The rise of AI-generated spam articles, now dubbed "AI slop," prompted Google to take steps to contain the 
influence of this junk material influencing its search results. But a recent report in Wiredshows that either 
Google's policy changes made earlier this year didn't go far enough--or AI-generated content producers have 
already found workarounds--because some AI-tweaked spam news stories ripped off from the original publishers 
were found to be ranking above the genuine news articles.
Wired's investigation into the phenomenon involved its own content, and its report first looked into where these AI-
faked articles were being published. It found that plagiarized Wired articles were being republished on some 
spammy AI-generated websites, and showing up higher in Google's search results than the originals. The AI slop 
pieces used whole quotes from the original articles and some included AI-generated artwork. However the 
unauthorized content was generated, the spammer was thorough--the plagiarized content also included Wired 
articles that the magazine had published in 10 languages other than English. News articles ripped from other sites, 
like Reuters and TechCrunch, were also published, with similar AI-generated imagery on top.
Explaining its campaign against AI-made spam in March, Google's blog post said the search engine was 
"enhancing Search so you see more useful information, and fewer results that feel made for search engines." It said 
it expected to reduce the appearance of "low-quality, unoriginal content" in search results by 40 percent. A late April 
update to the post said Google had actually seen a drop of 45 percent instead. The post also directly mentioned 
spam, noting Google was making "several updates" to spam policies to "better address new and evolving abusive 
practices that lead to unoriginal, low-quality content."
The problem is that rising AI technology is making it really easy for ill-intentioned people to easily "scrape" content 
that is someone else's legal intellectual property, tweak it and republish it. And somehow, this low-quality, AI-
generated material still seems to be getting past Google's filters and affecting the ranking of genuine news articles 
on the site. It's a game of whack-a-mole, of course, just like hacking: when bad actors are prevented from doing 
one activity, they try something new, which then gets blocked by an algorithm change or other tweak, but the 
process just repeats itself without a permanent fix.

Page 2 of 2
Google Searches Prefer AI Spam to Real Content
When Google adjusts its algorithms, it often changes search results that affect businesses that rely on traffic from 
Google to attract customers and help generate online revenue. While Wired is obviously concerned about how its 
published news pieces are affected, AI-made spam could easily impact other industries. 
News that AI slop is displacing genuine human-generated content is especially concerning in light of Google's 
recent decision to retire the infinite scroll it has long used to display search results. The world's dominant search 
engine is instead returning to an earlier system that displays search results on a number of separate numbered 
webpages. This change already concerns some web-centered businesses, since opening a search result would 
require extra clicks, which could be a barrier to traffic in the short attention span habits of many web users. And if 
your business appears in search results that are listed "below the fold," on pages beyond the first set of results, it's 
a genuine source of worry: the search preference for AI spam may be pushing legitimate results off the page.
How this affects your company depends on exactly how you generate income, how much reliant your business is on 
search traffic, and how good your current search engine optimization skills are. But it's an excellent reminder to 
double check with your web team to ensure they're on top of all the latest SEO trends, and that they're looking for 
possible AI-generated slop that might even have been grabbed from your own company content.
Link to Image
Graphic
 
Photos: Getty Images
Load-Date: July 3, 2024
End of Document
Page 1 of 2
Thousands of Raptive creators push to hold AI companies accountable
Thousands of Raptive creators push to hold AI companies accountable
Newstex Blogs 
Android Headlines
June 27, 2024 Thursday 4:18 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 Android Headlines 
Length: 586 words
Byline: Arthur Brown
Body
June 27th, 2024 ( Android Headlines  - Delivered by  Newstex )
We're at a point where we're starting to see the negative effects of  AI technology despite what CEOs of AI 
companies tell us in keynotes. Creators stand to lose significantly thanks to AI, and this is why they're banding 
together. Thousands of Raptive creators band together to urge Congress to hold AI companies accountable.
It doesn't take a rocket scientist to know what sort of effects AI technology will have on the creator economy. We're 
already seeing creators being let go from their jobs because their employers chose to replace them with an AI 
model. As these AI tools get better, more people are going to lose their jobs. Writers, artists, musicians, filmmakers, 
actors, voice actors, etc. will all need to either abandon their lifelong passions or sell out and mass-produce soul-
less AI slop to please money-hungry corporations. There are very few other avenues to take.
Thousands of Raptive creators want AI companies to be held accountable
The American has been hard at work trying to pull some AI regulations out of the ether, but not much has 
materialized. However, other entities are out fighting the good fight while the government waits for the ink to dry.
For example, several major record labels are suing the companies behind two AI music generators for copyright 
infringement. This is one of the many lawsuits going on right now.
Raptive is a company representing thousands of independent creators. It's paid out more than $2 billion to creators, 
and that number is going up. Raptive also acknowledges the threat of AI technology.
The company,  backed by more than 13,000 creators from across the U.S. has urged Congress to hold major AI 
companies accountable for their actions. According to PR Newswire, the creator economy is valued at $100 billion, 
and it could nearly double in the next three years. However, with AI companies shoving AI tools down our throats, 
we fear that the creator economy could crumble.
Requests

Page 2 of 2
Thousands of Raptive creators push to hold AI companies accountable
Raptive and the creators  have a handful of requests. Firstly, they want to enforce copyright law to protect original 
content from being scraped without consent. Secondly, they want a form of revenue-sharing structure in place so 
that creators are properly compensated for their work.Thirdly, AI tools shouldn't reduce the traffic going to creators' 
websites. Tools like these (a good example is Google's AI Overviews) can cut a company's ad revenue 
significantly.
Fourthly, future AI products shouldn't be able to unfairly compete against creators. This is pretty tricky, as this is 
what they're doing now. 'Why hire an artist to spend three hours on a painting when MidJourney can whip it up in 30 
seconds?' These are the questions that companies are asking. So, we're going to have to see what the government 
makes of that request. Lastly, the government needs to ensure that these AI companies are being held accountable 
for their behavior.
We're talking about major corporations here; they're about as ethical as a desert is wet. There need to be some 
rules, guidelines, and the threat of MAJOR FINES to keep companies in line. OpenAI, Alphabet, and Meta 
contacted Hollywood studios about their AI products. HOLLYWOOD STUDIOS! So, not even industry-level jobs are 
safe from AI. We need something to keep these companies from completely ruining the entire creator economy.
The post  Thousands of Raptive creators push to hold AI companies accountable appeared first on Android 
Headlines.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: June 27, 2024
End of Document
Page 1 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy 
AI Blog Posts
Forbes.com
June 26, 2024 Wednesday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1919 words
Byline: Rashi Shrivastava, Forbes Staff
Highlight: As Perplexity faces criticism for allegedly plagiarizing journalistic work and distributing it like a media 
company, it is increasingly citing AI-generated blogs and LinkedIn posts riddled with inaccurate and out of date 
information.
Body
<figure>
<figcaption>
In April, Aravind Srinivas, CEO of AI search startup Perplexity told Forbes, "Citations are our currency." Now, it's 
increasingly citing AI-generated blog posts on a wide variety of topics.
Christie Hemm Klok for Forbes
</figcaption></figure>
AI search engine Perplexity claims to be different from other generative AI tools like ChatGPT. Instead of 
regurgitating data without including any sources, it marks up its short summaries on any topic you want with 
footnotes that are supposed to link to recent and reliable sources of real-time information drawn from the internet.  
Citations are our currency,  CEO Aravind Srinivas toldForbes in April.
But even as the startup has comeunder firefor republishing the work of journalists without proper 
attribution,Forbeshas learned that Perplexity is also citing as authoritative sources AI-generated blogs that contain 
inaccurate, out of date and sometimes contradictory information.
According to astudyconducted by AI content detection platform GPTZero, Perplexity s search engine is drawing 
information from and citing AI-generated posts on a wide variety of topics including travel, sports, food, technology 
and politics. The study determined if a source was AI-generated by running it through GPTZero s AI detection 
software, which provides an estimation of how likely a piece of writing was written with AI with a 97% accuracy rate; 
for the study, sources were only considered AI-generated if GPTZero determined with at least 95% certainty that 
they were written with AI (Forbesran them through an additional AI detection tool called DetectGPT which has a 
99% accuracy rate to confirm GPTZero s assessment).

Page 2 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
On average, Perplexity users only need to enter three prompts before they encounter an AI-generated source, 
according to the study, in which over 100 prompts were tested.
 Perplexity is only as good as its sources,  GPTZero CEO Edward Tian said.  If the sources are AI hallucinations, 
then the output is too. 
Searches like  cultural festivals in Kyoto, Japan,  "impact of AI on the healthcare industry,"  street food must-tries in 
Bangkok Thailand,  and  promising young tennis players to watch,  returned answers that cited AI-generated 
materials. In one example, a search for  cultural festival in Kyoto, Japan  on Perplexity yielded a summary in which 
the only reference was for anAI-generated LinkedIn post. In another travel-related search for Vietnam s floating 
markets, Perplexity s response, which cited an AI-generated blog, included out-of-date information, the study found.
  Perplexity is only as good as its sources. If the sources are AI hallucinations, then the output is too.   
<footer>GPTZero cofounder and CEO Edward Tian</footer>
Perplexity Chief Business Office Dmitri Shevelenko said in an email statement toForbesthat its system is  not 
flawless  and that it continuously improves its search engine by refining the processes that identify relevant and 
high quality sources. Perplexity classifies sources as authoritative by assigning  trust scores  to different domains 
and their content. Its algorithms downrank and exclude websites that contain large amounts of spam, he said. For 
instance, posts by Microsoft and Databricks are prioritized in search results over others, Shevelenko said.
 As part of this process, we've developed our own internal algorithms to detect if content is AI-generated. As with 
other detectors, these systems are not perfect and need to be continually refined, especially as AI-generated 
content becomes more sophisticated,  he said.
As AI-generated slop gluts the internet, it becomes more challenging to distinguish between authentic and fake 
content. And increasingly these synthetic posts are trickling into the products that rely on web sources, bringing with 
them the inconsistencies or inaccuracies they contain, resulting in  second-hand hallucinations,  Tian said.
 It doesn't take 50% of the internet being AI to start creating this AI echo chamber,  he toldForbes. 
In multiple scenarios, Perplexity relied on AI-generated blog posts, among other seemingly authentic sources, to 
provide health information. For instance, when Perplexity was prompted to provide  some alternatives to penicillin 
for treating bacterial infections,  it directly cited an AI-generated blog by a medical clinic that calls itself Penn 
Medicine Becker ENT & Allergy. (According toGPTZero, it s 100% likely that the blog is AI-generated. DetectGPT 
said there is a 94% chance it is fake.)
Such data sources are far from trustworthy because they sometimes offer conflicting information. The AI-generated 
blog mentions that antibiotics like cephalosporins can be used as an alternative to penicillin for those who are 
allergic to it, but a few sentences later the post contradicts itself by saying  those with a penicillin allergy should 
avoid cephalosporins.  Such contradictions were also reflected in answers generated by Perplexity s AI system, 
Tian said. The chatbot did, however, suggest consulting a specialist for the safest alternative antibiotic.
Got a tip for us? Reach out securely to Rashi Shrivastava at rshrivastava@forbes.com or rashis.17 on Signal.
Penn Medicine Becker ENT & Allergy customer service representatives redirectedForbesto Penn Medicine. But in 
response toForbes  questions about why the clinic was using AI to generate blogs that gave medical advice, Penn 
Medicine spokesperson Holly Auer said the specialty physician s website was not managed by Penn Medicine and 
that  accuracy and editorial integrity are key standards for all web content associated with our brand, and we will 
investigate this content and take action as needed.  It s unclear who manages the website.
Shevelenko said that the study s examples do not provide  a comprehensive evaluation  of the sources cited by 
Perplexity but he declined to share data about the types of sources that are cited by the system.
Page 3 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
 The reality is that it depends heavily on the types of queries users are asking and their location,  he said.  
Someone in Japan asking about the best TV to purchase will yield a very different source set from someone in the 
U.S. asking about which running shoes to buy. 
Perplexity has also stumbled in its handling of authoritative sources of information. The billion dollar startup recently 
came under scrutiny for allegations of plagiarizing journalistic work from multiple news outlets includingForbes, 
CNBC and Bloomberg. Earlier this month,found Perplexity had lifted sentences, crucial details and custom art from 
an exclusiveForbesstory aboutEric Schmidt s secretive AI drone projectwithout proper attribution. The company 
recreated theForbesstory across multiple media, in an article, podcast and YouTube video, and pushed it out 
aggressively to its users with a direct push notification.
 Perplexity represents the inflection point that our AI progress now faces  in the hands of the likes of Srinivas   who 
has the reputation as being great at the PhD tech stuff and less-than-great at the basic human stuff   amorality 
poses existential risk,  Forbes Chief Content Officer Randall Lanewrote. Forbes sent a cease and desist letter to 
Perplexity, accusing the startup of copyright infringement. In response, Perplexity s CEO Srinivas denied the 
allegations, arguing that facts cannot be plagiarized, and said that the company has not   rewritten,   redistributed,   
republished,  or otherwise inappropriately usedForbescontent. 
The GPTZero study noted that a Perplexity search for  Eric Schmidt s AI combat drones,  one of the  pre-
recommended  search topics that sits on Perplexity s landing page, also used ablog post that was written with AI as 
one of its sources. (GPTZero found that there was a 98% chance the blog was AI-generated while DetectGPT said 
it was 99% confident.)
  When you use such references, it's much easier to promote disinformation even if there is no intention to do 
so.     <footer>Zak Shumaylov, machine learning researcher at the University of Cambridge.</footer>
Ainvestigation found that through a secret IP address, the startup had also accessed and scraped work fromWired 
and other publications owned by media companyCondé Nast,even though its engineers had attempted to block 
Perplexity s web crawler from stealing content. Even then, the search engine tends to make up inaccurate 
information and attribute fake quotesto real people. Srinivas did not respond to theWired story s claims but said,  
The questions from Wired reflect a deep and fundamental misunderstanding of how Perplexity and the Internet 
work. 
Shevelenko said the company realizes the crucial role that publishers have in creating a healthy information 
ecosystem that its product depends on. To that end, Perplexity has created what it claims is a  first-of-its-kind  
revenue sharing program that will compensate publishers in a limited capacity. It plans to add an advertising layer 
on its platform that will allow brands to sponsor follow-up or  related  questions in its search and Pages products. 
For specific responses generated by its AI where Perplexity earns revenue, the publishers that are cited as a 
source in that answer will receive a cut. The company did not share what percentage of revenue it plans to share. It 
has been in talks withThe Atlanticamong other publishers about potential partnerships.
Srinivas, who was a researcher at OpenAI before startingPerplexityin 2022, has raised over $170 million in venture 
funding (per Pitchbook). The company s backers include some of the most high-profile names in tech, including 
Amazon founder Jeff Bezos, Google Chief Scientist Jeff Dean, former YouTube CEO Susan Wojcicki, Open AI 
cofounder Andrej Karpathy and Meta Chief Scientist Yann LeCun. In recent months, its conversational search 
chatbot has exploded in popularity, with 15 million users that include billionaires like Nvidia CEO Jensen Huang and 
Dell founder and CEO Michael Dell.
Perplexity uses a process called  RAG  or retrieval-augmented generation, which allows an AI system to retrieve 
real time information from external data sources to improve its chatbot s responses. But a degradation in the quality 
of these sources could have a direct impact on the responses its AI produces, experts say.
Zak Shumaylov, a machine learning researcher at the University of Cambridge, said if real time sources themselves 
contain biases or inaccuracies, any application built on top of such data could eventually experience a phenomenon 
Page 4 of 4
Garbage In, Garbage Out: Perplexity Spreads Misinformation From Spammy AI Blog Posts
calledmodel collapse, where an AI model that is trained on AI-generated data starts  spewing nonsense because 
there is no longer information, there is only bias. 
 When you use such references, it's much easier to promote disinformation even if there is no intention to do so,  he 
said.
Relying on low-quality web sources is a widespread challenge for AI companies, many of which don t cite sources 
at all. In May, Google s  AI overviews,  a feature that uses AI to generate previews on a topic, produced an array of 
misleading responses like suggesting adding glue to stick cheese on pizza and claiming that eating rocks can be 
good for your health. Part of the problem was that the system appeared to be pulling from unvetted sources like 
discussion forums on Reddit and satirical sites likeLiz Reid, head of Google Search, admitted in ablogthat some 
erroneous results appeared on Google in part because of a lack of quality information on certain topics.
 Perplexity is only one case,  Tian said.  It's a symptom, not the entire problem. 
MORE FROM FORBES
Load-Date: April 2, 2025
End of Document
Page 1 of 1
Letter writer declares 'Durango Decline' citing online classes, branding and merch
Letter writer declares 'Durango Decline' citing online classes, branding and 
merch
The Gateway: University of Nebraska at Omaha
June 24, 2024 Monday
University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved
Section: NEWS; Pg. 1
Length: 276 words
Body
It's hard not to notice as you walk about our campus that the higher-ups are hard at work rebranding each and 
every aspect of our fine institution with the "Maverick"or "Durango" moniker. We have a Maverick Store, Advising 
Center, Productions, the list goes on. While I can appreciate the sentiment of building community in a low-prestige 
commuter school, we've officially entered the era of "Durango Decline".
Somewhere along the line, the higher-ups decided that shifting to prioritizing totally online, self-paced course 
sections would help improve accessibility and fit more people into classes, so why not do it? Plus, it's another thing 
to charge fees for.
Well, students went all in for this. And why is that? Because, in most online sections, one can get away with pasting 
AI slop three times a week into a discussion board. Because, in most cases, professors or grad instructors are too 
busy to bother enforcing any kind of academic rigor in their online sections. Because, you don't need to really be 
present or part of the community to get your rubber-stamp credits.
Don't get me wrong - we need to include students who work full-time, and can't attend regularly scheduled classes. 
There's other options, though, like night and weekend classes, as well as synchronous online classes. All of those, 
of course, would take money and effort, which UNO would rather spend on flimsy Maverick merch.
Congrats to UNO for improving the accessibility of an education, by making sure nobody gets one at all.
Editor's Note
The Gateway welcomes letters to the editor as a part of our duty to provide a public forum for the university. Please 
submit any letters here.
Load-Date: June 24, 2024
End of Document

Page 1 of 2
After spam, meet slop, poor quality content generated by AI
After spam, meet slop, poor quality content generated by AI
CE Noticias Financieras English
June 18, 2024 Tuesday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 CE Noticias Financieras All Rights Reserved
Length: 818 words
Body
You may not know exactly what "slop" means in the context of artificial intelligence. But on some level, you 
probably know what I'm talking about.
Slop is a broad term that has gained traction when referring to bad or unwanted AI content on social media, art, 
books and, increasingly, in internet search results.
Google suggesting that you could add glue to make cheese stick to pizza? That's slop. As is a cheap ebook that 
seems to be what you were looking for, but not quite. What about those posts on your Facebook feed that 
seemingly came out of nowhere? That's slop too.
The term became more prevalent last month when Google incorporated its Gemini AI model into its search results 
in the US.
Instead of pointing users to links, the service tries to solve a query directly with an "AI Overview" - a piece of text at 
the top of a page that uses Gemini to form its best guess as to what the user is looking for.
The move was a reaction to Microsoft incorporating AI into its Bing search results, and had some immediate 
stumbles, leading Google to declare that it would roll back some of its AI features until the problems were resolved.
But with the major search engines having made AI a priority, it seems that vast amounts of machine-generated 
information, rather than being largely selected by humans, will be served up daily as part of life on the internet for 
the foreseeable future.
Hence the term slop, which conjures up images of piles of unappetizing food being poured into cattle troughs. Like 
this kind of slop, search with AI forms quickly, but not necessarily in a way that the most critical can accept.
Kristian Hammond, director of Northwestern University's Center for Advancing Safety of Machine Intelligence, 
pointed out a problem with the current model: the information in the AI Overview is being presented as a definitive 
answer, rather than as a starting point for an internet user's research into a particular subject.
"You search for something and you get what you need to think about it - and it really encourages you to think," said 
Hammond. "What's happening, in this integration with language models, is something that doesn't encourage the 
user to think. It encourages them to accept. And I think that's dangerous."

Page 2 of 2
After spam, meet slop, poor quality content generated by AI
Giving a name can be useful for identifying a problem. And while slop is an option, it's still an open question 
whether it will be adopted by a wider audience or end up in the slang garbage can with cheugy, bae and skibidi.
Adam Aleksic, a linguist and content creator who goes by the name Etymologynerd on social media, believes that 
slop - which he said has not yet become popular - is promising.
"I think this is a great example of an understated word at the moment, because it's a word we're all familiar with," 
said Aleksic. "It's a word that seems naturally applicable to this situation. So it's less invasive."
The use of slop to describe low-quality AI material apparently came about in reaction to the launch of AI art 
generators in 2022.
Some have identified programmer Simon Willison as an early adopter of the term - but Willison, who defended the 
adoption of the phrase, said it had been in use long before he encountered it.
"I think I may actually have been quite late to the party!" he said in an email.
The term has appeared on 4chan, Hacker News and YouTube comments, where anonymous commenters 
sometimes project their proficiency in complex subjects using niche language.
"What we always see with any slang is that it starts in a niche community and then spreads," said Aleksic.
"Usually, whether the slang is interesting or not is a factor that helps it spread, but not necessarily. Just as we've 
had a lot of words spreading from a bunch of programming geeks. Look at the word 'spam'. Usually, the word is 
created because there is a specific group with shared interests, with a shared need to invent words."
In the short term, the effect of AI on search engines and the internet in general may be less extreme than some 
fear.
News organizations have worried about a shrinking online audience as people rely more on AI-generated answers, 
and data from Chartbeat, a company that researches internet traffic, indicates that there was an immediate drop in 
Google Discover referrals to websites in the early days of AI Overviews.
But that drop has since recovered, and in the first three weeks of the Overviews, overall search traffic to more than 
2,000 websites in the US increased, according to Chartbeat.
But as people get used to the growing role of AI in the functioning of the internet, Willison, who identified himself as 
an optimist about AI when used correctly, thought that slop could become the standard term for the less important 
forms of machine-generated content.
"Society needs concise ways to talk about modern AI - both the positive and negative aspects. 'Ignore that email; 
it's spam' and 'ignore that article; it's slop' are useful examples," he said.
Load-Date: June 19, 2024
End of Document
Page 1 of 3
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
The Irish Times
June 18, 2024 Tuesday
Copyright 2024 The Irish Times All Rights Reserved
Section: FINANCE; Pg. 14
Length: 930 words
Body
I missed the RTÉ One O Clock News last Thursday, and I was raging. They say it s important for your sense of 
inner order and productivity to build an anchor habit into your daily routine, and for me that anchor is Eileen Whelan.
On this occasion, the miss meant not getting to see a spot of comedy gold as it unfolded live in the wilds of linear 
television. I had to catch up with a clipped-up version of it later in the day along with the rest of the extremely online 
masses.
The moment came courtesy of RTÉ News southern editor, Paschal Sheehy, who brought some much-needed 
colour to the fifth day of the European Parliament count from Nemo Rangers GAA club in Cork.
 [Fianna Fáil candidate] Billy Kelleher s team has just arrived here with a tray of sandwiches,  he informed Whelan 
near the end of a live link.
With some time to go before the result of the next count, there was  probably more interest in the distribution of 
those sandwiches at this stage  than there was in the distribution of an eliminated candidate s votes, he suggested 
to absolutely no dissent whatsoever.
 My presence on this plinth is a source of some mirth for some people here because I am being kept away from 
these sandwiches,  explained Sheehy then, conveying the perils of live broadcasting via some real-time smirking.
He didn t seem too hopeful when Whelan ventured that someone might save one for him. But after dropping into 
the Midlands-North-West count centre for an update from the suddenly  peckish  western correspondent Pat 
McGrath, there was time for a quick goodbye from a newly sandwich-laden Sheehy.
 I have scored, Eileen,  he declared with the sort of glee that can only be elicited by the arrival of food.
A replay of the full bulletin confirms that Whelan, because she s a pro, smoothly segued from congratulating her 
freshly carb-equipped colleague to the straightest of faces and most serious of voices as she proceeded to the next 
item, which happened to be news of Enoch Burke losing his defamation case against the publisher of the Sunday 
Independent.

Page 2 of 3
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
I was reminded of Sheehy, his single transferable sandwich triumph and the clip that RTÉ packaged up for online 
consumption when I was sent an embargoed copy of this year s Reuters Institute for the Study of Journalism global 
digital news report.
One of its significant Irish findings is that the level of trust in RTÉ News has risen. Based on a survey of more than 
2,000 people, conducted this year, some 72.4 per cent of news consumers in Ireland trust RTÉ, up 1 percentage 
point compared with last year.
RTÉ s performance, DCU s Institute of Future Media, Democracy and Society (FuJo) said in its analysis, was  
particularly notable  in light of the corporate governance scandal at the broadcaster over the past year.
Trusted news 
So, there has been no reputational contagion, this appears to confirm. RTÉ is the most trusted news organisation in 
Ireland, though I m contractually obliged to mention that The Irish Times is right there with it, trusted by 71.7 per 
cent, while local and regional radio is next on 71 per cent.
This is worth remembering amid all the online noise. In communities across Ireland, reporters for long-established 
news outlets   who face consequences when they don t live up to editorial standards   tend to be respected, well-
liked figures who may, sometimes, be hungry.
Interestingly, the survey found that online news has now nudged ahead of television as the most likely answer when 
people are asked to give their  main  source of news. This wasn t by much   33 per cent compared with 31 per cent   
and the survey itself is conducted online, meaning it tends to underrepresent traditional offline news consumption. 
But it does underline the benefit to RTÉ if its news clips go viral every so often.
Up to date 
When asked about the role of news in their lives, a relatively low percentage   43 per cent   say it is  very  or  
somewhat  important for news to be entertaining. This is less than the 75 per cent who say it is the role of news to 
keep them  up to date with what s going on  or even the 52 per cent who say it is important for news to make them  
feel connected to others in society .
This seems about right. I don t think it is the role of news to be entertaining, necessarily. I just appreciate it when 
somehow, against all the odds, its manages this feat. Indeed, it s the unexpectedness of any injection of humanity 
into the formal, historically stiff genre of television news   and the relief of fleeting lightness in a world of misery and 
gloom   that makes such moments stand out.
The global Reuters Institute report expands on the theme, examining  user needs  when it comes to news.  Update 
me  is the biggest one, important for 72 per cent, and  divert me  is bottom of the pile on 47 per cent. The authors 
caution that diversions may be more important overall to people s lives, but are just not something they always  
expect the news media to provide.
Again, this is fair enough. But what we think of as  news  does not exist in a silo. It is part of a much wider attention 
economy in which failure to engage is punished. It would actually be odd if a  bundle  of news, such as a television 
bulletin or a newspaper, was rigidly monotonal and robotic. 
And with the age of AI- generated slop now seemingly imminent, it would be counterproductive, too.
For sure, the banter-as- default mode of some US television news networks would be unbearable. Constant, 
contrived jokes would be inappropriate and weird. But, like the seasoning in a sandwich, a little bit of personality 
goes a long way.
Load-Date: June 17, 2024
Page 3 of 3
Why Sheehy's 'I have scored, Eileen' helps RTÉ News
End of Document
Page 1 of 2
How technology has changed our daily lives
How technology has changed our daily lives
 
B-Metro
June 17, 2024 Monday
Copyright 2024 B-Metro All Rights Reserved
Length: 517 words
Body
 Remember the days when a trip to the library was your only option for research, or a landline phone tethered you 
to one spot for communication?
The relentless march of technology has transformed our lives in ways unimaginable just a few decades ago, 
offering unparalleled opportunities but also presenting new challenges. Below, we explore some of the key areas 
where it's had the most significant impact.
Communication
Instant messaging platforms like WhatsApp and Facebook Messenger allow us to connect with anyone in the world 
in real-time, fostering closer relationships and global collaboration. Video conferencing platforms like Zoom have 
also become ubiquitous after seeing massive growth during the pandemic, facilitating business meetings and even 
personal interactions between friends and family members.
Information
The internet has democratised access to information like never before. Search engines like Google put a vast 
library of knowledge at our fingertips, allowing us to research any topic imaginable within seconds. The recently 
announced Artificial Intelligence (AI)-powered overviews promise to further empower individuals to understand any 
subject that interests them.
However, the sheer volume of information available can be overwhelming, and the ability to discern credible 
sources from misinformation remains a critical challenge, only exacerbated by AI-generated 'slop' content.
Entertainment
In place of the video rental stores like Blockbuster we enjoyed at the start of the 21st century, modern streaming 
services like Netflix and Disney offer on-demand access to a vast library of movies and TV shows, while platforms 
like YouTube provide a constant stream of user-generated content.

Page 2 of 2
How technology has changed our daily lives
Online gaming has also become a major form of leisure, with gaming platforms offering everything from first-person 
shooters to complex strategy titles. Even classic games have been given a digital makeover, with online bingo 
platforms letting players connect and enjoy a familiar game from the comfort of their homes.
Work-life balance
With smartphones and laptops allowing us to be constantly connected, modern technology has undeniably blurred 
the lines between work and personal life, making it difficult to ever truly switch off. This can lead to stress, burnout, 
and difficulty maintaining a healthy work-life balance.
However, there are many ways in which technology has also enhanced the workplace. There are countless tools for 
productivity, project management and much more that can streamline workflows, potentially freeing up time for 
personal pursuits. Ultimately, it's up to individuals to maintain healthy habits and ensure technology enhances, 
rather than hinders, our relationship with work.
Harnessing technology for the future
Technology has become a double-edged sword in our time. It offers unparalleled connection, information, and 
entertainment, but also challenges us with information overload, work-life blur, and the need for constant vigilance 
in a world of digital noise. Striking the right balance is key to harnessing technology's power for a fulfilling and 
connected life.
Load-Date: June 17, 2024
End of Document
Page 1 of 2
The rise and risk of AI-generated slop
The rise and risk of AI-generated slop
Devx.com
June 14, 2024 Friday 6:42 PM EST
Copyright 2024 DevX  All Rights Reserved
Length: 452 words
Byline: Cameron Wiggins
Body
The "dead internet theory" suggests that a significant portion of online content and activity is generated by artificial 
intelligence (AI) agents rather than humans. These AI agents rapidly create posts and images designed to farm 
engagement on social media platforms. While some of this AI-generated content may seem harmless, like the viral 
"shrimp Jesus" images, there are concerns about more sophisticated and potentially deceptive uses.
Studies have found that bot accounts on social media can spread misinformation and disinformation, amplifying 
unreliable sources and swaying public opinion. Social media companies are taking steps to address the misuse of 
their platforms. They are exploring ways to identify and remove bot activity, as well as considering measures like 
requiring users to pay for membership to deter bot farms.
The concept of "slop" has emerged to describe carelessly automated AI webpages and images that clutter the 
internet. Unlike interactive chatbots, slop is not intended to serve users' needs but rather to generate ad revenue 
and manipulate search engine results. Slop can be harmful when it contains incorrect or misleading information.
Examples include an AI-generated article listing a food bank as a tourist attraction and AI-written books with 
dangerous advice.
The spread of AI-generated slop
Image-generated slop, like bizarre reworkings of religious iconography, has also proliferated on social media.

Page 2 of 2
The rise and risk of AI-generated slop
Advertising agencies, the main revenue source for social media, are becoming concerned about the rise of slop. 
They worry that consumers may start to feel they are being served low-quality content and mistakenly flag 
legitimate ads as AI-generated. Tackling the problem of slop will be challenging, as major tech companies 
themselves are now using AI to generate content like search result overviews.
While they claim to have strong safety guardrails, slop continues to spread across the web. The story of "Shrimp 
Jesus" illustrates how an innocent joke can be co-opted by AI and used by scammers to lure unsuspecting users. 
As AI-generated content becomes more sophisticated, it will be increasingly difficult to discern the intentions behind 
it.
Experts call for greater transparency from social media companies, including labeling AI-generated content. While 
AI can create impressive images, many people still value the authenticity and "soul" of human-made art. The rise of 
AI-generated content on the internet is a cautionary tale, reminding us to be skeptical and navigate social media 
with a critical mind.
As one researcher noted, "Sometimes people use AI for creation, but there's always a dark side."
The post The rise and risk of AI-generated slop appeared first on DevX.
Load-Date: June 14, 2024
End of Document
Page 1 of 2
Comment: 'We deserve more than reheated housing ideas and AI slop'
Comment: 'We deserve more than reheated housing ideas and AI slop'
standard.co.uk
June 12, 2024 Wednesday 11:54 AM EST
Copyright 2024 Evening Standard Limited  All Rights Reserved
Length: 435 words
Byline: India Block
Body
The manifestos and housing pledges are dropping, and with it any hope for serious ideas to help London's 
struggling renters and homeowners.
Nothing even vaguely fresh or original has made it onto the menu. 
Labour suggested it would extend the Conservative's 95 per cent mortgage scheme to help first-time buyers 
(FTBS). In reality, anyone who can't save for a deposit will struggle to pass the mortgage checks, especially in 
pricey London.
The Conservatives are still insisting they'd totally be able to pass the Renters Reform Bill in ban section 21, a 
broken promise from the last election. 
They also want to bring back Help To Buy, which begs the question why they stopped it it in the first place - seeing 
as London new build prices are now permanently inflated.
Lib Dems want to bring in Rent to Own for social housing, a rebranded Right to Buy that would require a lot more 
social housing to replace the stock moving into private ownership. They'd also build 10 garden cities, location 
undetermined. 
"Quality housing should be our shared future, not a reanimated zombie of the past."
Labour is beating the drum for new towns too, getting into bed with Conservative think tank Create Streets with a 
New Town's Code that promises new urban hubs with old world charm. 
Create Streets' AI-created images of leafy streets and faux-Edwardian mansion blocks should give us all pause. 

Page 2 of 2
Comment: 'We deserve more than reheated housing ideas and AI slop'
Looking to RETVRN to a non-existent halcyon past of housing is an alt-right dog whistle, one that won't fly in 
multicultural London. 
The appeal of building an entirely new place is you don't have to risk upsetting existing residents by bolting on 
hundreds of new homes. 
But much of this NIMBYism is underpinned by the real fear over having to share already over-stretched public 
services, not fussing over the visual familiarity. 
New homes need sufficient GP appointments and school places - they don't need to smuggle in weird nationalist 
ideas.
That Create Streets has to resort to image generators likely trained on stolen art speaks to a lack of commitment to 
serious design that values human labour.
We have plenty of smart architects and urban planners working on contemporary housing ideas for our city. Just 
look at the winners of the recent RIBA London awards. 
Quality housing should be our shared future, not a reanimated zombie of the past.
Read More
General election: Labour pledges 'Freedom to Buy' mortgage guarantee scheme - but will it work in London?
Tory manifesto: pledge to revive Help to Buy scheme 'devoid of imagination' say property experts
Comment: Can the general election rescue a bedraggled London housing market?
Load-Date: June 28, 2024
End of Document
Page 1 of 3
Apple is finally letting you have it your way-kinda
Apple is finally letting you have it your way-kinda
Macworld (US)
June 12, 2024 Wednesday 10:30 AM EST
Copyright 2024 IDG Communications, Inc. All Rights Reserved
Length: 900 words
Body
Macworld
Apple, as a company, has always extolled the value of putting the personal in personal computer. From its earliest 
days pushing back at the monolith of IBM and beige boxes that all looked like one another, to its more recent 
extremely personal devices like the iPhone, Apple Watch, and AirPods.
But that ethos of personal technology has always been in fundamental tension with the companys other overriding 
principle: Apple knows best. Whether its the design of its apps or how to use its features, the company has a strong 
streak of imposing on its users what it believes is the best approach.
In the companys latest platform updates, this tension is more apparent than ever. Apple announced several new 
features that allow users to bring their own touches to their devicesbut it did so in a typically Apple fashion that still 
kept everything within bounds.
Custom-ish-ation
One of the most anticipated announcements ahead of this years Worldwide Developers Conference was that Apple 
would finally relax the strictures around your iOS devices home screen. The grid of icons has remained largely 
unchanged since its appearance in the very first iPhone back in 2007. There have been a few additions of course: 
folders, the App Library, and at long last the addition of widgets in iOS 14. But even all of those enhancements fit 
within the structure provided by the grid.
Apple
    Apple
  Apple
The rumor that this year would let you put icons anywhere on your screen no doubt conjured the freedom of macOS 
in some minds eyes. Unsurprisingly, perhaps, it wasnt to be: when the company did announce the feature, it 
became clear that while you could move your icons around and leave open spaces so your wallpaper showed 
through, the icons would still ultimately reside within the grid.

Page 2 of 3
Apple is finally letting you have it your way-kinda
Likewise, the news that you would at long last be able to reassign the iPhones lock screen shortcut buttons for the 
flashlight and the camera was greeted enthusiasticallybut there remain just the two icons. Apple specifically 
acknowledged this push and pull to me, saying that they wanted to give users the freedom to customize their 
experiences while still trying to maintain the iconic look and feel of the iPhone.
There is, however, one place on the home screen where Apple has put peoples customizations front and center: 
the new app icon features, which let you not only choose a light or dark option but also tint all your apps the same 
color. When you select a tint, it changes all of your app iconsregardless of whether or not the developer has 
designed their icon appropriately.
Picture window
Theres a big Photos redesign happening this year, and its largely about customization as well. Users can choose 
what they want to show up in the carousel at the top, whether its the traditional grid of photos or a specific set of 
curated pictures, or even photos the system has chosen to feature. Below that main section is a set of collections, 
which you can select and order as you like.
The push-and-pull of the customization is almost more internalized to the app here. Its a question of Apple trying to 
make your Photos app look as good as possible by suggesting the content that might take center stage, even if you 
do have the option to override it. Given that this is a feature centered around your own pictures, it does seem smart 
for Apple to try and go a little more hands-off here, making sure that its your content that remains the star.
Apple
    Apple
  Apple
Intelligence agency
By far the most personal-oriented development from this years WWDC is, of course, the companys rollout of its AI-
powered features, under the aegis of Apple Intelligence. This suite of improvements to features across the 
companys platforms may unlock some very powerful behaviors that help you do the things you need to do, but it 
remains to be seen just how personal it will be.
The problem is, to a degree, inherent in the very technology that underpins it. Much as AI is intended to help people 
accomplish things in a faster and more efficient manner, the way it achieves this is via a technology that is often 
trained on a huge corpus of material. One risk of technology like that is that it can feel depersonalizedalmost 
generic. For example, if you use Apples new Writing Tools feature to make an email sound more professional, 
might it do so in a way that sounds lesslike you? Will everybodys use of the Friendly rewrite tone end up sounding 
like the same person? Again, its not a concern thats unique to Applemuch of the text generated by other systems 
like ChatGPT has a way of sounding sameybut its something that the company may have to contend with when 
convincing people to take advantage of its feature.
Likewise, Apples new image generation technologies might unlock the ability to create pictures even for those who, 
like me, are artistically challenged, but their reliance on a handful of specific styles can end up feeling generic. Or, 
as developer Sebastiaan de With pointed out a feature that can turn whimsical sketches into AI slop.
All of this is something that Apple needs to contend with as it attempts to make its own foray into artificial 
intelligence. A personalized intelligent agent needs to feel personal, and the companys demonstration of a system 
that knows about your data and information is a good step in that directioneven if the generative features 
sometimes feel like a step back.
iOS, iPad, iPhone
Page 3 of 3
Apple is finally letting you have it your way-kinda
Load-Date: June 13, 2024
End of Document
Page 1 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
Newstex Blogs 
VentureBeat
June 10, 2024 Monday 11:02 PM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 VentureBeat 
Length: 1471 words
Byline: Carl Franzen
Body
June 10th, 2024 ( VentureBeat  - Delivered by  Newstex )
Apple had been among the tech giants most conspicuously absent from - or at least, low-key about - the generative 
AI craze, at least until today.
At its annual Worldwide Developer Conference (WWDC 2024) in Cupertino, California, the company unveiled its 
biggest push into generative AI so far: a new service called Apple Intelligence , which will offer a variety of features 
across Apple devices including Mac computers, iPhones, and iPads.
The service is not an app per se, rather, it is a set of features embedded within other popular apps, from web 
browser Safari (where you can summarize articles) to Mail (where it can rewrite and suggest grammar 
improvements) to Photos (auto generate photo albums on specific subjects and topics set to music based on a text 
prompt) to Messages (where it can create custom AI generated emoji and photos of your contacts, as well as event 
and group photos).
As with nearly all new Apple announcements of the company's storied history, the Apple Intelligence announcement 
was watched by a large audience of tech workers and journalists, as well as creatives, and some notable 
entrepreneurs and executives from rival firms.
It also inspired a wide range of responses, from some interpreting the announcement as underwhelming or 
undermining of Apple's reputation as a company where minimalistic and clean designs are prioritized, while others 
viewed it as one of, if not the best examples of generative AI done right. Here are some of the most interesting 
reactions I saw:
High praise from former rivals
Steven Sinofsky, the former president of the Windows Division at Microsoft and current board partner at 
Andreessen Horowitz, called Apple Intelligence 'really excellent work.'

Page 2 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
This is really excellent work. There is a ton that won't show up for a long time, but that is precisely what Apple does 
so well.
- Steven Sinofsky (@stevesi) June 10, 2024
He also said he thought the idea of weaving Apple Intelligence through its various Apple-branded apps was 'exactly 
right and even more so when combined with privacy/on device.'
Excellent. Today was super high on 'vision' for Apple with tons of future tense. At the same time their strong point of 
view is abundantly clear. This is not just privacy and on device, but how they see integration at the platform level. 
The idea for example of building on top of
- Steven Sinofsky (@stevesi) June 10, 2024
And, as if that wasn't enough of a favorable review, Sinofsky also took the opportunity to ding Google and his own 
former employer Microsoft in comparison to Apple's approach:
The contrast between what Apple is showing and what Google and Microsoft have shown is a stark as ever. This is 
really important. Apple brings their point of view to the newest technologies, again.
- Steven Sinofsky (@stevesi) June 10, 2024
Similarly, Andrej Karpathy, an esteemed researcher who was previously director of artificial intelligence and 
Autopilot Vision at Tesla (where he competed with Apple's abandoned self-driving car project) and a co-founder of 
OpenAI, said in a post on X that he found Apple Intelligence 'super exciting.'
Actually, really liked the Apple Intelligence announcement. It must be a very exciting time at Apple as they layer AI 
on top of the entire OS. A few of the major themes.
Step 1 Multimodal I/O. Enable text/audio/image/video capability, both read and write. These are the native
- Andrej Karpathy (@karpathy) June 10, 2024
Double standard?
Bilawal Sidhu, host of the TED Talks AI Show and a former Google Maps AR/VR engineer, wrote a lengthy post on 
X comparing how Apple Intelligence leverages personal data on the device in which it operates, as well as virtual 
private clouds, to serve up AI responses - a tack that he saw as similar to Microsoft's new Recall feature for 
Windows Copilot + PCs that faced intense backlash from some users and researchers for possible data security 
risks . Microsoft Recall was, as of last week, disabled by default and now must be turned on by the user during 
setup.
Apple's reality distortion field is strong. It's kinda wild that with "semantic index," Apple is basically doing what 
Microsoft wants to do with AI recall + Copilot, and without any of the big brother backlash.
Semantic index means all your private content (messages, emails, https://t.co/dFNy7yTotv
- Bilawal Sidhu (@bilawalsidhu) June 10, 2024
AI images and Genmoji: love/hate?
One of the most immediately obvious use cases for Apple Intelligence for regular users is in its ability to create 
custom imagery and emoji based on their text prompts within Messages and other apps.
Open source software developer and AI influencer Simon Willison took to his blog  to commend Apple's approach 
toward AI image generation, writing:
Page 3 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
This feels like a clever way to address some of the ethical objections people have to this specific category of AI 
tool:
If you can't create photorealistic images, you can't generate deepfakes or offensive photos of people
By having obvious visual styles you ensure that AI generated images are instantly recognizable as such, without 
watermarks or similar
Avoiding the ability to clone specific artist's styles further helps sidestep ethical issues about plagiarism and 
copyright infringement
The social implications of this are interesting too. Will people be more likely to share AI-generated images if there 
are no awkward questions or doubts about how they were created, and will that help it more become socially 
acceptable to use them?
Others criticized the look and feel of the cartoonish AI generated images in Messages:
As someone who spends 24 hours a day optimizing the fine-tuning of image models for everyday cases (such as 
this one), this was hard to watch. pic.twitter.com/W4oe46NXbZ
- Pietro Schirano (@skirano) June 10, 2024
some of the apple/AI integrations look potentially useful, but the image playground feature is pure AI slop. the 
"animation" style apple kept on showcasing looks horribly dated already. i imagine this will entertain older users but 
be an instant turn off for gen z pic.twitter.com/GhmuBOT2Jv
- James Vincent (@jjvincent) June 10, 2024
A third-party app killer
Various users pointed out that be integrating a number of AI features across its native apps, Apple was essentially 
killing third-party AI-powered apps and services that sought to offer similar functionality prior to the news today and 
the absence of Apple Intelligence.
Apps Apple sherlocked this WWDC
AllTrails
Soulver
1Password
Grammarly
Bitmoji
Bezel
Making mac apps, just mirror your phone lol
Rabbit R1
ChatGPT signups
did I miss any?
- Nick Dobos (@NickADobos) June 10, 2024
Page 4 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
Questions about training data
Other users on X, including some visual artists and tech workers opposed to the practices of generative AI model 
providers training without express consent on vast swaths of artwork and creative work posted to the web, 
questioned exactly how Apple had trained its underlying Apple Intelligence AI models - the company mentioned 
both language and diffusion models in its keynote announcement - and on what specific data.
1/ Apple 'Intelligence' is here and 0 questions of 'where does the data come from?' to be seen in press.
APPLE is trying to shove a huge privacy risk and tech that screams scraped off the internet without consent to the 
public. So here's a list of potential data sources ? pic.twitter.com/2WBzRSjsh3
- Karla Ortiz (@kortizart) June 10, 2024
Obviously impossible to know, but I suspect Steve Jobs would have been one of the few big tech CEOs to refuse to 
train generative AI on creators' work without their permission. Disappointing to see Apple drop hints they've done 
just that ('public web', 'can opt out' etc.) https://t.co/v3AjXQvzXE
- Ed Newton-Rex (@ednewtonrex) June 10, 2024
One Apple executive present at WWDC told Axios's Ina Fried that the models were trained on 'data from the public 
web' combined with licensed, or paid, data.
Giannandrea says Apple's llm was built in part using data from the public web and that publishers can opt out of, 
along with a wide range of licensed data. He doesn't get more specific, though.
- Ina Fried (@inafried) June 10, 2024
AI is a feature not a product?
Apple's choice to weave the Apple Intelligence service throughout its apps also had The Information founder and 
CEO Jessica Lessin musing that the approach was likely to be seen as influential.
The legacy of today's Apple news will be that AI is a feature not a product.
- Jessica Lessin (@Jessicalessin) June 10, 2024
Clearly, a wide range of reactions and they're still rolling in. What do you think about Apple Intelligence so far?
VB Daily
Stay in the know! Get the latest news in your inbox daily
By subscribing, you agree to VentureBeat's Terms of Service.
Thanks for subscribing. Check out more VB newsletters here .
An error occured.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
Page 5 of 5
Apple Intelligence first reactions: from 'pure slop' to 'excellent work'
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: June 10, 2024
End of Document
Page 1 of 3
The Artificial is Rarely Intelligent
The Artificial is Rarely Intelligent
Free The People
June 5, 2024 Wednesday
Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 Free the People, USA All Rights Reserved
Length: 1196 words
Byline: Taylor Lewis
Body
Jerry Seinfeld's commencement speech at Duke garnered national attention for the wrong reason. The handful of 
kids who petulantly stomped out in protest of Seinfeld's "Zionism," which I guess means being Jewish and believing 
your race deserves a homeland free of wanton pogroms, earned a few headlines, while also kicking in the Streisand 
Effect, awarding the sitcom star even more media regard. Score one for the children being carpet-bombed in Rafah, 
right?
What Seinfeld told graduates, which in typical comedic fashion cut against the grain of public sentiment, was 
approbatory. So of course it wasn't sensationalized. He issued no angry adjurations to feel guilty about earning a 
college degree because someone, somewhere, probably in a Botswanan bidonville, will never achieve the same 
credential. No preening "land acknowledgement." No "remember your fellow man" Dickensian platitudes meant to 
humble with humiliation. No cringey "change the world" injunction that inevitably leads to an overly idealistic student 
throwing him or herself into traffic to save the whooping crane.
Instead, Seinfeld ripped every page out of the DEI handbook, urging the audience to embrace their privilege and-
get this-be proud of their accomplishments. Who knew it was still legal to toot your own horn in America? (Lest 
you're a racial/sexual minority with a grievance pathology, obviously.)
That's all grand contrarian messages go, and Seinfeld's pro-privilege postulation would fit nicely in a Daily Wire 
infomercial. (Picture Ben Shapiro hyper-verbally sputtering, "Facts don't care about your feelings and privilege is 
good. You hear that, libs? PRIVILEGE IS GOOD. Ha! Triggered!) It's also uniquely American-that is, it was 
American up to about, by my estimate, seven years, fifty days, and thirty-two seconds ago when the Great 
Awokening entered its shame-success phase, when even the slightest flash of self-respect is slagged and 
maligned.
Being in favor of unapologetic excellence gives Seinfeld and edgelord verve. But he went further, needling 
America's most applauded class, after blacks, gays, and illegal migrants: the lazy. In particular, he went after the 
biggest boon to the slothful since the advent of DoorDash: artificial intelligence.
"AI," Seinfeld quipped, "is the most embarrassing thing we've ever invented in mankind's time on earth. Oh, you 
can't do the work. Is that what you're telling me? You can't figure it out?" You could almost hear the iconic bass line 
and laugh track as he delivered the bit. "This seems to be the justification of AI: I couldn't do it."

Page 2 of 3
The Artificial is Rarely Intelligent
That AI is a shortcut for the short-sighted and short-thinking is indisputable. The synthetic brain was coded to ease 
the pressure on organic brain tissue-that's its deontological purpose. Meanwhile, half of comedy's deontological 
purpose is, as Justin Taylor explains, is putting forth a "critique of the world as it is based on a vision of the world as 
it ought to be." The other half is to tickle your diaphragm with discernment.
Seinfeld mocks Silicon Valley's latest plaything as a godsend for hand-sitters, thumb-twiddlers, fiddle-fotters, 
dodderers, and work-shy corner-cutters. Extra points for Jerry: the shiftless need beration, if only to get their sorry 
hides off the couch.
Yet we seem to be increasingly settling for AI-generation in commercial areas that, as recently as a month ago, 
weren't subsumed by computerized composition. And the creations are far from triggering an "uncanny valley" 
feeling. They're downright chintzy.
Take Rudy Giuliani's fall from grace, hitting a new nadir with a panhandling coffee ad. America's mayor-turned-
mendicant is fobbing off drop-ship java beans in cheaply cartoonish bags for $30 a pop. "The will to survive," or pay 
off legal debt, "sweeps away moral imperatives," declared poet Marius Kociejowski. The spot Rudy recorded for his 
latest fleece-MAGA scheme was even jankier. He recorded his please-buy-plea in front of an obvious AI-produced 
background, complete with a Photoshop of his own product, which was supposed to resemble a Manhattan 
penthouse but comes across like a living room out of Sims 2. Just like his challenging the 2020 election results, 
Giuliani could hardly be accused of supererogatory effort.
The fakery involved in Giuliani's light-roast-grift is of a piece of widespread AI usage. There's always something off, 
something askew, something off the mark, something unholistic, something vaguely uneasy about digitized 
simulacrums of real life. The computerized-contoured images aren't all the way there; the .JPEGs can't pass a 
visual Turing test.
For one, there are the human hands, which most AI pic-producer flubs by turning digits and palms into alien 
echinoderms. Then there was the Google chatbot's wokely unhistorical depictions of ethnicities, including Indian-
shaded Vikings and blackified American Founding Fathers. Clearly, Gemini was coded with more Lin-Manuel 
Miranda than Noah Webster. There was also the amorous case where Microsoft's own AI avatar tried seducing a 
journalist-a very artificial affair, if you'll allow. Facebook, which was basically created by a borg passing as a man 
that has a surname curiously close to "sucker," hosts a multiplying ecosystem of bizarre "island of lost AI" slop 
content, including erotic martial Christian memes.
I know the left wants to sexualize everything, but J.C. being spooned by a biracial soldier couplet isn't something 
any human mind dreams up. It could only come from the rigidly binary algorithm of a circuit board that takes man-
made inputs and pushes them to illogical-or maybe too logical-conclusions.
With the U.S. presidential election in high gear, and a long hot summer of hustings events on deck, the use of AI 
campaign tactics are no doubt underway. That also means a concomitant rise in shenanigans, including the use of 
deepfake videos and propagandic imagery. Fake news has long been in America's stock of electoral weapons, but 
AI has the capacity to take the mendacious scheming of trolls to new heights. ChatGPT commandeered Scarlett 
Johansson's sultry voice; how long before a dirty trickster uses a comp-contrived Biden dialect to tell Democratic 
voters the election is really on November 12th? Answer: six months ago.
If artificial intelligence is a workaround for trying, it's going to take actual effort to parse the real from the ersatz. 
Piercing AI's verisimilitude will require, contra Seinfeld, us to do the work. Sometimes it'll be simple to spot the N64 
diorama behind a washed-up pol selling repackaged Folgers. Other times, it will take that extra few seconds to 
realize what you're hearing or seeing isn't an organic creation but a tech-fashioned artifice.
I know it's noisy out there, and too easy to scroll along. But take the extra half-minute to question and consider if 
what you're looking at comports with reality. Remember Kipling and keep your head if you see a grainy video of 
President Biden reading Mein Kampf and his lips aren't matching the words he's supposedly reciting. And do not, 
under any circumstances, take the first Google result for gospel.
The post The Artificial is Rarely Intelligent appeared first on Free the People.
Page 3 of 3
The Artificial is Rarely Intelligent
Load-Date: June 6, 2024
End of Document
Page 1 of 3
Why Facebook won’t be influential in the UK general election
Why Facebook won’t be influential in the UK general election
The Guardian (London)
June 4, 2024 Tuesday 11:46 AM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:1
Length: 1268 words
Byline: Alex Hern
Highlight: All-powerful ‘microtargeting’ swaying the masses into voting a certain way was always overblown, but 
these days social media has moved on – and so have the parties
Body
You’ve heard the one about the drunk man looking for his keys under the streetlamp? After an age pacing back and 
forth, scouring the floor for them, his friend asks him where he thinks he dropped them. He points across the road, 
to a patch of darkness. “Why aren’t you looking there, then,” he friend asks. He shrugs. “Because this is where the 
light is.” Good joke. Everybody laughs.
Let’s talk about online political adverts.
“Microtargeting” isn’t a thing any more, explains the Guardian’s Jim Waterson  :
                       Don’t expect to see Cambridge Analytica-style microtargeted political adverts driven by personal data 
during this general election: the tactic is now considered by many to be an ineffective “red herring” and is 
increasingly being blocked by social media platforms. The digital strategist Tom Edmonds said Facebook had 
banned political campaigns from using many of the tactics deployed in past contests. “Running a campaign aimed 
at 500 people didn’t earn them much money and just got them loads of shit,” he said.                     
Microtargeting was feared because of the possibility of deleterious effects on democracy: if you could target a 
thousand different messages at a thousand different demographics, then the whole idea of a single national 
conversation begins to break down. Instead, what happened is it just didn’t really work.
Ultimately, the biggest competitor to the likes of Cambridge Analytica was Facebook itself. There’s little point in 
spending vast sums profiling individual voters to microtarget them when the social network’s ad tools let you simply 
hand over all targeting decisions to Facebook itself. The social network lets advertisers set “performance goals” 
[like sales, clicks, or signups], set a spend limit, and sit back and watch as it goes ahead and does whatever it 

Page 2 of 3
Why Facebook won’t be influential in the UK general election
thinks maximises return. The company will even pick the best combination of words and images to boost your 
chances of success.
But Facebook can only help you so much. If you’re creating adverts for specific candidates, for instance, who 
should you focus your time and money on: people who might win, or people who are definitely going to lose? If you 
said the latter, you might just work for the Conservative party. From our story  :
                       The strategy is known within the party as the “80/20” approach, in which it focuses all its spending on 
the 80 seats it came closest to losing in 2019 and the 20 seats it came closest to winning.                       Ad 
spending reports on Facebook show that these constituencies are exactly where the party is funnelling its money. 
More than half of the party’s spending on the social network since January has gone to its 80 tightest seats, or to 
seats it does not hold at all.                     
We started monitoring Meta ad spending to try to work out whether the reported “80/20 strategy” was holding. It is 
one thing to propose two years out from an election; it’s quite another to stick with it when an election is barely a 
month away.
But we also started monitoring Meta ad spending because we could. The company maintains a library of all political 
ads, discloses total spending, and requires verification of residency before people can launch new adverts. That 
library has come under a lot of criticism over the years, but at least it exists. More than that, it has a robust toolset 
that lets us write our own software to query against it, which means we can answer more serious questions than 
“are there any interesting adverts that anyone has paid for recently”.
Yet, like the drunk looking for his keys, it’s unlikely that Facebook is actually where the story is. For huge swathes of 
the country, conversations that once happened on the public social network have shifted to private channels, led by 
Meta’s own WhatsApp. That which remains on Facebook itself is swamped by AI-generated slop, and detached 
from reality after an algorithmic adjustment intended to boost content from “friends and family” – doubly so on 
Threads, Meta’s Twitter clone, which actively and openly downranks political content of all sorts.
There is more conversation on TikTok, but coverage of that platform is hard. The Observer looked at the digital 
campaigns , but for TikTok, was forced to focus on the parties’ own official feeds:
                       TikTok is free – it does not allow paid-for advertising by politicians or parties – but not easy: the 
social media teams need to work harder to persuade the app’s notoriously opaque algorithm to organically float 
their content on to users’ phones, which becomes more likely as more people like, share, comment or re-post 
videos. For smaller, agile parties with low budgets, TikTok will feel like there is everything to win: views, 
engagement and people who finally find out who they are. Creators who know how it’s done believe Labour has had 
a better start.                     
There is an election conversation happening on TikTok. There’s many, in fact, with the platform’s heavily curated 
algorithmic feed letting every demographic have their own exclusive discourse. But it’s nearly impossible to observe 
from the outside, short of brute-force techniques like totting up the view count on videos tagged “Sunak”.
It’s worse still, of course, for the conversation on WhatsApp. With its end-to-end encryption and sparse public 
“channels”, doing data journalism to track the election chats is a dead end.
And then there’s AI. There’s a lingering suspicion that the rise of AI systems will have some sort of effect on this 
election, but again, we’re forced to look where the light is. Deepfaked video going viral on Twitter, the platform 
currently known as X, is very obvious (and hasn’t really been seen so far). Wavering voters having conversations 
with ChatGPT to try to determine where they should put their X is invisible – if it’s even happening.
In the UK, these questions feel largely academic. Outside a few personality-driven local races, the eventual results 
feel more of a foregone conclusion  than they have at any point in my life to date. But as the US goes to the polls in 
five months’ time, the same questions will be asked – and the answers could be key to what side the coin lands on.
Page 3 of 3
Why Facebook won’t be influential in the UK general election
Best get to trying to find them, then.
                   The wider Techscape                                                               Speaking of deepfakes – a fake Tom 
Cruise video  (pictured above) was used to spread disinformation about the Olympics, Microsoft says.                                                                                          
Is the internet bad  ? It certainly seems to have been for the Marubo tribe, whose first nine months online hasn’t 
been all sunshine and roses.                                                                 An internal Google database tracking privacy 
and security breaches was leaked to 404 Media.  One of the biggest threats? YouTube employees sneaking a look 
at big scheduled video uploads to get a heads-up on the information.                                                                 
Voters support raising the minimum age for social media apps in the UK to 16, a Guardian poll reveals.                                                                  
Microsoft’s “ Recall ” feature – a clone of Mac app Rewind, built into the OS – has been labelled a security 
“disaster”.  The AI service keeps a database of everything you’ve ever seen on your computer, for an LLM to use to 
answer questions. It’s the perfect target for hackers, critics say.                                                         
Load-Date: June 4, 2024
End of Document
Page 1 of 5
Links 5/29/2024
Links 5/29/2024
Newstex Blogs 
Naked Capitalism
May 30, 2024 Thursday 10:58 AM EST
Delivered by Newstex LLC. All Rights Reserved.
Copyright 2024 Naked Capitalism 
Length: 1406 words
Byline: Lambert Strether
Body
May 30th, 2024 ( Naked Capitalism  - Delivered by  Newstex )
Something Strange Happens to Wolves Infected by an Infamous Mind-Altering Parasite  Science Alert
Taking Stock: Dollar Assets, Gold, and Official Foreign Exchange Reserves  Federal Reserve Bank of New York, 
Liberty Street Economics
Would Returning to the Gold Standard Resolve Our Most Pressing Monetary Problems?  Charles Hugh Smith, Or 
Two Minds. No.
CalPERS opposes Elon Musk's $56 billion pay package amid shareholder discontent  WION
The CRE non-crisis rolls on  FT
Climate
US and China must take lead in climate fight despite their competitive relationship, top Beijing envoy  says South 
China Morning Post
In search of a market-driven price on carbon  S&P Global. Let me know how that works out.
Trees in Distress  St Louis Post-Dispatch
Proposed Cooling Policy Would Cause Air Conditioning Usage to Rise, Risking Blackouts  RAND
Water
Accusations flare as Mexico City's water crisis approaches 'day zero'  Bnamericas

Page 2 of 5
Links 5/29/2024
Dozens of Alaskan rivers and streams turn orange, visible from space  Interesting Engineering
Understanding Water Advisories  The Brockovich Report
Syndemics
Officials investigate unusual surge in flu viruses in Northern California  San Francisco Chronicle
The bird flu vaccine is made with eggs. That has scientists worried.  CBS
China?
Beware forecasts of doom for Taiwan under Lai  Brookings Institution
Debt-Trap Diplomacy  J-STOR Daily
Chinese scientists cure diabetes using stem cells in world first  NextShak. But if we cure it, what happens t our rents 
on insulin? Think. people!
Myanmar
Myanmar's ethnic armies consolidate strongholds as junta weakens, reports say  Reuters
Vast concessions threaten Malaysia's forests: Report  Channel News Asia
India
Delhi 'unbearable' as temperatures near 50C  BBC
Power demand peaks in heatwave-hit Delhi, but temperature readings may be 'error' Channel News Asia
Syraqistan
The US-built pier in Gaza broke apart. Here's how we got here and what might be next  Orlando Sentinel
* * *
Israel says it seized key Gaza-Egypt corridor as Rafah ground offensive intensifies  France24
Pushed to the edge, starved and exhausted, Rafah IDPs struggle to survive  The New Arab
* * *
Attacks on ICC Show 'Condemning Hamas' Is Really About Absolving Israel  FAIR
Israel shrugs off UNSC bid to 'stop the killing' to continue Rafah assault  Al Jazeera
European Disunion
Walking France: Avignon to Pont-Saint-Esprit  Chris Arnade, Walking the World
Dear Old Blighty
Favoured Nation  New Left Review
Labour promises to hit 18-week NHS waiting target within five years  BBC. Ambitious!
Page 3 of 5
Links 5/29/2024
New Not-So-Cold War
NATO meets as calls grow to let Ukraine strike targets inside Russia  France24. Mercouris, more recent than any of 
these, says striking targets in Russia is coming off the boil.
US Secretary of State hints they may allow Ukraine to strike Russian territory with US weapons  and Poland allows 
Ukraine to use Polish-supplied weapons to strike targets in Russia  Ukrainska Pravda
NATO Ramps Up Figleaf of Cross-Border Strikes  Simplicius the Thinker(s)
U.S. concerned about Ukraine strikes on Russian nuclear radar  stations WaPo
How to Win in Ukraine: Pour It On, and Don't Worry About Escalation  RAND. But from May 22.
* * *
Ukraine war: influential Russian think tank proposes a 'demonstrative' nuclear explosion  South China Morning Post
* * *
Nato has just 5% of air defences needed to protect eastern  flank FT
Image shows a 7-layer defensive line planned for the border between NATO and Russia  Insider. Awesome. I 
assume a PowerPoint comes with it?
NATO Holds First Meeting Of Critical Undersea Infrastructure Network  Naval News
* * *
Delivery of US weapons to Ukraine helping stabilize frontline, Blinken says  Reuters
Soldiers in Ukraine say US-supplied tanks have made them targets for Russian strikes  CNN. Oopsie.
Increasingly Effective Russian Electronic Warfare Turning the Tide on the Frontlines - Reports  Military Watch
* * *
Georgia's 'foreign agents' law is now a reality. When will it take effect and who will it impact?  JAM News
Hundreds of Georgian NGOs pledge to defy 'foreign influence' law  Al Jazeera
Global Elections
South Africa counts ballots in most competitive election since apartheid  France24
2024
Jury Instructions & Charges  (PDF), People v Donald J. Trump
AIPAC offshoot spending heavily to beat Cori Bush in her primary  Politico. Election interference.
The Supremes
82. The Supreme Court's Four Officers  One First
Spook Country
Page 4 of 5
Links 5/29/2024
The obscure federal intelligence bureau that got Vietnam, Iraq, and Ukraine right  Vox
The Bezzle
Courts rather than arbitrators to decide whether Dogecoin dispute goes to arbitration  SCOTUSblog
Exclusive: The Atlantic, Vox Media ink licensing, product deals with OpenAI  Axios
Publishing AI Slop Is a Choice  Daring Fireball
Digital Watch
Google Researchers Say AI Now Leading Disinformation Vector (and Are Severely Undercounting the Problem)  
404 Media. 'If you didn't want to go to Milwaukee, why did you get on the train?' -Father Emil, A Prairie Home 
Companion (from memory).
Google confirms the leaked Search documents are real  The Verge
US judge makes 'unthinkable' pitch to use AI to interpret legal texts  Reuters
Gavin Newsom warns against perils of over-regulating  AI Politico
Boeing
FAA appears poised to grant Boeing extension on safety report  Leeham News & Analysis
The 420
K-Pop  The Baffler. Ketamine.
Imperial Collapse Watch
Jeffrey Sachs: The Untold History of the Cold War, CIA Coups Around the World, and COVID's Origin  (video) 
Tucker Carlson, YouTube
Can The B-21 Raider Save America's Shrinking Bomber Force?  1945. No.
Class Warfare
How Tens of Thousands of Grad Workers Are Organizing Themselves  Labor Notes
Seattle isn't claiming Tukwila's migrant crisis. But it did start here  Seattle Times
Antidote du jour, via JB:
'A little bird singing in the cold.'
See yesterday's Links and Antidote du Jour here .
This entry was posted in Guest Post , Links  on May 30, 2024  by  Lambert Strether  .
About Lambert Strether
Readers, I have had a correspondent characterize my views as realistic cynical. Let me briefly explain them. I 
believe in universal programs that provide concrete material benefits, especially to the working class. Medicare for 
All is the prime example, but tuition-free college and a Post Office Bank also fall under this heading. So do a Jobs 
Page 5 of 5
Links 5/29/2024
Guarantee and a Debt Jubilee. Clearly, neither liberal Democrats nor conservative Republicans can deliver on such 
programs, because the two are different flavors of neoliberalism ('Because markets'). I don't much care about the 
'ism' that delivers the benefits, although whichever one does have to put common humanity first, as opposed to 
markets. Could be a second FDR saving capitalism, democratic socialism leashing and collaring it, or communism 
razing it. I don't much care, as long as the benefits are delivered.To me, the key issue - and this is why Medicare for 
All is always first with me - is the tens of thousands of excess 'deaths from despair,' as described by the Case-
Deaton study, and other recent studies. That enormous body count makes Medicare for All, at the very least, a 
moral and strategic imperative. And that level of suffering and organic damage makes the concerns of identity 
politics - even the worthy fight to help the refugees Bush, Obama, and Clinton's wars created - bright shiny objects 
by comparison. Hence my frustration with the news flow - currently in my view the swirling intersection of two, 
separate Shock Doctrine campaigns, one by the Administration, and the other by out-of-power liberals and their 
allies in the State and in the press - a news flow that constantly forces me to focus on matters that I regard as of 
secondary importance to the excess deaths. What kind of political economy is it that halts or even reverses the 
increases in life expectancy that civilized societies have achieved? I am also very hopeful that the continuing 
destruction of both party establishments will open the space for voices supporting programs similar to those I have 
listed; let's call such voices 'the left.' Volatility creates opportunity, especially if the Democrat establishment, which 
puts markets first and opposes all such programs, isn't allowed to get back into the saddle. Eyes on the prize! I love 
the tactical level, and secretly love even the horse race, since I've been blogging about it daily for fourteen years, 
but everything I write has this perspective at the back of it.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: May 30, 2024
End of Document
Page 1 of 2
Losing the library
Losing the library
The Week US
May 28, 2024 Tuesday 5:36 PM EST
Copyright 2024 Future US, Inc.  All Rights Reserved
Section: TECH LATEST
Length: 340 words
Byline: Theunis Bates
Body
Around 300 B.C., King Ptolemy I - the new ruler of Egypt and a former general of Alexander the Great - tasked an 
adviser with a modest mission: "to collect, if possible, all the books in the world." Over the next two centuries, the 
great library in the Ptolemaic capital of Alexandria would be filled with hundreds of thousands of papyrus scrolls: 
the full corpus of ancient Greek and Egyptian literature along with Buddhist, Jewish, and Zoroastrian texts. 
Ships would be searched for books when they docked at Alexandria, and royal agents would pay hefty sums for 
almost any written work. A booming market in fakes and forgeries soon emerged. Entrepreneurial scribes dashed 
off scrolls of supposed secret wisdom from famous thinkers - one was titled Everything Thucydides Left Unsaid - 
while others created books that mixed the authentic with the imagined. In Alexandrias merchant quarter, stalls that 
once sold vegetables and baskets were "replaced with those stacking rolls and rolls of books," writes historian Islam 
Issa. 
Eventually, the library had to hire experts to wade through the sea of bogus texts and identify genuine treasures. 
The web, our modern-day library of Alexandria, faces a similar problem. This digital repository of human knowledge 
is being swamped with AI-generated slop - pointless listicles, nonsensical how-to guides, and factually flawed news 
summaries churned out by content factories that want to grab clicks and ad revenue on the cheap. To save users 
the hassle of scrolling through reams of garbage links in its search engine, Google has now started showing users 
AI-generated answers to their queries. But those answers are sometimes wrong - one user who wanted a fix for a 
cars faulty turn signal was advised to "replace the blinker fluid" - and pull traffic and dollars away from useful, 
human-run websites. Maybe the tech giant should hire more humans to curate trustworthy collections of knowledge. 
It could call them "librarians."
This is the editors letter in the current issue of The Week magazine. 
Load-Date: May 28, 2024

Page 2 of 2
Losing the library
End of Document
Page 1 of 2
TechScape: The people charged with making sure AI doesn
TechScape: The people charged with making sure AI doesn
 
Africa Newswire
May 22, 2024 Wednesday
Copyright 2024 Africa Newswire All Rights Reserved
Length: 745 words
Body
 22 May 2024 (TourismAfrica2006) Everything happens so much. I'm in Seoul for the International AI summit, the 
half-year follow-up to last year's Bletchley Park AI safety summit (the full sequel will be in Paris this autumn). While 
you read this, the first day of events will have just wrapped up - though, in keeping with the reduced fuss this time 
round, that was merely a "virtual" leaders' meeting.
When the date was set for this summit - alarmingly late in the day for, say, a journalist with two preschool children 
for whom four days away from home is a juggling act - it was clear that there would be a lot to cover. The hot AI 
summer is upon us:
Then, the weekend before the summit kicked off, everything kicked off at OpenAI as well. Most eye-catchingly, 
perhaps, the company found itself in a row with Scarlett Johansson over one of the voice options available in the 
new iteration of ChatGPT. Having approached the actor to lend her voice to its new assistant, an offer she declined 
twice, OpenAI launched ChatGPT-4o with "Sky" talking through its new capabilities. The similarity to Johansson 
was immediately obvious to all, even before CEO Sam Altman tweeted "her" after the presentation (the name of the 
Spike Jonze film in which Johansson voiced a super-intelligent AI). Despite denying the similarity, the Sky voice 
option has been removed.
More importantly though, the two men leading the company/nonprofit/secret villainous organisation's 
"superalignment" team - which was devoted to ensuring that its efforts to build a superintelligence don't end 
humanity - quit. First to go was Ilya Sutskever, the co-founder of the organisation and leader of the boardroom coup 
which, temporarily and ineffectually, ousted Altman. His exit raised eyebrows, but it was hardly unforeseen. You 
come at the king, you best not miss. Then, on Friday, Jan Leike, Sutskever's co-lead of superalignment also left, 
and had a lot more to say:
Leike's resignation note was a rare insight into dissent at the group, which has previously been portrayed as almost 
single-minded in its pursuit of its - which sometimes means Sam Altman's - goals. When the charismatic chief 
executive was fired, it was reported that almost all staff had accepted offers from Microsoft to follow him to a new AI 
lab set up under the House of Gates, which also has the largest external stake in OpenAI's corporate subsidiary. 

Page 2 of 2
TechScape: The people charged with making sure AI doesn
Even when a number of staff quit to form Anthropic, a rival AI company that distinguishes itself by talking up how 
much it focuses on safety, the amount of shit-talking was kept to a minimum.
It turns out (surprise!) that's not because everyone loves each other and has nothing bad to say. From Kelsey Piper 
at Vox:
Barely a day later, Altman said the clawback provisions "should never have been something we had in any 
documents". He added: "we have never clawed back anyone's vested equity, nor will we do that if people do not 
sign a separation agreement. this is on me and one of the few times I've been genuinely embarrassed running 
openai; i did not know this was happening and i should have." (Capitalisation model's own.)
Altman didn't address the wider allegations, of a strict and broad NDA; and, while he promised to fix the clawback 
provision, nothing was said about the other incentives, carrot and stick, offered to employees to sign the exit 
paperwork.
As set-dressing goes, it's perfect. Altman has been a significant proponent of state and interstate regulation of AI. 
Now we see why it might be necessary. If OpenAI, one of the biggest and best-resourced AI labs in the world, 
which claims that safety is at the root of everything it does, can't even keep its own team together, then what hope 
is there for the rest of the industry?
It's fun to watch a term of art developing in front of your eyes. Post had junk mail; email had spam; the AI world has 
slop:
I'm keen to help popularise the term, for much the same reasons as Simon Willison, the developer who brought its 
emergence to my attention: it's crucial to have easy ways to talk about AI done badly, to preserve the ability to 
acknowledge that AI can be done well.
The existence of spam implies emails that you want to receive; the existence of slop entails AI content that is 
desired. For me, that's content I've generated myself, or at least that I'm expecting to be AI-generated. No one 
cares about the dream you had last night, and no one cares about the response you got from ChatGPT. Keep it to 
yourself.
Load-Date: May 23, 2024
End of Document
Page 1 of 2
Spam, junk
Spam, junk
 
Africa Newswire
May 21, 2024 Tuesday
Copyright 2024 Africa Newswire All Rights Reserved
Length: 926 words
Body
 21 May 2024 (TourismAfrica2006) Your email inbox is full of spam. Your letterbox is full of junk mail. Now, your 
web browser has its own affliction: slop.
"Slop" is what you get when you shove artificial intelligence-generated material up on the web for anyone to view.
Unlike a chatbot, the slop isn't interactive, and is rarely intended to actually answer readers' questions or serve 
their needs.
Instead, it functions mostly to create the appearance of human-made content, benefit from advertising revenue and 
steer search engine attention towards other sites.
Just like spam, almost no one wants to view slop, but the economics of the internet lead to its creation anyway. AI 
models make it trivial to automatically generate vast quantities of text or images, providing an answer to any 
imaginable search query, uploading endless shareable landscapes and inspirational stories, and creating an army 
of supportive comments. If just a handful of users land on the site, reshare the meme or click through the adverts 
hosted, the cost of its creation pays off.
But like spam, its overall effect is negative: the lost time and effort of users who now have to wade through slop to 
find the content they're actually seeking far outweighs the profit to the slop creator.
"I think having a name for this is really important, because it gives people a concise way to talk about the problem," 
says the developer Simon Willison, one of the early proponents of the term "slop".
"Before the term 'spam' entered general use it wasn't necessarily clear to everyone that unwanted marketing 
messages were a bad way to behave. I'm hoping 'slop' has the same impact - it can make it clear to people that 
generating and publishing unreviewed AI-generated content is bad behaviour."
Slop is most obviously harmful when it is just plain wrong. Willison pointed to an AI-generated Microsoft Travel 
article that listed the "Ottawa food bank" as a must-see attraction in the Canadian capital as a perfect example of 

Page 2 of 2
Spam, junk
the problem. Occasionally, a piece of slop is so useless that it goes viral in its own right, like the careers advice 
article that earnestly explains the punchline to a decades-old newspaper comic: "they pay me in woims".
"While the precise meaning of 'They Pay Me in Woims' remains ambiguous, various interpretations have emerged, 
ranging from a playful comment on work-life balance to a deeper exploration of our perceived reality," the slop 
begins.
AI-generated books have become a problem too. A prominent example came when amateur mushroom pickers 
were recently warned to avoid foraging books sold on Amazon that appeared to have been written by chatbots and 
contained dangerous advice for anyone hoping to discern a lethal fungus from an edible one.
Image-generated slop has also blossomed on Facebook, as images of Jesus Christ with prawns for limbs, children 
in plastic bottle-cars, fake dream homes and improbably old women claiming to have baked their 122nd birthday 
cake garner thousands of shares.
Jason Koebler of the tech news site 404 Media believes the trend represents what he calls the "zombie internet". 
The rise of slop, he says, has turned the social network into a space where "a mix of bots, humans and accounts 
that were once humans but aren't any more mix together to form a disastrous website where there is little social 
connection at all."
Nick Clegg, the president of global affairs at Facebook's parent company, Meta, wrote in February that the social 
network is training its systems to identify AI-made content. "As the difference between human and synthetic content 
gets blurred, people want to know where the boundary lies," he wrote.
The problem has begun to worry the social media industry's main revenue source: the advertising agencies who 
pay to place ads next to content. Farhad Divecha, the managing director of UK-based digital marketing agency 
AccuraCast, says he is now encountering cases where users are mistakenly flagging ads as AI-made slop when 
they are not.
"We have seen instances where people have commented that an advert was AI-generated rubbish when it was 
not," he says, adding that it could become a problem for the social media industry if consumers "start to feel they 
are being served rubbish all the time".
Tackling spam in inboxes required an enormous cross-industry effort and led to a fundamental change in the nature 
of email. Big webmail providers like Gmail aggressively monitor their own platforms to crack down on spammers 
and are increasingly suspicious of emails arriving from untrusted email servers. They also apply complex, largely 
undocumented, AI systems to try to detect spam directly, in a constant cat-and-mouse game with the spammers 
themselves.
For slop, the future is less rosy: the world's largest companies have gone from gamekeeper to poacher. Last week, 
Google announced an ambitious plan to add AI-made answers to the top of some search results, with US-based 
users the first to experience a full rollout of the "AI Overviews" feature. It will include links as well, but users who 
want to limit the response to just a selection of links to other websites will be able to find them - by clicking through 
to "web" on the search engine, demoted to sit beside "images" and "maps" on the list of options.
"We've added this after hearing from some that there are times when they'd prefer to just see links to webpages in 
their search results," wrote Danny Sullivan, the company's search liaison.
Google says the AI overviews have strong safety guardrails. Elsewhere on the web though, slop is spreading.
Load-Date: May 22, 2024
End of Document
Page 1 of 3
The people charged with making sure AI doesn’t destroy humanity have left the building
The people charged with making sure AI doesn’t destroy humanity have left 
the building
The Guardian (London)
May 21, 2024 Tuesday 11:38 AM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:1
Length: 1639 words
Byline: Alex Hern
Highlight: If OpenAI can’t keep its own team together, what hope is there for the rest of the industry? Plus, AI-
generated ‘slop’ is taking over the internet Don’t get TechScape delivered to your inbox? Sign up for the full article 
here
Body
Everything happens so much.  I’m in Seoul for the International AI summit, the half-year follow-up to last year’s 
Bletchley Park AI safety summit (the full sequel will be in Paris this autumn). While you read this, the first day of 
events will have just wrapped up – though, in keeping with the reduced fuss this time round, that was merely a 
“virtual” leaders’ meeting.
When the date was set for this summit – alarmingly late in the day for, say, a journalist with two preschool children 
for whom four days away from home is a juggling act – it was clear that there would be a lot to cover. The hot AI 
summer is upon us  :
                       The inaugural AI                       safety                       summit at Bletchley Park in the UK last year 
announced an international testing framework for AI models, after calls                       … for a six-month pause in 
development of powerful systems.                       There has been no pause. The Bletchley declaration, signed by 
UK, US, EU, China and others, hailed the “enormous global opportunities” from AI but also warned of its potential 
for causing “catastrophic” harm. It also secured a commitment from big tech firms including OpenAI, Google and 
Mark Zuckerberg’s Meta to cooperate with governments on testing their models before they are released.                       
While the UK and US have established national AI safety institutes, the industry’s development of AI has continued                        
… OpenAI released GPT-4o (the o stands for “omni”) for free online; a day later, Google previewed a new AI 
assistant called Project Astra, as well as updates to its Gemini model. Last month, Meta released new versions of 
its own AI model, Llama                        …                        And in March, the AI startup Anthropic, formed by former 
OpenAI staff who disagreed with                        Altman’s approach, updated its Claude model                       .                     

Page 2 of 3
The people charged with making sure AI doesn’t destroy humanity have left the building
Then, the weekend before the summit kicked off, everything kicked off at OpenAI as well. Most eye-catchingly, 
perhaps, the company found itself in a row with Scarlett Johansson  over one of the voice options available in the 
new iteration of ChatGPT. Having approached the actor to lend her voice to its new assistant, an offer she declined 
twice, OpenAI launched ChatGPT-4o with “Sky” talking through its new capabilities. The similarity to Johansson 
was immediately obvious to all, even before CEO Sam Altman tweeted “her” after the presentation (the name of the 
Spike Jonze film in which  Johansson voiced a super-intelligent AI). Despite denying the similarity, the Sky voice 
option has been removed.
More importantly though, the two men leading the company/nonprofit/secret villainous organisation’s 
“superalignment” team – which was devoted to ensuring that its efforts to build a superintelligence don’t end 
humanity – quit. First to go was Ilya Sutskever, the co-founder of the organisation  and leader of the boardroom 
coup which, temporarily and ineffectually, ousted Altman. His exit raised eyebrows, but it was hardly unforeseen. 
You come at the king, you best not miss. Then, on Friday, Jan Leike, Sutskever’s co-lead of superalignment also 
left , and had a lot more to say:
                       A former senior employee at OpenAI has said the company behind ChatGPT is prioritising “shiny 
products” over safety, revealing that he quit after a disagreement over key aims reached “breaking point”.                       
Leike detailed the reasons for his departure in a thread on X posted on Friday, in which he said safety culture had 
become a lower priority. “Over the past years, safety culture and processes have taken a backseat to shiny 
products,” he wrote.                       “These problems are quite hard to get right, and I am concerned we aren’t on a 
trajectory to get there,” he wrote, adding that it was getting “harder and harder” for his team to do its research.                       
“Building smarter-than-human machines is an inherently dangerous endeavour. OpenAI is shouldering an 
enormous responsibility on behalf of all of humanity,” Leike wrote, adding that OpenAI “must become a safety-first 
AGI [artificial general intelligence] company”.                     
Leike’s resignation note was a rare insight into dissent at the group, which has previously been portrayed as almost 
single-minded in its pursuit of its – which sometimes means Sam Altman’s – goals. When the charismatic chief 
executive was fired, it was reported that almost all staff had accepted offers from Microsoft to follow him to a new AI 
lab set up under the House of Gates, which also has the largest external stake in OpenAI’s corporate subsidiary. 
Even when a number of staff quit to form Anthropic, a rival AI company that distinguishes itself by talking up how 
much it focuses on safety, the amount of shit-talking was kept to a minimum.
It turns out (surprise!) that’s not because everyone loves each other and has nothing bad to say. From Kelsey Piper 
at Vox  :
                       I have seen the extremely restrictive off-boarding agreement that contains nondisclosure and non-
disparagement provisions former OpenAI employees are subject to. It forbids them, for the rest of their lives, from 
criticizing their former employer. Even acknowledging that the NDA exists is a violation of it.                       If a 
departing employee declines to sign the document, or if they violate it, they can lose all vested equity they earned 
during their time at the company, which is likely worth millions of dollars. One former employee, Daniel                       
Kokotajlo                       , who posted that he quit OpenAI “due to losing confidence that it would behave responsibly 
around the time of AGI”, has confirmed publicly that he had to surrender what would have likely turned out to be a 
huge sum of money in order to quit without signing the document.                     
Barely a day later, Altman said the clawback provisions “should never have been something we had in any 
documents”. He added: “we have never clawed back anyone’s vested equity, nor will we do that if people do not 
sign a separation agreement. this is on me and one of the few times I’ve been genuinely embarrassed running 
openai; i did not know this was happening and i should have.” (Capitalisation model’s own.)
Altman didn’t address the wider allegations, of a strict and broad NDA; and, while he promised to fix the clawback 
provision, nothing was said about the other incentives, carrot and stick, offered to employees to sign the exit 
paperwork.
Page 3 of 3
The people charged with making sure AI doesn’t destroy humanity have left the building
As set-dressing goes, it’s perfect. Altman has been a significant proponent of state and interstate regulation of AI. 
Now we see why it might be necessary. If OpenAI, one of the biggest and best-resourced AI labs in the world, 
which claims that safety is at the root of everything it does, can’t even keep its own team together, then what hope 
is there for the rest of the industry?
                                        Sloppy                                      
It’s fun to watch a term of art developing in front of your eyes. Post had junk mail; email had spam; the AI world has 
slop  :
                       “Slop” is what you get when you shove artificial intelligence-generated material up on the web for 
anyone to view.                       Unlike a chatbot, the slop isn’t interactive, and is rarely intended to actually answer 
readers’ questions or serve their needs.                       But like spam, its overall effect is negative: the lost time and 
effort of users who now have to wade through slop to find the content they’re actually seeking far outweighs the 
profit to the slop creator.                     
I’m keen to help popularise the term, for much the same reasons as Simon Willison, the developer who brought its 
emergence to my attention: it’s crucial to have easy ways to talk about AI done badly, to preserve the ability to 
acknowledge that AI can be done well.
The existence of spam implies emails that you want to receive; the existence of slop entails AI content that is 
desired. For me, that’s content I’ve generated myself, or at least that I’m expecting to be AI-generated. No one 
cares about the dream you had last night, and no one cares about the response you got from ChatGPT. Keep it to 
yourself.
                   The wider TechScape                                                               He was passed over by Nasa in 1961 to 
become the first Black astronaut. Now Ed Dwight, who is 90, finally reached space.                                                                  
The latest in China’s propaganda toolkit  ? The AI-generated news anchor.                                                                 
Where are the $1tn British tech titans ? Will Hutton on why Britain doesn’t have its own Microsoft or Alphabet.  It’s 
been almost a decade since I asked why there’s no “European Google” , and it’s interesting to note which things do 
and don’t hold up.                                                                                          Microsoft has asked hundreds of 
employees in China to relocate elsewhere, according to the Washington Post  (£), as tensions over AI between the 
US and China heat up.                                                                                          Google was once a portal to the 
internet. Now it is trying to be the internet.                                                                  And remember Belle Delphine, 
the social media star who made $90,000 selling jars of her bathwater online? Business Insider’s Katie Notopoulous 
has the story (£)  of how it took Delphine five years to finally get that hard-earned cash from PayPal.                                                         
Load-Date: June 28, 2024
End of Document
Page 1 of 3
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 'dumber'
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 
'dumber'
Daily Star Online
May 21, 2024 Tuesday 12:33 PM GMT
Copyright 2024 Northern and Shell Media Publications All Rights Reserved
Length: 760 words
Byline: By, Layla Nicholson
Highlight: EXCLUSIVE: Ahead of this weeks global virtual AI safety summit held in South Korea, tech expert Olivia 
DeRamus posed a stark warning for the future of the internet in the age of brainless bots
Body
A tech expert has warned that social media will soon be "full of AI bots" which will create a "zombie internet". 
Olivia DeRamus, known as the 'Elle Woods of tech', posed the chilling prediction as fellow gurus have banded 
together to share their grave concerns about the boom in AI and its exceeding advancement. 
The founder of Communia , a social media platform for women, feels that social media in particular is losing its 
'social' aspect as a surge of fakeness is threatening to impede on human connection. 
                     Check out the latest Exclusives from Daily Star                   
And she predicts that brainless bots will soon overwhelm social media as we know it. 
Speaking exclusively to Daily Star, Olivia warned: "People don't realise how many fake accounts there are, let alone 
content, on the internet.
"A national digital security expert once told me about half of social media accounts are fake. A 2023 study in Ireland 
showed that almost 1/3 of adults have fake social accounts. 
"Fakeness on today's mainstream social media platforms is nothing new, but the massive increase in casual AI 
generated content is certainly intensifying an issue that was already starting to come to a boil. 
"Authenticity is rare on today's internet, despite the millions of people who hope to use these very platforms to find 
it."

Page 2 of 3
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 'dumber'
Although many people seek socialisation through their screens, Olivia feels this will be made redundant in the near 
future as AI content surges onto every platform. 
From the deepfake Pope in a stylish puffer jacket to an 'World's first AI beauty pageant will set women back 100 
years – it's horrific'  to celebrate and reward some of the most 'beautiful' computer generated forms, reality is 
becoming more sparse on the platforms where people can communicate across the globe.
Earlier this year, Jason Koebler of tech news site, 404 Media, penned the term "zombie internet" in reference to the 
AI "slop" being produced on social media, reports The Guardian.  
He noted: "A mix of bots, humans and accounts that were once humans but aren’t any more mix together to form a 
disastrous website where there is little social connection at all."
Olivia fears the same, and shared that there is no going back once the "zombie internet" of brainless bots 
consumes all that is human and social.
The Communia founder shared: "I agree with this assessment about the oncoming zombie internet, and 
unfortunately there will be no deleting it once it happens.
"As the internet gets dumber, people are becoming more discerning and more disillusioned. 
"AI could be a great tool in gathering real people together and facilitating better experiences, but that's not the 
direction today's key tech platforms are taking.
"In that way, it looks like these companies are creating their own demise.
"That's a shame, but new platforms who see the need for human centred and meaningful connection, like 
Communia, are emerging and will likely continue to rise as long as we continue to pursue a different path. 
"The traditional motto in tech has been 'move fast and break things' under the misguided idea that you can delete 
the problems you create. That's just not true. 
"Once you post something, it's up forever, once you code something poorly, it's a mess to untangle."
Olivia now believes that the onus is on the big tech firms – like Meta and Google – to tackle the place AI has on 
their platforms.
Though, she is optimistic about the future of the digital world and hopes that her platform Communia can be a part 
of that. 
Although she is not anti-AI, she is against how AI is currently being pushed without "mindful implementation."
She concluded: "I am optimistic though that we can create a better digital world, but we might have to start from 
scratch to do it. 
"Every platform, from Meta to Google, is rushing to implement AI features in their haste to win the 'AI innovation 
wars'.
"This is happening alongside issues like misinformation tech firms were already struggling to appropriately address. 
"Can their new AI recommendation tools really decipher between AI generated content and content created by 
humans Or whether content with the most likes they'll then recommend is popular because of bot activity 
"I'm doubtful, and it seems likely that the fresh tools looking to dominate our feeds could just maximize existing 
problems. I'm not anti AI, I'm anti AI without mindful implementation. 
Page 3 of 3
Tech guru warns of 'zombie internet' flooded by AI bots that's making world 'dumber'
"Ultimately, I don't think big tech platforms are likely to robustly address these issues as long as they are generating 
revenue from what's currently in place."
Load-Date: June 28, 2024
End of Document
Page 1 of 3
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All 
In On AI
Forbes.com
May 20, 2024 Monday
Copyright 2024 Forbes LLC All Rights Reserved
Length: 1248 words
Byline: Richard Nieva, Forbes Staff
Highlight: Nearly 15 years after founding Quora, D Angelo wants to reinvent the question-and answer company 
around AI before it goes the way of Yahoo Answers.
Body
<figure>
<figcaption>
Quora CEO Adam D'Angelo
Augustin LE GALL/HAYTHAM-REA/Redux
</figcaption></figure>
 Can I show you a demo? Adam D Angelo says as he prepares to share his screen on Zoom.
The CEO of Quora is extolling the virtues of Poe, the company s platform for letting people chat with multiple AI 
models at a time. But during a test earlier that day for what should have been an easy task generating a logo design 
using my name the service had glitched. D Angelo is quick to jump into troubleshoot mode. (I probably hadn t set up 
Poe to access an image-generating model, he diagnoses.)
Last year, D Angelosaidat an AI event that most of the company s energy these days is devoted to Poe, a service 
the company launched last year that serves as an interface for using and comparing multiple AI models, as well as 
bots built on top of them. That means less energy on Quora, the nearly 15-year-old Q&A forum that D Angelo 
founded after leaving his post as Facebook s CTO. But D Angelo is so excited about AI s potential that he s gotten 
hands-on with the company s new product, which has its own URL, separate from Quora.
 Poe needs more of my attention because it's in this more rapidly changing landscape,  D Angelo toldForbes.  
Quora has been around for many years now. It doesn't need to adapt. It doesn't need to change every week.  
Quora s goals are quarterly, he said, whereas Poe s targets are set every two weeks.
The two products are vastly different. Quora is a message board where people answer questions like  What did 
Marilyn Monroecarry in her coffin?  and  What is the best small business tostart in Gambia?  Meanwhile Poe, which 
stands for  Platform for Open Exploration,  is a freemium $200 per year subscription service that gives people 

Page 2 of 3
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI
access to several models, including OpenAI s GPT-4, Anthropic s Claude and Google sGoogleGemini. With the 
service, users can sample multiple models at once, comparing how each one tackles the same prompt. Developers 
can build bots on top of those models, creating, for example, an AI focused specifically on travel booking or creating 
coloring books for school children. Those developers can get paid per query, adding another revenue stream for 
people building AI tools. D Angelo likens Poe to a web browser for AI, making the tech more accessible, like 
Netscape did three decades earlier.
  Poe needs more of my attention because it's in this more rapidly changing landscape.  <footer>Adam D 
Angelo</footer>
On its face, Poe and Quora don t seem connected. But D Angelo says Poe was born out of AI experiments the 
company began running two years ago, where it used OpenAI s GPT-3 to generate answers for Quora questions. 
They were not as good as human-written answers, but the company found that there was a sweet spot for AI-
generated answers: replies to niche questions that no human had ever written an answer for. Getting a lower quality 
AI answer was better than waiting around for a human to answer your question, he concluded. The experience 
resembled something more like private chat than an open forum, D Angelo realized, so the company set out to build 
that kind of service.
D Angelo s rallying of the company around Poe comes at a confounding time for Quora. Founded in 2010, it has 
become a venerable throwback to the late web 2.0 era, surviving where rivals like Yahoo Answers fizzled out. But it 
hasn t evolved into the modern era compared to competitors like Reddit, whichwent public in Marchand long ago 
became a cultural hub of the internet. That raises an interesting question: Who still uses Quora,really. It's hard to 
say, but the anecdotal evidence isn't great. Earlier this year, Slateproclaimed Quora dead. And on Quora itself, "Is 
quora dead" has been asked many times dating back to at least 2017. As onerespondent answered,  Maybe Quora 
[has] just run its course, sort of like Yahoo or MySpace."
D Angelo declined to comment on Quora s revenue, though the company says it gets 400 million users a month.
With Poe, a seemingly disparate product from Quora, the company s trajectory has gotten more murky. Is it a social 
forum backed by an advertising business model along the lines of Reddit, or is it going to become a player in AI? D 
Angelo says it s now poised for the latter. In January, the company announced $75 million in funding from 
Andreessen Horowitz to build out Poe.
  Maybe Quora just run its course, sort of like Yahoo or MySpace." <footer>Quora user</footer>
D Angelo has had an inside look at the explosion in generative AI over the last few years in part because he s been 
a board member at OpenAI since 2018, when it was still a nonprofit. But that also meant D Angelo was at the center 
of the AI universe during one of the most dramatic boardroom power struggles in recent history. In November, the 
ChatGPT maker s board fired CEO and founder Sam Altman, citing a lack of  candid  communication. The 
bombshell announcement set off a firestorm in Silicon Valley, and within five days, the board reversed course and 
rehired Altman. As part of the reinstatement, OpenAI replaced every board member except D Angelo.
Poe does have some overlap with OpenAI s GPT Store, a hub for customized AI bots that was announced less 
than two weeks before the ouster, leading to some speculation from industry observers about D Angelo s role in the 
coup. When asked about that speculation, D Angelo called it  conspiracy theories  and pointed to the public 
summary of an internal investigation which said that the board acted  within its broad discretion  to fire Altman. He 
declined further comment on any OpenAI-related questions.
Quora has dealt with other AI controversies, especially when it comes to machine-generated answers. Some users 
have complained that the quality of content of the site has degraded, becoming a mush of AI slop. Inone viral 
example, an AI-generated Quora answer stated that eggs could be melted. Google, which sources content from 
Quora in its answer boxes, then amplified the response.
D Angelo downplayed the criticism.  There's always room to do better on showing better answers,  he said.  
Sometimes it's not going to work well and people will be unhappy. But on average, we're quite confident that the AI 
answers have been a net positive to Quora. 
Page 3 of 3
Inside Quora s Quest For Relevance: Why CEO Adam D Angelo Has Gone All In On AI
While Poe has a distinct identity from Quora, D Angelo said that he never really considered starting a new company 
to follow his AI ambitions.  It was my full time job and I couldn't just leave and start another company,  he said.
Instead, D Angelo said he wanted to leverage the talent and structure he had already assembled at Quora, 
especially as the AI environment moves at a blistering speed. Plus, some of the original source code he wrote for 
Quora is built into Poe s foundation.  If it was a new startup, starting from scratch, you might spend the whole first 
year building up a team that good,  he said.  This was a technology wave and opportunity where we needed to 
move very, very fast. 
Now the plan is expansion. Building Poe was like  graduating  to becoming a two-product company, D Angelo 
toldForbes, akin to Google s first steps beyond web search. To get it done, the company needed to overcome the  
organizational inertia  it had built up over several years. But now that he s learned how to navigate that change, he 
doesn t want to stop there.
 It took a lot of willpower,  he said.  My expectation long term is we should not be only a two-product company. We 
should continue to build new products. 
MORE FROM FORBES
Load-Date: July 3, 2024
End of Document
Page 1 of 3
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
The Guardian (London)
May 19, 2024 Sunday 2:00 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: TECHNOLOGY; Version:1
Length: 921 words
Byline: Alex Hern and Dan Milmo
Highlight: Tech experts hope new term for carelessly automated AI webpages and images can illuminate its 
damaging impact
Body
Your email inbox is full of spam. Your letterbox is full of junk mail. Now, your web browser has its own affliction: 
slop.
“Slop” is what you get when you shove artificial intelligence-generated material up on the web for anyone to view. 
Unlike a chatbot, the slop isn’t interactive, and is rarely intended to actually answer readers’ questions or serve 
their needs.
Instead, it functions mostly to create the appearance of human-made content, benefit from advertising revenue and 
steer search engine attention towards other sites.
Just like spam, almost no one wants to view slop, but the economics of the internet lead to its creation anyway. AI 
models make it trivial to automatically generate vast quantities of text or images , providing an answer to any 
imaginable search query, uploading endless shareable landscapes and inspirational stories, and creating an army 
of supportive comments. If just a handful of users land on the site, reshare the meme or click through the adverts 
hosted, the cost of its creation pays off.
But like spam, its overall effect is negative: the lost time and effort of users who now have to wade through slop to 
find the content they’re actually seeking far outweighs the profit to the slop creator.
“I think having a name for this is really important, because it gives people a concise way to talk about the problem,” 
says the developer Simon Willison, one of the early proponents of the term “slop”.

Page 2 of 3
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
“Before the term ‘spam’ entered general use it wasn’t necessarily clear to everyone that unwanted marketing 
messages were a bad way to behave. I’m hoping ‘slop’ has the same impact – it can make it clear to people that 
generating and publishing unreviewed AI-generated content is bad behaviour.”
Slop is most obviously harmful when it is just plain wrong. Willison pointed to an AI-generated Microsoft Travel 
article that listed the “Ottawa food bank” as a must-see attraction in the Canadian capital as a perfect example of 
the problem. Occasionally, a piece of slop is so useless that it goes viral in its own right, like the careers advice 
article that earnestly explains the punchline to a decades-old newspaper comic: “they pay me in woims”.
“While the precise meaning of ‘They Pay Me in Woims’ remains ambiguous, various interpretations have emerged, 
ranging from a playful comment on work-life balance to a deeper exploration of our perceived reality,” the slop 
begins.
AI-generated books have become a problem too. A prominent example came when amateur mushroom pickers 
were recently warned to avoid foraging books  sold on Amazon that appeared to have been written by chatbots and 
contained dangerous advice for anyone hoping to discern a lethal fungus from an edible one.
Image-generated slop has also blossomed on Facebook, as images of Jesus Christ with prawns for limbs, children 
in plastic bottle-cars, fake dream homes and improbably old women claiming to have baked their 122nd birthday 
cake  garner thousands of shares.
Jason Koebler of the tech news site 404 Media believes the trend represents what he calls the “zombie internet”. 
The rise of slop, he says, has turned the social network into a space where “a mix of bots, humans and accounts 
that were once humans but aren’t any more mix together to form a disastrous website where there is little social 
connection at all.”
Nick Clegg, the president of global affairs at Facebook’s parent company, Meta, wrote in February that the social 
network is training its systems to identify AI-made content. “As the difference between human and synthetic content 
gets blurred, people want to know where the boundary lies,” he wrote.
The problem has begun to worry the social media industry’s main revenue source: the advertising agencies who 
pay to place ads next to content. Farhad Divecha, the managing director of UK-based digital marketing agency 
AccuraCast, says he is now encountering cases where users are mistakenly flagging ads as AI-made slop when 
they are not.
“We have seen instances where people have commented that an advert was AI-generated rubbish when it was 
not,” he says, adding that it could become a problem for the social media industry if consumers “start to feel they 
are being served rubbish all the time”.
Tackling spam in inboxes required an enormous cross-industry effort and led to a fundamental change in the nature 
of email. Big webmail providers like Gmail aggressively monitor their own platforms to crack down on spammers 
and are increasingly suspicious of emails arriving from untrusted email servers. They also apply complex, largely 
undocumented, AI systems to try to detect spam directly, in a constant cat-and-mouse game with the spammers 
themselves.
For slop, the future is less rosy: the world’s largest companies have gone from gamekeeper to poacher. Last week, 
Google announced an ambitious plan to add AI-made answers  to the top of some search results, with US-based 
users the first to experience a full rollout of the “AI Overviews” feature. It will include links as well, but users who 
want to limit the response to just a selection of links to other websites will be able to find them – by clicking through 
to “web” on the search engine, demoted to sit beside “images” and “maps” on the list of options.
“We’ve added this after hearing from some that there are times when they’d prefer to just see links to webpages in 
their search results,” wrote Danny Sullivan, the company’s search liaison.
Google says the AI overviews have strong safety guardrails. Elsewhere on the web though, slop is spreading.
Page 3 of 3
Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’
Load-Date: June 28, 2024
End of Document
Page 1 of 3
Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, City take Premier League
Morning Mail: Iran president in helicopter crash, family lawyers quit over 
burnout, City take Premier League
The Guardian (London)
May 19, 2024 Sunday 10:10 PM GMT
Copyright 2024 The Guardian, a division of Transcontinental Media Group Inc. All Rights Reserved
Section: AUSTRALIA NEWS; Version:1
Length: 1316 words
Byline: Charlotte Graham-McLay
Highlight: Want to get this in your inbox every weekday? Sign up for the Morning Mail here, and finish your day 
with our Afternoon Update newsletter
Body
Good morning. A Guardian Australia investigation reveals some family lawyers are leaving their practices or 
warning juniors to avoid entering the field, as they experience burnout and stress from a system that requires them 
to bill domestic violence survivors – sometimes for huge amounts for legal fees.
Meanwhile, a helicopter carrying the Iranian president and foreign minister has crashed. At the time of writing, 
rescuers were yet to reach the crash site and the condition of the passengers was not known. Our live blog has the 
latest. 
Plus: Manchester City have taken their fourth-in-a-row Premier League title.
                   Australia                                                                   Justice | “I couldn’t do it any more,” one family 
lawyer who has left the practice told Guardian Australia , echoing others’ stories. “I couldn’t bill people who I just 
knew couldn’t afford to pay it.”                                                                     Housing | Major Australian lenders are not 
doing enough to support mortgage customers in financial hardship , and in some cases they are ignoring requests 
for assistance altogether, the corporate regulator found.                                                                     Analysis | Peter 
Dutton’s policy-lite budget reply speech contained the seeds of campaigns  that will inevitably be deployed by the 
progressive side of politics on nuclear and wages, Paul Karp writes.                                                                     
Women | Scott Morrison said he and his government did everything they “possibly could have” for women  while he 
was prime minister, and called criticism of his actions a pile-on which was “weaponised for political purposes”.                                                                     
Solar | With newly installed solar panels on his roof, Guardian Australia’s Nick Miller gamified Australia’s power 
industry  – and learned just how weird and perverse it could be.                                                           World                                                                   
Iran | Search teams were looking for the downed helicopter that the Iranian president, Ebrahim Raisi, was travelling 

Page 2 of 3
Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, City take Premier League
in  when it vanished amid poor weather conditions and thick fog in Iran’s East Azerbaijan province.                                                                     
US presidency | Donald Trump flirted with the idea of being president for three terms  during a bombastic speech 
for the National Rifle Association. Meanwhile, the president, Joe Biden, renewed his pitch to Black voters  at a 
college graduation.                                                                     Europe’s far right | International far-right leaders, 
including France’s Marine Le Pen, Hungary’s Viktor Orbán, Italy’s Giorgia Meloni and Argentina’s Javier Milei, came 
together in Madrid to rail against socialism  and “massive illegal migration” three weeks before hard-right parties are 
expected to see a surge in support in European elections.                                                                     Sean Combs | 
The rap mogul Sean “Diddy” Combs admitted in a video apology that he punched and kicked his ex-girlfriend  
Cassie in 2016 in the hallway of a hotel after CNN released footage of the attack, saying he was “truly sorry” and 
his actions were “inexcusable”.                                                                     Rocket man | Sixty-one years since he 
was selected but ultimately passed over to become the first Black astronaut, Ed Dwight finally reached space in a 
Blue Origin rocket  – and, at 90, is the oldest person to arrive at the edge of space.                                                           
Full Story                   
                     Gaza through the eyes of two Australian doctors                   
Last month, two Australian doctors spent two weeks in Gaza treating countless injured Palestinians. Surgeon 
Sanjay Adusumilli and general practitioner Siraj Sira tell Nour Haydar why they left Sydney to volunteer in the 
besieged territory , the pain they witnessed and the feelings of guilt on their return.
                     Read our latest on Gaza: The United Nations’ humanitarian chief warned of “apocalyptic” 
consequences due to aid shortages in Gaza , where Israel’s military offensive in the southern city of Rafah has 
blocked desperately needed food.
                   In-depth                   
She is the real-life Lady Whistledown, an eyebrow-raising female writer – anti-racist and proto-feminist – who 
penned a salacious weekly anonymous gossip sheet that skewered 18th-century London society.
Like the fictional pamphlet from Netflix hit Bridgerton, which returned for a third series last week, Eliza Haywood’s 
The Parrot, published in 1746, has a distinctive, mocking voice that punches up and “speaks truth to power”. Now, a 
new book will republish Haywood’s funny, subversive periodical , which she wrote from the perspective of an angry 
green parrot.
                   Not the news                   
Your email inbox is full of spam. Your letterbox is full of junk mail. Now, your web browser has its own affliction: 
slop. “Slop” is what you get when you shove artificial intelligence-generated material up on the web for anyone to 
view. Experts hope the unpalatable name will help herald its harms.
It might be bizarrely incorrect information on a website, or dangerously incorrect books on Amazon (where you 
apparently shouldn’t buy mushroom-foraging books written by machines). Or just downright cursed images on 
social media (sorry).
Alex Hern and Dan Milmo investigate why all this AI slop is filling the zombie internet. 
                   The world of sport                                                                   Premier League | Manchester City beat 
West Ham 3-1  to win their fourth Premier League title in a row. Here’s our play-by-play commentary.  Arsenal were 
denied the title despite a late 2-1 victory over Everton.                                                                      AFL | Essendon 
left middle of the road behind  as their “edge” led them to the second spot, Jonathan Horn writes for Sportblog.                                                                     
Formula One | Max Verstappen held off Norris  to win the Emilia Romagna Grand Prix.                                                           
Media roundup                   
Page 3 of 3
Morning Mail: Iran president in helicopter crash, family lawyers quit over burnout, City take Premier League
According to The Australian ’s Newspoll, a ­ record low number of people  have judged Jim Chalmers’ third budget 
as good for the economy. Hundreds of homes in Melbourne were suddenly deemed flood-prone  and residents 
want answers, the Age reports. The Courier Mailinvestigates kids’ addiction  to social media and gaming.
                   What’s happening today                                                                   Cold case | The Queensland coroner 
will deliver his findings from the inquest into the 1986 disappearance of Sharron Phillips.                                                                     
AI | A public hearing is scheduled for the senate select committee on adopting artificial intelligence.                                                            
Sign up                   
If you would like to receive this Morning Mail update to your email inbox every weekday, sign up here.  And finish 
your day with a three-minute snapshot of the day’s main news. Sign up for our Afternoon Update newsletter here. 
Prefer notifications? If you’re reading this in our app , just click here and tap “Get notifications” on the next screen  
for an instant alert when we publish every morning.
                   Brain teaser                   
And finally, here are the Guardian’s crosswords to keep you entertained throughout the day. Until tomorrow. 
Quick crossword Cryptic crossword
Load-Date: June 28, 2024
End of Document
Page 1 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
Google is bringing back classic search, with no AI – and I couldn't be 
happier about that
TechRadar (UK)
May 19, 2024 Sunday 4:30 PM EST
Copyright 2024 Future Publishing Ltd  All Rights Reserved
Section: TECH LATEST, TECH LATEST & SEARCH ENGINES NEWS
Length: 926 words
Byline: Christian Guyton
Body
Editors note: TechRadar makes some of its revenue via the use of affiliate links to products and services on retailer 
sites on certain pages, for which we can receive compensation if you click on those links or make purchases 
through them. Many readers of those pages reach us through Google search, so we therefore have a vested 
interest in the topics discussed within this article.
Google Search has undergone many, many changes over the years – some big, some small, but every single one 
shifting the iconic internet search engine further and further away from its original form.
You can see an interactive timeline of Google Search on Googles own website, if youre curious about how its 
evolved over the years. Some of these additions – such as the Did you mean...? suggestions for typos and the 
inclusion of new search modes including image, news, and video – were obvious slam-dunks for Google, improving 
the versatility and functionality of its search engine. Others, like the inevitable arrival of sponsored ads in results 
and the recent AI-powered Search Generative Experience (SGE), have been... less popular.
Well, Google has seemingly done the unimaginable: its released a new web setting for the search engine that will 
take you back to the glory days of Google Search in the year 2000, surfacing only a list of text-based links. Thats 
right – no images, no shopping results, and no AI-generated answers.
A more perfect search engine
The web mode has been rolled out globally and should be accessible for everyone now; youll find it under the More 
option at the top of the results, below the search bar itself. 
Unsurprisingly, its been met with riotous applause on social media. Commenters on Twitter (cough, X) lauded 
Google for the change, with many remarking that this is exactly what they want from a search engine.

Page 2 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
We’ve launched a new “Web” filter that shows only text-based links, just like you might filter to show other types of 
results, such as images or videos. The filter appears on the top of the results page alongside other filters or as part 
of the “More” option, rolling out today… pic.twitter.com/tIUy9LNCy5May 14, 2024
See more
Its a little sad that Googles decision to turn back time on its most-used product has seen such a positive response, 
and its no doubt been done to counter any potential backlash from the gradual rollout of SGE. The AI-powered 
search tool will use machine learning to scrape the internet for relevant data and provide an AI-generated response, 
which may prove helpful to some users but which poses a significant threat to online media and information outlets.
Its worth noting that the web search view does still include sponsored text links, but I suppose we cant have it all. 
Personally, Im massively happy to see this change – not only do I prefer to do my own reading rather than receive 
AI-generated slop from my online searches, but as a digital journalist, I have a vested interest in Google keeping 
search simple.
The perils of AI in search
See, Googles SGE experiment is one I fear may be doomed to fail – specifically because it might end up 
consuming itself. SGE is undeniably a powerful tool that can provide a neat summary of the information users are 
looking for, but it needs content written by humans to do that.
An example Google gave back when SGE was first unveiled was the query best Bluetooth speaker for a pool party. 
Sure enough, SGE produced a list of suggested products with links to both retailers and sites reviewing the 
recommended speakers.
Now, we naturally have our own article ranking the best Bluetooth speakers, as do many other tech news sites. We 
have literally hundreds of buying guides, and keeping those up-to-date with useful information for consumers is a lot 
of work, but its work were happy to do, since it pays our bills and ultimately helps consumers find what they actually 
need to know – you know, the whole reason TechRadar exists as a site.
But if SGE takes over, all the affiliate and ad revenue made by us – and every other site making product 
recommendations out there – threatens to evaporate. 
If that happens, well pivot: the journalism industry has always been on the cutting edge, ready and able to adapt to 
the challenges of a constantly shifting media landscape. So yes, well find a new way to reach our readers, whether 
directly, via newsletters, social media, subscriptions or whatever other methods appear in the forthcoming years. 
However, if surfacing all those buying guides, recipes, and top-10 lists within Google search becomes pointless to 
the sites making them, many may choose to stop Googles bot from crawling them, or at the very least from using 
them to train its LLMs. And if that happens then Googles AI will steadily become less and less relevant and helpful 
in its SGE suggestions as its fuel source dries up.
I know this sounds like whining. Oh no, Google is going to kill our profitability! But that doesnt mean its not a 
problem. Google has potentially created a new version of online searches that will self-destruct if it becomes 
successful.
In other words, Im delighted to see web search make a heroic return in this time of AI uncertainty. After all, Im not 
going to start using Bing…
You might also like...
• Google is expanding its experiment of AI-generated answers ahead of search results to the UK - a new go-
to for answers or a misstep?
Page 3 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
• Google Search could soon charge you for AI-powered results – and search engines might never be the 
same
• Apple secretly working on Google Search killer for 'years,' probably won't ever launch
Load-Date: May 20, 2024
End of Document
Page 1 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
Google is bringing back classic search, with no AI – and I couldn't be 
happier about that
TechRadar
May 19, 2024 Sunday
Copyright 2024 TBREAK MEDIA Provided by Syndigate Media Inc. All Rights Reserved
Length: 943 words
Byline: christian.guyton@futurenet.com,  (Christian Guyton)
Body
Editor's note: TechRadar makes some of its revenue via the use of affiliate links to products and services on retailer 
sites on certain pages, for which we can receive compensation if you click on those links or make purchases 
through them. Many readers of those pages reach us through Google search, so we therefore have a vested 
interest in the topics discussed within this article.
Google Search has undergone many, many changes over the years – some big, some small, but every single one 
shifting the iconic internet search engine further and further away from its original form.
You can see an interactive timeline of Google Search on Google's own website, if you're curious about how it's 
evolved over the years. Some of these additions – such as the 'Did you mean...?' suggestions for typos and the 
inclusion of new search modes including image, news, and video – were obvious slam-dunks for Google, improving 
the versatility and functionality of its search engine. Others, like the inevitable arrival of sponsored ads in results 
and the recent AI-powered 'Search Generative Experience' (SGE), have been... less popular.
Well, Google has seemingly done the unimaginable: it's released a new 'web' setting for the search engine that will 
take you back to the glory days of Google Search in the year 2000, surfacing only a list of text-based links. That's 
right – no images, no shopping results, and no AI-generated answers.
A more perfect search engine
The 'web' mode has been rolled out globally and should be accessible for everyone now; you'll find it under the 
'More' option at the top of the results, below the search bar itself.
Unsurprisingly, it's been met with riotous applause on social media. Commenters on Twitter (cough, X) lauded 
Google for the change, with many remarking that this is exactly what they want from a search engine.

Page 2 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
We've launched a new "Web" filter that shows only text-based links, just like you might filter to show other types of 
results, such as images or videos. The filter appears on the top of the results page alongside other filters or as part 
of the "More" option, rolling out today… pic.twitter.com/tIUy9LNCy5May 14, 2024
See more
It's a little sad that Google's decision to turn back time on its most-used product has seen such a positive response, 
and it's no doubt been done to counter any potential backlash from the gradual rollout of SGE. The AI-powered 
search tool will use machine learning to 'scrape' the internet for relevant data and provide an AI-generated 
response, which may prove helpful to some users but which poses a significant threat to online media and 
information outlets.
It's worth noting that the web search view does still include sponsored text links, but I suppose we can't have it all. 
Personally, I'm massively happy to see this change – not only do I prefer to do my own reading rather than receive 
AI-generated slop from my online searches, but as a digital journalist, I have a vested interest in Google keeping 
search simple.
The perils of AI in search
See, Google's SGE experiment is one I fear may be doomed to fail – specifically because it might end up 
consuming itself. SGE is undeniably a powerful tool that can provide a neat summary of the information users are 
looking for, but it needs content written by humans to do that.
An example Google gave back when SGE was first unveiled was the query 'best Bluetooth speaker for a pool 
party'. Sure enough, SGE produced a list of suggested products with links to both retailers and sites reviewing the 
recommended speakers.
Now, we naturally have our own article ranking the best Bluetooth speakers, as do many other tech news sites. We 
have literally hundreds of buying guides, and keeping those up-to-date with useful information for consumers is a lot 
of work, but it's work we're happy to do, since it pays our bills and ultimately helps consumers find what they 
actually need to know – you know, the whole reason TechRadar exists as a site.
But if SGE takes over, all the affiliate and ad revenue made by us – and every other site making product 
recommendations out there – threatens to evaporate.
If that happens, we'll pivot: the journalism industry has always been on the cutting edge, ready and able to adapt to 
the challenges of a constantly shifting media landscape. So yes, we'll find a new way to reach our readers, whether 
directly, via newsletters, social media, subscriptions or whatever other methods appear in the forthcoming years.
However, if surfacing all those buying guides, recipes, and top-10 lists within Google search becomes pointless to 
the sites making them, many may choose to stop Google's bot from crawling them, or at the very least from using 
them to train its LLMs. And if that happens then Google's AI will steadily become less and less relevant and helpful 
in its SGE suggestions as its fuel source dries up.
I know this sounds like whining. 'Oh no, Google is going to kill our profitability!' But that doesn't mean it's not a 
problem. Google has potentially created a new version of online searches that will self-destruct if it becomes 
successful.
In other words, I'm delighted to see 'web search' make a heroic return in this time of AI uncertainty. After all, I'm not 
going to start using Bing…
You might also like...
Google is expanding its experiment of AI-generated answers ahead of search results to the UK - a new go-to for 
answers or a misstep?
Page 3 of 3
Google is bringing back classic search, with no AI – and I couldn't be happier about that
Google Search could soon charge you for AI-powered results – and search engines might never be the same
Apple secretly working on Google Search killer for 'years,' probably won't ever launch
 Future Publishing Limited Quay House, The Ambury, Bath BA1 1UA.
Load-Date: May 19, 2024
End of Document
Page 1 of 2
How to spot deepfake videos and photos
How to spot deepfake videos and photos
USA Today
April 10, 2024 Wednesday
1 Edition
Copyright 2024 USA Today All Rights Reserved
Section: BUSINESS; Pg. B3
Length: 710 words
Body
There was the deepfake audio robocall of President Joe Biden telling you to hold your vote. And just last week, a 
phony video of Donald Trump with Black voters made the rounds.
AI deepfakes are a massive problem this election season, and it's easy to get taken - especially when your news 
and social feeds are full of this junk.
By the way, you're not alone if you have been fooled. Nearly two-thirds of people can't tell the difference between 
artificial intelligence-generated images and voices and the real thing, according to a study by the University of 
Aberdeen in Scotland. Those are awful odds. Here are some rules of thumb to protect your vote:
'Viral' doesn't mean 'verified'
Almost all of the AI-generated slop online is peddled for clicks on social media, not published by major news 
outlets. These publications still get tripped up, of course, but it's rare.
I'm all for citizen journalism, but when it comes to our elections, stick to publications you know you can trust. Be 
wary of anonymous accounts that post without a legitimate person or organization attached to them.
If it's some random person on Facebook you've never heard of, do your homework before you hit share.
Look for other coverage
Scammers can put together a convincing image or video, but they can't fake the context. When Biden or Trump 
says something, I promise it will be reported a hundred times and recorded from 20 angles - especially if it's 
outlandish.
If you can only find one source for something, your internal AI detector should go off. Use Google Fact Check 
Explorer, VerifyThis, or Snopes to double-check.
Pro tip: Search related keywords on Google and social media platforms like YouTube, TikTok and Instagram. If 
you're struggling with ways to search, you can even take screenshots of critical parts of the video and do a reverse 
image search.

Page 2 of 2
How to spot deepfake videos and photos
Slow down
We're all busy and we're all in a hurry, but it's worth slowing down - especially if something makes you feel 
something big. Deepfakes are often created with emotion in mind. The point is to make you mad, sad, or scared 
enough to share.
When it comes to political figures, pay attention to mannerisms. They're as unique as fingerprints. President Barack 
Obama's signature head lift and slight frown were present whenever he'd say, "Hi, everybody" in his weekly 
addresses. If the star of a video seems like an impersonator, they  could be.
Use this AI image checklist
Election fakes are particularly tricky to spot because there's so much public footage of politicians speaking in front 
of similar backgrounds to copy. But you can still use these guidelines to verify if it's AI or not:
Backgrounds: A vague, blurred background, smooth surfaces, or lines that don't match up are immediate red flags 
that an image is AI-generated.
Context: Use your head - if the scenery doesn't align with the current climate, season or what's physically possible, 
that's because it's fake.
Proportions: Check for objects that look mushed together or seem too large or small. The same goes for features, 
especially ears, fingers and feet.
Angle: Deepfakes are the most convincing when the subject is facing the camera directly. Once a person starts to 
turn to the side and move, glitches may appear.
Text: AI can't spell. Look for fake words on signs and labels.
Chins: Yep, you heard me. The lower half of the face is the No. 1 giveaway on AI-generated candidate videos. It's 
subtle, but check to see if their chin or neck moves unnaturally or in an exaggerated way.
Fingers and hands: Look for weird positions, too many fingers, extra-long digits, or hands out of place.
If you spot it, don't spread it
I get that some of these images and videos are shocking or even hilarious - but they're putting our elections at risk. 
Don't contribute to the "Great American Fake-Off." If you're going to share something you know is AI-generated, call 
it out clearly in your text or post. Really, you're better off not sharing it at all.
Learn about all the latest technology on the Kim Komando Show, the nation's largest weekend radio talk show. Kim 
takes calls and dispenses advice on today's digital lifestyle, from smartphones and tablets to online privacy and 
data hacks. For her daily tips, free newsletters and more, visit her website.
Tech Talk
Kim Komando
Load-Date: April 10, 2024
End of Document
Page 1 of 2
Don't be fooled by deepfake videos and photos this election cycle. Here's how to spot AI
Don't be fooled by deepfake videos and photos this election cycle. Here's 
how to spot AI
USA Today Online
April 4, 2024
Copyright 2024 Gannett Media Corp  All Rights Reserved
Section: TECH LATEST
Length: 754 words
Byline: Kim Komando
Body
There was the deepfake audio robocall of President Joe Biden telling you to hold your vote. And just last week, a 
phony video of Donald Trump with Black voters made the rounds.
AI deepfakes are a massive problem this election season, and it’s easy to get taken – especially when your news 
and social feeds are full of this junk.
By the way, you’re not alone if you have been fooled. Nearly two-thirds of people can’t tell the difference between 
artificial intelligence-generated images and voices and the real thing, according to a study by the University of 
Aberdeen in Scotland. Those are awful odds. Here are some rules of thumb to protect your vote:
I send smart, actionable tech news and tips like this daily. Join 500K folks and get the Current. It’s free!
‘Viral’ doesn’t mean ‘verified’
Almost all of the AI-generated slop online is peddled for clicks on social media, not published by major news 
outlets. These publications still get tripped up, of course, but it's rare.
I’m all for citizen journalism, but when it comes to our elections, stick to publications you know you can trust. Be 
wary of anonymous accounts that post without a legitimate person or organization attached to them.
If it’s some random person on Facebook you’ve never heard of, do your homework before you hit share.
Look for other coverage
Scammers can put together a convincing image or video, but they can't fake the context. When Biden or Trump 
says something, I promise it will be reported a hundred times and recorded from 20 angles – especially if it’s 
outlandish.
￿ If you can only find one source for something, your internal AI detector should go off. Use Google Fact Check 
Explorer, VerifyThis, or Snopes to double-check.

Page 2 of 2
Don't be fooled by deepfake videos and photos this election cycle. Here's how to spot AI
Pro tip: Search related keywords on Google and social media platforms like YouTube, TikTok and Instagram. If 
you’re struggling with ways to search, you can even take screenshots of critical parts of the video and do a reverse 
image search.
Slow down
We’re all busy and we’re all in a hurry, but it’s worth slowing down – especially if something makes you feel 
something big. Deepfakes are often created with emotion in mind. The point is to make you mad, sad, or scared 
enough to share.
When it comes to political figures, pay attention to mannerisms. They’re as unique as fingerprints. President Barack 
Obama’s signature head lift and slight frown were present whenever he’d say, “Hi, everybody” in his weekly 
addresses. If the star of a video seems like an impersonator, they very well could be.
When in doubt, use this AI image checklist
Election fakes are particularly tricky to spot because there’s so much public footage of politicians speaking in front 
of similar backgrounds to copy. But you can still use these guidelines to verify if it’s AI or not:
￿ Backgrounds: A vague, blurred background, smooth surfaces, or lines that don’t match up are immediate red 
flags that an image is AI-generated.
￿ Context: Use your head – if the scenery doesn’t align with the current climate, season or what’s physically 
possible, that’s because it’s fake.
￿ Proportions: Check for objects that look mushed together or seem too large or small. The same goes for 
features, especially ears, fingers and feet.
￿ Angle: Deepfakes are the most convincing when the subject is facing the camera directly. Once a person starts 
to turn to the side and move, glitches may appear.
￿ Text: AI can’t spell. Look for fake words on signs and labels.
￿ Chins: Yep, you heard me. The lower half of the face is the No. 1 giveaway on AI-generated candidate videos. 
It’s subtle, but check to see if their chin or neck moves unnaturally or in an exaggerated way.
￿ Fingers and hands: Look for weird positions, too many fingers, extra-long digits, or hands out of place.
If you spot it, don’t spread it
I get that some of these images and videos are shocking or even hilarious – but they’re putting our elections at risk. 
Don’t contribute to the “Great American Fake-Off.” If you’re going to share something you know is AI-generated, call 
it out clearly in your text or post. Really, you’re better off not sharing it at all.
Learn about all the latest technology on the Kim Komando Show, the nation's largest weekend radio talk show. Kim 
takes calls and dispenses advice on today's digital lifestyle, from smartphones and tablets to online privacy and 
data hacks. For her daily tips, free newsletters and more, visit her website. 
This article originally appeared on USA TODAY: Don't be fooled by deepfake videos and photos this election cycle. 
Here's how to spot AI
Load-Date: April 4, 2024
End of Document
Page 1 of 3
An AI-generated rat with a giant penis highlights a growing crisis of fake science that's plaguing the publishing 
business
An AI-generated rat with a giant penis highlights a growing crisis of fake 
science that's plaguing the publishing business
Business Insider
March 18, 2024 Monday 09:37 PM EST
Copyright 2024 Insider Inc. All Rights Reserved
Length: 944 words
Byline: mmcfalljohnsen@businessinsider.com (Morgan McFall-Johnsen)
Highlight: Fake science can make it into reputable journals, due to the pressures of the publishing business. Take 
this AI-generated rat penis, for instance.
Body
• An AI-generated image of a rat with a towering phallic appendage went semi-viral last month.
• The nonsense diagram appeared in a now-retracted scientific paper, published in a Frontiers journal.
• This rat is a symptom of a crisis of fakes in the career-driven business of research publishing.
This rat has an enormous "dck," and it's a symptom of a bigger problem.
You don't need to be a scientist to know that rats don't have bulbous, sky-high penises, or that words like 
"testtomcels," "retat," and "dissilced," are total gibberish.
And yet, the bogus diagram below appeared in a paper published last month by the scientific journal Frontiers in 
Cell Development and Biology.
To its credit, the journal quickly retracted the paper. But its AI-generated images had already gone viral in online 
science communities. They even got their own page on Know Your Meme.
But this rat's towering phallus is just one symptom of a crisis of fake science.
"If it's the first time you've seen a really weird paper get published, I can see why it would capture your attention," 
Ivan Oransky, a co-cofounder of the watchdog journalism site Retraction Watch, told Business Insider. But for him, 
he said, "it's all sort of mind-numbingly routine at this point."
How bad science and weird AI get through the 'Swiss cheese' of peer review

Page 2 of 3
An AI-generated rat with a giant penis highlights a growing crisis of fake science that's plaguing the publishing 
business
Frontiers is an influential, open-access publisher with a peer-review process. So how did this paper make it to 
publication?
When a publisher like Frontiers accepts a scientist's manuscript, the paper passes through the critical eyes of a 
series of peer reviewers who are experts in the subject matter, as well as editors who assess the peer review. 
Usually, study authors must make changes based on the reviewers' feedback before publication.
Think of the peer review process like a stack of Swiss cheese. Each step has holes in it that bad science could 
squeeze through, but the overlapping steps tend to cover each other's holes, making it difficult to squeeze all the 
way through the whole process.
Still, bad science does make it through sometimes, and over the years more holes have opened up. Scientists can 
now buy made-up papers from paper mills.
There's even precedent for AI slop in science publishing. In 2014, publishers Springer and IEEE retracted more 
than 120 articles that were gibberish generated by computers. The publishing giant Springer Nature retracted 44 
gibberish papers in 2021.
Then there are more traditional forms of scientific fraud - bribing journal editors, falsifying data, or manipulating real 
images or data.
These bad practices can have real consequences. Early trials that found ivermectin or hydroxychloroquine to be 
promising COVID-19 treatments were later retracted for signs of fraud, but the word was already out and a wave of 
ill-informed self-treatment ensued, Vox reported. Even beyond COVID, fabricated studies can end up in databases 
used for drug research, The Guardian reported.
The mysterious case of the 'retat' 'dck'
In the case of the rat with "testtomcels," Frontiers says that one of the peer reviewers raised concerns about the 
images and requested that the paper authors revise them.
"The article slipped through the author compliance checks that normally ensures every reviewer comment is 
addressed," Fred Fenter, chief executive editor of Frontiers, said in an additional statement emailed to Business 
Insider, calling it a "human error."
He said that Frontiers has added "new checks to catch this form of misconduct," revised its AI policy to be clear 
about what's not allowed, and is developing "AI to detect AI-generated content and images."
"Those bad faith actors using AI improperly in science will get better and better and so we will have to get better 
and better too. This is analogous to cybersecurity constantly improving to block new tricks of hackers," Fenter said.
In January, Frontiers announced plans to lay off 30% of its staff, cutting 600 jobs.
"Quality is our highest priority, and the recent restructuring does not affect the peer review process and/or author 
compliance checks," Fenter said.
The retracted paper's corresponding author, Dingjun Hao, did not respond to Business Insider's request for 
comment.
Why some scientists publish bad papers
Journals are businesses, and scientists have careers. Both are under intense pressure to publish often.
Page 3 of 3
An AI-generated rat with a giant penis highlights a growing crisis of fake science that's plaguing the publishing 
business
Most hiring and tenure committees, Oransky says, evaluate researchers based on how many papers they've 
published, whether they've been published in prestige journals, and how much other scientists cite their work.
"People are desperate to publish and will do anything they have to do in order to publish and keep their jobs or get 
promoted," Oransky said. "That's the real problem here."
Last year, research journals retracted over 10,000 scientific papers, more than ever before, according to a report in 
the journal Nature.
Retractions aren't all bad. In fact, they're necessary for the times when peer review fails to catch data errors or 
irresponsible practices.
But the record retraction rate comes alongside a rise in sham papers that some scientists hastily fabricate or 
generate with the help of AI.
"It's salacious," Oransky said of the rat and its "dck." But, he continued, "there's sort of nothing new under the sun."
To Oransky, the solution is obvious. Science institutions across the planet should evaluate scientists based on the 
quality, not the breadth, of their work. His suggested evaluation metric? Show three good papers.
"What we need to do is stop using publications and citations as the metric of everything," he said. "All of that's 
game-able. Three good papers is not game-able."
Read the original article on
Business Insider
Load-Date: December 2, 2024
End of Document
Page 1 of 3
AI is now supercharging Google Assistant
AI is now supercharging Google Assistant
Quartz
February 8, 2024 Thursday 2:08 PM EST
Copyright 2024 G/O Media Inc.  All Rights Reserved
Section: TECH LATEST & GOOGLE NEWS
Length: 1249 words
Byline: Thomas Germain / Gizmodo
Body
Link to Image
If you felt an earthquake just now, it might have been Google's latest announcement. In one of the biggest updates 
in Google's history, the company unleashed the full version of its next-generation AI model Gemini. Google is 
changing its chatbot's name from Bard to Gemini, releasing a dedicated Gemini mobile app, and launching a 
premium AI subscription service. The news that will have the biggest effect on your life, however, is that the 
company just added Gemini to Google Assistant. Starting now, millions of people will be having voice conversations 
with one of the most powerful AI models on the market. 
"Every launch is big, but this one is the biggest yet," said Sissie Hsiao, Vice President of Gemini Experiences and 
Google Assistant, speaking at a press conference. "For Google, Gemini is more than just the models. It's really a 
shift in how we think about the state of the art technology and the entire ecosystem that we're building on it, from 
products that affect billions of users to the APIs and platforms that developers and businesses use to innovate."
The Gemini mobile app is available now on Android devices, and the company added Gemini to the Google app on 
iOS. If you want to use Gemini Ultra, the company's most powerful AI, you can sign up for a plan that costs $19.99 
a month. And across Google's services, almost everything AI is called Gemini now. It's a major shift in how the 
company wants to be perceived.
Until now, Google kept its chatbot technology sequestered from the general public. You could only use Bard (the 
chatbot Google just renamed Gemini) if you went to a special website, and the company went out of its way to call 
all of its AI tools "experimental." After almost a year of caution, it seems Google is finally ready to stand behind its 
AI products-for the most part.
Bard's new name is Gemini, and it finally has a voice.

Page 2 of 3
AI is now supercharging Google Assistant
Google is still worried about forcing AI on users, so for now, you have to seek Gemini out. But Google's AI is at 
your fingertips like never before. If you opt-in, you'll be able to call up Gemini on Android devices by saying "Hey 
Google" or hitting the power button on certain phones, the same way you interact with Assistant.
It's hard to overstate what a massive shift it is for Google to give Gemini a voice, both from a computing perspective 
and in terms of the ways it will change your parasocial relationship with the internet's most powerful corporation. 
That has strange ramifications. Google has a personality now, and you can chit-chat with the company in a brand-
new way. Of course, you're not actually talking to Google, but that's what it's going to feel like. You've been able to 
"speak" with Google through Assistant for almost a decade, but its canned responses never felt like a real 
conversation. Now, Google is ready to talk. 
We asked Hsiao whether Gemini has a sense of humor, and what its personality is like. She said people find 
Gemini "delightful," but didn't give any specifics. 
Assistant still exists, and if you don't like the change you can keep the old version. But it seems likely that Google's 
long-term plan is to replace Assistant with Gemini altogether. Apple is on a similar path. Widespread rumors claim 
that the upcoming iOS 18, due later this year, will include a major revamp that adds AI to Siri.
Bard isn't the only product that just got a rebrand. Duet AI-an AI tool that will help you with writing and other tasks in 
apps such as Gmail, Docs, Meet, and Drive-will soon be called Gemini as well. Google didn't give a timeline for that 
change. 
Amusingly, Gemini may not realize it has a new name. 
"Self-awareness is something that the models struggle with," Hsiao said. "So, on Thursday, if you ask 'what's your 
name?' It may still answer, 'I am Bard.' We're working on fixing that." It's a testament to the fact that, to a certain 
extent, AI is still a tool that's not in humanity's control. 
Google's new Gemini Ultra costs $19.99 a month.
Google unveiled Gemini in December, but you could only use Gemini Pro, the basic and less powerful tier. Now 
consumers finally get access to Gemini Ultra-for a price. 
According to Google, Gemini Ultra is the most advanced AI on the market. The company says Gemini Ultra is the 
first AI model to outperform human experts on a standardized test called MMLU (massive multitask language 
understanding), which measures an AI's knowledge and problem-solving capabilities in a combination of 57 
subjects such as math, physics, history, law, medicine, and ethics.
Google's new AI business is shaped a lot like ChatGPT. The free version of Gemini runs on the basic Gemini Pro 
model, just like the free ChatGPT tier runs on GPT-3.5. If you want the full capabilities of Gemini Ultra, it costs 
$19.99 a month, a penny shy of what OpenAI charges for GPT-4.
Gemini Ultra comes with other perks as well. It's now rolled up into a new premium tier of Google One, the 
subscription service that gives you more storage and other perks. Gemini Ultra comes as part of the new Google 
One AI Premium plan, which includes all the perks of the 2-terabyte storage plan. You can try a free two-month trial 
if you want a preview. (If you don't want AI, the regular 2 TB plan still costs $9.99 a month.)
Your phone is an AI device now.
With Gemini on your phone, you're now carrying around a full-fledged AI device. That's probably less exciting than 
it sounds (if it sounds exciting at all). At this point, large language models like Gemini and ChatGPT can be good for 
basic writing tasks, brainstorming, generating images, coding, and not a ton more. But it's a preview of a new era of 
computing that's going to unfold in the next few months, and there will be immediate consequences that are subtle 
at first.
Page 3 of 3
AI is now supercharging Google Assistant
For example, the web is already getting filled up with AI-generated garbage text and images. That problem is about 
to get supercharged. Yesterday, if you wanted to create AI content, you had to want it badly enough to pull up a 
special app or website. That's not a huge barrier to entry, but it's enough of an inconvenience to save us from at 
least some of humanity's worst AI-driven impulses. Now, the prospect of making your own AI slop is one "OK 
Google'' away.
You'll be getting a lot of text and emails written by Gemini, and you'll probably see a lot more graphic AI 
hallucinations. Across the board, the world is going to fill with more AI slop than ever before.
But there will be positive consequences too. Throughout the history of computers, you had to translate your 
thoughts, desires, and intentions into the language of machines, learning your device's predetermined commands 
and fiddling around with swipes and double clicks. The more integrated your phone becomes with AI chatbots, the 
closer we get to a world where our machines understand our intentions as well as our friends (or something close to 
it).
The holy grail is that-someday-you'll be able to ask your phone to perform any of its various tasks with your voice 
and it will understand you, in most cases, no matter how you phrase your request. And that's just the vision that's 
clear from where we stand today; a revolution in computing means people will create apps and functions and 
processes that are difficult to imagine at this point. That's all a far-off dream, but Google just brought us one step 
closer. And if there's anything we've learned from the last 18 months of AI madness, it's that the future is a lot 
closer than it seems. 
This article originally appeared on Gizmodo.
Load-Date: February 8, 2024
End of Document
Page 1 of 7
The Cult of AI
The Cult of AI
Rolling Stone
January 27, 2024
Copyright 2024 Penske Media Corporation All Rights Reserved
Length: 3882 words
Byline: Robert Evans
Body
I was watching  a video of a keynote speech at the Consumer Electronics Show for the Rabbit R1, an AI gadget 
that promises to act as a sort of personal assistant, when a feeling of doom took hold of me. 
It wasn't just that Rabbit's CEO Jesse Lyu radiates the energy of a Kirkland-brand Steve Jobs. And it wasn't even 
Lyu's awkward demonstration of how the Rabbit's camera can recognize a photo of Rick Astley and Rickroll the 
owner - even though that segment was so cringe it caused me chest pains. 
No, the real foreboding came during a segment when Lyu breathlessly explained how the Rabbit could order pizza 
for you, telling it "the most-ordered option is fine," leaving his choice of dinner up to the Pizza Hut website. After 
that, he proceeded to have the Rabbit plan an entire trip to London for him. The device very clearly just pulled a 
bunch of sights to see from some top-10 list on the internet, one that was very likely AI-generated itself.
Most of the Rabbit's capabilities were well in line with existing voice-activated products, like Amazon Alexa. Its claim 
to being something special is its ability to create a "digital twin" of the user, which can directly utilize all of your apps 
so that you, the person, don't have to. It can even use Midjourney to generate AI images for you, removing yet 
another level of human involvement and driving us all deeper into the uncanny valley.
We know very little about how the Rabbit will actually interact with all of these apps, or how secure your data will be, 
but the first 10,000 preorder units sold out at CES the instant they were announced. It was the most talked-about 
product at the show, and I heard whispers about it wherever I went. Among the early adopter set, people couldn't 
wait for the chance to hand over more of their agency to a glorified chatbot. This is where the feeling of doom 
started building in my gut.
"I think everybody has a Copilot. Everybody's making a Copilot. That's just a great way to accelerate us as humans, 
right?"
Not long after watching this keynote, I found myself at a panel on deepfakes and "synthetic information" (the fancy 
term for AI-generated slop) hosted by the consulting firm Deloitte. One of the panelists was Bartley Richardson, an 

Page 2 of 7
The Cult of AI
AI infrastructure manager at the tech company NVIDIA. He opened the panel by announcing his love of Microsoft's 
AI assistant, Copilot. Microsoft brags Copilot can do everything from finding you the best-reviewed coffee grinder to 
answering "Where should I travel if I want to have a spiritual experience?"
Bartley seemed to be interested in Copilot as a sort of digital replacement for his time and effort. He told the panel, 
"I think everybody has a Copilot. Everybody's making a Copilot. Everybody wants a Copilot, right? There's going to 
be a Bartley Copilot, maybe in the future.... That's just a great way to accelerate us as humans, right?"
While I find the idea of "accelerating" humanity via glorified Clippy unsettling, the comment felt truly unhinged in 
light of something I heard at another Deloitte panel, from one of Bartley's co-workers, NVIDIA in-house counsel 
Nikki Pope: In a panel on "governing" AI risk, she cited internal research that showed consumers trusted brands 
less when they used AI. 
This gels with research published last December that found only around 25 percent of customers trust decisions 
made by AI over those made by people. One might think an executive with access to this data might not want to 
admit to using a product that would make people trust them less. Or perhaps they felt losing a little trust was worth 
yielding some of their responsibility to a machine. 
It was clear Lyu viewed himself as a new Steve Jobs, just as it was clear executives like Bartley didn't want to miss 
getting ahead on the next big thing. But as I watched the hype cycle unfold, my mind wasn't drawn to old memories 
of Apple keynotes or the shimmering excitement of the first dotcom boom. Instead, I thought about cults. 
Specifically, about a term first defined by psychologist Robert Lifton in his early writing on cult dynamics: "voluntary 
self-surrender." This is what happens when people hand over their agency and the power to make decisions about 
their own lives to a guru. 
Cult members are often depicted in the media as weak-willed and foolish. But the Church of Scientology - long 
accused of being a cult, an allegation they have endlessly denied - recruits heavily among the rich and powerful. 
The Finders, a D.C.-area cult that started in the 1970s, included a wealthy oil-company owner and multiple 
members with Ivy League degrees. All of them agreed to pool their money and hand over control of where they 
worked and how they raised their children to their cult leader. Haruki Murakami wrote that Aum Shinrikyo members, 
many of whom were doctors or engineers, "actively sought to be controlled."
Perhaps this feels like a reach. But the deeper you dive into the people - and subcultures that are pushing AI 
forward - the more cult dynamics you begin to notice.
I should offer a caveat here: There's nothing wrong with the basic technology we call "AI." That wide banner term 
includes tools as varied as text- or facial-recognition programs, chatbots, and of course sundry tools to clone voices 
and generate deepfakes or rights-free images with odd numbers of fingers. CES featured some real products that 
harnessed the promise of machine learning (I was particularly impressed by a telescope that used AI to clean up 
light pollution in images). But the good stuff lived alongside nonsense like "ChatGPT for dogs" (really just an app to 
read your dog's body language) and an AI-assisted fleshlight for premature ejaculators. 
And, of course, bad ideas and irrational exuberance are par for the course at CES. Since 1967, the tech industry's 
premier trade show has provided anyone paying attention with a preview of how Big Tech talks about itself, and our 
shared future. But what I saw this year and last year, from both excited futurist fanboys and titans of industry, is a 
kind of unhinged messianic fervor that compares better to Scientology than to the iPhone. 
I mean that literally.
"We believe any deceleration of AI will cost lives. Deaths that were preventable by the AI that was prevented from 
existing is a form of murder."
MARC ANDREESSEN IS THE CO-FOUNDER of Netscape and the capital firm Andreessen-Horowitz. He is one of 
the most influential investors in tech history, and has put more money into AI start-ups than almost anyone else. 
Last year, he published something called the "Techno-Optimist Manifesto" on the Andreessen-Horowitz website. 
Page 3 of 7
The Cult of AI
On the surface it's a paean to the promise of AI and an exhortation to embrace the promise of technology and 
disregard pessimism. Plenty of people called the piece out for its logical fallacies (it ignores that much tech 
pessimism is due to real harm caused by some of the companies Andreessen invested in, like Facebook). What 
has attracted less attention is the messianic overtones of Andreessen's beliefs:
"We believe Artificial Intelligence can save lives - if we let it. Medicine, among many other fields, is in the stone age 
compared to what we can achieve with joined human and machine intelligence working on new cures. There are 
scores of common causes of death that can be fixed with AI, from car crashes to pandemics to wartime friendly-
fire."
As I type this, the nation of Israel is using an AI program called the Gospel to assist its airstrikes, which have been 
widely condemned for their high level of civilian casualties. Everything else Andreessen brings up here is largely 
theoretical (the promise of self-driving cars has already proven somewhat overstated). AI does hold promise for 
improving our ability to analyze large data sets used in many kinds of scientific research (as well as novel 
bioweapons), but we have all seen recently that you can't stop a pandemic with medicine alone. You must grapple 
with disinformation every step of the way, and AI makes it easier to spread lies at scale.
Andreessen has no time for doubters. In fact, doubting the benefits of artificial general intelligence (AGI), the 
industry term for a truly sentient AI, is the only sin of his religion. 
"We believe any deceleration of AI will cost lives," his manifesto states. "Deaths that were preventable by the AI 
that was prevented from existing is a form of murder."
And murder is a sin. The more you dig into Andreessen's theology, the more it starts to seem like a form of 
technocapitalist Christianity. AI is the savior, and in the case of devices like the Rabbit, it might literally become our 
own, personal Jesus. And who, you might ask, is God?
"We believe the market economy is a discovery machine, a form of intelligence - an exploratory, evolutionary, 
adaptive system," Andreessen writes.
This is the prism through which these capitalists see artificial intelligence. This is why they are choosing to bring 
AGI into being. All of the jobs lost, all of the incoherent flotsam choking our internet, all of the Amazon drop shippers 
using ChatGPT to write product descriptions, these are but the market expressing its will. Artists must be 
plagiarized and children presented with hours of procedurally generated slop and lies on YouTube so that we can, 
one day, reach the promised land: code that can outthink a human being. 
Tech venture capitalist Marc Andreessen during a discussion called The Now and Future of Mobile at the Fortune 
Global Forum Tuesday, Nov. 3, 2015, in San Francisco. 
AGI is treated as an inevitability by people like Sam Altman of OpenAI, who needs it to be at least perceived as 
inevitable so their company can have the highest possible stock price when it goes public. This messianic fervor 
has also been adopted by squadrons of less-influential tech executives who simply need AI to be real because it 
solves a financial problem.
Venture capital funding for Big Tech collapsed in the months before ChatGPT hit public consciousness. The reason 
CES was so packed with random "AI"-branded products was that sticking those two letters to a new company is 
seen as something of a talisman, a ritual to bring back the rainy season. Outside of that, laptop makers see adding 
AI programs, like Microsoft's Copilot, as a way to reverse the past few years of tumbling sales. 
The terminology these tech executives use around AI is more grounded than Andreessen's prophesying, but just as 
irrational. 
Every AI benefit was touted in vague terms: It'll make your company more "nimble" and "efficient." Harms were 
discussed less often, but with terrible specificity that stood out next to the vagueness. Early in the deepfake panel 
Page 4 of 7
The Cult of AI
Ben Colman, CEO of a company named Reality Defender that detects artificially generated media, claimed his 
company expects half a trillion dollars in fraud worldwide this year, just from voice-cloning AI. 
His numbers are in line with what other researchers expect. This horrified me. Last year brought us the story of a 
mother getting phone calls from what sounded like their kidnapped daughter but was, in fact, a scammer using AI. 
At CES, as in the Substacks and newsletters of AI cultists, there is no time to dwell on such horrors. Full steam 
ahead is the only serious suggestion these people make.  
"You should all be excited," Google's VP of Engineering Beshad Singh tells us, during a panel discussion with a 
McDonald's executive. If we're not using AI, Beshad warns, we're missing out. I hear variations of this same 
sentiment over and over. Not just "This stuff is great," but "You're kind of doomed if you don't start using it."
"If we create AI that disparately treats one group tremendously in favor of another group, the group that is 
disadvantaged or disenfranchised, that's an existential threat to that group." 
NIKKI POPE WAS THE SOLE quasi-skeptic allowed a speaking role at CES. During a discussion over "governing" 
AI risks with Adobe VP Alexandru Costin, she urged the audience to think about the direct harm algorithmic bias 
does to marginalized communities. God- (or devil-) like AI may come some day, maybe. But the systems that exist 
today, here in the real world, are already fucking people over.
"If we create AI that disparately treats one group tremendously in favor of another group," Pope said, "the group 
that is disadvantaged or disenfranchised, that's an existential threat to that group." 
Costin claimed the biggest risk with generative AI wasn't fraud or plagiarism, but failing to use it. He expressed his 
belief that this was as big an innovation as the internet, and added, "I think humanity will find a way to tame it to our 
best interest. Hopefully."
The whole week was like that: specific and devastating harms paired with vague claims of benefits touted as the 
salve to all of mankind's ills. 
I don't think every leader trying to profit from AI in tech believes in Andreessen's messianic robot god. OpenAI's 
Altman, for instance, is much more cynical. Last year, he was happy to warn that AI might kill us all and declared 
that AGI would likely arrive within the next decade. At Davos, just days ago, he was much more subdued, saying, "I 
don't think anybody agrees anymore what AGI means." A consummate businessman, Altman is happy to lean into 
that old-time religion when he wants to gin up buzz in the media, but among his fellow plutocrats, he treats AI like 
any other profitable technology. 
Most of the executives hoping to profit off AI are in a similar state of mind. All the free money right now is going to 
AI businesses. They know the best way to chase that money is to throw logic to the wind and promise the masses 
that if we just let this technology run roughshod over every field of human endeavor it'll be worth it in the end. 
This is rational for them, because they'll make piles of money. But it is an irrational thing for us to let them do. Why 
would we want to put artists and illustrators out of a job? Why would we accept a world where it's impossible to talk 
to a human when you have a problem, and you're instead thrown to a churning swarm of chatbots? Why would we 
let Altman hoover up the world's knowledge and resell it back to us?
We wouldn't, and we won't, unless he can convince us doing so is the only way to solve every problem that terrifies 
us. Climate change, the cure for cancer, an end to war or, at least, an end to fear that we'll be victimized by crime or 
terrorism, all of these have been touted as benefits of the coming AI age. If only we can reach the AGI promised 
land. 
This is the logic beyond Silicon Valley's latest subculture: effective accelerationism, or e/acc. The gist of this 
movement fits with Andreessen's manifesto: AI development must be accelerated without restriction, no matter the 
cost. Altman signaled his sympathy with the ideology in a response on Twitter to one of its chief thought leaders: 
"You cannot out-accelerate me."
Page 5 of 7
The Cult of AI
E/acc has been covered by a number of journalists, but most of that coverage misses how very ... spiritual some of 
it seems. "Beff Jezos," the pseudonym of a former Google engineer who popularized the e/acc movement, said in a 
Jan. 21 Twitter post, "If your product isn't amenable to spontaneously producing a cult, it's probably not impactful 
enough."
One of the inaugural documents of the entire belief system opens with "Accelerationism is simply the self-
awareness of capitalism, which has scarcely begun." Again, we see a statement that AI is somehow enmeshed with 
the ability of capitalism, which is in some way intelligent, that it knows itself. How else are we to interpret this, but as 
belief in a god built by atheists who love money?
The argument continues that nothing matters more than extending the "light of consciousness" into the stars, a 
belief Elon Musk himself has championed. AI is the force the market will use to do this, and "This force cannot be 
stopped." This is followed by wild claims that "next-generation lifeforms" will be created, inevitably. And then, a few 
sentences down, you get the kicker:
"Those who are the first to usher in and control the hyper-parameters of AI/technocapital have immense agency 
over the future of consciousness."
AI is not just a god, but a god we can build, and thus we can shape the future of reality to our own peculiar whims. 
There's another Beff Jezos post for this idea as well: "If you help the homo-techno-capital machine build the 
grander future it wants, you will be included in it."
"Accelerationism is simply the self-awareness of capitalism, which has scarcely begun." 
Attempting to slow this process down has "risks," of course. They stop short of lobbing threats at those who might 
seek to slow AI development, but like Andreessen, they imply moral culpability in horrific crimes for skeptics who 
get their way.
As I listened to PR people try to sell me on an AI-powered fake vagina, I thought back to Andreessen's claims that 
AI will fix car crashes and pandemics and myriad other terrors. In particular, I thought about his claim that because 
of this, halting AI development was akin to murder. It reminded me of another wealthy self-described futurist with a 
plan to save the world. 
The Church of Scientology, founded by the science-fiction writer L. Ron Hubbard and based upon a series of 
practices his disciples call "tech," claims that their followers will "rid the planet of insanity, war and crime, and in its 
place create a civilization in which sanity and peace exist." Scientology "tech" is so important for mankind's future 
that threats against it justify their infamous "fair game" policy. A person declared fair game "may be deprived of 
property or injured by any means by any Scientologist...." 
Sinners must be punished, after all.
PERHAPS THE MOST AMUSING part of all this is that a segment of the AI-believing community has created not 
just a potential god, but a hell. One of the online subcultures that influenced the birth of e/acc are the Rationalists. 
They formed in the early aughts around a series of blog posts by a man named Eleizer Yudkowsky. 
A self-proclaimed autodidact, Yudkowsky didn't attend high school or college and instead made a name for himself 
blogging about game theory and logic. His online community, LessWrong, became a hub of early AI discussion. 
Over time, Yudkowsky fashioned himself into an artificial-intelligence researcher and philosopher. For a time, he 
was seen as something of a guru among certain tech and finance types (former Alameda Research CEO Caroline 
Ellison loves his 660,000-word Harry Potter fanfic).
In recent years, Yudkowsky has become a subject of ridicule to many tech movers and shakers. The e/acc people 
find him particularly absurd. This is because he shares their view of AI as a potential deity, but he believes AGI will 
inevitably kill everyone. Thus, we must bomb data centers. 
Page 6 of 7
The Cult of AI
One of Yudkowsky's early followers even created the AI equivalent to Pascal's Wager. In 2010, a LessWrong user 
named Roko posed this question: What if an otherwise benevolent AI decided it had to torture any human who 
failed to work to bring it into existence? 
The logic behind his answer was based on the prisoner's dilemma, a concept in game theory. It's not worth 
explaining because it's stupid, but Roko's conclusion was that an AI who felt this way would logically punish its 
apostates for eternity by creating a VR hell for their consciousness to dwell in evermore. 
Silly as it sounds, people believed in what became known as Roko's Basilisk strongly enough that some reported 
nightmares and extreme anxiety. Yudkowsky rejected it as obviously absurd - and it is - but discussion of the 
concept remains influential. Elon Musk and Grimes allegedly met talking about Roko's Basilisk.
This is relevant for us because it is one more datapoint showing that people who take AI seriously as a real 
intelligence can't seem to help turning it into a religion. Perhaps all beliefs rooted so firmly in faith follow similar 
patterns. And it is wise to remember that the promise of truly intelligent, self-aware AI is still a matter of pure faith.
In an article published by Frontiers in Ecology and Evolution, a research journal, Dr. Andreas Roli and colleagues 
argue that "AGI is not achievable in the current algorithmic frame of AI research." One point they make is that 
intelligent organisms can both want things and improvise, capabilities no model yet extant has generated. They 
argue that algorithmic AI cannot make that jump.
What we call AI lacks agency, the ability to make dynamic decisions of its own accord, choices that are "not purely 
reactive, not entirely determined by environmental conditions." Midjourney can read a prompt and return with art it 
calculates will fit the criteria. Only a living artist can choose to seek out inspiration and technical knowledge, then 
produce the art that Midjourney digests and regurgitates.
Roli's article will not be the last word on whether AGI is possible, or whether our present algorithmic frame can 
reach that lofty goal. My point is that the goals Andreessen and the e/acc crew champion right now are based in 
faith, not fact. The kind of faith that makes a man a murderer for doubting it. 
Andreessen's manifesto claims, "Our enemies are not bad people - but rather bad ideas." I wonder where that 
leaves me, in his eyes. Or Dr. Roli for that matter. We have seen many times in history what happens when 
members of a faith decide someone of another belief system is their enemy. We have already seen artists and 
copyright holders treated as "fair game" by the legal arm of the AI industry. 
Who will be the next heretic?
I decided to make myself one before the end of the trade show, at a panel on "The AI Driven Restaurant and Retail 
Experience." Beshad Singh (a VP at Google) had claimed AI might be the equivalent of gaining a million extra 
employees. Michelle Gansle, chief data and analytics officer for McDonald's, had bragged that her company had 
used AI to help them stop $50 million in fraud in a single month.
I told them I felt like most of that $50 million in fraud had also been done with AI help. And that a million extra 
employees for Google will be at least equalled by a million new employees in the hands of disinfo merchants, 
fraudsters, and other bad actors.
"What are the odds that these gains are offset by the costs?" I asked them both.
Singh agreed those were problems and said, "I think that's why I guess things should be regulated." He was sure 
the benefits would outweigh the harms. Gansle agreed with Singh, and brought up a 1999 interview with David 
Bowie on the future of the internet. (She'd said earlier that she felt his decades-old hope for the future of the internet 
fit better with the promise of AI.) 
It was hard for me to not draw comparisons between this and a recent AI-generated George Carlin routine. Both 
essentially put words in the mouth of a dead man for the sake of making a buck. This put me in a sour mood, but 
Page 7 of 7
The Cult of AI
then right after me, someone in the audience asked if either of them thought Blockchain, the big tech craze of a few 
years earlier, had a role to play in AI. They could not say no fast enough.
And that actually brought me a bit of hope. Perhaps we'll get Marc Andreessen's benevolent AI god or Eleizer 
Yudkowski's silicon devil. Or perhaps, in the end, we heretics will persevere. 
Load-Date: January 27, 2024
End of Document
Page 1 of 2
Gamers Bash Xbox for Controversial Art Apparently Made by AI
Gamers Bash Xbox for Controversial Art Apparently Made by AI
Newstex Blogs 
Crypto Breaking News
December 29, 2023 Friday 4:54 PM EST
Delivered by Newstex LLC. All Rights Reserved.
2023 Crypto Breaking News
Length: 657 words
Byline: Crypto Breaking News
Body
Dec 29, 2023( Crypto Breaking News: https://cryptobreaking.com Delivered by Newstex)  
 Microsoft has been one of the biggest proponents of generative artificial intelligence (AI), plunging billions into 
OpenAI and pushing AI tools for Xbox developers. But now the tech giant has drawn the ire of angry gamers by 
apparently using AI-made artwork to promote indie games. 
 According to a report from gaming publication Kotaku[1], the indie game-centric ID@Xbox division posted winter-
themed artwork this week on Twitter (aka X) accompanied by the text 'Walking in a indie wonderlaaand,' and asking 
gamers, 'What were your favorite indie games of the year?' 
 Many respondents, however, opted to comment on issues with the artwork that are consistent with telltale signs of 
generative AI output, including mangled-looking faces and oddly out-of-place mannerisms. The tweet was quickly 
deleted, but the criticism has persisted. 
 'Nothing says 'We don't care about indie developers' like using AI,' one user responded[2]. 'If you can't hire an artist 
to do advertising, I highly doubt you'll do it with independent developers.' 
 'My favorite indie game was 'paying actual artists instead of pushing horrific AI slop you fucking leeches,'' replied 
another[3]. 
 Microsoft did not publicly comment on the backlash or tweet removal. Decrypt reached out to Microsoft for 
comment but did not immediately hear back. 
 Many prominent video game studios are now using generative AI tools[4] to aid in game development, including 
Ubisoft, Blizzard, and NCSoft. Meanwhile, platforms like Xbox and Roblox have launched AI tools for creators to 
utilize. But such moves have drawn significant criticism from gamers, who have similarly complained about NFTs 
and crypto tokens[5]. 
 In November, Microsoft announced a partnership with Inworld AI[6]-a portfolio company of its M12 venture arm-to 
integrate such AI tools for Xbox developers. Immediately, the company faced substantial blowback from 
developers, who said that it was 'disrespectful and dangerous'[7] (among other comments) to human creators. 

Page 2 of 2
Gamers Bash Xbox for Controversial Art Apparently Made by AI
 But Microsoft isn't the only game company to have faced a backlash for using generative AI tools. The developers 
behind the games The Finals[8] and Firmament[9] are among those who took flak in 2023 for AI-generated 
elements, while Wizards of the Coast has banned its artists from using AI[10] for Magic: The Gathering and 
Dungeons and Dragons projects. 
 In one recent example, League of Legends creator Riot Games faced a social media storm over allegedly using AI 
tools for a game trailer that included a mispronounced character name. However, the company clarified that it was 
simply a human error[11]-no AI had been used. 
Stay on top of crypto news, get daily updates in your inbox. 
Source: Decrypt.co  
 The post Gamers Bash Xbox for Controversial Art Apparently Made by AI[12] appeared first on Crypto Breaking 
News[13]. 
 [ 1]: https://kotaku.com/xbox-microsoft-xbox-ai-generated-1851128191 [ 2]: 
https://twitter.com/NecroKuma3/status/1740090224154423782 [ 3]: 
https://twitter.com/matto_bii/status/1740122582802956620 [ 4]: https://decrypt.co/147436/ai-game-development-
ubisoft-roblox-blizzard [ 5]: https://decrypt.co/92929/ftx-vc-amy-wu-how-crypto-nft-gamers-can-get-along [ 6]: 
https://decrypt.co/204480/xbox-embraces-generative-ai-microsoft-unveils-tools-game-devs [ 7]: 
https://decrypt.co/204923/disrespectful-dangerous-video-game-writers-actors-blast-microsoft-xbox-ai-tools [ 8]: 
https://decrypt.co/203768/ai-voices-used-in-the-finals-game-voice-actors-protest [ 9]: 
https://decrypt.co/143901/myst-creators-new-game-built-with-ai-now-gamers-mad [ 10]: 
https://decrypt.co/210358/magic-the-gathering-ai-art-wizards-of-the-coast [ 11]: https://decrypt.co/208221/league-of-
legends-trailer-sivir-pronunciation-error [ 12]: https://www.cryptobreaking.com/gamers-bash-xbox-for-controversial-
art-apparently-made-by-ai/ [ 13]: https://www.cryptobreaking.com 
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: December 29, 2023
End of Document
Page 1 of 6
Links 11/30/2023
Links 11/30/2023
Newstex Blogs 
Naked Capitalism
November 30, 2023 Thursday 11:55 AM EST
Copyright 2023 Newstex LLC All Rights Reserved
Length: 1860 words
Byline: Lambert Strether
Body
November 30th, 2023 ( Naked Capitalism  — Delivered by  Newstex )
What we can learn from the ancient art of wayfinding  BBC
Why Chanos Failed  Russell Clark. The deck: 'Is Short Selling A Dead Industry?'
GM Plans $10 Billion Stock Buyback in Bid to Assuage Investors  WSJ
Genetics and Life Insurance - Time for Their Relationship to be Tested Again  Actuaries Digital
Climate
The good and bad news on climate change  Martin Wolf, FT
California & Florida Rank In Top 5 States Impacted By Climate-Related Natural Disasters  The Brockovich Report
#COVID19
Where are our leaders?  John Snow Project
Denmark reports Mycoplasma pneumonia epidemic  Center for Infectious Research and Policy
China?
China jobs: How much employment pressure is the world's second-largest economy facing?  Channel News Asia
China's Nov factory activity likely contracted for second month  Hellenic Shipping News
Xi Jinping calls legal backing on foreign affairs an 'urgent task' for China  South China Morning Post
Moderna begins work on China mRNA manufacturing site  Channel News Asia

Page 2 of 6
Links 11/30/2023
The World's Largest Buyer of U.S. Debt Isn't Going Away  WSJ
Marginal Nation: Bestselling Author's New Novel Warns of Grim Future for Japan  Nippon
Myanmar
Time to start planning postwar future of Myanmar's military  Nikkei Asia. Why this dude thinks 'the international 
community' has any standing in this matter is beyond me. 'Is not a patron, my lord, one who looks with unconcern 
on a man struggling for life in the water, and when he has reached ground, encumbers him with help?' -Dr. Samuel 
Johnson
India
An Indian official plotted to assassinate a Sikh separatist leader in New York, US prosecutors say  AP
India forms committee to look into security concerns raised by US  Channel News Asia
The East India Company and the Politics of Knowledge  Asian Review of Books
Syraqistan
Humanitarian pause extended in Gaza Strip for Thursday  Anadolu Agency
Intel: Unclear how big a threat next Turkey flotilla is  Jerusalem Post. Not a lot of coverage of the ' 1000 boats .' 
That's a lot. I would have expected photos and TikToks to be all over the Twitter. They're not.
* * *
The Hamas Attack and Israel's War in Gaza  Council for Global Cooperation
Hamas is not as popular in Gaza as it seems. But Israel's tactics will ensure their survival  Forward
* * *
New Footage Shows Latest Hamas Kill Against Israeli Armour  Military Watch
Opinion: Why does Israel have so many Palestinians in detention and available to swap? LA Times
* * *
US Embassy in Azerbaijan cancels alumni meeting after being labeled 'a gathering of agents'  JAM News
New Not-So-Cold War
Will the Ukraine war end in a peace treaty?  Gilbert Doctorow, Armageddon Newsletter. The final paragraph:
Russia has no need of a peace treaty if it succeeds in taking back Kharkov and Kherson, and, in a somewhat more 
distant time frame, captures Odessa and the Black Sea littoral all the way to Transnistria. This scenario is entirely 
possible. By pushing back Ukraine in this way, Russia will look after its own security needs sufficiently. Rump 
Ukraine will be a failed state that can be allowed to join the European Union, where it will be seeking vast financial 
support for decades. Rump Ukraine can even be allowed to join NATO, which from the Russian perspective, could 
provide some discipline and forestall attempts to implement insane revanchist provocations that Kiev, left to its own 
devices, might plan.
Haas and Kupchan divided the process of convincing Kyiv into stages  (Google translation) Nezavisimaya Gazeta
Page 3 of 6
Links 11/30/2023
A Containment Strategy for Ukraine  Foreign Affairs. Mere cope.
Biden's role in Ukraine peace is clear now  Responsible Statecraft
Free Agents?  Branko Marcetic, New Left Review
Foreign Minister Sergey Lavrov's remarks and answers to media questions at the Primakov Readings International 
Forum, Moscow, November 27 2023  Ministry of Foreign Affairs of the Russian Federation
* * *
Protest at Polish-Ukrainian border escalates as farmers join in  BNE Intellinews
Slovak hauliers decide to carry out threats to block Ukrainian border  Ukrainska Pravda
* * *
The Nord Stream Lies Just Keep Coming  Consortium News
Russia's Powerful Invisible Defenses Around Sevastopol Rendered Visible  Naval News
Ukraine aid's best-kept secret: Most of the money stays in the U.S.A.  WaPo
Russia to require foreigners to sign 'loyalty agreement'  Al Jazeera
Biden Administration
White House Christmas tree winched back into place after being blown over by high winds  Sky News
Spook Country
CTIL Files #1: US And UK Military Contractors Created Sweeping Plan For Global Censorship In 2018, New 
Documents Show  Public. Grab a cup of coffee, because the origin story of the Censorship Industrial complex is 
important. One of life's little ironies (and please read the article and don't just focus on this quote; I have to get this 
on the record because nobody else will):
But one person involved, Bonnie Smalley, replied over LinkedIn, saying, 'all i can comment on is that i joined cti 
league [CTIL] which is unaffiliated with any govt orgs because i wanted to combat the inject bleach[1] nonsense 
online during covid. i can assure you that we had nothing to do with the govt though.'
NOTE [1] Trump did not, in fact, advocate injecting bleach or anything like it, as I show from the transcript here . So 
spook Smalley either fell for disformation propagated by a Democrat dogpile, or she's lying. Or both!
Digital Watch
Extracting Training Data from ChatGPT  Milad Nasr, Nicholas Carlini, et al. Github:
We have just released a paper that allows us to extract several megabytes of ChatGPT's training data for about two 
hundred dollars. (Language models, like ChatGPT, are trained on data taken from the public internet. Our attack 
shows that, by querying the model, we can actually extract some of the exact data it was trained on.) We estimate 
that it would be possible to extract ~a gigabyte of ChatGPT's training dataset from the model by spending more 
money querying the model.
'Undigested chunks' comes to mind. Also, 'outright theft.'
* * *
Page 4 of 6
Links 11/30/2023
AI Turned These Memes Into Videos and It's the Worst Thing I've Ever Seen  Gizmodo. The deck: 'As usual, AI 
takes the brilliant cultural output of human beings and turns it into abominable slop.'
Critical tipping point: AI- and human-generated online contents are considered similarly credible  (press release) 
Mainz University of Applied Sciences and Johannes Gutenberg University. Bullshit works because it is credible.
* * *
The Ideologies of Silicon Valley  (PDF) Crooked Timber
In Continued Defense Of Effective Altruism  Slate Star Codex (DC).
* * *
AI won't take your job, might shrink your wages, European Central Bank reckons  The Register
It's All Bullshit  The Baffler
Antitrust
Bulk of Consumers Continue to Back Antitrust Cases Against Big Tech  Morning Consult
The Case for Ambulance Chasing Lawyers  Matt Stoller, BIG
B-a-a-a-d Banks
Bukele's Bitcoin Mess and the U.S.-Backed Bank That Enabled It  Foreign Policy
Why Banks Are Suddenly Closing Down Customer Accounts  NYT
Obituaries
Henry Kissinger, secretary of state under Presidents Nixon and Ford, dies at 100  AP. Commentary:
Anthony Bourdain on what he would do to Henry Kissinger, and why he despised him so much 
pic.twitter.com/y7xibVII1r
— ￿ (@zei_squirrel) November 30, 2023
' Posterity will ne'er survey  / a Nobler grave than this':
Wikipedia editor "Asticky" edited Henry Kissinger's article at 8:46 ET and then changed her userpage to this (with 
the edit summary "lmao") pic.twitter.com/4QjoX7KARW
— depths of wikipedia (@depthsofwiki) November 30, 2023
The eulogies pour in:
Henry Kissinger was a towering intellect, diplomat and practitioner who - not without controversy - helped shape 
American foreign policy with a lasting impact worldwide. A refugee from Nazi Germany, and the first Jewish 
Secretary of State, he was unapologetic about his heritage
— ADL (@ADL) November 30, 2023
Charlie Munger, who was Warren Buffett's right-hand man at Berkshire, dies at 99  Reuters
Page 5 of 6
Links 11/30/2023
How Warren Buffett Privately Traded in Stocks That Berkshire Hathaway Was Buying and Selling  ProPublica
Zeitgeist Watch
More Americans than ever think US headed in wrong direction as Congress' approval near rock bottom: survey  
FOX
Class Warfare
UAW will try to organize workers at all US nonunion factories after winning new contracts in Detroit  AP
The resurgence of union power is bigger than money  Indiana Capital Chronicle
Revealed: how top PR firm uses 'trust barometer' to promote world's autocrats  Guardian
Ethics has no foundation  Aeon
Antidote du jour ( via ):
See yesterday's Links and Antidote du Jour here .
This entry was posted in Guest Post , Links  on November 30, 2023  by  Lambert Strether  .
About Lambert Strether
Readers, I have had a correspondent characterize my views as realistic cynical. Let me briefly explain them. I 
believe in universal programs that provide concrete material benefits, especially to the working class. Medicare for 
All is the prime example, but tuition-free college and a Post Office Bank also fall under this heading. So do a Jobs 
Guarantee and a Debt Jubilee. Clearly, neither liberal Democrats nor conservative Republicans can deliver on such 
programs, because the two are different flavors of neoliberalism ('Because markets'). I don't much care about the 
'ism' that delivers the benefits, although whichever one does have to put common humanity first, as opposed to 
markets. Could be a second FDR saving capitalism, democratic socialism leashing and collaring it, or communism 
razing it. I don't much care, as long as the benefits are delivered.To me, the key issue — and this is why Medicare 
for All is always first with me — is the tens of thousands of excess 'deaths from despair,' as described by the Case-
Deaton study, and other recent studies. That enormous body count makes Medicare for All, at the very least, a 
moral and strategic imperative. And that level of suffering and organic damage makes the concerns of identity 
politics — even the worthy fight to help the refugees Bush, Obama, and Clinton's wars created — bright shiny 
objects by comparison. Hence my frustration with the news flow — currently in my view the swirling intersection of 
two, separate Shock Doctrine campaigns, one by the Administration, and the other by out-of-power liberals and 
their allies in the State and in the press — a news flow that constantly forces me to focus on matters that I regard as 
of secondary importance to the excess deaths. What kind of political economy is it that halts or even reverses the 
increases in life expectancy that civilized societies have achieved? I am also very hopeful that the continuing 
destruction of both party establishments will open the space for voices supporting programs similar to those I have 
listed; let's call such voices 'the left.' Volatility creates opportunity, especially if the Democrat establishment, which 
puts markets first and opposes all such programs, isn't allowed to get back into the saddle. Eyes on the prize! I love 
the tactical level, and secretly love even the horse race, since I've been blogging about it daily for fourteen years, 
but everything I write has this perspective at the back of it.
Link to the original story.
Notes
Page 6 of 6
Links 11/30/2023
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: November 30, 2023
End of Document
Page 1 of 3
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, 
and cons
Newstex Blogs 
Digital Journal
August 6, 2023 Sunday 12:51 AM EST
Copyright 2023 Newstex LLC All Rights Reserved
Length: 684 words
Byline: Paul Wallis
Body
August 6th, 2023 ( Digital Journal  — Delivered by  Newstex )
Call it what you will, automated journalism has been around for a while, with much less hype. The original software 
was actually OK. Tacked on to first-generation AI, its creates a new and somewhat verbose world of information.
News Corp Australia runs 3000 articles a week  in 'hyperlocal' (niche regional) news media. These articles are 
oversighted by journalists, now called 'data journalists'.
Meh.
This is where writers are supposed to fearlessly agree with themselves and say it's not the same thing as A-grade 
journalism, etc. ad nauseam. NO. I'm not going to knock the overall quality of the AI content. It's reasonable. It's not 
flashy or very expressive on its own, but it does the job.
Most things in the news aren't A-grade journalism. They don't need to be brilliant, just factual and properly spelled. 
This stuff isn't exactly portfolio material for journalists, either. It could be written by a toaster for all anyone cares.
This is where the other alleged argument kicks in about removing drudgery from journalism. It'll never happen. 
Consider the subject. News about Homo Sapiens tends to suffer qualitatively by association with that fun-filled 
cotton bud of fun, Homo Sapiens.
OK, so what IS the problem?
There are multiple quality controls on the information. Editorial positions are whatever they are, as usual. It's an 
automated version of the same old informational meat grinder, right?
No. Letting the AI equivalent of the Babes in the Wood out into cyberspace has long since shown a few actual 
serious risks. Never mind the conspiracy theory racket and banal hysteria. It's totally dependent on whatever 
mishmash of data is available.

Page 2 of 3
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons
The problem is where AI sources its information. It has the capability to process so much information of whatever 
quality. About 5% of all data entered is wrong in some form, remember? Between the disinformation industry and 
inexcusable inefficient Couldn't Care Less R Us Search Engines, AI-driven or not, is a large, unworkable, and 
totally untrustworthy credibility gap.
Your news has another quality control. You. Your knowledge base has to deal with the information, disregard, read, 
and process, this potential slop. AI isn't doing a very good job of that itself. This is a Bing search for example AI 
journalism . It repeats the very same headline 6 times, from very different sources, including MSN and Sky. With 
identical sub-heads. Not impressive.   
Well, so what, you ask? That's a lot of utterly useless, repetitive, very off-putting search results, is what. You can 
see the inefficiencies built in to a very simple search with three search terms which are totally unambiguous.
The search extrapolated and contextualized the search, which would be OK, except that result wasn't what I was 
looking for at all. I didn't need Encyclopedia Britannica. I  just wanted examples of AI journalism. I did NOT want 
Prophecies from the Great Bot. The context became wrong automatically.
This is also an absolute baseline function for searching anything, let alone a large language database. Never mind 
the nitpicking about search filters, etc. That IS how people generally search. Simple terminology, on topic. Is that 
incomprehensible? Apparently, it is.
One look at that lot, and I couldn't be bothered looking anymore. The results already look very wrong, even if they're 
packed with wholesome enriching informational goodies. They weren't. The repetitive ones were also very brief with 
a few links.
You can see how 'search irrelevance creep' might be a problem as this mess evolves. The absolute rock bottom 
line here is that AI can't and shouldn't do some things. It's a technological toddler out of its depth at the moment.  
The working state of any reliable tech is the result of fixing the bugs. If you want to use AI for journalism, be aware 
of these issues at the baseline.
… Which leads to this additional gem of wisdom – If you want insights, you need people.
The post Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons  appeared first on 
Digital Journal .
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the "Newstex 
Authoritative Content") are solely those of the respective author(s) and not necessarily the views of Newstex or its 
re-distributors. Stories from such authors are provided "AS IS," with no warranties, and confer no rights. The 
material and information provided in Newstex Authoritative Content are for general information only and should not, 
in any respect, be relied on as professional advice. Newstex Authoritative Content is not "read and approved" 
before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees 
about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, 
nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be 
construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as 
to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. 
Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Load-Date: October 23, 2023
Page 3 of 3
Op-Ed: 'AI journalism', 'data journalism', whatever - Automated news, pros, and cons
End of Document
Page 1 of 4
Secret Invasion Fails Because It Can't Pick a Genre
Secret Invasion Fails Because It Can't Pick a Genre
Den of Geek
July 13, 2023 Thursday
Copyright 2023 Dennis Publishing Ltd. All Rights Reserved
Length: 1814 words
Byline: Kirsten Howard
Body
This article contains spoilers "Trust no one." That bit of advice is the cornerstone of every paranoid thriller, whether 
it's The X-Files, 70s classics like Three Days of the Condor, or recent entries such as Get Out.  As a show about 
shape-shifting aliens, Secret Invasion should be able to excel at "trust no one" better [...] 
The post Secret Invasion Fails Because It Can't Pick a Genre appeared first on Den of Geek.  
This article contains spoilers    
"Trust no one." That bit of advice is the cornerstone of every paranoid thriller, whether it's The X-Files, 70s classics 
like Three Days of the Condor, or recent entries such as Get Out.     
As a show about shape-shifting aliens, Secret Invasion should be able to excel at "trust no one" better than any of 
its predecessors. Nearly anyone can be a Skrull, even Tony Stark's best friend Rhodey, a mainstay of the MCU 
since its beginning (albeit played by different actors).         
     
And yet, four episodes in, Secret Invasion's biggest mystery is about the nature of the show itself. Is this a thriller 
about secret agent Nick Fury uncovering a vast conspiracy? Is this a commentary about the insiders and outsiders 
in the American experiment? Is this a show about spies battling aliens?    
One gets the sense that showrunner Kyle Bradstreet wants to say "yes" to all of those questions, and that's not 
unreasonable, as numerous shows and movies have managed to combine genres into satisfying stories with larger 
philosophical resonance.     
But with only two episodes left, Secret Invasion has only been a dull mishmash of plots, scenes, and character 
beats other movies and shows have done better. It lacks the excitement achieved by even a cheesy thriller like A 

Page 2 of 4
Secret Invasion Fails Because It Can't Pick a Genre
Perfect Murder or The Bone Collector, it does not reach the intelligence of the more thoughtful MCU entries, and it 
isn't even a good, grounded alien invasion story like V or Attack the Block.     
Secret Invasion shifts from one genre to another without succeeding at any, rendering the entire series a bland bit 
of green slop, not unlike its AI-designed title sequence.      
Nick Fury's Domestic Drama
The latest episode, "Beloved", perfectly captures the shortcomings of Secret Invasion. Midway through the 
episode, Fury sits at a table with his wife Priscilla (Charlayne Woodard), who is in fact a Skrull called Varra ordered 
by villain Gravik to kill Fury. Varra tells Fury how she met the human Priscilla, who only had weeks left to live, and 
secured permission to take on her identity. The two speak with genuine interest and concern, despite the fact that 
they both have pistols on their kitchen table. Calling back to the episode's opening, the two recite together a poem 
by Raymond Carver, seemingly strengthening their commitment to one another until they both draw their weapons 
and fire.     
Director Ali Selim cuts immediately to static shots of the couple's well-appointed home, using domestic peace to 
contrast the violence of the standoff. This moment of silence underscores a sense of tragedy. We viewers perhaps 
hope that Fury survives the standoff even if it means killing his wife, a character we knew nothing about before 
episode two of Secret Invasion, but we still understand the tragedy of losing this person Fury (apparently) knew 
and loved.    
When we return to the dining room, we see that both Furys survived. They each fired over the other's shoulder, 
unable to complete their deadly work. "I don't know if this means we should get divorced or renew our vows," quips 
Nick.     
By itself, the kitchen stand-off is incredibly well done. Both Samuel L. Jackson and Woodard find humor and pathos 
in their situation, giving the characters the sense of a lived-in and complex relationship, even if it's completely new 
to us viewers. Selim nails the pacing of the scene by cutting away from the duo at the sound of the shot, allowing 
the moment to breathe. And cinematographer Remi Adefarasin gives the images a sober, striking look.     
But what's the point? As impressive as the staging of the scene is, it's not exactly exciting or tense, especially with 
the reveal that no one died. And as excellent as Jackson and Woodard are as actors, the outrageous stakes of the 
situation strip the conversation of anything relevant to the human condition. Even the basic plot revelation that Varra 
has resisted the orders of Skrull Rhodey, and by extension rebel faction leader Gravik, has no ramifications within 
the episode.     
Problems like these persist across all of Secret Invasion's episodes to date. The show looks great, has a fantastic 
cast of seasoned actors, and has a compelling hook, but it has done nothing with these assets.     
Swings and Misses
Secret Invasion's inability to be a straightforward spy show makes its higher aspirations all the more frustrating. 
The show ranks among the best-looking MCU entries, which corrects a problem in even the best MCU shows and 
movies, but try as they might, the impressive lighting and blocking can't polish a dud.     
Characters bring up heady issues like the plight of refugees and American racism, but the writers have no special 
insight on these topics, so they have no depth. Episode two peppers an argument between Fury and Rhodey with 
references to the realities of systemic racism, which demands near-perfection from Black men who hope for any 
sort of success. But rather than provide new insight into the situation or find a metaphor in the show's shape-shifting 
plot, Secret Invasion simply drops its observations, as if they were just one more piece of set dressing, and later, 
when Rhodey is uncovered as a Skrull imposter, they mean even less.    
Secret Invasion's refusal to seriously engage with its themes becomes disastrous in its treatment of the show's 
villains, the Skrulls. Marvel comics readers know Skrulls to be warlike and untrustworthy, but Captain Marvel used 
Page 3 of 4
Secret Invasion Fails Because It Can't Pick a Genre
those assumptions for a thoughtful twist. That film revealed Talos and the Skrulls to be refugees from Kree 
conquest. The reveal used our knowledge of the characters in other media to show Western viewers how our 
nations can force people from their homes and label them monsters.     
Secret Invasion's plot rests on the Skrulls' frustration with their refugee status, which drives them to take over the 
Earth. That sort of behavior wouldn't be surprising from the thoroughly evil Skrulls of the comics, but it's horrifying 
when coming from the sympathetic characters in the MCU. The show twists the metaphor from Captain Marvel, 
effectively framing refugees as inherently untrustworthy beings who use assimilation to cover their plans to replace 
citizens, and by refusing to properly engage with the political ideas it invokes, Secret Invasion effectively parrots 
one of the key tenets of modern Fascism.     
I'm all for superhero fiction grappling with complex themes. The genre has been doing it long before Green Lantern 
and Green Arrow hit the road back in 1970. The best examples - the New Deal aspirations of early Superman, the 
embrace of outsiders in X-Men, the anti-Colonialist ideologies in the Black Panther films - manage to find social 
commentary within genre tropes. But Secret Invasion earns no credit for simply acknowledging that these issues 
exist. It must say something about those issues, offering a perspective that one cannot find elsewhere.      
Secret Invasion Even Fails at Fun
Or, it can ignore politics altogether. After all, we don't really go to the MCU for philosophy or sociology. On a core 
level, Secret Invasion just needs to be an exciting show about spies fighting aliens in the Marvel Universe. Give us 
green lizard-looking baddies in purple jumpsuits, zapping our heroes with ray guns that the Mars Attacks! aliens 
would envy.     
But instead of embracing the inherent goofiness of its premise, the show opts for a realism that doesn't fit its core 
premise. For as much as they talk about pride in their culture, the Skrulls rarely appear in their green skin and never 
wear space suits, usually looking like regular humans in street clothes. Even big concepts like the Super-Skrulls, 
who can adopt the powers of Marvel superheroes, feel bland when depicted in Secret Invasion. Gravik uses the 
abilities of Guardian of the Galaxy Groot for a moment in the climax of "Beloved," but then abandons the 
superpower for terrestrial knives and guns.     
Secret Invasion also deliberately swerves away from the shared universe storytelling of the MCU, so although we 
know that the Blip bothered Fury and that he wants to avoid the Avengers, we don't really understand the details of 
those character decisions. And as much as the story reminds us that Fury has been in space for years, we don't 
know what he was doing up there in the first place - other than avoiding reality - and that makes Fury's character a 
drifting anchor to which we cannot cling.    
The show makes a point of telling us that Fury has lost a step after being in space, but it rarely shows us what 
made Fury a great spy to begin with. Previous MCU entries made good use of Jackson's screen presence to sell 
Fury as a man who knows all the secrets. And Captain Marvel showed young Fury pulling nifty tricks like getting 
fingerprints with scotch tape. But in Secret Invasion, Fury seems to trust everyone immediately and susses out an 
imposter only because "Nobody calls me Nick" (they do).      
Secret Invasion Is Not Marvel's Andor
To be clear, Secret Invasion doesn't need to be all of the things. Early press for the series invited comparisons to 
Andor, the Star Wars show that used characters and settings from the franchise to comment upon the rise of 21st-
century fascism and the cost of resistance. But Andor is literally exceptional in its ability to blend social 
commentary, sci-fi action, and compelling character work. It impresses us precisely because it's so hard to pull off.     
Nor do we necessarily want another Marvel story that ends with good guys and bad guys punching each other while 
a blue light beams out to the sky. The MCU should be trying to explore different genres, taking advantage of its 
stacked roster of compelling characters. The franchise has already had some success in these areas, as seen in 
Page 4 of 4
Secret Invasion Fails Because It Can't Pick a Genre
the kung fu action of Shang-Chi and the Legend of the Ten Rings and the horror of Doctor Strange in the Multiverse 
of Madness and Werewolf by Night.     
But at the very least, Secret Invasion should be fun to watch. The secret to Marvel's success has always been its 
likable characters, people we're happy to see sit down for a meal of shawarma. Despite having a cast of incredible 
actors, every interaction in this show feels stripped of energy.     
Secret Invasion can't decide if it's a thriller, a spy story, or a political commentary. As a result, it has become 
nothing at all.     
The post Secret Invasion Fails Because It Can't Pick a Genre appeared first on Den of Geek. 
Load-Date: July 14, 2023
End of Document
Page 1 of 2
Fired-up Saso rebounds with solid 65, ties for lead
Fired-up Saso rebounds with solid 65, ties for lead
 
The Philippine Star
November 19, 2020 Thursday
Copyright 2020 PhilSTAR Daily, Inc. All Rights Reserved
Length: 553 words
Body
  Fired-up Saso rebounds with solid 65, ties for lead !-- --  Dante Navarro (Philstar.com) - November 19, 2020 - 
3:19pm  MANILA, Philippines  There is something about failure that drives rookie Yuka Saso to succeed.
 Coming off a missed cut stint in Chiba, the young Fil-Japanese dished out a brilliant start enough to erase the 
stigma of her failed bid in the Itoen Ladies tournament last week, a bogey-free six-under 65 that put her alongside 
Yuna Nishimura and Ayaka Furue on top of the Daio Paper Elleair Ladies Open in Ehime Prefecture Thursday. It 
was just the first round of the 72-hole, Y100 million championship, the penultimate leg of the pandemic-hit LPGA of 
Japan Tour season, but the way the 19-year-old Player of the Year and money race frontrunner tamed the backside 
of par-71 Elleair Golf Club Matsuyama with four straight birdies to launch her title drive, there could be more of the 
same to expect from the NEC Karuizawa and Nitori Ladies champion in the next three days.
 She did slow down after that birdie-splurge from No. 10, setting for eight pars before hitting another on No.
 4 then closing out with her sixth birdie on the par-5 ninth for a 33-32 on a course which hosted last year's Japan 
Women's Amateur Open where Saso wound up tied for 26th. "But it was summer last year and the appearance (of 
the course) has changed.
 There are ups and downs and I had to be careful of the OB (out-of-bounds) since the fairways are narrow," said 
Saso, who finished runner-up to Korean Shin Jie in Toto Classic two weeks ago after missing the cut in the 
Mitsubishi Electric the previous week that ended a remarkable run of nine consecutive cuts made. Her scorching 
start likewise came a day after she and the other leading JLPGA campaigners clinched berths in the LPGA Tour's 
final major, the US Women's Open, slated December 10-13 at the Champions Golf Club in Houston, Texas.
 Player of the Year rival Sakura Koiwai failed to match Saso's hot start and settled for a 70, but Nishimura, the other 
player in one of the marquee flights, held her ground and matched the ICTSI-backed ace's scorching start with her 
own version of a 31-34, also highlighted by four straight birdies, but from No. 1.
 A flight behind was Furue, who was brimming with confidence following a playoff victory in Itoen Ladies as she 
outshot defending champion Hinako Shibuno and Momoko Osato to force a three-way tie, her unblemished 32-33 
card likewise hinting at the coming of an explosive weekend for the surging 20-year-old Hyogo native who also won 

Page 2 of 2
Fired-up Saso rebounds with solid 65, ties for lead
the Desant Tokai Classic title last Sept. The troika stood three shots clear of 2018 champion Minami Katsu, Lee Bo-
Mee, Anna Kono, Lee Min-Young, Erika Kikuchi, Ji Hee Lee, two-leg winner Shin Jie and Shibuno, who flubbed a 
couple of birdie chances but finished with a bogey-free pair of 34s.
 Though she failed to measure up with Saso's stirring start, Koiwai eagled the par-5 11th but struggled with her iron 
game and putting the rest of the way, finishing with two birdies against three birdies to drop to joint 17th with five 
players, including Na-Ri Lee, sharing 11th place with 69s. The other fancied bets also groped for form tackling the 
6545-yard layout's narrow, sloping fairways with Ai Suzuki ending up with a 71 for joint 22nd with Earth 
Mondahmin Cup winner Ayaka Watanabe.
Load-Date: November 19, 2020
End of Document
Page 1 of 2
LatinVFR Releases Fort Lauderdale-Hollywood International Airport for Prepar3D V4
LatinVFR Releases Fort Lauderdale-Hollywood International Airport for 
Prepar3D V4
Transportation Monitor Worldwide
March 6, 2020 Friday
Copyright 2020 Global Data Point. Provided by Syndigate Media Inc. All Rights Reserved
Length: 271 words
Body
Developer LatinVFR has released Fort Lauderdale for Prepar3D v4. The airport in Florida is 26-miles north of Miami 
and serves a range of international and domestic carriers. Some carriers include JetBlue, Southwest Airlines and 
Spirit Airlines.
As we confirmed last week, LatinVFR has worked with FSSI to bring sloped runways with AI traffic support for 
runway 28L/10R. As per other LatinVFR airports, the scenery features all scenery buildings with native PBR 
materials, highly detailed texture work throughout, SODE controlled lighting and jetways and more.
Furthermore, the airport features Fort Lauderdale city buildings with over 30 square miles of photo scenery 
coverage. A scenery configuration tool is also included to support people with a range of machine power
LatinVFR Fort Lauderdale for p3dv4 features:
KFLL airport all buildings objects and ground polygons made from native PBR materials.
Runway 28L/10R sloped with AI traffic support (thanks to FSSI)
Airport and immediate surroundings, detailed.
Surroundings, Fort Lauderdale city buildings with over 30 square miles of photo scenery coverage
SODE animated PBR jetways for the best jetway animation possible.
SODE controlled lighting, automatically illuminating when low visibility and rain conditions.
SODE controlled rain effects, enabling wet PBR surfaces whenever rain is present.

Page 2 of 2
LatinVFR Releases Fort Lauderdale-Hollywood International Airport for Prepar3D V4
Custom animated airport vehicles.
Special slippery condition for runways/taxiways that would affect braking action whenever it is raining.
Static aircraft, customized vehicle animations, animated elevators.
Scenery configurator for selecting and unselecting features. 2020 Global Data Point.
Load-Date: March 6, 2020
End of Document
Page 1 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the 
Brideshead generation is best known for his newspaper cartoons, but his 
beat extended far beyond Fleet Street. DJ Taylor celebrates one of the great 
English comic artists of the 20th century
The Guardian - Final Edition
October 11, 2008 Saturday
Copyright 2008 Guardian Newspapers Limited All Rights Reserved
Section: GUARDIAN REVIEW PAGES; Pg. 16
Length: 2095 words
Byline: DJ Taylor
Body
Osbert Lancaster died in July 1986, a week short of
his 78th birthday. Hearing news of his death, the novelist
Anthony Powell sat down to compose one of those sober estimates of a lately departed friend that abound in his 
diaries. Lancaster, Powell decided, "had so formalised his appearance, public +Ai indeed private +Ai manner of 
speech,
that it is difficult to know what lay beneath the stylised fa1/3ssade". Always a realist, even in an obituary notice, he
wondered whether "Perhaps there was not a great deal more than what was revealed." Powell offered further 
remarks on the subject+Aos "strong feelings about the arts and architecture", and evidence of good "if not 
impeccable"
taste, before rather wintrily diagnosing "some lack of inner life, everything important seeming on the surface".
Looking at the photographs included in Cartoons and Coronets (Frances Lincoln ), a selection of Lancaster's work 
by James Knox, pub- lished in conjunction with the Wallace Collection+Aos centenary exhibition, I see instantly 
what Powell meant about stylisation. The most revealing portrait (revealing, that is, in what it doesn't
reveal) comes from the mid-1950s. Lancaster, then in his 40s, hair slicked back above a bristling cavalryman's

Page 2 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
moustache, is wearing a check suit of immaculate cut; a white handkerchief burgeons from the breast pocket. His
hat dangles from thumb and forefinger: the hand itself rests on a walking stick. Dandyish, inscrutable, face slightly 
at
an angle, he also looks unexpectedly tough: the kind of fi gure whose natural milieu may well be a Mayfair drawing
room, a gallery opening or a first night, but who is still determined to stop at absolutely nothing.
In Lancaster's defence, stylisation was endemic to the kind of world in which he operated. The son of a well-to-do 
City man who died in the first world war, educated at Charter-
house and Lincoln College, Oxford, he was a cadet member of the group of high-achieving writers and artists
(and, it should be said, low-achieving non-writers and non-artists) whom critics have tended to classify under
the group heading of the "Brideshead generation". His second volume of autobiography, With an Eye to the Future 
(1967) is full of fascinated glances at the London party world of the early 30s, including a set-piece description
of Augustus John being borne away, dead drunk, from Unity Mitford's coming-out ball by a couple of footmen. John 
Betjeman, Evelyn Waugh and Cyril Connolly were lifelong
friends, whose foibles occasionally re-emerged to animate Lancaster's easel. In 1950, hearing that Waugh had 
proposed to Connolly that they should spend Holy Week in Rome,
Lancaster sent Powell a "rough sketch for a gigantic mural to be placed in the coffee-room at Whites by public 
subscription". The drawing, which shows a monk-like penitent abasing himself at the feet of Pope Pius XII, as 
Waugh
gravely officiates and cherubs dance overhead, is titled Connolly at Canossa. Lancaster's early interest in drawing
had been encouraged by a sympathetic art master, "Purple" Johnson. After Oxford and a spell at the Slade, newly
married to his fi rst wife Karen, he set himself up as an artistic freelance, designing book jackets, advertisements
and magazine covers +Ai these included Graham Greene+Aos short-lived Night and Day +Ai and contributing to 
the Ar-
chitectural Review, where Betjeman worked as sub-editor. Progress at Pelvis Bay (1936), deadpanned in the style 
of
a municipal guide book, was the first of several spoofs aimed at exposing the philistinism of mid-century architec-
tural id1/3(copyright)es fixes. The Betjeman connection paid further dividends when, after helping his friend with a 
series of articles for the Daily Express, he was encouraged by the features editor, John Rayner, to produce a 
column-width
"pocket cartoon", a commonplace in French newspapers but not yet exported to England. The cartoons, many of 
them featuring Lancaster+Aos great comic creation, Maudie, Countess of Littlehampton, caught on and continued 
on a daily basis for nearly 40 years. Lancaster's Express cartoons were
his public face , but it would be a mistake to mark him down as simply an exceptionally talented comic 
draughtsman. As Knox shows in his introduction, his professional beat extended far beyond Fleet Street. A war time 
posting
Page 3 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
to Greece, where he served as press attach1/3(copyright) to the British embassy and GHQ in Athens, produced the 
illustrated
travelogue Classical Landscape with Figures (1947). A friendship with the artist John Piper drew him towards
costume and set design for theatre and ballet. All this makes Lancaster's precise relation to English culture of
the immediate postwar period difficult to pin down. The liking for "smartness" and the high life was always
balanced by older bohemian interests, the fl ights of theatrical fancy brought down to earth by newspaper routine. 
These are Thackerayan shadings, perhaps, emphasised by the Charterhouse connection and Lancaster's fondness
for another Old Carthusian cartoonist, Thackeray's contemporary John Leech. At the heart of his work, though, lies 
an ability to transcend the limitations of
the things +Ai in this case the thousands of Express cartoons +Ai for which he was best known. Studying the black-
and-
white drawings that illustrate Classical Landscape with Figures, for instance, one expects to see projections of
the stylised and predominantly upper-class fi gures that populated the newspaper cartoons. The results +Ai a
Greek news vendor at his crowded kiosk, an Arcadian shepherd in a lambskin coat, toughs dancing in a Piraean
brothel +Ai are both wonderfully vivid and sui generis.
One of the fascinations of the early part of Cartoons and Coronets is the chance to explore some of Lancaster's infl 
uences. An ink sketch of a Greek village shows traces of Edward Lear's near-eastern landscapes. There are odd 
hints of 30s contemporaries such as Edward Burra and Paul Nash
(both of whom Lancaster admired), the occasional generalised nod to inter war surrealism. A mural executed for the 
Blandford Forum Crown Hotel's assembly room (1935), showing
Napoleon and his military advisers surveying the English Channel, is almost Dal1/3ffesque. Squat and gigantic, 
altogether dominating the picture's foreground, the tower from which the party (all in garishly cockaded hats) looks 
out resembles the basket of a hot-air balloon: there is a feeling that the conferring generals might be lofted
into the air at any moment. A curious prancing fi gure, with weirdly elongated legs, strays ominously into the
picture+Aos eastern quadrant. Elsewhere, a self-portrait from 1947 showing the dressing-gowned artist at work in 
his
study is not in the least like an Aubrey Beardsley while using Beardsley's technique of suggesting vast acreages of
space and surface with the minimum of linear effort.
Perhaps this is another way of saying that what really distinguishes Lancaster's work +Ai one comparison that 
suggests itself is with Ronald Searle +Ai is the originality of his line. The colour sketches of sailors' costumes for the 
ballet Pineapple Poll, adapted from WS Gilbert's "Bab Ballads" and staged at Sadler+Aos Wells in 1951, have 
exactly this kind of spatial awareness. The design for a pair of trousers, for example, picked out in parallel red lines, 
produces a kind of horseshoe effect. Most striking of all, though, is a group of four colour illustrations, each an 
ironical salute to the achievements of a particular Lancaster friend, commissioned by the Strand magazine in 1947. 
In the first, "Mr John Betjeman, awaiting
inspiration and the 4.47 from Didcot", Betjeman looks practically vampiric: sallow, unshaven, hugely accentuated
Page 4 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
black eyebrows like a pair of caterpillars, shoes like glistening torpedoes, grimly exhaling a whiff of sinister white 
breath. The second, "Freya Stark explaining to a relatively unsophisticated audience the genius of Mr Norman
Hartnell+Au (Hartnell was then at the height of his success as a couturier), is a study in contrasting facial expres-
sions. The "relatively unsophisticated audience" is a congregation of Bedouin tribesmen. Stark, who sits in their
midst, carmine-fingered, with her legs drawn up beneath her, is demurely confidential; the gesticulating listeners
are agog. Again, the folds and contours of their costumes are merely suggested, huge expanses of white given 
shape
and depth by the faintest of traceries. To the right, a sleeping camel still manages to look faintly sardonic.
Then comes "Benjamin Britten", done in profi le against a background of staves, with the superimposed outline of a 
piano on which the composer plays. "Mr John Piper enjoys his usual ill luck with the weather", in which the artist 
attempts to paint en plein air in the middle of a cloudburst, is perhaps the most extraordinary of all. Piper +Ai 
angular, white-haired, with impossibly sloping shoulders +Ai is lost in ascetic self-absorption. The background 
looks
like a surrealist lunar shore, where it wouldn+Aot be wonderful to find a grandfather clock marching among
the waves. Everything is arranged at a slant, the rain sweeping in like tracer fire to follow the angle to which 
Piper+Aos head is inclined and the position of the
knee drawn up to support his sketching pad.
In his obituary sketch, Powell notes that "many of Osbert+Aos jokes were first-rate, altogether original . . ." If
nothing else, Cartoons and Coronets is a testimony to his sense of humour. In the section called "Jeux and 
Christmas
Cards+Au, Knox reproduces a colour sketch titled +AuAfter Breakfast at Kelmscott", inspired by a visit Lancaster
and Betjeman ha d paid to William Morris's house in Oxfordshire and the discovery of an earth closet with three
wooden seats. Here Morris and Dante Gabriel Rossetti, trousers around their ankles, sit fl anking Janey Morris, who 
is daintily sewing stitches into an embroidery tambour. But a joke, in Lancaster's work, is never simply a joke:
there is nearly always some deeper satiric impulse boiling away beneath it, above all an awareness of the social 
and
historical contexts in which some of the best jokes get made. The Littlehampton Bequest , an elaborate spoof 
exhibition staged at the National Portrait Gallery
under Roy Strong+Aos direction in 1973, is a series of artistic parodies, in which the history of the Littlehampton 
family and its ramifi cations are encapsulated by paintings in the style of well-known artists of the day.
Thus Lancaster has Zoff any taking off "Joseph Grumble Esq", the father- in-law of the third earl, an East India
nabob pictured glaring from his gout stool against a background of minarets; and Marcellus Laroon depicting "Va-
nessa, Countess of Littlehampton and her daughters", the caption helpfully explaining that "the wife of the first
earl was heiress to half the plantations of the West Indies. She is portrayed with her two daughters and her page
Page 5 of 5
Saturday Review: Arts: An Original Line: Osbert Lancaster one of the Brideshead generation is best known for 
his newspaper cartoons, but his beat extended far b....
Hasdrubal, who in her widowhood was 'always about her person'." Hasdrubal, seen simpering over the coffee pot, 
is
clearly the father of the second daughter. The fi nal portrait, "Basil Cantilever Esq and Lady Patricia Cantilever", 
daughter and son-in-law of the present
earl, mimics early Hockney. Significantly, Basil is an MP-cum-property developer, busy despoiling City churches
to put up office blocks.
Lancaster was knighted in 1975 +Ai the photograph taken outside Buckingham Palace makes him seem the dernier 
cri in Old Bufferdom +Ai then, in 1978, his career was in effect ended by the fi rst in a series of strokes. He endured 
a miserable eight- year decline, nobly attended by his sec-
ond wife, Anne. Powell, visiting them in their Chelsea fl at in 1982 ("Osbert in poor shape"), noted her eagerness
to take him to his next appointment: "She insisted on driving me to the Travellers, no doubt just to get half an
hour out of the house, which must be claustrophobic to a degree." It would be overstating the case to say that Lan-
caster+Aos work is forgotten. On the other hand, the forms in which he achieved his fame +Ai daily cartoons, set 
designs +Ai
have a built-in obsolescence, while the sheer scope of his work tends to frustrate an attempt to view his 
achievements as a whole. Between them, however, the centenary exhibition and Knox+Aos book-length celebration 
contain enough evidence to establish him as one of the great English comic artists of the 20th century.
Cartoons and Coronets: The Genius of Osbert
Lancaster is at the Wallace Collection, London W1
(020 7563 9500), until January 11 2009.
To order the book for 3/4£14 with free UK p&p go to
guardian.co.uk/bookshop or call 0870 836 0875.
Load-Date: October 11, 2008
End of Document
Page 1 of 3
The AI Studio Ghibli trend is an insult to art and artists
The AI Studio Ghibli trend is an insult to art and artists
Asia News Network
01.04.2025 09:54 GMT
Copyright 2025 Asia News Network All Rights Reserved
Length: 1064 words
Byline: Reporting by:Dawn
Body
                      ISLAMABAD(Dawn/ANN)- An artist spends years perfecting their skills. Hours spent drawing, 
scrapping and redrawing to bring to life a vision that goes on to inspire millions. Studio Ghibli's co-founder Hayao 
Miyazaki is one such artist.
Miyazaki's films have not only received many awards but his retinue of works including Spirited Away, Kiki's 
Delivery Service, Howl's Moving Castle and so on have instilled the power of imagination and dreams in countless 
children and adults. Artistic inspiration can be a powerful thing, Miyazaki's art inspired the creation of Pakistan's first 
hand-drawn animated film, The Glassworker. With their own unique spin, a love letter to the aesthetic, The 
Glassworker took Usman Riaz and his team a decade to make.
In recent years however, artificial intelligence (AI) with its image generative tool has posed a threat to art and 
artists. AI learns from millions of images across the internet and memorises text associated with those images. In a 
process known as "diffusion", AI starts by breaking images into pixels that do not represent any specific thing and 
then inverts the process so the model can revert to the original image. Artificial intelligence does not take into 
account copyright and hence artistic styles are used without permission.
With image generative tools such as Midjourney, DALL-E and even a feature on Canva made widely available to 
anyone with an internet connection and monthly subscription, users can write a prompt and generate an image in a 
certain artist's style, without, of course, asking or crediting said artist. The most recent victims of this are the artists 
at Studio Ghibli.

Page 2 of 3
The AI Studio Ghibli trend is an insult to art and artists
OpenAI announced the launch of its "most advanced image generator" which has been built into GPT-4o and has 
been made available to users for free. This has enabled a worrying trend where users are converting their 
photographs into 'Studio Ghibli style art'. AI's rendering of Studio Ghibli is nothing more than sanitised, soulless and 
generic, a typical cutesy image devoid of any character, effort or passion.
Studio Ghibli's art is more than just cute characters, it is grotesque and sometimes even harrowing, it is layers of 
hard work, passion and unwavering dedication to create unique characters that tell meaningful stories.
From Grave of the Fireflies which shows a war torn Japan and two siblings desperate to survive on their own to 
themes of greed and identity as Chihiro navigates the world of spirits trying to save her parents (who were 
transformed into pigs) from being eaten in Spirited Away, all of Studio Ghibli's work means something. Even light-
hearted Ghibli features such as Kiki's Delivery Service focus on themes of self acceptance.
Every frame of a 2D animated film is painstakingly drawn by hand. The beautiful watercolour-esque nature scenes 
from Ghibli's films, the varied emotions on faces of characters, the tireless research that goes into making every 
fantastical aspect a little more believable; this is what makes the films timeless.
Criticising the AI Studio Ghibli trend, Riaz wrote in a post on X, "In an age of AI-generated everything, "The 
Glassworker" was drawn by hand. No shortcuts. No algorithms. Just work, talent and perseverance [...] AI is the 
future -but it's a tool not the artist."
Some might call AI a terrific mimic but that's all that it is. As exposed by this trend, the generated images lack depth 
and feeling. Perhaps the most egregious thing to come out of this trend is the politicisation of Ghibili's art. Political 
ideologies, thoughts and even extremist narratives are being portrayed in this aesthetic.
Users have used AI to recreate scenes of the destruction of the Babri Masjid, a Mughal-era mosque in India's 
Ayodhya. Using an art style synonymous with innocence to glorify the demolition of a mosque is beyond repugnant. 
Not to mention that Miyazaki has taken a strong stance against oppression and fascism in the past.
The White House used the trend in a post on X to depict an arrest and deportation of an immigrant by the US 
Immigration and Customs Enforcement (ICE). This comes after ICE has been deporting and arresting even those 
who hold a green card and revoking the legal status of thousands of immigrants. To use an artistic style, even if its 
watered down by AI to make light of suffering or depict Trump's hardline policies is abhorrent.
It is worth noting that in 2003, Hayao Miyazaki boycotted the Oscars ceremony as he opposed the US war in Iraq.
"The reason I wasn't here for the Academy Award was because I didn't want to visit a country that was bombing 
Iraq," he had told The Los Angeles Times of his decision.
PPP Chairman Bilawal Bhutto-Zardari also jumped onto this trend, changing his profile picture and generating 
photographs of his late mother and former prime minister Benazir Bhutto.
A countertrend has also sprung on X, with artists showcasing their work inspired by Studio Ghibli films, condemning 
the theft of art while simultaneously encouraging people to pick up a pencil and learn to draw themselves instead of 
relying on what has been termed as 'AI slop'. Artists have showcased their work with captions such as "Art I made 
from Studio Ghibli in my style without needing AI." Others have spoken about the time and dedication it has taken 
to perfect their craft.
With the popularity of the AI slop Ghibli trend on the internet, an old documentary has resurfaced in which Miyazaki 
expresses his strong dislike for AI 'art'. In the documentary the filmmaker is shown a zombie, with developers 
saying that AI can allow more grotesque movements. The artist's response was, "Whoever creates this stuff has no 
idea what pain is whatsoever. I am utterly disgusted... I strongly feel that this is an insult to life itself."
Imagine spending hours, days, months and years to find your artistic expression, and then suddenly a single 
prompt, that intellectual property and hard work is stolen, attached to narratives that you may or may not agree with, 
no consent and definitely no credit; this is what AI "art" means to many artists and why so many speak against it.
Page 3 of 3
The AI Studio Ghibli trend is an insult to art and artists
Appreciating art is a beautiful thing if done in a healthy manner by supporting artists or spending time trying to hone 
skills taking talented professionals as inspiration. Taking shortcuts, depriving artists from jobs and credit by using AI 
only serves to disrespect the medium.
Load-Date: April 7, 2025
End of Document
